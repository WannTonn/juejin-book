{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction "},"JavaScript设计模式核⼼原理与应⽤实践/01.开篇：前端工程师的成长论.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/01.开篇：前端工程师的成长论.html","title":"01.开篇：前端工程师的成长论","keywords":"","body":"即使是在瞬息万变的前端领域，也存在一些具备“一次学习，终生受用”特性的知识，比如前端性能优化的核心思路，再比如我们这次要展开来讲的JavaScript设计模式。 在软件工程中，设计模式（design pattern）是对软件设计中普遍存在（反复出现）的各种问题，所提出的解决方案。 ——维基百科 烹饪有菜谱，游戏有攻略，每个领域都存在一些能够让我们又好又快地达成目标的“套路”。在程序世界，编程的“套路”就是设计模式。 授人以鱼，不如授人以渔。在尝试学习一门知识之前，最重要的事情是搞清楚这块知识本身的意义（为什么要学？）、作用（学了它能干嘛？）和特性（怎么学比较好？），从而建立起自己的全局观 —— 这个过程和知识本身同样重要，也正是这一节我们要着重解决的两个问题。 此外，作为小册作者，更是作为大家的同行，我也想借这个机会，在这个有点冷的春天里，跟大家聊一些更实在的东西——聊聊我们前端工程师怎么变秃变强的话题，这部分内容位于本节的“前言”部分，如需跳读，大家直接往下拉到第二小节即可。 前言 下定决心写这本小册，是在2018年的年末。 相信 18 年下半年到现在（19年初）这段时间，大家都对这样一个事情深有体会： 贩卖焦虑的人越来越多了。 许多技术公众号频繁以带有“危机”、“寒冬”这样的标题 po 文，技术社区也开始反复出现类似于“前脚对需求后脚被解约”这样不太好的消息。伴随这些声音而来的，是同行们数不清的自我怀疑：互联网的风口要没了，要不要先走为敬；写前端/写后端/写客户端/写算法没前途了，要不要趁早转行；程序员市场是不是已经饱和了，我还能不能分到一杯羹······等等等等。 一夜之间，有更多的人开始犹豫向前走还是向后退的问题。 职业选择也好、人生规划也罢，这些东西都因人而异，每个人的想法都值得我们去尊重。咱们今天不聊焦虑，也不灌鸡汤，我就想简单地和大家说说我所看到的。 可能和很多同学想的不一样，我所体验到的现实是：前端团队真的很缺人；前端，真的太难招了。 单说 18 年这一年，我所了解到的前团队、现团队和兄弟团队都在招人 —— 用人这个需求就没断过。所以说缺人，是真缺。说招不到，也是真招不到 —— 很多情况下，受试者的编码能力、设计思维和计算机基础都不那么经得起推敲，纵使有再多的 HC 也白搭。行业没有以前那么“景气”了，这不假，但情况远没有糟糕到人人自危的程度。 当下的这波寒潮，带来的主要问题是曾经站在风口上就能飞起来的猪，现在飞不起来了。但没关系，努力修炼修炼，做鹰就不怕了。 从目前我所了解到的、肉眼可见的巨大的前端工程师的数量缺口来看，前端领域距离人才饱和还有很长很长一段路要走。所以说操心行业的未来意义不大，大家更应该去思考如何去练下扎实的基本功、过硬的业务素质和灵活的适配能力，这样便能不畏变化（小册第二节我们会提到，设计模式的根本目的是为了使我们的代码具备更强的应对变化的能力。 面对变幻莫测的需求，代码尚且有23式，更何况我们写代码的人呢？）。 话说回来，有缺口却招不到人，这是个非常麻烦的事情。这一点，除了需求方和受试者双方的问题，和前端这个行业的特性也有着密不可分的关系。 我知道很多同学入行差不多是这样的顺序：JavaScript 基础-> jQuery（现在很多人可能没写过 jQuery 了）->热门框架->仿站->找工作。首先要说这个过程，它没有错 —— 前端这门课，大学不开，也不存在什么规范的系统化教程能够作为金科玉律，大家都是野路子出身，野路子入行不这么搞还能怎么搞？能够把这样一个过程完完整整走下来的同学，足以证明其对编程的兴趣和够格的执行力！所以说这么搞没错，错的是把这些东西当作了一个合格前端需要/应该掌握的全部。 变与不变 前端这个职业确实不轻松，尤其是移动互联网大热的这几年，技术革命就没消停过。单说框架/库吧，我相信屏幕前一定有跟我一样从原生 JavaScript 开始写，然后写 jQuery，写 zepto，写 Angular，写写写，一直写到现在的 Vue/React 等等。就算是刚刚入行、没有经历过技术变革摧残的的新同学，也能被当下纷繁复杂的前端生态给迷了眼。很多同学刚刚掌握了一门技术，以为settle down了、可以沉淀一下了，结果又冒出一个新玩意儿，没办法，继续追！所以说我没见过哪个前端写代码、学东西是不卖力的 —— 不卖力早掉队了。 但大家现在需要冷静下来思考这么一个问题：我很拼，别人也很拼，所有人都在拼的时候，我特别的地方、或者准确地说——我的核心竞争力在哪里？ 能够决定一个前端工程师的本质的，不是那些瞬息万变的技术点，而是那些不变的东西。 什么是不变的东西？ 我给大家举个例子。两年前某厂有个团队发了一则招聘广告，说重金求 Node 玩家，愿意给很高的 P 级，薪资什么的不用说自然非常丰厚。完了没过几天，这则招聘信息的截图竟然出现在了一个培训机构的招生广告里，附的文案是“ BAT 砸 xx 万招 Node 工程师，而你却还在学 PHP？！”。这事儿作为一个段子流传了很久，因为它足够滑稽——大家想想，Node的语法难不难？不难，准确地说，足够友好了！我相信每个团队都不缺会用 Node 或者说用任何一门语言去写 Hello World 的同学 —— 缺的是能够驾驭这门语言、能凭借自己深刻的架构思想和工程思想去支配这门语言、利用它去创造牛逼产出的人。 所谓“不变的东西”，说的就是这种驾驭技术的能力。 具体来说，它分为以下三个层次： 能用健壮的代码去解决具体的问题； 能用抽象的思维去应对复杂的系统； 能用工程化的思想去规划更大规模的业务。 这三种能力在你的成长过程中是层层递进的关系，而后两种能力可以说是对架构师的要求。事实上，在我入行以来接触过的工程师里，能做到第一点，并且把它做到扎实、做到娴熟的人，已经堪称同辈楷模。 前端工程师，首先是软件工程师 基础理论知识是一个人的基线，理论越强基线越高。再为自己定一个目标和向上攀附的阶梯，那么达到目标就是时间问题，而很多野路子工程师搞了半辈子也未达到优秀工程师的基线，很多他们绞尽脑汁得出的高深学问，不过是正规工程师看起来很自然的东西。—— 吴军 过去，人们对软件工程的理解比较狭隘，认为前端就是页面，和软件是两回事儿。随着前端应用复杂度的日新月异，如今的前端应用也妥妥地成为了软件思想的一种载体，而前端工程师，也被要求在掌握多重专业技能之余，具备最基本的软件理论知识。 技术人之间的口水战，每次但凡想上升一点高度，便要拿”架构“这样高大上的话题出来晃晃眼。但事实上，很多人缺乏的并不是这种高瞻远瞩的激情，而是我们前面提到的“不变能力”中最基本的那一点——用健壮的代码去解决具体的问题的能力。这个能力在软件工程领域所对标的经典知识体系，恰恰就是设计模式。 所以说，想做靠谱开发，先掌握设计模式。 设计模式的学习之道 我们整本小册的知识体系与格局，用思维导图展示如下： “橘生淮南则为橘,橘生淮北则为枳”——一些在服务端应用场景下看似合理、好用又酷炫的操作，生搬硬套到前端的场景里可能就会弄巧成拙。本册的目的并不是做传统设计模式书籍的“译本”，而是面向前端工程师，讲有利于前端的技术。因此在正式的实战章节里，我们权衡每种模式对前端的价值、对 23 种设计模式做了取舍，保留下来的这些设计模式，具备这两个共性： 前端能用，而且好用； 面试会考，而且常考。 通过学习这部分设计模式，我们至少可以达到三个目的： 充分理解前端设计模式的核心思想和基本理念，在具体的场景中掌握抽象的设计原则 会写代码，会写好代码； 会面试，能言之有物。 其实不难 设计模式的“难”，在于其令人望而生畏的抽象性和知识点的分散性。这带来了本册要着重解决的问题——帮助大家摆脱枯燥乏味的技术恐惧感。 抽象性几乎是所有理论性知识共有的特性，它带来最直观的问题就是可能一段话你每个字都认识，但连在一起不知道它在说啥：）。于是产生了“这块知识看起来好牛逼，我一定学不会吧”这样的错觉。 其实设计模式并不高大上，它是一个非常接地气、非常实际的东西——因为它本身就是一帮非常苦逼的程序员在自己的职业生涯里实打实地踩坑踩出来的。解决知识抽象性带来的理解障碍，重要的不是反复的陈述、解释，而是把自己放到一个正确的场景里，去体会这个模式的好。在学习具体设计模式的过程中，我们每个章节都以原理->实践->总结这样的流程来走，也希望大家不要随意跳读，确保自己不仅是跟着看了，更是跟着做了。设计模式说起来是理论知识，但它毕竟是人们在实践过程中总结、提炼出来的，掌握它的意义，正是为了把它还原到我们日常的实践中去。 分散性则是因为设计模式本身就是一套解决不同问题的方案的集合，这些方案之间乍一看好像没有什么关联，故而很容易使学习者陷入边学边忘的窘境。 但所谓“分散性”其实也是纸老虎——深入了解设计模式后，大家会发现模式与模式间存在着不可忽略的共性与关联——在下一小节《设计模式的道与术》中，我们将会学习设计模式中几个重要的设计原则和核心的设计思想；接下来学习具体的设计模式时，小册会在具体的应用场景里把这些设计原则掰碎嚼烂了还原给大家。在这个过程中大家会发现，不同的设计模式并非是一座座的孤岛，他们之间彼此呼应、相互成就，共同构建起了一套完整而经典的软件思想体系。 此外，设计模式中有几个特别重要、特别好使、特别受面试官关注的的，我们在讲解的过程中会有针对性地穿插一些高频面试真题（注意面试题不一定会单开小节，有的面试题就穿插于原理讲解之中~）。具体是哪几个，可能要等大家读到了那一节才知道了哈哈（所以不要随便跳读：））。 设计模式中最核心的理念和思想有哪些，如何将设计模式从传统的 C++、Java 语言迁移到 JavaScript、从服务端业务场景迁移到现代化的前端应用场景，如何把握本书的重点难点 —— 在进入实战环节之前，我们首先需要走进《设计模式的道与术》中，对以上问题一窥究竟。 "},"JavaScript设计模式核⼼原理与应⽤实践/02.设计模式的“道”与“术”.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/02.设计模式的“道”与“术”.html","title":"02.设计模式的“道”与“术”","keywords":"","body":"本节为统领全书的纲要性章节，是后续多个章节的伏笔，因此不建议大家跳读。另一方面，也不建议大家死磕 —— 有的东西你这会儿没看懂也没关系，正常。接着往下看实战就完了，跟着做跟着跑，不知不觉你就会有“啊原来前面那个xx说的是这个xx啊”的奇妙感觉。 设计模式之道 设计模式，究竟有着怎样的力量？ 每一个模式描述了一个在我们周围不断重复发生的问题，以及该问题的解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复劳动。 —— Christopher Alexander 设计模式是“拿来主义”在软件领域的贯彻实践。和很多人的主观臆断相反，设计模式不是一堆空空如也、晦涩鸡肋的理论，它是一套现成的工具 —— 就好像你想要做饭的时候，会拿起厨具直接烹饪，而不会自己去铸一口锅、磨一把菜刀一样。 用做数学题来打比方，可能大家会更能体会这种概念 —— 我们解题目的时候，往往会用到很多公式/现成的解题方法。比如已知直角三角形两边长，求另一边，我们会直接用勾股定理（我想应该没有人会每求一次边长都自己推一遍勾股定理才用吧）。 识别题目特征 —— catch题目想要考查的知识点 —— 快速在脑海中映射出它对应的解决方法，这个过程在我们学生时代几乎是一个本能的、条件反射一样的脑回路机制。在学习设计模式时，如果各位可以回忆起这种“从映射到默写”的思维方式，相信这个学习过程会是轻松的、自然的。 SOLID设计原则 \"SOLID\" 是由罗伯特·C·马丁在 21 世纪早期引入的记忆术首字母缩略字，指代了面向对象编程和面向对象设计的五个基本原则。 设计原则是设计模式的指导理论，它可以帮助我们规避不良的软件设计。SOLID 指代的五个基本原则分别是： 单一功能原则（Single Responsibility Principle） 开放封闭原则（Opened Closed Principle） 里式替换原则（Liskov Substitution Principle） 接口隔离原则（Interface Segregation Principle） 依赖反转原则（Dependency Inversion Principle） 糟糕，又出现了看似高大上的东西，而且是五个！ 别怕，这五个原则，都不难，而且并不是每一个都要求大家掌握，因为在 JavaScript 设计模式中，主要用到的设计模式基本都围绕“单一功能”和“开放封闭”这两个原则来展开。 在本节，我们不会对设计原则作任何进一步的介绍——在没有实际操作的情况下，干讲理论没有任何意义，反而会挫伤初学者的积极性。具体的原则、理论，我们都会放在后续的实战小节里结合实例一起讲解。 设计模式的核心思想——封装变化 设计模式出现的背景，是软件设计的复杂度日益飙升。软件设计越来越复杂的“罪魁祸首”，就是变化。 这一点相信大家不难理解——如果说我们写一个业务，这个业务是一潭死水，初始版本是 1.0，100 年后还是 1.0，不接受任何迭代和优化，那么这个业务几乎可以随便写。反正只要实现功能就行了，完全不需要考虑可维护性、可扩展性。 但在实际开发中，不发生变化的代码可以说是不存在的。我们能做的只有将这个变化造成的影响最小化 —— 将变与不变分离，确保变化的部分灵活、不变的部分稳定。 这个过程，就叫“封装变化”；这样的代码，就是我们所谓的“健壮”的代码，它可以经得起变化的考验。而设计模式出现的意义，就是帮我们写出这样的代码。 设计模式的“术” 所谓“术”，其实就是指二十年前 GOF 提出的最经典的23种设计模式。二十年前，四位程序员前辈（Erich Gamma, Richard Helm, Ralph Johnson & John Vlissides）通过编写《设计模式：可复用面向对象软件的基础》这本书，阐述了设计模式领域的开创性成果。在这本书中，将23种设计模式按照“创建型”、“行为型”和“结构型”进行划分： 前面我们说过，设计模式的核心思想，就是“封装变化”。确实如此，无论是创建型、结构型还是行为型，这些具体的设计模式都是在用自己的方式去封装不同类型的变化 —— 创建型模式封装了创建对象过程中的变化，比如下节的工厂模式，它做的事情就是将创建对象的过程抽离；结构型模式封装的是对象之间组合方式的变化，目的在于灵活地表达对象间的配合与依赖关系；而行为型模式则将是对象千变万化的行为进行抽离，确保我们能够更安全、更方便地对行为进行更改。 封装变化，封装的正是软件中那些不稳定的要素，它是一种防患于未然的行为 —— 提前抽离了变化，就为后续的拓展提供了无限的可能性，如此，我们才能做到在变化到来的时候从容不迫。 从 Java/C++ 到 JavaScript 的迁移 设计模式迁移到 JavaScript，不仅仅是从一类语言到另一类语言这么简单。强类型语言不仅和 JavaScript 之间存在着基本语法的差异，还存在着应用场景的差异。设计模式的“前端化”，正是我们后续十余个章节要做的事情。在这个过程中，场景是基础，代码是辅助，逻辑是主角。 OK，说了这么多，想必大家现在心里都对设计模式有了一套自己的全局观。下面我们就正式进入实战的环节，将目标设计模式各个击破~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/03.创建型：工厂模式·简单工厂——区分“变与不变”.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/03.创建型：工厂模式·简单工厂——区分“变与不变”.html","title":"03.创建型：工厂模式·简单工厂——区分“变与不变”","keywords":"","body":"前面我们说过，设计模式的核心操作是去观察你整个逻辑里面的变与不变，然后将变与不变分离，达到使变化的部分灵活、不变的地方稳定的目的。我们本节就来验证一下这个思想。 先来说说构造器 在介绍工厂模式之前，为了辅助大家的理解，我想先在这儿给大家介绍一下构造器模式。 别看这个名字很吓人（其实设计模式里每个名字好像都挺吓人的哈哈哈），这玩意儿你几乎天天用（所以咱们不单独给它开小节），不信你来看看： 有一天你写了个公司员工信息录入系统，这个系统开发阶段用户只有你自己，想怎么玩怎么玩。于是在创建“自己”这个唯一的用户的时候，你可以这么写： const liLei = { name: '李雷', age: 25, career: 'coder', } 有一天你的同桌韩梅梅突然说：“李雷，让我瞅瞅你的系统做得咋样了，我也想被录进去”。你说好，不就多一个人的事情吗，于是代码里手动多了一个韩梅梅： const liLei = { name: '李雷', age: 25, career: 'coder', } const hanMeiMei = { name: '韩梅梅', age: 24, career: 'product manager' } 又过了两天你老板过来了，说李雷，系统今天提测了，先把部门的 500 人录入看看功能。李雷心想，500 个对象字面量，要死要死，还好我有构造函数。于是李雷写出了一个可以自动创建用户的 User 函数： function User(name , age, career) { this.name = name this.age = age this.career = career } 楼上个这 User，就是一个构造器。此处我们采用了 ES5 构造函数的写法，因为 ES6 中的 class 其实本质上还是函数，class 语法只是语法糖，构造函数，才是它的真面目。 接下来要做的事情，就是让程序自动地去读取数据库里面一行行的员工信息，然后把拿到的姓名、年龄等字段塞进User函数里，进行一个简单的调用： const user = new User(name, age, career) 从此李雷再也不用手写字面量。 像 User 这样当新建对象的内存被分配后，用来初始化该对象的特殊函数，就叫做构造器。在 JavaScript 中，我们使用构造函数去初始化对象，就是应用了构造器模式。这个模式太简单了，简单到我这一通讲对很多同学来说其实并不必要，大家都是学过 JavaScript 基础的人，都知道怎么 new 一个对象。但是我们洋洋洒洒这么一段的目的，并不是为了带大家复习构造函数本身的用法，而是希望大家去思考开篇我们提到的问题： 在创建一个user过程中，谁变了，谁不变？ 很明显，变的是每个user的姓名、年龄、工种这些值，这是用户的个性，不变的是每个员工都具备姓名、年龄、工种这些属性，这是用户的共性。 那么构造器做了什么？ 构造器是不是将 name、age、career 赋值给对象的过程封装，确保了每个对象都具备这些属性，确保了共性的不变，同时将 name、age、career 各自的取值操作开放，确保了个性的灵活？ 如果在使用构造器模式的时候，我们本质上是去抽象了每个对象实例的变与不变。那么使用工厂模式时，我们要做的就是去抽象不同构造函数（类）之间的变与不变。 简单工厂模式 咱们先不说简单工厂模式定义是啥，咱们先来看李雷的新需求： 老板说这个系统录入的信息也太简单了，程序员和产品经理之间的区别一个简单的career字段怎么能说得清？我要求这个系统具备给不同工种分配职责说明的功能。也就是说，要给每个工种的用户加上一个个性化的字段，来描述他们的工作内容。 完了，这下员工的共性被拆离了。还好有构造器，李雷心想不就是多写个构造器的事儿吗，我写： function Coder(name , age) { this.name = name this.age = age this.career = 'coder' this.work = ['写代码','写系分', '修Bug'] } function ProductManager(name, age) { this.name = name this.age = age this.career = 'product manager' this.work = ['订会议室', '写PRD', '催更'] } 现在我们有两个类（后面可能还会有更多的类），麻烦的事情来了：难道我每从数据库拿到一条数据，都要人工判断一下这个员工的工种，然后手动给它分配构造器吗？不行，这也是一个“变”，我们把这个“变”交给一个函数去处理： function Factory(name, age, career) { switch(career) { case 'coder': return new Coder(name, age) break case 'product manager': return new ProductManager(name, age) break ... } 看起来是好一些了，至少我们不用操心构造函数的分配问题了。但是大家注意我在 switch 的末尾写了个省略号，这个省略号比较恐怖。看着这个省略号，李雷哭了，他想到：整个公司上下有数十个工种，难道我要手写数十个类、数十行 switch 吗？ 当然不！回到我们最初的问题：大家仔细想想，在楼上这两段并不那么好的代码里，变的是什么？不变的又是什么？ Coder 和 ProductManager 两个工种的员工，是不是仍然存在都拥有 name、age、career、work 这四个属性这样的共性？它们之间的区别，在于每个字段取值的不同，以及 work 字段需要随 career 字段取值的不同而改变。这样一来，我们是不是对共性封装得不够彻底？那么相应地，共性与个性是不是分离得也不够彻底？现在我们把相同的逻辑封装回User类里，然后把这个承载了共性的 User 类和个性化的逻辑判断写入同一个函数： function User(name , age, career, work) { this.name = name this.age = age this.career = career this.work = work } function Factory(name, age, career) { let work switch(career) { case 'coder': work = ['写代码','写系分', '修Bug'] break case 'product manager': work = ['订会议室', '写PRD', '催更'] break case 'boss': work = ['喝茶', '看报', '见客户'] case 'xxx': // 其它工种的职责分配 ... return new User(name, age, career, work) } 这样一来，我们要做事情是不是简单太多了？不用自己时刻想着我拿到的这组数据是什么工种、我应该怎么给它分配构造函数，更不用手写无数个构造函数——Factory已经帮我们做完了一切，而我们只需要像以前一样无脑传参就可以了！ 现在我们一起来总结一下什么是工厂模式：工厂模式其实就是将创建对象的过程单独封装。它很像我们去餐馆点菜：比如说点一份西红柿炒蛋，我们不用关心西红柿怎么切、怎么打鸡蛋这些菜品制作过程中的问题，我们只关心摆上桌那道菜。在工厂模式里，我传参这个过程就是点菜，工厂函数里面运转的逻辑就相当于炒菜的厨师和上桌的服务员做掉的那部分工作——这部分工作我们同样不用关心，我们只要能拿到工厂交付给我们的实例结果就行了。 总结一下：工厂模式的目的，就是为了实现无脑传参，就是为了爽！ 小结 工厂模式的简单之处，在于它的概念相对好理解：将创建对象的过程单独封装，这样的操作就是工厂模式。同时它的应用场景也非常容易识别：有构造函数的地方，我们就应该想到简单工厂；在写了大量构造函数、调用了大量的 new、自觉非常不爽的情况下，我们就应该思考是不是可以掏出工厂模式重构我们的代码了。 但工厂模式可不止这一种表达形式。本节我们可以看到，构造器解决的是多个对象实例的问题，简单工厂解决的是多个类的问题。那么当复杂度从多个类共存上升到多个工厂共存时又该怎么处理呢？在下个小节，我们一起来看看这个问题。 "},"JavaScript设计模式核⼼原理与应⽤实践/04.创建型：工厂模式·抽象工厂——理解“开放封闭”.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/04.创建型：工厂模式·抽象工厂——理解“开放封闭”.html","title":"04.创建型：工厂模式·抽象工厂——理解“开放封闭”","keywords":"","body":"抽象工厂这块知识，对入行以来一直写纯 JavaScript 的同学可能不太友好——因为抽象工厂在很长一段时间里，都被认为是 Java/C++ 这类语言的专利。 Java/C++ 的特性是什么？它们是强类型的静态语言。用这些语言创建对象时，我们需要时刻关注类型之间的解耦，以便该对象日后可以表现出多态性。但 JavaScript，作为一种弱类型的语言，它具有天然的多态性，好像压根不需要考虑类型耦合问题。而目前的 JavaScript 语法里，也确实不支持抽象类的直接实现，我们只能凭借模拟去还原抽象类。因此有一种言论认为，对于前端来说，抽象工厂就是鸡肋。 抽象工厂模式的学习价值、以及为何被布局在小册 No.2 这个位置背后的思量，我会在文末给大家一五一十地捋清楚。但现在，各位先答应我，不要跳读，不要看见“抽象”俩字儿就跑 —— 鸡肋不鸡肋，学明白了才有发言权。 一个不简单的简单工厂引发的命案 在实际的业务中，我们往往面对的复杂度并非数个类、一个工厂可以解决，而是需要动用多个工厂。 我们继续看上个小节举出的例子，简单工厂函数最后长这样： function Factory(name, age, career) { let work switch(career) { case 'coder': work = ['写代码','写系分', '修Bug'] break case 'product manager': work = ['订会议室', '写PRD', '催更'] break case 'boss': work = ['喝茶', '看报', '见客户'] case 'xxx': // 其它工种的职责分配 ... return new User(name, age, career, work) } 乍一看没什么问题，但是经不起推敲呀。首先映入眼帘的 Bug，是我们把 Boss 这个角色和普通员工塞进了一个工厂。大家知道，Boss 和基层员工在职能上差别还是挺大的，具体在员工系统里怎么表现呢？首先他的权限就跟咱们不一样。有一些系统，比如员工绩效评估的打分入口，就只有 Boss 点得进去，对不对？除此之外还有许多操作，是只有管理层可以执行的，因此我们需要对这个群体的对象进行单独的逻辑处理。 怎么办？去修改 Factory 的函数体、增加管理层相关的判断和处理逻辑吗？单从功能实现上来说，没问题。但这么做其实是在挖坑——因为公司不仅仅只有这两类人，除此之外还有外包同学、还有保安，他们的权限、职能都存在着质的差别。如果延续这个思路，每考虑到一个新的员工群体，就回去修改一次 Factory 的函数体，这样做糟糕透了——首先，是Factory会变得异常庞大，庞大到你每次添加的时候都不敢下手，生怕自己万一写出一个Bug，就会导致整个Factory的崩坏，进而摧毁整个系统；其次，你坑死了你的队友：Factory 的逻辑过于繁杂和混乱，没人敢维护它；最后，你还连带坑了隔壁的测试同学：你每次新加一个工种，他都不得不对整个Factory 的逻辑进行回归——谁让你的改变是在 Factory 内部原地发生的呢！这一切悲剧的根源只有一个——没有遵守开放封闭原则。 我们再复习一下开放封闭原则的内容：对拓展开放，对修改封闭。说得更准确点，软件实体（类、模块、函数）可以扩展，但是不可修改。楼上这波操作错就错在我们不是在拓展，而是在疯狂地修改。 抽象工厂模式 上面这段可能仍有部分同学觉得抽象，也没关系。这里咱们先不急着理解透彻这个干巴巴的概念，先来看这么一个示例： 大家知道一部智能手机的基本组成是操作系统（Operating System，我们下面缩写作 OS）和硬件（HardWare）组成。所以说如果我要开一个山寨手机工厂，那我这个工厂里必须是既准备好了操作系统，也准备好了硬件，才能实现手机的量产。考虑到操作系统和硬件这两样东西背后也存在不同的厂商，而我现在并不知道我下一个生产线到底具体想生产一台什么样的手机，我只知道手机必须有这两部分组成，所以我先来一个抽象类来约定住这台手机的基本组成： class MobilePhoneFactory { // 提供操作系统的接口 createOS(){ throw new Error(\"抽象工厂方法不允许直接调用，你需要将我重写！\"); } // 提供硬件的接口 createHardWare(){ throw new Error(\"抽象工厂方法不允许直接调用，你需要将我重写！\"); } } 楼上这个类，除了约定手机流水线的通用能力之外，啥也不干。如果你尝试让它干点啥，比如 new 一个 MobilePhoneFactory 实例，并尝试调用它的实例方法。它还会给你报错，提醒你“我不是让你拿去new一个实例的，我就是个定规矩的”。在抽象工厂模式里，楼上这个类就是我们食物链顶端最大的 Boss——AbstractFactory（抽象工厂）。 抽象工厂不干活，具体工厂（ConcreteFactory）来干活！当我们明确了生产方案，明确某一条手机生产流水线具体要生产什么样的手机了之后，就可以化抽象为具体，比如我现在想要一个专门生产 Android 系统 + 高通硬件的手机的生产线，我给这类手机型号起名叫 FakeStar，那我就可以为 FakeStar 定制一个具体工厂： // 具体工厂继承自抽象工厂 class FakeStarFactory extends MobilePhoneFactory { createOS() { // 提供安卓系统实例 return new AndroidOS() } createHardWare() { // 提供高通硬件实例 return new QualcommHardWare() } } 这里我们在提供安卓系统的时候，调用了两个构造函数：AndroidOS 和 QualcommHardWare，它们分别用于生成具体的操作系统和硬件实例。像这种被我们拿来用于 new 出具体对象的类，叫做具体产品类（ConcreteProduct）。具体产品类往往不会孤立存在，不同的具体产品类往往有着共同的功能，比如安卓系统类和苹果系统类，它们都是操作系统，都有着可以操控手机硬件系统这样一个最基本的功能。因此我们可以用一个抽象产品（AbstractProduct）类来声明这一类产品应该具有的基本功能（众：什么抽象产品？？？要这些玩意儿干啥？老夫写代码就是一把梭，为啥不让我老老实实一个一个写具体类？？？大家稍安勿躁，先把例子看完，下文会有解释） // 定义操作系统这类产品的抽象产品类 class OS { controlHardWare() { throw new Error('抽象产品方法不允许直接调用，你需要将我重写！'); } } // 定义具体操作系统的具体产品类 class AndroidOS extends OS { controlHardWare() { console.log('我会用安卓的方式去操作硬件') } } class AppleOS extends OS { controlHardWare() { console.log('我会用🍎的方式去操作硬件') } } ... 硬件类产品同理： // 定义手机硬件这类产品的抽象产品类 class HardWare { // 手机硬件的共性方法，这里提取了“根据命令运转”这个共性 operateByOrder() { throw new Error('抽象产品方法不允许直接调用，你需要将我重写！'); } } // 定义具体硬件的具体产品类 class QualcommHardWare extends HardWare { operateByOrder() { console.log('我会用高通的方式去运转') } } class MiWare extends HardWare { operateByOrder() { console.log('我会用小米的方式去运转') } } ... 好了，如此一来，当我们需要生产一台FakeStar手机时，我们只需要这样做： // 这是我的手机 const myPhone = new FakeStarFactory() // 让它拥有操作系统 const myOS = myPhone.createOS() // 让它拥有硬件 const myHardWare = myPhone.createHardWare() // 启动操作系统(输出‘我会用安卓的方式去操作硬件’) myOS.controlHardWare() // 唤醒硬件(输出‘我会用高通的方式去运转’) myHardWare.operateByOrder() 关键的时刻来了——假如有一天，FakeStar过气了，我们需要产出一款新机投入市场，这时候怎么办？我们是不是不需要对抽象工厂MobilePhoneFactory做任何修改，只需要拓展它的种类： class newStarFactory extends MobilePhoneFactory { createOS() { // 操作系统实现代码 } createHardWare() { // 硬件实现代码 } } 这么个操作，对原有的系统不会造成任何潜在影响 所谓的“对拓展开放，对修改封闭”就这么圆满实现了。前面我们之所以要实现抽象产品类，也是同样的道理。 总结 大家现在回头对比一下抽象工厂和简单工厂的思路，思考一下：它们之间有哪些异同？ 它们的共同点，在于都尝试去分离一个系统中变与不变的部分。它们的不同在于场景的复杂度。在简单工厂的使用场景里，处理的对象是类，并且是一些非常好对付的类——它们的共性容易抽离，同时因为逻辑本身比较简单，故而不苛求代码可扩展性。抽象工厂本质上处理的其实也是类，但是是一帮非常棘手、繁杂的类，这些类中不仅能划分出门派，还能划分出等级，同时存在着千变万化的扩展可能性——这使得我们必须对共性作更特别的处理、使用抽象类去降低扩展的成本，同时需要对类的性质作划分，于是有了这样的四个关键角色： 抽象工厂（抽象类，它不能被用于生成具体实例）： 用于声明最终目标产品的共性。在一个系统里，抽象工厂可以有多个（大家可以想象我们的手机厂后来被一个更大的厂收购了，这个厂里除了手机抽象类，还有平板、游戏机抽象类等等），每一个抽象工厂对应的这一类的产品，被称为“产品族”。 具体工厂（用于生成产品族里的一个具体的产品）： 继承自抽象工厂、实现了抽象工厂里声明的那些方法，用于创建具体的产品的类。 抽象产品（抽象类，它不能被用于生成具体实例）： 上面我们看到，具体工厂里实现的接口，会依赖一些类，这些类对应到各种各样的具体的细粒度产品（比如操作系统、硬件等），这些具体产品类的共性各自抽离，便对应到了各自的抽象产品类。 具体产品（用于生成产品族里的一个具体的产品所依赖的更细粒度的产品）： 比如我们上文中具体的一种操作系统、或具体的一种硬件等。 抽象工厂模式的定义，是围绕一个超级工厂创建其他工厂。本节内容对一些工作年限不多的同学来说可能不太友好，但抽象工厂目前来说在JS世界里也应用得并不广泛，所以大家不必拘泥于细节，只需留意以下三点： 学会用 ES6 模拟 JAVA 中的抽象类； 了解抽象工厂模式中四个角色的定位与作用； 对“开放封闭原则”形成自己的理解，知道它好在哪，知道执行它的必要性。 如果能对这三点有所掌握，那么这一节的目的就达到了，最难搞、最难受的抽象工厂也就告一段落了。 最后，再跟大家谈谈学习 现在我们回到开篇抛出的那个问题——抽象工厂对于各位而言的价值是什么？这么一个看似鸡肋、其实也确实不怎么常用的一个设计模式，凭什么值得我们花这么大力气去理解它？原因有三： 其一： 开篇我们说过，前端工程师首先是软件工程师。只会写 JavaScript、只理解 JavaScript、只通过 JavaScript 去理解软件世界，是一件可怕的事情，它会窄化你的技术视野——因为 JavaScript 只是编程语言中的一个分支，准确地说，它是一个后辈。虽说它确实很流行，但它还不够强大（正是因为不够强大，所以在演化发展的过程中必然需要借鉴其它优秀语言的优秀特性，也会渐渐遇到其它语言的应用场景，不信大家看看 ES6789 都做了什么，再看看遍地开花的 TypeScript）。 但写这本小册并不是为了把大家指去学 Java/C++，而是为了以最小的时间成本帮大家去理解设计模式的套路和原则。比起要求大家为了这个设计模式去理解强类型语言、去理解强类型语言里的应用场景，我更希望能在这儿用 JavaScript 把这个东西给说清楚，把那些关键的设计模式概念在这儿给大家引出来——哪怕你当下用到它的场景还不是那么多（相信以当下前端语言和前端应用的发展速度和发展趋势来看，它会有用的：））。 其二： 在大家今后的职业生涯里，可能会不止一次地遇到服务端/客户端出身、或者单纯对受试者知识广度有疯狂执念的各种不同背景不同脑回路的面试官。在他们的世界里，不知道抽象工厂就像不知道 this 一样恐怖：）。所以，要学。 其三： 也是最重要的一点。前面我们说过，设计模式的“术”说到底是在佐证它的“道”。充分理解了设计原则后，设计模式纵有 1w 种也难不倒大家。抽象工厂是佐证“开放封闭原则”的良好素材，通过本节的学习，相信大家会对这个抽象的概念有更加具体和感性的认知。在后面的章节中，“开放封闭”作为各位的老朋友，会被反复提及。有了本节的平稳过渡，相信大家在后续的学习中可以真正做到心中有数、游刃有余。 说了这么多，无非是想传达给大家一个学习态度：不要小看那些看似“无用”的知识。 技术，尤其是前端技术，它的更新迭代速度是非常快的。仅仅因为“这个技术点我现在用不到”而推开摆在眼前的知识，是一种非常糟糕的学习方法——它会极大地限制你的能力和你职业生涯的可能性。举个例子，React 新版本推出的 Fiber 架构现在很火，很多同学认为这是个特别新潮的玩意儿——它新吗？新个屁！作为一种架构模式，它在软件领域早就有过不同姿势的生产实践了，React 并不是 Fiber 的发明者，而是 Fiber 的使用者和受益者。 同理，包括 ES2015 刚出来的时候，有同学说这个也没见过、那个也要重新学，累死了累死了，学不动了想转行...哎，其实它们都是软件世界里存在了很久很久的模式和知识点啊同学们。试想如果这份知识曾经摆在你面前的时候你没有拒绝它，此刻你的学习成本又该低了多少呢？ 设计模式之外的东西，我们点到即止，剩下的就看大家的悟性和造化了。 接下来，我们一起看点更好玩的东西~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/05.创建型：单例模式——Vuex的数据管理哲学.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/05.创建型：单例模式——Vuex的数据管理哲学.html","title":"05.创建型：单例模式——Vuex的数据管理哲学","keywords":"","body":"保证一个类仅有一个实例，并提供一个访问它的全局访问点，这样的模式就叫做单例模式。 单例模式是设计模式中相对较为容易理解、容易上手的一种模式，同时因为其具有广泛的应用场景，也是面试题里的常客。因此单例模式这块我们除了讲解单例模式的原理及其在 Vuex 中的应用实践(本节)，还会附上两道面试真题供大家练手(下节)。 单例模式的实现思路 现在我们先不考虑单例模式的应用场景，单看它的实现，思考这样一个问题：如何才能保证一个类仅有一个实例？一般情况下，当我们创建了一个类（本质是构造函数）后，可以通过new关键字调用构造函数进而生成任意多的实例对象。像这样： class SingleDog { show() { console.log('我是一个单例对象') } } const s1 = new SingleDog() const s2 = new SingleDog() // false s1 === s2 楼上我们先 new 了一个 s1，又 new 了一个 s2，很明显 s1 和 s2 之间没有任何瓜葛，两者是相互独立的对象，各占一块内存空间。而单例模式想要做到的是，不管我们尝试去创建多少次，它都只给你返回第一次所创建的那唯一的一个实例。 要做到这一点，就需要构造函数具备判断自己是否已经创建过一个实例的能力。我们现在把这段判断逻辑写成一个静态方法(其实也可以直接写入构造函数的函数体里）： class SingleDog { show() { console.log('我是一个单例对象') } static getInstance() { // 判断是否已经new过1个实例 if (!SingleDog.instance) { // 若这个唯一的实例不存在，那么先创建它 SingleDog.instance = new SingleDog() } // 如果这个唯一的实例已经存在，则直接返回 return SingleDog.instance } } const s1 = SingleDog.getInstance() const s2 = SingleDog.getInstance() // true s1 === s2 除了楼上这种实现方式之外，getInstance的逻辑还可以用闭包来实现： SingleDog.getInstance = (function() { // 定义自由变量instance，模拟私有变量 let instance = null return function() { // 判断自由变量是否为null if(!instance) { // 如果为null则new出唯一实例 instance = new SingleDog() } return instance } })() 可以看出，在getInstance方法的判断和拦截下，我们不管调用多少次，SingleDog都只会给我们返回一个实例，s1和s2现在都指向这个唯一的实例。 生产实践：Vuex中的单例模式 近年来，基于 Flux 架构的状态管理工具层出不穷，其中应用最广泛的要数 Redux 和 Vuex。无论是 Redux 和 Vuex，它们都实现了一个全局的 Store 用于存储应用的所有状态。这个 Store 的实现，正是单例模式的典型应用。这里我们以 Vuex 为例，研究一下单例模式是怎么发光发热的： 理解 Vuex 中的 Store Vuex 使用单一状态树，用一个对象就包含了全部的应用层级状态。至此它便作为一个“唯一数据源 (SSOT)”而存在。这也意味着，每个应用将仅仅包含一个 store 实例。单一状态树让我们能够直接地定位任一特定的状态片段，在调试的过程中也能轻易地取得整个当前应用状态的快照。 ——Vuex官方文档 在Vue中，组件之间是独立的，组件间通信最常用的办法是 props（限于父组件和子组件之间的通信），稍微复杂一点的（比如兄弟组件间的通信）我们通过自己实现简单的事件监听函数也能解决掉。 但当组件非常多、组件间关系复杂、且嵌套层级很深的时候，这种原始的通信方式会使我们的逻辑变得复杂难以维护。这时最好的做法是将共享的数据抽出来、放在全局，供组件们按照一定的的规则去存取数据，保证状态以一种可预测的方式发生变化。于是便有了 Vuex，这个用来存放共享数据的唯一数据源，就是 Store。 关于 Vuex 的细节，大家可以参考Vuex的官方文档，此处提及 Vuex，除了为了拓宽大家的知识面，更重要的是为了说明单例模式在生产实践中广泛的应用和不可或缺的地位。如果对 Vuex 没有兴趣，那么大家只需关注“一个 Vue 实例只能对应一个 Store”这一点即可。 Vuex如何确保Store的唯一性 我们先来看看如何在项目中引入 Vuex： // 安装vuex插件 Vue.use(Vuex) // 将store注入到Vue实例中 new Vue({ el: '#app', store }) 通过调用Vue.use()方法，我们安装了 Vuex 插件。Vuex 插件是一个对象，它在内部实现了一个 install 方法，这个方法会在插件安装时被调用，从而把 Store 注入到Vue实例里去。也就是说每 install 一次，都会尝试给 Vue 实例注入一个 Store。 在 install 方法里，有一段逻辑和我们楼上的 getInstance 非常相似的逻辑： let Vue // 这个Vue的作用和楼上的instance作用一样 ... export function install (_Vue) { // 判断传入的Vue实例对象是否已经被install过Vuex插件（是否有了唯一的state） if (Vue && _Vue === Vue) { if (process.env.NODE_ENV !== 'production') { console.error( '[vuex] already installed. Vue.use(Vuex) should be called only once.' ) } return } // 若没有，则为这个Vue实例对象install一个唯一的Vuex Vue = _Vue // 将Vuex的初始化逻辑写进Vue的钩子函数里 applyMixin(Vue) } 楼上便是 Vuex 源码中单例模式的实现办法了，套路可以说和我们的getInstance如出一辙。通过这种方式，可以保证一个 Vue 实例（即一个 Vue 应用）只会被 install 一次 Vuex 插件，所以每个 Vue 实例只会拥有一个全局的 Store。 小结 这里大家不妨开个脑洞，思考一下：如果我在 install 里没有实现单例模式，会带来什么样的麻烦？ 我们通过上面的源码解析可以看出，每次 install 都会为Vue实例初始化一个 Store。假如 install 里没有单例模式的逻辑，那我们如果在一个应用里不小心多次安装了插件： // 在主文件里安装Vuex Vue.use(Vuex) ...(中间添加/修改了一些store的数据) // 在后续的逻辑里不小心又安装了一次 Vue.use(Vuex) 失去了单例判断能力的 install 方法，会为当前的Vue实例重新注入一个新的 Store，也就是说你中间的那些数据操作全都没了，一切归 0。因此，单例模式在此处是非常必要的。 除了说在 Vuex 中大展身手，我们在 Redux、jQuery 等许多优秀的前端库里也都能看到单例模式的身影。重要的单例模式自然在面试中有了重要的地位，下一节，我们就来看两道面试真题~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/06.创建型：单例模式——面试真题手把手教学.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/06.创建型：单例模式——面试真题手把手教学.html","title":"06.创建型：单例模式——面试真题手把手教学","keywords":"","body":"实现一个 Storage 描述 实现Storage，使得该对象为单例，基于 localStorage 进行封装。实现方法 setItem(key,value) 和 getItem(key)。 思路 拿到单例模式相关的面试题，大家首先要做的是回忆我们上个小节的“基本思路”部分——至少要记起来getInstance方法和instance这个变量是干啥的。 具体实现上，把判断逻辑写入静态方法或者构造函数里都没关系，最好能把闭包的版本也写出来，多多益善。 总之有了上节的基础，这个题简直是默写！ 实现：静态方法版 // 定义Storage class Storage { static getInstance() { // 判断是否已经new过1个实例 if (!Storage.instance) { // 若这个唯一的实例不存在，那么先创建它 Storage.instance = new Storage() } // 如果这个唯一的实例已经存在，则直接返回 return Storage.instance } getItem (key) { return localStorage.getItem(key) } setItem (key, value) { return localStorage.setItem(key, value) } } const storage1 = Storage.getInstance() const storage2 = Storage.getInstance() storage1.setItem('name', '李雷') // 李雷 storage1.getItem('name') // 也是李雷 storage2.getItem('name') // 返回true storage1 === storage2 实现： 闭包版 // 先实现一个基础的StorageBase类，把getItem和setItem方法放在它的原型链上 function StorageBase () {} StorageBase.prototype.getItem = function (key){ return localStorage.getItem(key) } StorageBase.prototype.setItem = function (key, value) { return localStorage.setItem(key, value) } // 以闭包的形式创建一个引用自由变量的构造函数 const Storage = (function(){ let instance = null return function(){ // 判断自由变量是否为null if(!instance) { // 如果为null则new出唯一实例 instance = new StorageBase() } return instance } })() // 这里其实不用 new Storage 的形式调用，直接 Storage() 也会有一样的效果 const storage1 = new Storage() const storage2 = new Storage() storage1.setItem('name', '李雷') // 李雷 storage1.getItem('name') // 也是李雷 storage2.getItem('name') // 返回true storage1 === storage2 实现一个全局的模态框 描述 实现一个全局唯一的Modal弹框 思路 这道题比较经典，基本上所有讲单例模式的文章都会以此为例，同时它也是早期单例模式在前端领域的最集中体现。 万变不离其踪，记住getInstance方法、记住instance变量、记住闭包和静态方法，这个题除了要多写点 HTML 和 CSS 之外，对大家来说完全不成问题。 实现 完整代码如下： 单例模式弹框 #modal { height: 200px; width: 200px; line-height: 200px; position: fixed; left: 50%; top: 50%; transform: translate(-50%, -50%); border: 1px solid black; text-align: center; } 打开弹框 关闭弹框 // 核心逻辑，这里采用了闭包思路来实现单例模式 const Modal = (function() { let modal = null return function() { if(!modal) { modal = document.createElement('div') modal.innerHTML = '我是一个全局唯一的Modal' modal.id = 'modal' modal.style.display = 'none' document.body.appendChild(modal) } return modal } })() // 点击打开按钮展示模态框 document.getElementById('open').addEventListener('click', function() { // 未点击则不创建modal实例，避免不必要的内存占用;此处不用 new Modal 的形式调用也可以，和 Storage 同理 const modal = new Modal() modal.style.display = 'block' }) // 点击关闭按钮隐藏模态框 document.getElementById('close').addEventListener('click', function() { const modal = new Modal() if(modal) { modal.style.display = 'none' } }) 是不是发现又是熟悉的套路？又可以默写了？（ES6 版本的实现大家自己尝试默写一下，相信对现在的你来说已经非常简单了）。 这就是单例模式面试题的特点，准确地说，是所有设计模式相关面试题的特点——牢记核心思路，就能举一反三。所以说设计模式的学习是典型的一分耕耘一分收获，性价比极高。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/07.创建型：原型模式——谈Prototype无小事.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/07.创建型：原型模式——谈Prototype无小事.html","title":"07.创建型：原型模式——谈Prototype无小事","keywords":"","body":"原型模式不仅是一种设计模式，它还是一种编程范式（programming paradigm），是 JavaScript 面向对象系统实现的根基。 在原型模式下，当我们想要创建一个对象时，会先找到一个对象作为原型，然后通过克隆原型的方式来创建出一个与原型一样（共享一套数据/方法）的对象。在 JavaScript 里，Object.create方法就是原型模式的天然实现——准确地说，只要我们还在借助Prototype来实现对象的创建和原型的继承，那么我们就是在应用原型模式。 有的设计模式资料中会强调，原型模式就是拷贝出一个新对象，认为在 JavaScript 类里实现了深拷贝方法才算是应用了原型模式。这是非常典型的对 JAVA/C++ 设计模式的生搬硬套，更是对 JavaScript 原型模式的一种误解。事实上，在JAVA中，确实存在原型模式相关的克隆接口规范。但在 JavaScript 中，我们使用原型模式，并不是为了得到一个副本，而是为了得到与构造函数（类）相对应的类型的实例、实现数据/方法的共享。克隆是实现这个目的的方法，但克隆本身并不是我们的目的。 以类为中心的语言和以原型为中心的语言 相信很多小伙伴读到这儿还会有些迷惑：使用 JavaScript 以来，我确实离不开Prototype，按照上面的说法，也算是原型模式重度用户了。但这个原型模式用得我一脸懵逼啊——难道我还有除了Prototype以外的选择？ Java 中的类 作为 JavaScript 开发者，我们确实没有别的选择 —— 毕竟开头我们说过，原型模式是 JavaScript 这门语言面向对象系统的根本。但在其它语言，比如 JAVA 中，类才是它面向对象系统的根本。所以说在 JAVA 中，我们可以选择不使用原型模式 —— 这样一来，所有的实例都必须要从类中来，当我们希望创建两个一模一样的实例时，就只能这样做（假设实例从 Dog 类中来,必传参数为姓名、性别、年龄和品种）： Dog dog = new Dog('旺财', 'male', 3, '柴犬') Dog dog_copy = new Dog('旺财', 'male', 3, '柴犬') 没错，我们不得不把一模一样的参数传两遍，非常麻烦。而原型模式允许我们通过调用克隆方法的方式达到同样的目的，比较方便，所以 Java 专门针对原型模式设计了一套接口和方法，在必要的场景下会通过原型方法来应用原型模式。当然，在更多的情况下，Java 仍以“实例化类”这种方式来创建对象。 所以说在以类为中心的语言中，原型模式确实不是一个必选项，它只有在特定的场景下才会登场。 JavaScript 中的“类” 这时有一部分小伙伴估计要炸毛了：啥？？？JavaScript 只能用Prototype？我看你还活在上世纪，ES6 早就支持类了！现在我们 JavaScript 也是以类为中心的语言了。 这波同学的思想非常危险，因为 ES6 的类其实是原型继承的语法糖: ECMAScript 2015 中引入的 JavaScript 类实质上是 JavaScript 现有的基于原型的继承的语法糖。类语法不会为 JavaScript 引入新的面向对象的继承模型。 ——MDN 当我们尝试用 class 去定义一个 Dog 类时： class Dog { constructor(name ,age) { this.name = name this.age = age } eat() { console.log('肉骨头真好吃') } } 其实完全等价于写了这么一个构造函数: function Dog(name, age) { this.name = name this.age = age } Dog.prototype.eat = function() { console.log('肉骨头真好吃') } 所以说 JavaScript 这门语言的根本就是原型模式。在 Java 等强类型语言中，原型模式的出现是为了实现类型之间的解耦。而 JavaScript 本身类型就比较模糊，不存在类型耦合的问题，所以说咱们平时根本不会刻意地去使用原型模式。因此我们此处不必强行把原型模式当作一种设计模式去理解，把它作为一种编程范式来讨论会更合适。 谈原型模式，其实是谈原型范式 原型编程范式的核心思想就是利用实例来描述对象，用实例作为定义对象和继承的基础。在 JavaScript 中，原型编程范式的体现就是基于原型链的继承。这其中，对原型、原型链的理解是关键。 原型 在 JavaScript 中，每个构造函数都拥有一个prototype属性，它指向构造函数的原型对象，这个原型对象中有一个 construtor 属性指回构造函数；每个实例都有一个__proto__属性，当我们使用构造函数去创建实例时，实例的__proto__属性就会指向构造函数的原型对象。 具体来说，当我们这样使用构造函数创建一个对象时： // 创建一个Dog构造函数 function Dog(name, age) { this.name = name this.age = age } Dog.prototype.eat = function() { console.log('肉骨头真好吃') } // 使用Dog构造函数创建dog实例 const dog = new Dog('旺财', 3) 这段代码里的几个实体之间就存在着这样的关系： 原型链 现在我在上面那段代码的基础上，进行两个方法调用: // 输出\"肉骨头真好吃\" dog.eat() // 输出\"[object Object]\" dog.toString() 明明没有在 dog 实例里手动定义 eat 方法和 toString 方法，它们还是被成功地调用了。这是因为当我试图访问一个 JavaScript 实例的属性/方法时，它首先搜索这个实例本身；当发现实例没有定义对应的属性/方法时，它会转而去搜索实例的原型对象；如果原型对象中也搜索不到，它就去搜索原型对象的原型对象，这个搜索的轨迹，就叫做原型链。 以我们的 eat 方法和 toString 方法的调用过程为例，它的搜索过程就是这样子的： 楼上这些彼此相连的prototype，就组成了一个原型链。 注： 几乎所有 JavaScript 中的对象都是位于原型链顶端的 Object 的实例，除了Object.prototype（当然，如果我们手动用Object.create(null)创建一个没有任何原型的对象，那它也不是 Object 的实例）。 以上为大家介绍了原型、原型链等 JavaScript 中核心的基础知识。这些不仅是基础中的基础，也是面试中的重点。此外在面试中，一些面试官可能会刻意混淆 JavaScript 中原型范式和强类型语言中原型模式的区别，当他们这么做的时候不一定是因为对语言、对设计模式的理解有问题，而很有可能是为了考察你对象的深拷贝。 对象的深拷贝 这类题目的发问方式又很多，除了“模拟 JAVA 中的克隆接口”、“JavaScript 实现原型模式”以外，它更常见、更友好的发问形式是“请实现JS中的深拷贝”。 实现 JavaScript 中的深拷贝，有一种非常取巧的方式 —— JSON.stringify： const liLei = { name: 'lilei', age: 28, habits: ['coding', 'hiking', 'running'] } const liLeiStr = JSON.stringify(liLei) const liLeiCopy = JSON.parse(liLeiStr) liLeiCopy.habits.splice(0, 1) console.log('李雷副本的habits数组是', liLeiCopy.habits) console.log('李雷的habits数组是', liLei.habits) 丢进控制台检验一下，我们发现引用类型也被成功拷贝了，副本和本体相互不干扰，正合我意~ 但是注意，这个方法存在一些局限性，比如无法处理 function、无法处理正则等等——只有当你的对象是一个严格的 JSON 对象时，可以顺利使用这个方法。在面试过程中，大家答出这个答案没有任何问题，但不要仅仅答这一种做法。 深拷贝没有完美方案，每一种方案都有它的边界 case。而面试官向你发问也并非是要求你破解人类未解之谜，多数情况下，他只是希望考查你对递归的熟练程度。所以递归实现深拷贝的核心思路，大家需要重点掌握（解析在注释里）： function deepClone(obj) { // 如果是 值类型 或 null，则直接return if(typeof obj !== 'object' || obj === null) { return obj } // 定义结果对象 let copy = {} // 如果对象是数组，则定义结果数组 if(obj.constructor === Array) { copy = [] } // 遍历对象的key for(let key in obj) { // 如果key是对象的自有属性 if(obj.hasOwnProperty(key)) { // 递归调用深拷贝方法 copy[key] = deepClone(obj[key]) } } return copy } 调用深拷贝方法，若属性为值类型，则直接返回；若属性为引用类型，则递归遍历。这就是我们在解这一类题时的核心的方法。 拓展阅读 深拷贝在命题时，可发挥的空间主要在于针对不同数据结构的处理，比如除了考虑 Array、Object，还需要考虑一些其它的数据结构（Map、Set 等）；此外还有一些极端 case（循环引用等）的处理等等。深拷贝的实现细节，这里为大家推荐两个阅读材料： jQuery中的extend方法源码 深拷贝的终极探索 想要在深拷贝这一命题上拿高分的同学，不妨点开一看，相信你的收获会比你想象中更多~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/08.结构型：装饰器模式——对象装上它，就像开了挂.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/08.结构型：装饰器模式——对象装上它，就像开了挂.html","title":"08.结构型：装饰器模式——对象装上它，就像开了挂","keywords":"","body":"装饰器模式，又名装饰者模式。它的定义是“在不改变原对象的基础上，通过对其进行包装拓展，使原有对象可以满足用户的更复杂需求”。 当然，对于没接触过装饰器的同学来说，这段定义意义不大。我们先借助一个生活中的例子来理解装饰器： 生活中的装饰器 去年有个手机壳在同事里非常流行，我也随大流买了一个，它长这样： 这个手机壳的安装方式和普通手机壳一样，就是卡在手机背面。不同的是它卡上去后会变成一块水墨屏，这样一来我们手机就有了两个屏幕。平时办公或者玩游戏的时候，用正面的普通屏幕；阅读的时候怕伤眼睛，就可以翻过来用背面的水墨屏了。 这个水墨屏手机壳安装后，不会对手机原有的功能产生任何影响，仅仅是使手机具备了一种新的能力（多了块屏幕），因此它在此处就是一个标准的装饰器。 PS：手机壳是挺好用的，就是有点厚，用了一个月我就放弃了，目前正在工位一角吃灰。大家谨记理性消费、适度消费。 装饰器的应用场景 按钮是我们平时写业务时常见的页面元素。假设我们的初始需求是：每个业务中的按钮在点击后都弹出「您还未登录哦」的弹框。 那我们可以很轻易地写出这个需求的代码： 按钮点击需求1.0 #modal { height: 200px; width: 200px; line-height: 200px; position: fixed; left: 50%; top: 50%; transform: translate(-50%, -50%); border: 1px solid black; text-align: center; } 点击打开 关闭弹框 // 弹框创建逻辑，这里我们复用了单例模式面试题的例子 const Modal = (function() { let modal = null return function() { if(!modal) { modal = document.createElement('div') modal.innerHTML = '您还未登录哦~' modal.id = 'modal' modal.style.display = 'none' document.body.appendChild(modal) } return modal } })() // 点击打开按钮展示模态框 document.getElementById('open').addEventListener('click', function() { // 未点击则不创建modal实例，避免不必要的内存占用 const modal = new Modal() modal.style.display = 'block' }) // 点击关闭按钮隐藏模态框 document.getElementById('close').addEventListener('click', function() { const modal = document.getElementById('modal') if(modal) { modal.style.display = 'none' } }) 按钮发布上线后，过了几天太平日子。忽然有一天，产品经理找到你，说这个弹框提示还不够明显，我们应该在弹框被关闭后把按钮的文案改为“快去登录”，同时把按钮置灰。 听到这个消息，你立刻马不停蹄地翻出之前的代码，找到了按钮的 click 监听函数，手动往里面添加了文案修改&按钮置灰逻辑。但这还没完，因为你司的几乎每个业务里都用到了这类按钮：除了“点击打开”按钮，还有“点我开始”、“点击购买”按钮等各种五花八门的按钮，这意味着你不得不深入到每一个业务的深处去给不同的按钮添加这部分逻辑。 有的业务不在你这儿，但作为这个新功能迭代的 owner，你还需要把需求细节再通知到每一个相关同事（要么你就自己上，去改别人的代码，更恐怖），怎么想怎么麻烦。一个文案修改&按钮置灰尚且如此麻烦，更不要说我们日常开发中遇到的更复杂的需求变更了。 不仅麻烦，直接去修改已有的函数体，这种做法违背了我们的“开放封闭原则”；往一个函数体里塞这么多逻辑，违背了我们的“单一职责原则”。所以说这个事儿，越想越不能这么干。 我想一定会有同学质疑说为啥不把按钮抽成公共组件 Button，这样只需要在 Button 组件里修改一次逻辑就可以了。这种想法非常好。但注意，我们楼上的例子没有写组件直接写了 Button 标签是为了简化示例。事实上真要写组件的话，不同业务里必定有针对业务定制的不同 Button 组件，比如 MoreButton 、BeginButton等等，也是五花八门的，所以说我们仍会遇到同样的困境。 讲真，我想任何人去做这个需求的时候，其实都压根不想去关心它现有的业务逻辑是啥样的——你说这按钮的旧逻辑是我自己写的还好，理解成本不高；万一碰上是个离职同事写的，那阅读难度谁能预料呢？我不想接锅，我只是想对它已有的功能做个拓展，只关心拓展出来的那部分新功能如何实现，对不对？ 程序员说：“我不想努力了，我想开挂”，于是便有了装饰器模式。 装饰器模式初相见 为了不被已有的业务逻辑干扰，当务之急就是将旧逻辑与新逻辑分离，把旧逻辑抽出去： // 将展示Modal的逻辑单独封装 function openModal() { const modal = new Modal() modal.style.display = 'block' } 编写新逻辑： // 按钮文案修改逻辑 function changeButtonText() { const btn = document.getElementById('open') btn.innerText = '快去登录' } // 按钮置灰逻辑 function disableButton() { const btn = document.getElementById('open') btn.setAttribute(\"disabled\", true) } // 新版本功能逻辑整合 function changeButtonStatus() { changeButtonText() disableButton() } 然后把三个操作逐个添加open按钮的监听函数里： document.getElementById('open').addEventListener('click', function() { openModal() changeButtonStatus() }) 如此一来，我们就实现了“只添加，不修改”的装饰器模式，使用changeButtonStatus的逻辑装饰了旧的按钮点击逻辑。以上是ES5中的实现，ES6中，我们可以以一种更加面向对象化的方式去写： // 定义打开按钮 class OpenButton { // 点击后展示弹框（旧逻辑） onClick() { const modal = new Modal() modal.style.display = 'block' } } // 定义按钮对应的装饰器 class Decorator { // 将按钮实例传入 constructor(open_button) { this.open_button = open_button } onClick() { this.open_button.onClick() // “包装”了一层新逻辑 this.changeButtonStatus() } changeButtonStatus() { this.changeButtonText() this.disableButton() } disableButton() { const btn = document.getElementById('open') btn.setAttribute(\"disabled\", true) } changeButtonText() { const btn = document.getElementById('open') btn.innerText = '快去登录' } } const openButton = new OpenButton() const decorator = new Decorator(openButton) document.getElementById('open').addEventListener('click', function() { // openButton.onClick() // 此处可以分别尝试两个实例的onClick方法，验证装饰器是否生效 decorator.onClick() }) 大家这里需要特别关注一下 ES6 这个版本的实现，这里我们把按钮实例传给了 Decorator，以便于后续 Decorator 可以对它为所欲为进行逻辑的拓展。在 ES7 中，Decorator 作为一种语法被直接支持了，它的书写会变得更加简单，但背后的原理其实与此大同小异。在下一节，我们将一起去探究一下 ES7 中 Decorator 背后的故事。 值得关注的细节 结束了装饰器的感性认知之旅，下一节我们将直奔ES7装饰器原理&装饰器优秀案例教学。在此之前，我们对本节的一个小细节进行复盘： 单一职责原则 大家可能刚刚没来得及注意，按钮新逻辑中，文本修改&按钮置灰这两个变化，被我封装在了两个不同的方法里，并以组合的形式出现在了最终的目标方法changeButtonStatus里。这样做的目的是为了强化大家脑中的“单一职责”意识。将不同的职责分离，可以做到每个职责都能被灵活地复用；同时，不同职责之间无法相互干扰，不会出现因为修改了 A 逻辑而影响了 B 逻辑的狗血剧情。 但是，设计原则并非是板上钉钉的教条。在此处，我们的代码总共只有两行、且比较简单，逻辑分离的诉求并不特别强，分开最好，不分影响也不大（此处我们选择了拆散两段逻辑，更多地是为了强化大家的意识）。在日常开发中，当遇到两段各司其职的代码逻辑时，我们首先要有“尝试拆分”的敏感，其次要有“该不该拆”的判断——当逻辑粒度过小时，盲目拆分会导致你的项目里存在过多的零碎的小方法，这反而不会使我们的代码变得更好。 OK，真正的战斗才刚刚开始，大家梳理一下思路，一起进入下一节的学习吧~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/09.结构型：装饰器模式——深入装饰器原理与优秀案例.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/09.结构型：装饰器模式——深入装饰器原理与优秀案例.html","title":"09.结构型：装饰器模式——深入装饰器原理与优秀案例","keywords":"","body":"前置知识：ES7 中的装饰器 小册在知识储备上不要求所有同学掌握 ES6+ 语法，所以先带大家一起过一遍装饰器的基本操作~ 在 ES7 中，我们可以像写 python 一样通过一个@语法糖轻松地给一个类装上装饰器： // 装饰器函数，它的第一个参数是目标类 function classDecorator(target) { target.hasDecorator = true return target } // 将装饰器“安装”到Button类上 @classDecorator class Button { // Button类的相关逻辑 } // 验证装饰器是否生效 console.log('Button 是否被装饰了：', Button.hasDecorator) 也可以用同样的语法糖去装饰类里面的方法： // 具体的参数意义，在下个小节，这里大家先感知一下操作 function funcDecorator(target, name, descriptor) { let originalMethod = descriptor.value descriptor.value = function() { console.log('我是Func的装饰器逻辑') return originalMethod.apply(this, arguments) } return descriptor } class Button { @funcDecorator onClick() { console.log('我是Func的原有逻辑') } } // 验证装饰器是否生效 const button = new Button() button.onClick() 注：以上代码直接放进浏览器/Node 中运行会报错，因为浏览器和 Node 目前都不支持装饰器语法，需要大家安装 Babel 进行转码： 安装 Babel 及装饰器相关的 Babel 插件 npm install babel-preset-env babel-plugin-transform-decorators-legacy --save-dev 注：在没有任何配置选项的情况下，babel-preset-env 与 babel-preset-latest（或者 babel-preset-es2015，babel-preset-es2016 和 babel-preset-es2017 一起）的行为完全相同。 编写配置文件.babelrc： { \"presets\": [\"env\"], \"plugins\": [\"transform-decorators-legacy\"] } 最后别忘了下载全局的 Babel 命令行工具用于转码： npm install babel-cli -g 执行完这波操作，我们首先是对目标文件进行转码，比如说你的目标文件叫做 test.js，想要把它转码后的结果输出到 babel_test.js，就可以这么写: babel test.js --out-file babel_test.js 运行babel_test.js babel_test.js 就可以看到你的装饰器是否生效啦~ OK，知道了装饰器长啥样，我们一起看看装饰器的实现细节： 装饰器语法糖背后的故事 所谓语法糖，往往意味着“美好的表象”。正如 class 语法糖背后是大家早已十分熟悉的 ES5 构造函数一样，装饰器语法糖背后也是我们的老朋友，不信我们一起来看看@decorator都帮我们做了些什么： Part1：函数传参&调用 上一节我们使用 ES6 实现装饰器模式时曾经将按钮实例传给了 Decorator，以便于后续 Decorator 可以对它进行逻辑的拓展。这也正是装饰器的最最基本操作——定义装饰器函数，将被装饰者“交给”装饰器。这也正是装饰器语法糖首先帮我们做掉的工作 —— 函数传参&调用。 类装饰器的参数 当我们给一个类添加装饰器时： function classDecorator(target) { target.hasDecorator = true return target } // 将装饰器“安装”到Button类上 @classDecorator class Button { // Button类的相关逻辑 } 此处的 target 就是被装饰的类本身。 方法装饰器的参数 而当我们给一个方法添加装饰器时： function funcDecorator(target, name, descriptor) { let originalMethod = descriptor.value descriptor.value = function() { console.log('我是Func的装饰器逻辑') return originalMethod.apply(this, arguments) } return descriptor } class Button { @funcDecorator onClick() { console.log('我是Func的原有逻辑') } } 此处的 target 变成了Button.prototype，即类的原型对象。这是因为 onClick 方法总是要依附其实例存在的，修饰 onClik 其实是修饰它的实例。但我们的装饰器函数执行的时候，Button 实例还并不存在。为了确保实例生成后可以顺利调用被装饰好的方法，装饰器只能去修饰 Button 类的原型对象。 装饰器函数调用的时机 装饰器函数执行的时候，Button 实例还并不存在。这是因为实例是在我们的代码运行时动态生成的，而装饰器函数则是在编译阶段就执行了。所以说装饰器函数真正能触及到的，就只有类这个层面上的对象。 Part2：将“属性描述对象”交到你手里 在编写类装饰器时，我们一般获取一个target参数就足够了。但在编写方法装饰器时，我们往往需要至少三个参数： function funcDecorator(target, name, descriptor) { let originalMethod = descriptor.value descriptor.value = function() { console.log('我是Func的装饰器逻辑') return originalMethod.apply(this, arguments) } return descriptor } 第一个参数的意义，前文已经解释过。第二个参 数name，是我们修饰的目标属性属性名，也没啥好讲的。关键就在这个 descriptor 身上，它也是我们使用频率最高的一个参数，它的真面目就是“属性描述对象”（attributes object）。这个名字大家可能不熟悉，但Object.defineProperty方法我想大家多少都用过，它的调用方式是这样的： Object.defineProperty(obj, prop, descriptor) 此处的descriptor和装饰器函数里的 descriptor 是一个东西，它是 JavaScript 提供的一个内部数据结构、一个对象，专门用来描述对象的属性。它由各种各样的属性描述符组成，这些描述符又分为数据描述符和存取描述符： 数据描述符：包括 value（存放属性值，默认为默认为 undefined）、writable（表示属性值是否可改变，默认为true）、enumerable（表示属性是否可枚举，默认为 true）、configurable（属性是否可配置，默认为true）。 存取描述符：包括 get 方法（访问属性时调用的方法，默认为 undefined），set（设置属性时调用的方法，默认为 undefined ） 很明显，拿到了 descriptor，就相当于拿到了目标方法的控制权。通过修改 descriptor，我们就可以对目标方法为所欲为的逻辑进行拓展了~ 在上文的示例中，我们通过 descriptor 获取到了原函数的函数体（originalMethod），把原函数推迟到了新逻辑（console）的后面去执行。这种做法和我们上一节在ES5中实现装饰器模式时做的事情一狗一样，所以说装饰器就是这么回事儿，换汤不换药~ 生产实践 装饰器在前端世界的应用十分广泛，即便是在 ES7 未诞生的那些个蛮荒年代，也没能阻挡我们用装饰器开挂的热情。要说优秀的生产实践，可以说是两天两夜也说不完。但有一些实践，我相信大家可能都用过，或者说至少见过、听说过，只是当时并不清楚这个是装饰器模式。此处为了强化大家脑袋里已有的经验与设计模式知识之间的关联，更为了趁热打铁、将装饰器模式常见的用法给大家加固一下，我们一起来看几个不错的生产实践案例： React中的装饰器：HOC 高阶组件就是一个函数，且该函数接受一个组件作为参数，并返回一个新的组件。 HOC (Higher Order Component) 即高阶组件。它是装饰器模式在 React 中的实践，同时也是 React 应用中非常重要的一部分。通过编写高阶组件，我们可以充分复用现有逻辑，提高编码效率和代码的健壮性。 我们现在编写一个高阶组件，它的作用是把传入的组件丢进一个有红色边框的容器里（拓展其样式）。 import React, { Component } from 'react' const BorderHoc = WrappedComponent => class extends Component { render() { return } } export default borderHoc 用它来装饰目标组件 import React, { Component } from 'react' import BorderHoc from './BorderHoc' // 用BorderHoc装饰目标组件 @BorderHoc class TargetComponent extends React.Component { render() { // 目标组件具体的业务逻辑 } } // export出去的其实是一个被包裹后的组件 export default TargetComponent 可以看出，高阶组件从实现层面来看其实就是上文我们提到的类装饰器。在高阶组件的辅助下，我们不必因为一个小小的拓展而大费周折地编写新组件或者把一个新逻辑重写 N 多次，只需要轻轻 @ 一下装饰器即可。 使用装饰器改写 Redux connect Redux 是热门的状态管理工具。在 React 中，当我们想要引入 Redux 时，通常需要调用 connect 方法来把状态和组件绑在一起： import React, { Component } from 'react' import { connect } from 'react-redux' import { bindActionCreators } from 'redux' import action from './action.js' class App extends Component { render() { // App的业务逻辑 } } function mapStateToProps(state) { // 假设App的状态对应状态树上的app节点 return state.app } function mapDispatchToProps(dispatch) { // 这段看不懂也没关系，下面会有解释。重点理解connect的调用即可 return bindActionCreators(action, dispatch) } // 把App组件与Redux绑在一起 export default connect(mapStateToProps, mapDispatchToProps)(App) 这里给没用过 redux 的同学解释一下 connect 的两个入参：mapStateToProps 是一个函数，它可以建立组件和状态之间的映射关系；mapDispatchToProps也是一个函数，它用于建立组件和store.dispatch的关系，使组件具备通过 dispatch 来派发状态的能力。 总而言之，我们调用 connect 可以返回一个具有装饰作用的函数，这个函数可以接收一 个React 组件作为参数，使这个目标组件和 Redux 结合、具备 Redux 提供的数据和能力。既然有装饰作用，既然是能力的拓展，那么就一定能用装饰器来改写：把 connect 抽出来： import { connect } from 'react-redux' import { bindActionCreators } from 'redux' import action from './action.js' function mapStateToProps(state) { return state.app } function mapDispatchToProps(dispatch) { return bindActionCreators(action, dispatch) } // 将connect调用后的结果作为一个装饰器导出 export default connect(mapStateToProps, mapDispatchToProps) 在组件文件里引入connect： import React, { Component } from 'react' import connect from './connect.js' @connect export default class App extends Component { render() { // App的业务逻辑 } } 这样一来，我们的代码结构是不是清晰了很多？可维护性、可读性都上升了一个level，令人赏心悦目~ Tips： 回忆一下上面一个小节的讲解，对号入座看一看，connect装饰器从实现和调用方式上来看，是不是同时也是一个高阶组件呢？ 优质的源码阅读材料——core-decorators 前面都在教大家怎么写装饰器模式，这里来聊聊怎么用好装饰器模式。 装饰器模式的优势在于其极强的灵活性和可复用性——它本质上是一个函数，而且往往不依赖于任何逻辑而存在。这一点提醒了我们，当我们需要用到某个反复出现的拓展逻辑时，比起自己闷头搞，不如去看一看团队（社区）里有没有现成的实现，如果有，那么贯彻“拿来主义”，直接@就可以了。所以说装饰器模式是个好同志，它可以帮我们省掉大量复制粘贴的时间。 这里就要给大家推荐一个非常赞的装饰模式库 —— core-decorators。core-decorators 帮我们实现好了一些使用频率较高的装饰器，比如@readonly(使目标属性只读)、@deprecate(在控制台输出警告，提示用户某个指定的方法已被废除)等等等等。这里强烈建议大家把 core-decorators 作为自己的源码阅读材料，你能收获的或许比你想象中更多~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/10.结构型：适配器模式——兼容代码就是一把梭.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/10.结构型：适配器模式——兼容代码就是一把梭.html","title":"10.结构型：适配器模式——兼容代码就是一把梭","keywords":"","body":"适配器模式通过把一个类的接口变换成客户端所期待的另一种接口，可以帮我们解决不兼容的问题。 生活中的适配器 前段时间用了很久的 iPhone 6s丢了，请假跑出去买了台 iPhone X。结果有天听歌的时候发现X的耳机孔竟然是方形的，长这样： 而重度 iPhone 6s 用户&耳机发烧友的耳机线，可能是如图一所示，没错，它们都是圆头耳机，意识到这一点的时候，我佛了。 此时我好像只能在重新买一批耳机（很有可能同款耳机并没有方头的款式）和重新买一台手机之间做选择了。好在我不是一个普通的倒霉蛋，我学过设计模式，设计模式告诉我这种实际接口与目标接口不匹配的尴尬可以用一个叫适配器的东西来化解。打开万能的淘宝一搜，还真有，如图二所示。 只要装上它，圆头耳机就可以完美适配方形插槽，最终效果如图三所示。 绝了，正合我意！赶紧买一个来救火，从此又可以开心地为圆头耳机氪金啦~ 大家现在回顾楼上这波操作，这个耳机转换头做的事情，是不是就是我们开头说的把一个类（iPhone 新机型）的接口（方形）变换成客户端（用户）所期待的另一种接口（圆形）？ 最终达到的效果，就是用户（我）可以像使用 iPhone 6s 插口一样使用 iPhoneX 的插口，而不用感知两者间的差异。我们设计模式中的适配器，和楼上这个适配器做的事情可以说是一模一样，同样具有化腐朽为神奇的力量。 兼容接口就是一把梭——适配器的业务场景 大家知道我们现在有一个非常好用异步方案叫fetch，它的写法比ajax优雅很多。因此在不考虑兼容性的情况下，我们更愿意使用fetch、而不是使用ajax来发起异步请求。李雷是拜fetch教的忠实信徒，为了能更好地使用fetch，他封装了一个基于fetch的http方法库： export default class HttpUtils { // get方法 static get(url) { return new Promise((resolve, reject) => { // 调用fetch fetch(url) .then(response => response.json()) .then(result => { resolve(result) }) .catch(error => { reject(error) }) }) } // post方法，data以object形式传入 static post(url, data) { return new Promise((resolve, reject) => { // 调用fetch fetch(url, { method: 'POST', headers: { Accept: 'application/json', 'Content-Type': 'application/x-www-form-urlencoded' }, // 将object类型的数据格式化为合法的body参数 body: this.changeData(data) }) .then(response => response.json()) .then(result => { resolve(result) }) .catch(error => { reject(error) }) }) } // body请求体的格式化方法 static changeData(obj) { var prop, str = '' var i = 0 for (prop in obj) { if (!prop) { return } if (i == 0) { str += prop + '=' + obj[prop] } else { str += '&' + prop + '=' + obj[prop] } i++ } return str } } 当我想使用 fetch 发起请求时，只需要这样轻松地调用，而不必再操心繁琐的数据配置和数据格式化： // 定义目标url地址 const URL = \"xxxxx\" // 定义post入参 const params = { ... } // 发起post请求 const postResponse = await HttpUtils.post(URL,params) || {} // 发起get请求 const getResponse = await HttpUtils.get(URL) 真是个好用的方法库！老板看了李雷的 HttpUtils 库，喜上眉梢——原来老板也是个拜 fetch 教。老板说李雷，咱们公司以后要做潮流公司了，写代码不再考虑兼容性，我希望你能把公司所有的业务的网络请求都迁移到你这个 HttpUtils 上来，这样以后你只用维护这一个库了，也方便。李雷一听，悲从中来——他是该公司的第 99 代员工，对远古时期的业务一无所知。而该公司第1代员工封装的网络请求库，是基于 XMLHttpRequest 的，差不多长这样： function Ajax(type, url, data, success, failed){ // 创建ajax对象 var xhr = null; if(window.XMLHttpRequest){ xhr = new XMLHttpRequest(); } else { xhr = new ActiveXObject('Microsoft.XMLHTTP') } ...(此处省略一系列的业务逻辑细节) var type = type.toUpperCase(); // 识别请求类型 if(type == 'GET'){ if(data){ xhr.open('GET', url + '?' + data, true); //如果有数据就拼接 } // 发送get请求 xhr.send(); } else if(type == 'POST'){ xhr.open('POST', url, true); // 如果需要像 html 表单那样 POST 数据，使用 setRequestHeader() 来添加 http 头。 xhr.setRequestHeader(\"Content-type\", \"application/x-www-form-urlencoded\"); // 发送post请求 xhr.send(data); } // 处理返回数据 xhr.onreadystatechange = function(){ if(xhr.readyState == 4){ if(xhr.status == 200){ success(xhr.responseText); } else { if(failed){ failed(xhr.status); } } } } } 实现逻辑我们简单描述了一下，这个不是重点，重点是它是这样调用的： // 发送get请求 Ajax('get', url地址, post入参, function(data){ // 成功的回调逻辑 }, function(error){ // 失败的回调逻辑 }) 李雷佛了 —— 不仅接口名不同，入参方式也不一样，这手动改要改到何年何日呢？ 还好李雷学过设计模式，他立刻联想到了专门为我们抹平差异的适配器模式。要把老代码迁移到新接口，不一定要挨个儿去修改每一次的接口调用——正如我们想用 iPhoneX + 旧耳机听歌，不必挨个儿去改造耳机一样，我们只需要在引入接口时进行一次适配，便可轻松地 cover 掉业务里可能会有的多次调用（具体的解析在注释里）： // Ajax适配器函数，入参与旧接口保持一致 async function AjaxAdapter(type, url, data, success, failed) { const type = type.toUpperCase() let result try { // 实际的请求全部由新接口发起 if(type === 'GET') { result = await HttpUtils.get(url) || {} } else if(type === 'POST') { result = await HttpUtils.post(url, data) || {} } // 假设请求成功对应的状态码是1 result.statusCode === 1 && success ? success(result) : failed(result.statusCode) } catch(error) { // 捕捉网络错误 if(failed){ failed(error.statusCode); } } } // 用适配器适配旧的Ajax方法 async function Ajax(type, url, data, success, failed) { await AjaxAdapter(type, url, data, success, failed) } 如此一来，我们只需要编写一个适配器函数AjaxAdapter，并用适配器去承接旧接口的参数，就可以实现新旧接口的无缝衔接了~ 生产实践：axios中的适配器 数月之后，李雷的老板发现了网络请求神库axios，于是团队的方案又整个迁移到了axios——对于心中有适配器的李雷来说，这现在已经根本不是个事儿。不过本小节我们要聊的可不再是“如何使现有接口兼容axios”了（这招我们上个小节学过了）。此处引出axios，一是因为大家对它足够熟悉（不熟悉的同学，点这里可以快速熟悉一下~），二是因为axios本身就用到了我们的适配器模式，它的兼容方案值得我们学习和借鉴。在使用axios时，作为用户我们只需要掌握以下面三个最常用的接口为代表的一套api： // Make a request for a user with a given ID axios.get('/user?ID=12345') .then(function (response) { // handle success console.log(response); }) .catch(function (error) { // handle error console.log(error); }) .then(function () { // always executed }) axios.post('/user', { firstName: 'Fred', lastName: 'Flintstone' }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); axios({ method: 'post', url: '/user/12345', data: { firstName: 'Fred', lastName: 'Flintstone' } }) 便可轻松地发起各种姿势的网络请求，而不用去关心底层的实现细节。除了简明优雅的api之外，axios 强大的地方还在于，它不仅仅是一个局限于浏览器端的库。在Node环境下，我们尝试调用上面的 api，会发现它照样好使 —— axios 完美地抹平了两种环境下api的调用差异，靠的正是对适配器模式的灵活运用。 在 axios 的核心逻辑中，我们可以注意到实际上派发请求的是 dispatchRequest 方法。该方法内部其实主要做了两件事： 数据转换，转换请求体/响应体，可以理解为数据层面的适配； 调用适配器。 调用适配器的逻辑如下： // 若用户未手动配置适配器，则使用默认的适配器 var adapter = config.adapter || defaults.adapter; // dispatchRequest方法的末尾调用的是适配器方法 return adapter(config).then(function onAdapterResolution(response) { // 请求成功的回调 throwIfCancellationRequested(config); // 转换响应体 response.data = transformData( response.data, response.headers, config.transformResponse ); return response; }, function onAdapterRejection(reason) { // 请求失败的回调 if (!isCancel(reason)) { throwIfCancellationRequested(config); // 转换响应体 if (reason && reason.response) { reason.response.data = transformData( reason.response.data, reason.response.headers, config.transformResponse ); } } return Promise.reject(reason); }); 大家注意注释的第一行，“若用户未手动配置适配器，则使用默认的适配器”。手动配置适配器允许我们自定义处理请求，主要目的是为了使测试更轻松。 实际开发中，我们使用默认适配器的频率更高。默认适配器在axios/lib/default.js里是通过getDefaultAdapter方法来获取的： function getDefaultAdapter() { var adapter; // 判断当前是否是node环境 if (typeof process !== 'undefined' && Object.prototype.toString.call(process) === '[object process]') { // 如果是node环境，调用node专属的http适配器 adapter = require('./adapters/http'); } else if (typeof XMLHttpRequest !== 'undefined') { // 如果是浏览器环境，调用基于xhr的适配器 adapter = require('./adapters/xhr'); } return adapter; } 我们再来看看 Node 的 http 适配器和 xhr 适配器大概长啥样： http 适配器： module.exports = function httpAdapter(config) { return new Promise(function dispatchHttpRequest(resolvePromise, rejectPromise) { // 具体逻辑 } } xhr 适配器： module.exports = function xhrAdapter(config) { return new Promise(function dispatchXhrRequest(resolve, reject) { // 具体逻辑 } } 具体逻辑啥样，咱们目前先不关心，有兴趣的同学，可以狠狠地点这里阅读源码。咱们现在就注意两个事儿： 两个适配器的入参都是 config； 两个适配器的出参都是一个 Promise。 Tips：要是仔细读了源码，会发现两个适配器中的 Promise 的内部结构也是如出一辙。 这么一来，通过 axios 发起跨平台的网络请求，不仅调用的接口名是同一个，连入参、出参的格式都只需要掌握同一套。这导致它的学习成本非常低，开发者看了文档就能上手；同时因为足够简单，在使用的过程中也不容易出错，带来了极佳的用户体验，axios 也因此越来越流行。 这正是一个好的适配器的自我修养——把变化留给自己，把统一留给用户。在此处，所有关于 http 模块、关于 xhr 的实现细节，全部被 Adapter 封装进了自己复杂的底层逻辑里，暴露给用户的都是十分简单的统一的东西——统一的接口，统一的入参，统一的出参，统一的规则。用起来就是一个字 —— 爽！ 小结 本节我们除了针对适配器的原理、实践及应用场景进行讨论之外，还花了不少力气来讲 axios。这个操作可能会使一部分不太熟悉 axios 的同学阅读起来更加吃力——因为要想读懂这一节，你或许不得不点开我穿插进去的源码/文档链接先去尝试理解 axios —— 但这其实正是我想鼓励大家去做的事情。 在性能小册的开篇，我说过，希望大家都能去读“纸的背面”。这个“纸的背面”不仅仅是说代码之外的东西，它也可以是一些超越这本书的东西 —— 楼上吹了那么多 axios 的“彩虹屁”，难道本节是 axios 大型夸夸群现场吗？难道 axios 真的完美无缺，无可替代吗？不是的。 笔者洋洋洒洒这么多字，无非是希望给大家打开一个窗口 —— 在过去半年多和读者有直接沟通的这些时间里，我知道很多同学是不读源码的。这个“不读”不一定是不想读，可能只是不敢读，或者说读不动。无论是出于什么原因，在这里我都想告诉大家，开卷有益，源码是非常好的学习材料，它能教会你的东西，比你想象中多得多。 适配器模式的思想可以说是遍地开花，稍微多看几个库，你会发现不仅 axios 在用适配器，其它库也在用。如果哪怕只有一个同学因为今天读了这一节，对这个“看起来很厉害”的 axios 产生了好奇，或者说对读源码这件事情萌生了兴趣、进而刻意地去培养了自己的阅读习惯，那么你在繁忙的工作/学业中抽出的宝贵的用来阅读这一节内容的时间就没有白费，这本小册也算不负使命、远远大于它本身的价值了。 设计模式这座山，诸位已经翻过了半山腰。剩下的路，一起加油！ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/11.结构型：代理模式——一家小型婚介所的发家致富之路.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/11.结构型：代理模式——一家小型婚介所的发家致富之路.html","title":"11.结构型：代理模式——一家小型婚介所的发家致富之路","keywords":"","body":"代理模式，式如其名——在某些情况下，出于种种考虑/限制，一个对象不能直接访问另一个对象，需要一个第三者（代理）牵线搭桥从而间接达到访问目的，这样的模式就是代理模式。 代理模式非常好理解，因为你可能天天都在用，只是没有刻意挖掘过它背后的玄机——比如大家耳熟能详的科学上网，就是代理模式的典型案例。 科学上网背后的故事 科学上网，就是咱们常说的 VPN(虚拟专用网络)。大家知道，正常情况下，我们尝试去访问 Google.com，Chrome会给你一个这样的提示： 这是为啥呢？这就要从网络请求的整个流程说起了。一般情况下，当我们访问一个 url 的时候，会发生下图的过程： 为了屏蔽某些网站，一股神秘的东方力量会作用于你的 DNS 解析过程，告诉它：“你不能解析出xxx.xxx.xxx.xxx（某个特殊ip）的地址”。而我们的 Google.com，不幸地出现在了这串被诅咒的 ip 地址里，于是你的 DNS 会告诉你：“对不起，我查不到”。 但有时候，一部分人为了搞学习，通过访问VPN，是可以间接访问到 Google.com 的。这背后，就是代理模式在给力。在使用VPN时，我们的访问过程是这样的： 没错，比起常规的访问过程，多出了一个第三方 —— 代理服务器。这个第三方的 ip 地址，不在被禁用的那批 ip 地址之列，我们可以顺利访问到这台服务器。而这台服务器的 DNS 解析过程，没有被施加咒语，所以它是可以顺利访问 Google.com 的。代理服务器在请求到 Google.com 后，将响应体转发给你，使你得以间接地访问到目标网址 —— 像这种第三方代替我们访问目标对象的模式，就是代理模式。 婚姻介绍所的故事 我有个同事，技术很强，发型也很强。多年来因为沉迷 coding，耽误了人生大事。迫于寻找另一半的愿望比较急切，该同事同时是多个优质高端婚恋网站的注册VIP。工作之余，他常常给我们分享近期的相亲情感生活进展。 “你们看，这个妹子头像是不是超可爱！”同事哥这天发掘了一个新的婚介所，他举起手机，朝身边几位疯狂挥舞。“哥，那是新垣结衣。。。”同事哥的同桌无奈地摇摇头，没有停下 coding 的手。同事哥恢复了冷静，叹了口气：“这种婚恋平台的机制就是这么严格，一进来只能看到其它会员的姓名、年龄和自我介绍。要想看到本人的照片或者取得对方的联系方式，得先向平台付费成为 VIP 才行。哎，我又要买个 VIP 了。” 我一听，哇，这婚恋平台把代理模式玩挺 6 啊！大家想想，主体是同事 A，目标对象是新垣结衣头像的未知妹子。同事 A 不能直接与未知妹子进行沟通，只能通过第三方（婚介所）间接获取对方的一些信息，他能够获取到的信息和权限，取决于第三方愿意给他什么——这不就是典型的代理模式吗？ 用代理模式开一家婚姻介绍所吧 这样看来，开婚介所确实是个发家致富的好路子。既然暴富的机会就在眼前，那么事不宜迟，我们接下来就一起用 JavaScript 来实现一个小型婚介所。 前置知识： ES6中的Proxy 在 ES6 中，提供了专门以代理角色出现的代理器 —— Proxy。它的基本用法如下： const proxy = new Proxy(obj, handler) 第一个参数是我们的目标对象，也就是上文中的“未知妹子”。handler 也是一个对象，用来定义代理的行为，相当于上文中的“婚介所”。当我们通过 proxy 去访问目标对象的时候，handler会对我们的行为作一层拦截，我们的每次访问都需要经过 handler 这个第三方。 “婚介所”的实现 未知妹子的个人信息，刚问了下我们已经注册了 VIP 的同事哥，大致如下： // 未知妹子 const girl = { // 姓名 name: '小美', // 自我介绍 aboutMe: '...'（大家自行脑补吧） // 年龄 age: 24, // 职业 career: 'teacher', // 假头像 fakeAvatar: 'xxxx'(新垣结衣的图片地址） // 真实头像 avatar: 'xxxx'(自己的照片地址), // 手机号 phone: 123456, } 婚介所收到了小美的信息，开始营业。大家想，这个姓名、自我介绍、假头像，这些信息大差不差，曝光一下没问题。但是人家妹子的年龄、职业、真实头像、手机号码，是不是属于非常私密的信息了？要想 get 这些信息，平台要考验一下你的诚意了 —— 首先，你是不是已经通过了实名审核？如果通过实名审核，那么你可以查看一些相对私密的信息（年龄、职业）。然后，你是不是 VIP ？只有 VIP 可以查看真实照片和联系方式。满足了这两个判定条件，你才可以顺利访问到别人的全部私人信息，不然，就劝退你提醒你去完成认证和VIP购买再来。 // 普通私密信息 const baseInfo = ['age', 'career'] // 最私密信息 const privateInfo = ['avatar', 'phone'] // 用户（同事A）对象实例 const user = { ...(一些必要的个人信息) isValidated: true, isVIP: false, } // 掘金婚介所登场了 const JuejinLovers = new Proxy(girl, { get: function(girl, key) { if(baseInfo.indexOf(key)!==-1 && !user.isValidated) { alert('您还没有完成验证哦') return } //...(此处省略其它有的没的各种校验逻辑) // 此处我们认为只有验证过的用户才可以购买VIP if(user.isValidated && privateInfo.indexOf(key) && !user.isVIP) { alert('只有VIP才可以查看该信息哦') return } } }) 以上主要是 getter 层面的拦截。假设我们还允许会员间互送礼物，每个会员可以告知婚介所自己愿意接受的礼物的价格下限，我们还可以作 setter 层面的拦截。： // 规定礼物的数据结构由type和value组成 const present = { type: '巧克力', value: 60, } // 为用户增开presents字段存储礼物 const girl = { // 姓名 name: '小美', // 自我介绍 aboutMe: '...'（大家自行脑补吧） // 年龄 age: 24, // 职业 career: 'teacher', // 假头像 fakeAvatar: 'xxxx'(新垣结衣的图片地址） // 真实头像 avatar: 'xxxx'(自己的照片地址), // 手机号 phone: 123456, // 礼物数组 presents: [], // 拒收50块以下的礼物 bottomValue: 50, // 记录最近一次收到的礼物 lastPresent: present, } // 掘金婚介所推出了小礼物功能 const JuejinLovers = new Proxy(girl, { get: function(girl, key) { if(baseInfo.indexOf(key)!==-1 && !user.isValidated) { alert('您还没有完成验证哦') return } //...(此处省略其它有的没的各种校验逻辑) // 此处我们认为只有验证过的用户才可以购买VIP if(user.isValidated && privateInfo.indexOf(key) && !user.isVIP) { alert('只有VIP才可以查看该信息哦') return } } set: function(girl, key, val) { // 最近一次送来的礼物会尝试赋值给lastPresent字段 if(key === 'lastPresent') { if(val.value 看来婚介所这条路，真是不太好走。掌握了代理模式的常见使用方式之余，我们也敬这位同事哥是条汉子，希望他早日脱离苦海~ 不过如果认为代理模式的本领仅仅是开个婚介所这么简单，那就太小瞧它了。代理模式在前端领域一直是一种应用十分广泛的设计模式，在下个小节，我们将会选取其中最典型、最实用的四种类型的应用实践，帮助大家掌握代理模式在业务开发中的应用场景和使用方法。 "},"JavaScript设计模式核⼼原理与应⽤实践/12.结构型：代理模式——应用实践范例解析.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/12.结构型：代理模式——应用实践范例解析.html","title":"12.结构型：代理模式——应用实践范例解析","keywords":"","body":"本节我们选取业务开发中最常见的四种代理类型：事件代理、虚拟代理、缓存代理和保护代理来进行讲解。 在实际开发中，代理模式和我们下节要讲的“大 Boss ”观察者模式一样，可以玩出花来。但设计模式这玩意儿就是这样，变体再多、玩得再花，它的核心操作都是死的，套路也是死的——正是这种极强的规律性带来了极高的性价比。相信学完这节后，大家对这点会有更深的感触。 事件代理 事件代理，可能是代理模式最常见的一种应用方式，也是一道实打实的高频面试题。它的场景是一个父元素下有多个子元素，像这样： 事件代理 链接1号 链接2号 链接3号 链接4号 链接5号 链接6号 我们现在的需求是，希望鼠标点击每个 a 标签，都可以弹出“我是xxx”这样的提示。比如点击第一个 a 标签，弹出“我是链接1号”这样的提示。这意味着我们至少要安装 6 个监听函数给 6 个不同的的元素(一般我们会用循环，代码如下所示），如果我们的 a 标签进一步增多，那么性能的开销会更大。 // 假如不用代理模式，我们将循环安装监听函数 const aNodes = document.getElementById('father').getElementsByTagName('a') const aLength = aNodes.length for(let i=0;i考虑到事件本身具有“冒泡”的特性，当我们点击 a 元素时，点击事件会“冒泡”到父元素 div 上，从而被监听到。如此一来，点击事件的监听函数只需要在 div 元素上被绑定一次即可，而不需要在子元素上被绑定 N 次——这种做法就是事件代理，它可以很大程度上提高我们代码的性能。 事件代理的实现 用代理模式实现多个子元素的事件监听，代码会简单很多： // 获取父元素 const father = document.getElementById('father') // 给父元素安装一次监听函数 father.addEventListener('click', function(e) { // 识别是否是目标子元素 if(e.target.tagName === 'A') { // 以下是监听函数的函数体 e.preventDefault() alert(`我是${e.target.innerText}`) } } ) 在这种做法下，我们的点击操作并不会直接触及目标子元素，而是由父元素对事件进行处理和分发、间接地将其作用于子元素，因此这种操作从模式上划分属于代理模式。 虚拟代理 在《性能小册的Lazy-Load小节》，我们介绍了懒加载这种技术，此处强烈建议大家，尤其是近期有校招或跳槽需求的同学，转过头去复习一下这个小节，说不定下一次的面试题里就有原题，这点在该小节的评论区已经有同学佐证了。 我们此处简单地给大家描述一下懒加载是个什么东西：它是针对图片加载时机的优化：在一些图片量比较大的网站，比如电商网站首页，或者团购网站、小游戏首页等。如果我们尝试在用户打开页面的时候，就把所有的图片资源加载完毕，那么很可能会造成白屏、卡顿等现象。 此时我们会采取“先占位、后加载”的方式来展示图片 —— 在元素露出之前，我们给它一个 div 作占位，当它滚动到可视区域内时，再即时地去加载真实的图片资源，这样做既减轻了性能压力、又保住了用户体验。 除了图片懒加载，还有一种操作叫图片预加载。预加载主要是为了避免网络不好、或者图片太大时，页面长时间给用户留白的尴尬。常见的操作是先让这个 img 标签展示一个占位图，然后创建一个 Image 实例，让这个 Image 实例的 src 指向真实的目标图片地址、观察该 Image 实例的加载情况 —— 当其对应的真实图片加载完毕后，即已经有了该图片的缓存内容，再将 DOM 上的 img 元素的 src 指向真实的目标图片地址。此时我们直接去取了目标图片的缓存，所以展示速度会非常快，从占位图到目标图片的时间差会非常小、小到用户注意不到，这样体验就会非常好了。 上面的思路，我们可以不假思索地实现如下 class PreLoadImage { // 占位图的url地址 static LOADING_URL = 'xxxxxx' constructor(imgNode) { // 获取该实例对应的DOM节点 this.imgNode = imgNode } // 该方法用于设置真实的图片地址 setSrc(targetUrl) { // img节点初始化时展示的是一个占位图 this.imgNode.src = PreLoadImage.LOADING_URL // 创建一个帮我们加载图片的Image实例 const image = new Image() // 监听目标图片加载的情况，完成时再将DOM上的img节点的src属性设置为目标图片的url image.onload = () => { this.imgNode.src = targetUrl } // 设置src属性，Image实例开始加载图片 image.src = srcUrl } } 这个 PreLoadImage 乍一看没问题，但其实违反了我们设计原则中的单一职责原则。PreLoadImage 不仅要负责图片的加载，还要负责 DOM 层面的操作（img 节点的初始化和后续的改变）。这样一来，就出现了两个可能导致这个类发生变化的原因。 好的做法是将两个逻辑分离，让 PreLoadImage 专心去做 DOM 层面的事情（真实 DOM 节点的获取、img 节点的链接设置），再找一个对象来专门来帮我们搞加载——这两个对象之间缺个媒婆，这媒婆非代理器不可： class PreLoadImage { constructor(imgNode) { // 获取真实的DOM节点 this.imgNode = imgNode } // 操作img节点的src属性 setSrc(imgUrl) { this.imgNode.src = imgUrl } } class ProxyImage { // 占位图的url地址 static LOADING_URL = 'xxxxxx' constructor(targetImage) { // 目标Image，即PreLoadImage实例 this.targetImage = targetImage } // 该方法主要操作虚拟Image，完成加载 setSrc(targetUrl) { // 真实img节点初始化时展示的是一个占位图 this.targetImage.setSrc(ProxyImage.LOADING_URL) // 创建一个帮我们加载图片的虚拟Image实例 const virtualImage = new Image() // 监听目标图片加载的情况，完成时再将DOM上的真实img节点的src属性设置为目标图片的url virtualImage.onload = () => { this.targetImage.setSrc(targetUrl) } // 设置src属性，虚拟Image实例开始加载图片 virtualImage.src = targetUrl } } ProxyImage 帮我们调度了预加载相关的工作，我们可以通过 ProxyImage 这个代理，实现对真实 img 节点的间接访问，并得到我们想要的效果。 在这个实例中，virtualImage 这个对象是一个“幕后英雄”，它始终存在于 JavaScript 世界中、代替真实 DOM 发起了图片加载请求、完成了图片加载工作，却从未在渲染层面抛头露面。因此这种模式被称为“虚拟代理”模式。 缓存代理 缓存代理比较好理解，它应用于一些计算量较大的场景里。在这种场景下，我们需要“用空间换时间”——当我们需要用到某个已经计算过的值的时候，不想再耗时进行二次计算，而是希望能从内存里去取出现成的计算结果。这种场景下，就需要一个代理来帮我们在进行计算的同时，进行计算结果的缓存了。 一个比较典型的例子，是对传入的参数进行求和： // addAll方法会对你传入的所有参数做求和操作 const addAll = function() { console.log('进行了一次新计算') let result = 0 const len = arguments.length for(let i = 0; i 我们把这个方法丢进控制台，尝试同一套入参两次，结果喜人： 我们发现 proxyAddAll 针对重复的入参只会计算一次，这将大大节省计算过程中的时间开销。现在我们有 6 个入参，可能还看不出来，当我们针对大量入参、做反复计算时，缓存代理的优势将得到更充分的凸显。 保护代理 保护代理，其实在我们上个小节大家就见识过了。此处我们仅作提点，不作重复演示。 开婚介所的时候，为了保护用户的私人信息，我们会在同事哥访问小美的年龄的时候，去校验同事哥是否已经通过了我们的实名认证；为了确保婚介所的利益同事哥确实是一位有诚意的男士，当他想获取小美的联系方式时，我们会校验他是否具有VIP 资格。所谓“保护代理”，就是在访问层面做文章，在 getter 和 setter 函数里去进行校验和拦截，确保一部分变量是安全的。 值得一提的是，上节中我们提到的 Proxy，它本身就是为拦截而生的，所以我们目前实现保护代理时，考虑的首要方案就是 ES6 中的 Proxy。 小结 代理模式行文至此，相信大家都已经做到了心中有数。在本节，我们看到代理模式的目的是十分多样化的，既可以是为了加强控制、拓展功能、提高性能，也可以仅仅是为了优化我们的代码结构、实现功能的解耦。无论是出于什么目的，这种模式的套路就只有一个—— A 不能直接访问 B，A 需要借助一个帮手来访问 B，这个帮手就是代理器。需要代理器出面解决的问题，就是代理模式发光发热的应用场景。 从本小节开始，结构型模式的讲解也将告一段落。下个小节，我们将开始最后的征程，进入行为型模式的世界。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/13.行为型：策略模式——重构小能手，拆分“胖逻辑”.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/13.行为型：策略模式——重构小能手，拆分“胖逻辑”.html","title":"13.行为型：策略模式——重构小能手，拆分“胖逻辑”","keywords":"","body":"前言 策略模式和状态模式属于本书”彩蛋“性质的附加小节。这两种模式理解难度都不大，在面试中也几乎没有什么权重，但是却对大家培养良好的编码习惯和重构意识却大有裨益。针对这两种模式，大家了解、会用即可，不建议大家死磕。 策略模式不太适合一上来就怼概念，容易懵。咱们就先从一个非常贴近业务的需求讲起，大家跟我一起敲完这波代码，自然会知道策略模式是怎么回事儿了。 先来看一个真实场景 有一天，产品经理韩梅梅找到李雷，给李雷提了这么个需求：马上大促要来了，我们本次大促要做差异化询价。啥是差异化询价？就是说同一个商品，我通过在后台给它设置不同的价格类型，可以让它展示不同的价格。具体的逻辑如下： 当价格类型为“预售价”时，满 100 - 20，不满 100 打 9 折 当价格类型为“大促价”时，满 100 - 30，不满 100 打 8 折 当价格类型为“返场价”时，满 200 - 50，不叠加 当价格类型为“尝鲜价”时，直接打 5 折 李雷扫了一眼 prd，立刻来了主意。他首先将四种价格做了标签化： 预售价 - pre 大促价 - onSale 返场价 - back 尝鲜价 - fresh 接下来李雷仔细研读了 prd 的内容，作为资深 if-else 侠，他三下五除二就写出一套功能完备的代码： // 询价方法，接受价格标签和原价为入参 function askPrice(tag, originPrice) { // 处理预热价 if(tag === 'pre') { if(originPrice >= 100) { return originPrice - 20 } return originPrice * 0.9 } // 处理大促价 if(tag === 'onSale') { if(originPrice >= 100) { return originPrice - 30 } return originPrice * 0.8 } // 处理返场价 if(tag === 'back') { if(originPrice >= 200) { return originPrice - 50 } return originPrice } // 处理尝鲜价 if(tag === 'fresh') { return originPrice * 0.5 } } if-else 侠，人人喊打 随便跑一下，上述代码运行起来确实没啥毛病。但也只是“运行起来”没毛病而已。作为人人喊打的 if-else 侠，李雷必须为他的行为付出代价。我们一起来看看这么写代码会带来什么后果： 首先，它违背了“单一功能”原则。一个 function 里面，它竟然处理了四坨逻辑——这个函数的逻辑太胖了！这样会带来什么样的糟糕后果，笔者在前面的小节中已经 BB 过很多次了：比如说万一其中一行代码出了 Bug，那么整个询价逻辑都会崩坏；与此同时出了 Bug 你很难定位到底是哪个代码块坏了事；再比如说单个能力很难被抽离复用等等等等。相信跟着我一路学下来的各位，也已经在重重实战中对胖逻辑的恶劣影响有了切身的体会。总之，见到胖逻辑，我们的第一反应，就是一个字——拆！ 不仅如此，它还违背了“开放封闭”原则。假如有一天韩梅梅再次找到李雷，要他加一个满 100 - 50 的“新人价”怎么办？他只能继续 if-else： function askPrice(tag, originPrice) { // 处理预热价 if(tag === 'pre') { if(originPrice >= 100) { return originPrice - 20 } return originPrice * 0.9 } // 处理大促价 if(tag === 'onSale') { if(originPrice >= 100) { return originPrice - 30 } return originPrice * 0.8 } // 处理返场价 if(tag === 'back') { if(originPrice >= 200) { return originPrice - 50 } return originPrice } // 处理尝鲜价 if(tag === 'fresh') { return originPrice * 0.5 } // 处理新人价 if(tag === 'newUser') { if(originPrice >= 100) { return originPrice - 50 } return originPrice } } 没错，李雷灰溜溜地跑去改了 askPrice 函数！随后他恬不知耻地徐徐转头，对背后的测试同学说：哥，我改了询价函数，麻烦你帮我把整个询价逻辑回归一下。测试同学莞尔一笑， 心中早已有无数头羊驼在狂奔。他强忍着周末加班的悲痛，做完了这漫长而不必要的回归测试，随后默默点击了同事系统里的举报按钮对李雷说：哥，求你学学设计模式吧！！ 重构询价逻辑 现在我们基于我们已经学过的设计模式思想，一点一点改造掉这个臃肿的 askPrice。 单一功能改造 首先，我们赶紧把四种询价逻辑提出来，让它们各自为政： // 处理预热价 function prePrice(originPrice) { if(originPrice >= 100) { return originPrice - 20 } return originPrice * 0.9 } // 处理大促价 function onSalePrice(originPrice) { if(originPrice >= 100) { return originPrice - 30 } return originPrice * 0.8 } // 处理返场价 function backPrice(originPrice) { if(originPrice >= 200) { return originPrice - 50 } return originPrice } // 处理尝鲜价 function freshPrice(originPrice) { return originPrice * 0.5 } function askPrice(tag, originPrice) { // 处理预热价 if(tag === 'pre') { return prePrice(originPrice) } // 处理大促价 if(tag === 'onSale') { return onSalePrice(originPrice) } // 处理返场价 if(tag === 'back') { return backPrice(originPrice) } // 处理尝鲜价 if(tag === 'fresh') { return freshPrice(originPrice) } } OK，我们现在至少做到了一个函数只做一件事。现在每个函数都有了自己明确的、单一的分工： prePrice - 处理预热价 onSalePrice - 处理大促价 backPrice - 处理返场价 freshPrice - 处理尝鲜价 askPrice - 分发询价逻辑 如此一来，我们在遇到 Bug 时，就可以做到“头痛医头，脚痛医脚”，而不必在庞大的逻辑海洋里费力去定位到底是哪块不对。 同时，如果我在另一个函数里也想使用某个询价能力，比如说我想询预热价，那我直接把 prePrice 这个函数拿去调用就是了，而不必在 askPrice 肥胖的身躯里苦苦寻觅、然后掏出这块逻辑、最后再复制粘贴到另一个函数去——更何况万一哪天 askPrice 里的预热价逻辑改了，你还得再复制粘贴一次，扎心啊老铁！ 到这里，在单一功能原则的指引下，我们已经解决了一半的问题。 我们现在来捋一下，其实这个询价逻辑整体上来看只有两个关键动作： 询价逻辑的分发 ——> 询价逻辑的执行 在改造的第一步，我们已经把“询价逻辑的执行”给摘了出去，并且实现了不同询价逻辑之间的解耦。接下来，我们就要拿“分发”这个动作开刀。 开放封闭改造 剩下一半的问题是啥呢？就是咱们上面说的那个新人价的问题——这会儿我要想给 askPrice 增加新人询价逻辑，我该咋整？我只能这么来： // 处理预热价 function prePrice(originPrice) { if(originPrice >= 100) { return originPrice - 20 } return originPrice * 0.9 } // 处理大促价 function onSalePrice(originPrice) { if(originPrice >= 100) { return originPrice - 30 } return originPrice * 0.8 } // 处理返场价 function backPrice(originPrice) { if(originPrice >= 200) { return originPrice - 50 } return originPrice } // 处理尝鲜价 function freshPrice(originPrice) { return originPrice * 0.5 } // 处理新人价 function newUserPrice(originPrice) { if(originPrice >= 100) { return originPrice - 50 } return originPrice } function askPrice(tag, originPrice) { // 处理预热价 if(tag === 'pre') { return prePrice(originPrice) } // 处理大促价 if(tag === 'onSale') { return onSalePrice(originPrice) } // 处理返场价 if(tag === 'back') { return backPrice(originPrice) } // 处理尝鲜价 if(tag === 'fresh') { return freshPrice(originPrice) } // 处理新人价 if(tag === 'newUser') { return newUserPrice(originPrice) } } 在外层，我们编写一个 newUser 函数用于处理新人价逻辑；在 askPrice 里面，我们新增了一个 if-else 判断。可以看出，这样其实还是在修改 askPrice 的函数体，没有实现“对扩展开放，对修改封闭”的效果。 那么我们应该怎么做？我们仔细想想，楼上用了这么多 if-else，我们的目的到底是什么？是不是就是为了把 询价标签-询价函数 这个映射关系给明确下来？那么在 JS 中，有没有什么既能够既帮我们明确映射关系，同时不破坏代码的灵活性的方法呢？答案就是对象映射！ 咱们完全可以把询价算法全都收敛到一个对象里去嘛： // 定义一个询价处理器对象 const priceProcessor = { pre(originPrice) { if (originPrice >= 100) { return originPrice - 20; } return originPrice * 0.9; }, onSale(originPrice) { if (originPrice >= 100) { return originPrice - 30; } return originPrice * 0.8; }, back(originPrice) { if (originPrice >= 200) { return originPrice - 50; } return originPrice; }, fresh(originPrice) { return originPrice * 0.5; }, }; 当我们想使用其中某个询价算法的时候：通过标签名去定位就好了： // 询价函数 function askPrice(tag, originPrice) { return priceProcessor[tag](originPrice) } 如此一来，askPrice 函数里的 if-else 大军彻底被咱们消灭了。这时候如果你需要一个新人价，只需要给 priceProcessor 新增一个映射关系： priceProcessor.newUser = function (originPrice) { if (originPrice >= 100) { return originPrice - 50; } return originPrice; } 这样一来，询价逻辑的分发也变成了一个清清爽爽的过程。当李雷以这种方式新增一个新人价的询价逻辑的时候，就可以底气十足地对测试同学说：老哥，我改了询价逻辑，但是改动范围仅仅涉及到新人价，是一个单纯的功能增加。所以你只测这个新功能点就 OK，老逻辑不用管！ 从此，李雷就从人人喊打的 if-else 侠，摇身一变成为了测试之友、中国好开发。业务代码里的询价逻辑，也因为李雷坚守设计原则100年不动摇，而变得易读、易维护。 这，就是策略模式！ 说起来你可能不相信，咱们上面的整个重构的过程，就是对策略模式的应用。现在大家来品品策略模式的定义： 定义一系列的算法,把它们一个个封装起来, 并且使它们可相互替换。 回头看看，咱们忙活到现在，是不是就干了这事儿？ 但你要直接读这句话，可能确实会懵圈——啥是算法？如何封装？可替换又是咋做到的？ 如今你你已经自己动手实现了算法提取、算法封装、分发优化的整个一条龙的操作流，相信面对这条定义，你可以会心一笑——算法，就是我们这个场景中的询价逻辑，它也可以是你任何一个功能函数的逻辑；“封装”就是把某一功能点对应的逻辑给提出来；“可替换”建立在封装的基础上，只是说这个“替换”的判断过程，咱们不能直接怼 if-else，而要考虑更优的映射方案。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流^_^） "},"JavaScript设计模式核⼼原理与应⽤实践/14.行为型：状态模式——自助咖啡机背后的力量.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/14.行为型：状态模式——自助咖啡机背后的力量.html","title":"14.行为型：状态模式——自助咖啡机背后的力量","keywords":"","body":"状态模式 状态模式和策略模式宛如一对孪生兄弟——它们长得很像、解决的问题也可以说没啥本质上的差别。虽然现在的你可能和本书的主人公李雷一样，对状态模式怀揣着一种“我没见过你所以我觉得你一定很牛x”的敬畏之心。不过没关系，随着我们本节学习过程的展开，你会慢慢体会到状态模式带来的快乐~ 咖啡奇缘一杯咖啡带来的思考 话说最近李雷公司楼下的咖啡机在搞年终促销：平时99820块一杯的香草拿铁，现在不要998只要9块9，价格堪称史低。虽然李雷本身没有喝咖啡的习惯，但是本着“有便宜不占就是吃大亏”的原则，他决定开始喝咖啡——并且要一直喝到这9.9的特价拿铁卖空为止。 每天一杯咖啡，让李雷体会到了做一个精致都市丽人996之余的快乐： 这一天，李雷像往常一样来到了咖啡机面前，大方地用支付宝刷了一个9块9，然后就进入了快乐的等咖啡环节。 这时，他的对口产品经理韩梅梅也过来买咖啡了。韩梅梅看到李雷也喜欢喝香草拿铁，觉得他是一个有品位的男人，便啧啧称赞：“哇，李雷，这是你的香草拿铁啊！”。 李雷莞尔一笑，尽力克制住自己内心对咖啡的渴望，缓缓地展示出了他的绅士风度：“不，这是你的优乐美香草拿铁。我可以等下一杯。“ 韩梅梅喜上眉梢，立刻把刚打好的咖啡牢牢地攥在了自己手里。为了表达对李雷的感谢，她决定陪李雷打完下一杯咖啡。 咖啡机轰轰作响，进入了第二杯咖啡的制作步骤。积极工作的咖啡机引发了韩梅梅的思考，她感慨道：“咖啡机其实也是一个产品。它在不同的选择下有着不同的任务：当我们选择香草拿铁时，它进入香草拿铁的制作工序；当我们选择美式时，它进入美式的制作工序。眼前一台小小的机器，可以根据用户的口味产出四种咖啡，想想也好厉害啊！李雷，听说你们程序员都是万能的，你能把这个过程用程序实现一下吗？” 李雷扶了扶墙、擦了擦额头上的汗，确认自己记住了韩梅梅刚刚语言中描述的需求点，大声吼出了下面这句话： “我们公司又tmd不做咖啡机！我这就给您整一个！” 说罢，李雷便忘记了眼前打好的第二杯咖啡，直接飞回了工位。（此处让我们恭喜韩梅梅智取两杯香草拿铁） 一台咖啡机的诞生 作为一个具备强大抽象思维能力的程序员，李雷没有辜负自己这么多年来学过的现代前端框架。他敏锐地感知到，韩梅梅所说的这些不同的”选择“间的切换，本质就是状态的切换。在这个能做四种咖啡的咖啡机体内，蕴含着四种状态： - 美式咖啡态（american)：只吐黑咖啡 - 普通拿铁态(latte)：黑咖啡加点奶 - 香草拿铁态（vanillaLatte）：黑咖啡加点奶再加香草糖浆 - 摩卡咖啡态(mocha)：黑咖啡加点奶再加点巧克力 嘿嘿，这么一梳理，李雷的思路一下子清晰了起来。作为死性不改的 if-else 侠，他再次三下五除二写出了一套功能完备的代码： class CoffeeMaker { constructor() { /** 这里略去咖啡机中与咖啡状态切换无关的一些初始化逻辑 **/ // 初始化状态，没有切换任何咖啡模式 this.state = 'init'; } // 关注咖啡机状态切换函数 changeState(state) { // 记录当前状态 this.state = state; if(state === 'american') { // 这里用 console 代指咖啡制作流程的业务逻辑 console.log('我只吐黑咖啡'); } else if(state === 'latte') { console.log(`给黑咖啡加点奶`); } else if(state === 'vanillaLatte') { console.log('黑咖啡加点奶再加香草糖浆'); } else if(state === 'mocha') { console.log('黑咖啡加点奶再加点巧克力'); } } } 测试一下，完美无缺： const mk = new CoffeeMaker(); mk.changeState('latte'); // 输出 '给黑咖啡加点奶' 不，我李雷必不可能再做 if-else 侠 望着眼前的代码，他陷入了沉思。他回忆起了那年狂写 if-else 后差点被测试同学毒打的惨痛经历（这段经历很沉重，希望正在读这篇文章的你也没忘，要是你忘了，赶紧跳转回上一个小节复习一下）。 鉴于 if-else 使不得，李雷赶紧翻出了他在策略模式中学到的“单一职责”和“开放封闭”原则，比猫画虎地改造起了自己的咖啡机： 改造咖啡机的状态切换机制 职责分离 首先，映入李雷眼帘最大的问题，就是咖啡制作过程不可复用： changeState(state) { // 记录当前状态 this.state = state; if(state === 'american') { // 这里用 console 代指咖啡制作流程的业务逻辑 console.log('我只吐黑咖啡'); } else if(state === 'latte') { console.log(`给黑咖啡加点奶`); } else if(state === 'vanillaLatte') { console.log('黑咖啡加点奶再加香草糖浆'); } else if(state === 'mocha') { console.log('黑咖啡加点奶再加点巧克力'); } } 李雷发现，这个 changeState 函数，它好好管好自己的事（状态切换）不行吗？怎么连做咖啡的过程也写在这里面？这不合理。 别的不说，就说咱李雷和韩梅梅都欲罢不能的香草拿铁吧：它是啥高深莫测的新品种么？它不是，它就是拿铁加点糖浆。那我至于把做拿铁的逻辑再在香草拿铁里写一遍么——完全不需要！直接调用拿铁制作工序对应的函数，然后末尾补个加糖浆的动作就行了——可惜，我们现在所有的制作工序都没有提出来函数化，而是以一种极不优雅的姿势挤在了 changeState 里面，谁也别想复用谁。太费劲了，咱们赶紧给它搞一搞职责分离： class CoffeeMaker { constructor() { /** 这里略去咖啡机中与咖啡状态切换无关的一些初始化逻辑 **/ // 初始化状态，没有切换任何咖啡模式 this.state = 'init'; } changeState(state) { // 记录当前状态 this.state = state; if(state === 'american') { // 这里用 console 代指咖啡制作流程的业务逻辑 this.americanProcess(); } else if(state === 'latte') { this.latteProcress(); } else if(state === 'vanillaLatte') { this.vanillaLatteProcress(); } else if(state === 'mocha') { this.mochaProcress(); } } americanProcess() { console.log('我只吐黑咖啡'); } latteProcress() { this.americanProcess(); console.log('加点奶'); } vanillaLatteProcress() { this.latteProcress(); console.log('再加香草糖浆'); } mochaProcress() { this.latteProcress(); console.log('再加巧克力'); } } const mk = new CoffeeMaker(); mk.changeState('latte'); 输出结果符合预期： 我只吐黑咖啡 加点奶 开放封闭 复用的问题解决了，if-else 却仍然活得好好的。现在咱们假如要增加”气泡美式“这个咖啡品种，就不得不去修改 changeState 的函数逻辑，这违反了开放封闭的原则。同时，一个函数里收敛这么多判断，也着实不够体面。咱们现在要像策略模式一样，想办法把咖啡机状态和咖啡制作工序之间的映射关系（也就是咱们上节谈到的分发过程）用一个更优雅地方式做掉。如果你策略模式掌握得足够好，你会第一时间反映出对象映射的方案： const stateToProcessor = { american() { console.log('我只吐黑咖啡'); }, latte() { this.american(); console.log('加点奶'); }, vanillaLatte() { this.latte(); console.log('再加香草糖浆'); }, mocha() { this.latte(); console.log('再加巧克力'); } } class CoffeeMaker { constructor() { /** 这里略去咖啡机中与咖啡状态切换无关的一些初始化逻辑 **/ // 初始化状态，没有切换任何咖啡模式 this.state = 'init'; } // 关注咖啡机状态切换函数 changeState(state) { // 记录当前状态 this.state = state; // 若状态不存在，则返回 if(!stateToProcessor[state]) { return ; } stateToProcessor[state](); } } const mk = new CoffeeMaker(); mk.changeState('latte'); 输出结果符合预期： 我只吐黑咖啡 加点奶 当我们这么做时，其实已经实现了一个 js 版本的状态模式。 但这里有一点大家需要引起注意：这种方法仅仅是看上去完美无缺，其中却暗含一个非常重要的隐患——stateToProcessor 里的工序函数，感知不到咖啡机的内部状况。 策略与状态的辨析 怎么理解这个问题？大家知道，策略模式是对算法的封装。算法和状态对应的行为函数虽然本质上都是行为，但是算法的独立性可高多了。 比如说我一个询价算法，我只需要读取一个数字，我就能啪啪三下五除二给你吐出另一个数字作为返回结果——它和计算主体之间可以是分离的，我们只要关注计算逻辑本身就可以了。 但状态可不一样了。拿咱们咖啡机来说，为了好懂，咱写代码的时候把真正咖啡的制作工序用 console 来表示了。但大家都知道，做咖啡要考虑的东西可太多了。 比如咱们做拿铁，拿铁里的牛奶从哪来，是不是从咖啡机的某个储物空间里去取？再比如我们行为函数是不是应该时刻感知咖啡机每种原材料的用量、进而判断自己的工序还能不能如期执行下去？这就决定了行为函数必须能很方便地拿到咖啡机这个主体的各种信息——它必须得对主体有感知才行。 策略模式和状态模式确实是相似的，它们都封装行为、都通过委托来实现行为分发。但策略模式中的行为函数是”潇洒“的行为函数，它们不依赖调用主体、互相平行、各自为政，井水不犯河水。而状态模式中的行为函数，首先是和状态主体之间存在着关联，由状态主体把它们串在一起；另一方面，正因为关联着同样的一个（或一类）主体，所以不同状态对应的行为函数可能并不会特别割裂。 进一步改造 按照我们这一通描述，当务之急是要把咖啡机和它的状态处理函数建立关联。 如果你读过一些早期的设计模式教学资料，有一种思路是将每一个状态所对应的的一些行为抽象成类，然后通过传递 this 的方式来关联状态和状态主体。这种思路也可以，不过它一般还需要你实现抽象工厂，比较麻烦。实际业务中这种做法极为少见。我这里要给大家介绍的是一种更方便也更常用的解决方案——非常简单，把状态-行为映射对象作为主体类对应实例的一个属性添加进去就行了： class CoffeeMaker { constructor() { /** 这里略去咖啡机中与咖啡状态切换无关的一些初始化逻辑 **/ // 初始化状态，没有切换任何咖啡模式 this.state = 'init'; // 初始化牛奶的存储量 this.leftMilk = '500ml'; } stateToProcessor = { that: this, american() { // 尝试在行为函数里拿到咖啡机实例的信息并输出 console.log('咖啡机现在的牛奶存储量是:', this.that.leftMilk) console.log('我只吐黑咖啡'); }, latte() { this.american() console.log('加点奶'); }, vanillaLatte() { this.latte(); console.log('再加香草糖浆'); }, mocha() { this.latte(); console.log('再加巧克力'); } } // 关注咖啡机状态切换函数 changeState(state) { this.state = state; if (!this.stateToProcessor[state]) { return; } this.stateToProcessor[state](); } } const mk = new CoffeeMaker(); mk.changeState('latte'); 输出结果为： 咖啡机现在的牛奶存储量是: 500ml 我只吐黑咖啡 加点奶 如此一来，我们就可以在 stateToProcessor 轻松拿到咖啡机的实例对象，进而感知咖啡机这个主体了。 状态模式复盘 和策略模式一样，咱们仍然是敲完代码之后，一起来复盘一下状态模式的定义： 状态模式(State Pattern) ：允许一个对象在其内部状态改变时改变它的行为，对象看起来似乎修改了它的类。 这个定义比较粗糙，可能你读完仍然 get 不到它想让你干啥。这时候，我们就应该把目光转移到它解决的问题上来： 状态模式主要解决的是当控制一个对象状态的条件表达式过于复杂时的情况。把状态的判断逻辑转移到表示不同状态的一系列类中，可以把复杂的判断逻辑简化。 仔细回忆一下我们这节做的事情，也确实就是这么回事儿。 唯一的区别在于，定义里强调了”类“的概念。但我们的示例中，包括大家今后的实践中，一个对象的状态如果复杂到了你不得不给它的每 N 种状态划分为一类、一口气划分很多类这种程度，我更倾向于你去反思一个这个对象是不是做太多事情了。事实上，在大多数场景下，我们的行为划分，都是可以像本节一样，控制在”函数“这个粒度的。 尾声 从此李雷和韩梅梅每天都一起喝一杯香草拿铁，过上了幸福的生活^_^。 可能很多同学会觉得这一节李雷和韩梅梅的画风有点清奇（事实也确实如此）。这也算是作者有意为之——作为本书最后一个更新上来的小节，它完成于圣诞前夕，也算是作为一个节日彩蛋送给大家。希望大家在学到实实在在的技术之余，也能感受到阅读的快乐（沾沾节庆的喜气，哈哈~）。 不过更重要的原因，倒不是节日不节日的，而是因为前几天我在我答不完的读者提问中，看到了这么一个清新脱俗的问题： 真是非常有趣，无意中甩出的一个梗，竟然会有人这么在意（他加了我以后就给我说了这么一件事）。干脆一不做二不休，在状态模式给他俩一个美好结局了，哈哈。 这里也希望大家在即将到来的2020年里，学好技术，用好设计模式、升职加薪走上人生巅峰（要是能像李雷一样凭借优秀的自身实力脱个单，那就更好了哈~~）。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流） "},"JavaScript设计模式核⼼原理与应⽤实践/15.行为型：观察者模式——鬼故事：产品经理拉了一个钉钉群.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/15.行为型：观察者模式——鬼故事：产品经理拉了一个钉钉群.html","title":"15.行为型：观察者模式——鬼故事：产品经理拉了一个钉钉群","keywords":"","body":" 观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个目标对象，当这个目标对象的状态发生变化时，会通知所有观察者对象，使它们能够自动更新。 —— Graphic Design Patterns 观察者模式，是所有 JavaScript 设计模式中使用频率最高，面试频率也最高的设计模式，所以说它十分重要——如果我是面试官，考虑到面试时间有限、设计模式这块不能多问，我可能在考查你设计模式的时候只会问观察者模式这一个模式。该模式的权重极高，我们此处会花费两个较长的章节把它掰碎嚼烂了来掌握。 重点不一定是难点。观察者模式十分重要，但它并不抽象，理解难度不大。这种模式不仅在业务开发中遍地开花，在日常生活中也是非常常见的。为了帮助大家形成初步的理解，在进入代码世界之前，我们照例来看一段日常： 生活中的观察者模式 周一刚上班，前端开发李雷就被产品经理韩梅梅拉进了一个钉钉群——“员工管理系统需求第99次变更群”。这个群里不仅有李雷，还有后端开发 A，测试同学 B。三位技术同学看到这简单直白的群名便立刻做好了接受变更的准备、打算撸起袖子开始干了。此时韩梅梅却说：“别急，这个需求有问题，我需要和业务方再确认一下，大家先各忙各的吧”。这种情况下三位技术同学不必立刻投入工作，但他们都已经做好了本周需要做一个新需求的准备，时刻等待着产品经理的号召。 一天过去了，两天过去了。周三下午，韩梅梅终于和业务方确认了所有的需求细节，于是在“员工管理系统需求第99次变更群”里大吼一声：“需求文档来了！”，随后甩出了\"需求文档.zip\"文件，同时@所有人。三位技术同学听到熟悉的“有人@我”提示音，立刻点开群进行群消息和群文件查收，随后根据群消息和群文件提供的需求信息，投入到了各自的开发里。上述这个过程，就是一个典型的观察者模式。 重点角色对号入座 观察者模式有一个“别名”，叫发布 - 订阅模式（之所以别名加了引号，是因为两者之间存在着细微的差异，下个小节里我们会讲到这点）。这个别名非常形象地诠释了观察者模式里两个核心的角色要素——“发布者”与“订阅者”。在上述的过程中，需求文档（目标对象）的发布者只有一个——产品经理韩梅梅。而需求信息的接受者却有多个——前端、后端、测试同学，这些同学的共性就是他们需要根据需求信息开展自己后续的工作、因此都非常关心这个需求信息，于是不得不时刻关注着这个群的群消息提醒，他们是实打实的订阅者，即观察者对象。 现在我们再回过头来看一遍开头我们提到的略显抽象的定义： 观察者模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个目标对象，当这个目标对象的状态发生变化时，会通知所有观察者对象，使它们能够自动更新。 在我们上文这个钉钉群里，一个需求信息对象对应了多个观察者（技术同学），当需求信息对象的状态发生变化（从无到有）时，产品经理通知了群里的所有同学，以便这些同学接收信息进而开展工作：角色划分 --> 状态变化 --> 发布者通知到订阅者，这就是观察者模式的“套路”。 在实践中理解定义 结合我们上面的分析，现在大家知道，在观察者模式里，至少应该有两个关键角色是一定要出现的——发布者和订阅者。用面向对象的方式表达的话，那就是要有两个类。 首先我们来看这个代表发布者的类，我们给它起名叫Publisher。这个类应该具备哪些“基本技能”呢？大家回忆一下上文中的韩梅梅，韩梅梅的基本操作是什么？首先是拉群（增加订阅者），然后是@所有人（通知订阅者），这俩是最明显的了。此外作为群主&产品经理，韩梅梅还具有踢走项目组成员（移除订阅者）的能力。OK，产品经理发布者类的三个基本能力齐了，下面我们开始写代码： // 定义发布者类 class Publisher { constructor() { this.observers = [] console.log('Publisher created') } // 增加订阅者 add(observer) { console.log('Publisher.add invoked') this.observers.push(observer) } // 移除订阅者 remove(observer) { console.log('Publisher.remove invoked') this.observers.forEach((item, i) => { if (item === observer) { this.observers.splice(i, 1) } }) } // 通知所有订阅者 notify() { console.log('Publisher.notify invoked') this.observers.forEach((observer) => { observer.update(this) }) } } ok，搞定了发布者，我们一起来想想订阅者能干啥——其实订阅者的能力非常简单，作为被动的一方，它的行为只有两个——被通知、去执行（本质上是接受发布者的调用，这步我们在Publisher中已经做掉了）。既然我们在Publisher中做的是方法调用，那么我们在订阅者类里要做的就是方法的定义： // 定义订阅者类 class Observer { constructor() { console.log('Observer created') } update() { console.log('Observer.update invoked') } } 以上，我们就完成了最基本的发布者和订阅者类的设计和编写。在实际的业务开发中，我们所有的定制化的发布者/订阅者逻辑都可以基于这两个基本类来改写。比如我们可以通过拓展发布者类，来使所有的订阅者来监听某个特定状态的变化。仍然以开篇的例子为例，我们让开发者们来监听需求文档（prd）的变化： // 定义一个具体的需求文档（prd）发布类 class PrdPublisher extends Publisher { constructor() { super() // 初始化需求文档 this.prdState = null // 韩梅梅还没有拉群，开发群目前为空 this.observers = [] console.log('PrdPublisher created') } // 该方法用于获取当前的prdState getState() { console.log('PrdPublisher.getState invoked') return this.prdState } // 该方法用于改变prdState的值 setState(state) { console.log('PrdPublisher.setState invoked') // prd的值发生改变 this.prdState = state // 需求文档变更，立刻通知所有开发者 this.notify() } } 作为订阅方，开发者的任务也变得具体起来：接收需求文档、并开始干活： class DeveloperObserver extends Observer { constructor() { super() // 需求文档一开始还不存在，prd初始为空对象 this.prdState = {} console.log('DeveloperObserver created') } // 重写一个具体的update方法 update(publisher) { console.log('DeveloperObserver.update invoked') // 更新需求文档 this.prdState = publisher.getState() // 调用工作函数 this.work() } // work方法，一个专门搬砖的方法 work() { // 获取需求文档 const prd = this.prdState // 开始基于需求文档提供的信息搬砖。。。 ... console.log('996 begins...') } } 下面，我们可以 new 一个 PrdPublisher 对象（产品经理），她可以通过调用 setState 方法来更新需求文档。需求文档每次更新，都会紧接着调用 notify 方法来通知所有开发者，这就实现了定义里所谓的： 目标对象的状态发生变化时，会通知所有观察者对象，使它们能够自动更新。 OK，下面我们来看看韩梅梅和她的小伙伴们是如何搞事情的吧： // 创建订阅者：前端开发李雷 const liLei = new DeveloperObserver() // 创建订阅者：服务端开发小A（sorry。。。起名字真的太难了） const A = new DeveloperObserver() // 创建订阅者：测试同学小B const B = new DeveloperObserver() // 韩梅梅出现了 const hanMeiMei = new PrdPublisher() // 需求文档出现了 const prd = { // 具体的需求内容 ... } // 韩梅梅开始拉群 hanMeiMei.add(liLei) hanMeiMei.add(A) hanMeiMei.add(B) // 韩梅梅发送了需求文档，并@了所有人 hanMeiMei.setState(prd) 以上，就是观察者模式在代码世界里的完整实现流程了。 相信走到这一步，大家对观察者模式的核心思想、基本实现模式都有了不错的掌握。下面我们趁热打铁，一起来看看如何凭借观察者模式，在面试中表演真正的技术~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/16.行为型：观察者模式——面试真题手把手教学.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/16.行为型：观察者模式——面试真题手把手教学.html","title":"16.行为型：观察者模式——面试真题手把手教学","keywords":"","body":"上节我们说过，观察者模式作为一个超高频考点，在设计模式中具有举足轻重的地位。单从面试的维度来说，说它是最重要的设计模式也不为过。正因为如此，它的面试题变体可以说是五花八门。 不过面试题这东西，和数学题一样，看似变化多端，实则大同小异。大家如果经历的面试足够多，会发现观察者模式考来考去也就是那么几种考法，所谓的“变化多端”，也无非是改个条件改个变量的事情。本节在梳理了大量相关面试题的基础上，为大家总结了观察者模式的四个出题方向。相信有了本节的加持和下节的强化，大家再和面试官聊到观察者模式时，一定可以滔滔不绝、轻松拿下~ Vue数据双向绑定（响应式系统）的实现原理 解析 Vue 框架是热门的渐进式 JavaScript框架。在 Vue 中，当我们修改状态时，视图会随之更新，这就是Vue的数据双向绑定（又称响应式原理）。数据双向绑定是Vue 最独特的特性之一。如果读者没有接触过 Vue，强烈建议阅读Vue官方对响应式原理的介绍。此处我们用官方的一张流程图来简要地说明一下Vue响应式系统的整个流程： 在 Vue 中，每个组件实例都有相应的 watcher 实例对象，它会在组件渲染的过程中把属性记录为依赖，之后当依赖项的 setter 被调用时，会通知 watcher 重新计算，从而致使它关联的组件得以更新——这是一个典型的观察者模式。这道面试题考察了受试者对Vue底层原理的理解、对观察者模式的实现能力以及一系列重要的JS知识点，具有较强的综合性和代表性。 值得注意的是，在面试过程中，面试官多数情况下不会要求大家写出完整的响应式原理实现代码，而是要求你“说说自己的理解”。在本节，我们不会带大家一行一行写代码（具体深入Vue框架的相关知识，建议大家阅读Vue源码及这本专门写Vue的小册。），而是针对Vue响应式系统中与观察者模式紧密关联的这部分知识作讲解，帮助大家捋清楚整套流程里的来龙去脉、加深对观察者模式的理解。 在Vue数据双向绑定的实现逻辑里，有这样三个关键角色： observer（监听器）：注意，此 observer 非彼 observer。在我们上节的解析中，observer 作为设计模式中的一个角色，代表“订阅者”。但在Vue数据双向绑定的角色结构里，所谓的 observer 不仅是一个数据监听器，它还需要对监听到的数据进行转发——也就是说它同时还是一个发布者。 watcher（订阅者）：observer 把数据转发给了真正的订阅者——watcher对象。watcher 接收到新的数据后，会去更新视图。 compile（编译器）：MVVM 框架特有的角色，负责对每个节点元素指令进行扫描和解析，指令的数据初始化、订阅者的创建这些“杂活”也归它管~这三者的配合过程如图所示： OK，实现方案搞清楚了，下面我们给整个流程中涉及到发布-订阅这一模式的代码来个特写： 核心代码 实现observer 首先我们需要实现一个方法，这个方法会对需要监听的数据对象进行遍历、给它的属性加上定制的 getter 和 setter 函数。这样但凡这个对象的某个属性发生了改变，就会触发 setter 函数，进而通知到订阅者。这个 setter 函数，就是我们的监听器： // observe方法遍历并包装对象属性 function observe(target) { // 若target是一个对象，则遍历它 if(target && typeof target === 'object') { Object.keys(target).forEach((key)=> { // defineReactive方法会给目标属性装上“监听器” defineReactive(target, key, target[key]) }) } } // 定义defineReactive方法 function defineReactive(target, key, val) { // 属性值也可能是object类型，这种情况下需要调用observe进行递归遍历 observe(val) // 为当前属性安装监听器 Object.defineProperty(target, key, { // 可枚举 enumerable: true, // 不可配置 configurable: false, get: function () { return val; }, // 监听器函数 set: function (value) { console.log(`${target}属性的${key}属性从${val}值变成了了${value}`) val = value } }); } 下面实现订阅者 Dep： // 定义订阅者类Dep class Dep { constructor() { // 初始化订阅队列 this.subs = [] } // 增加订阅者 addSub(sub) { this.subs.push(sub) } // 通知订阅者（是不是所有的代码都似曾相识？） notify() { this.subs.forEach((sub)=>{ sub.update() }) } } 现在我们可以改写 defineReactive 中的 setter 方法，在监听器里去通知订阅者了： function defineReactive(target, key, val) { const dep = new Dep() // 监听当前属性 observe(val) Object.defineProperty(target, key, { set: (value) => { // 通知所有订阅者 dep.notify() } }) } 实现一个Event Bus/ Event Emitter Event Bus（Vue、Flutter 等前端框架中有出镜）和 Event Emitter（Node中有出镜）出场的“剧组”不同，但是它们都对应一个共同的角色——全局事件总线。全局事件总线，严格来说不能说是观察者模式，而是发布-订阅模式（具体的概念甄别我们会在下个小节着重讲）。它在我们日常的业务开发中应用非常广。 上节开篇我说过，如果只能考一个设计模式的面试题，我一定会出观察者模式。 这句话接着往下说，如果只能选一道题，那这道题一定是 Event Bus/Event Emitter 的代码实现——我都说这么清楚了，这个知识点到底要不要掌握、需要掌握到什么程度，就看各位自己的了。 在Vue中使用Event Bus来实现组件间的通讯 Event Bus/Event Emitter 作为全局事件总线，它起到的是一个沟通桥梁的作用。我们可以把它理解为一个事件中心，我们所有事件的订阅/发布都不能由订阅方和发布方“私下沟通”，必须要委托这个事件中心帮我们实现。在Vue中，有时候 A 组件和 B 组件中间隔了很远，看似没什么关系，但我们希望它们之间能够通信。这种情况下除了求助于 Vuex 之外，我们还可以通过 Event Bus 来实现我们的需求。 创建一个 Event Bus（本质上也是 Vue 实例）并导出： const EventBus = new Vue() export default EventBus 在主文件里引入EventBus，并挂载到全局： import bus from 'EventBus的文件路径' Vue.prototype.bus = bus 订阅事件： // 这里func指someEvent这个事件的监听函数 this.bus.$on('someEvent', func) 发布（触发）事件： // 这里params指someEvent这个事件被触发时回调函数接收的入参 this.bus.$emit('someEvent', params) 大家会发现，整个调用过程中，没有出现具体的发布者和订阅者（比如上节的PrdPublisher和DeveloperObserver），全程只有bus这个东西一个人在疯狂刷存在感。这就是全局事件总线的特点——所有事件的发布/订阅操作，必须经由事件中心，禁止一切“私下交易”！ 下面，我们就一起来实现一个Event Bus（注意看注释里的解析）： class EventEmitter { constructor() { // handlers是一个map，用于存储事件与回调之间的对应关系 this.handlers = {} } // on方法用于安装事件监听器，它接受目标事件名和回调函数作为参数 on(eventName, cb) { // 先检查一下目标事件名有没有对应的监听函数队列 if (!this.handlers[eventName]) { // 如果没有，那么首先初始化一个监听函数队列 this.handlers[eventName] = [] } // 把回调函数推入目标事件的监听函数队列里去 this.handlers[eventName].push(cb) } // emit方法用于触发目标事件，它接受事件名和监听函数入参作为参数 emit(eventName, ...args) { // 检查目标事件是否有监听函数队列 if (this.handlers[eventName]) { // 如果有，则逐个调用队列里的回调函数 this.handlers[eventName].forEach((callback) => { callback(...args) }) } } // 移除某个事件回调队列里的指定回调函数 off(eventName, cb) { const callbacks = this.handlers[eventName] const index = callbacks.indexOf(cb) if (index !== -1) { callbacks.splice(index, 1) } } // 为事件注册单次监听器 once(eventName, cb) { // 对回调函数进行包装，使其执行完毕自动被移除 const wrapper = (...args) => { cb.apply(...args) this.off(eventName, wrapper) } this.on(eventName, wrapper) } } 在日常的开发中，大家用到EventBus/EventEmitter往往提供比这五个方法多的多的多的方法。但在面试过程中，如果大家能够完整地实现出这五个方法，已经非常可以说明问题了，因此楼上这个EventBus希望大家可以熟练掌握。学有余力的同学，推荐阅读FaceBook推出的通用EventEmiiter库的源码，相信你会有更多收获。 观察者模式与发布-订阅模式的区别是什么？ 在面试过程中，一些对细节比较在意的面试官可能会追问观察者模式与发布-订阅模式的区别。这个问题可能会引发一些同学的不适，因为在大量参考资料以及已出版的纸质书籍中，都会告诉大家“发布-订阅模式和观察者模式是同一个东西的两个名字”。本书在前文的叙述中，也没有突出强调两者的区别。其实这两个模式，要较起真来，确实不能给它们划严格的等号。 为什么大家都喜欢给它们强行划等号呢？这是因为就算划了等号，也不影响我们正常使用，毕竟两者在核心思想、运作机制上没有本质的差别。但考虑到这个问题确实可以成为面试题的一个方向，此处我们还是单独拿出来讲一下。 回到我们上文的例子里。韩梅梅把所有的开发者拉了一个群，直接把需求文档丢给每一位群成员，这种发布者直接触及到订阅者的操作，叫观察者模式。但如果韩梅梅没有拉群，而是把需求文档上传到了公司统一的需求平台上，需求平台感知到文件的变化、自动通知了每一位订阅了该文件的开发者，这种发布者不直接触及到订阅者、而是由统一的第三方来完成实际的通信的操作，叫做发布-订阅模式。 相信大家也已经看出来了，观察者模式和发布-订阅模式之间的区别，在于是否存在第三方、发布者能否直接感知订阅者（如图所示）。 观察者模式 发布-订阅模式 在我们见过的这些例子里，韩梅梅拉钉钉群的操作，就是典型的观察者模式；而通过EventBus去实现事件监听/发布，则属于发布-订阅模式。 既生瑜，何生亮？既然有了观察者模式，为什么还需要发布-订阅模式呢？ 大家思考一下：为什么要有观察者模式？观察者模式，解决的其实是模块间的耦合问题，有它在，即便是两个分离的、毫不相关的模块，也可以实现数据通信。但观察者模式仅仅是减少了耦合，并没有完全地解决耦合问题——被观察者必须去维护一套观察者的集合，这些观察者必须实现统一的方法供被观察者调用，两者之间还是有着说不清、道不明的关系。 而发布-订阅模式，则是快刀斩乱麻了——发布者完全不用感知订阅者，不用关心它怎么实现回调方法，事件的注册和触发都发生在独立于双方的第三方平台（事件总线）上。发布-订阅模式下，实现了完全地解耦。 但这并不意味着，发布-订阅模式就比观察者模式“高级”。在实际开发中，我们的模块解耦诉求并非总是需要它们完全解耦。如果两个模块之间本身存在关联，且这种关联是稳定的、必要的，那么我们使用观察者模式就足够了。而在模块与模块之间独立性较强、且没有必要单纯为了数据通信而强行为两者制造依赖的情况下，我们往往会倾向于使用发布-订阅模式。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/17.行为型：迭代器模式——真·遍历专家.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/17.行为型：迭代器模式——真·遍历专家.html","title":"17.行为型：迭代器模式——真·遍历专家","keywords":"","body":" 迭代器模式提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴露该对象的内部表示。 ——《设计模式：可复用面向对象软件的基础》 迭代器模式是设计模式中少有的目的性极强的模式。所谓“目的性极强”就是说它不操心别的，它就解决这一个问题——遍历。 “公元前”的迭代器模式 遍历作为一种合理、高频的使用需求，几乎没有语言会要求它的开发者手动去实现。在JS中，本身也内置了一个比较简陋的数组迭代器的实现——Array.prototype.forEach。 通过调用forEach方法，我们可以轻松地遍历一个数组： const arr = [1, 2, 3] arr.forEach((item, index)=>{ console.log(`索引为${index}的元素是${item}`) }) 但forEach方法并不是万能的，比如下面这种场景： 事件代理 链接1号 链接2号 链接3号 链接4号 链接5号 链接6号 我想拿到所有的a标签，我可以这样做： const aNodes = document.getElementsByTagName('a') console.log('aNodes are', aNodes) 我想取其中一个a标签，可以这样做： const aNode = aNodes[i] 在这个操作的映衬下，aNodes看上去多么像一个数组啊！但当你尝试用数组的原型方法去遍历它时： aNodes.forEach((aNode, index){ console.log(aNode, index) }) 你发现报错了： 震惊，原来这个aNodes是个假数组！准确地说，它是一个类数组对象，并没有为你实现好用的forEach方法。也就是说，要想实现类数组的遍历，你得另请高明。 现在问题就出现了：普通数组是不是集合？是！aNodes是不是集合？是！同样是集合，同样有遍历需求，我们却要针对不同的数据结构执行不同的遍历手段，好累！再回头看看迭代器的定义是什么——遍历集合的同时，我们不需要关心集合的内部结构。而forEach只能做到允许我们不关心数组这一种集合的内部结构，看来想要一套统一的遍历方案，我们非得请出一个更强的通用迭代器不可了。 这个小节的标题定语里有三个字“公元前”，这个“公元前”怎么定义呢？其实它说的就是ES标准内置迭代器之前的那些日子——差不多四五年之前，彼时还没有这么多轮子，jQuery风头正盛。当时面试可不问什么Vue原理、React原理、Webpack这些，当时问的最多的是你读过jQuery源码吗？答读过，好，那咱们就有的聊了。答没有？fine，看来你只是个调包侠，回见吧——因为前端的技术点在那时还很有限，所以可考察的东西也就这么点，读jQuery源码的程序员和不读jQuery源码的程序员在面试官眼里有着质的区别。但这也从一个侧面反映出来，jQuery这个库其实是非常优秀的，至少jQuery里有太多优秀的设计模式可以拿来考考你。就包括咱们当年想用一个真·迭代器又不想自己搞的时候，也是请jQuery实现的迭代器来帮忙： 首先我们要在页面里引入jQuery： 借助jQuery的each方法，我们可以用同一套遍历规则遍历不同的集合对象： const arr = [1, 2, 3] const aNodes = document.getElementsByTagName('a') $.each(arr, function (index, item) { console.log(`数组的第${index}个元素是${item}`) }) $.each(aNodes, function (index, aNode) { console.log(`DOM类数组的第${index}个元素是${aNode.innerText}`) }) 输出结果完全没问题： 当然啦，遍历jQuery自己的集合对象也不在话下： const jQNodes = $('a') $.each(jQNodes, function (index, aNode) { console.log(`jQuery集合的第${index}个元素是${aNode.innerText}`) }) 输出结果仍然没问题： 可以看出，jQuery的迭代器为我们统一了不同类型集合的遍历方式，使我们在访问集合内每一个成员时不用去关心集合本身的内部结构以及集合与集合间的差异，这就是迭代器存在的价值~ ES6对迭代器的实现 在“公元前”，JS原生的集合类型数据结构，只有Array（数组）和Object（对象）；而ES6中，又新增了Map和Set。四种数据结构各自有着自己特别的内部实现，但我们仍期待以同样的一套规则去遍历它们，所以ES6在推出新数据结构的同时也推出了一套统一的接口机制——迭代器（Iterator）。 ES6约定，任何数据结构只要具备Symbol.iterator属性（这个属性就是Iterator的具体实现，它本质上是当前数据结构默认的迭代器生成函数），就可以被遍历——准确地说，是被for...of...循环和迭代器的next方法遍历。 事实上，for...of...的背后正是对next方法的反复调用。 在ES6中，针对Array、Map、Set、String、TypedArray、函数的 arguments 对象、NodeList 对象这些原生的数据结构都可以通过for...of...进行遍历。原理都是一样的，此处我们拿最简单的数组进行举例，当我们用for...of...遍历数组时： const arr = [1, 2, 3] const len = arr.length for(item of arr) { console.log(`当前元素是${item}`) } 之所以能够按顺序一次一次地拿到数组里的每一个成员，是因为我们借助数组的Symbol.iterator生成了它对应的迭代器对象，通过反复调用迭代器对象的next方法访问了数组成员，像这样： const arr = [1, 2, 3] // 通过调用iterator，拿到迭代器对象 const iterator = arr[Symbol.iterator]() // 对迭代器对象执行next，就能逐个访问集合的成员 iterator.next() iterator.next() iterator.next() 丢进控制台，我们可以看到next每次会按顺序帮我们访问一个集合成员： 而for...of...做的事情，基本等价于下面这通操作： // 通过调用iterator，拿到迭代器对象 const iterator = arr[Symbol.iterator]() // 初始化一个迭代结果 let now = { done: false } // 循环往外迭代成员 while(!now.done) { now = iterator.next() if(!now.done) { console.log(`现在遍历到了${now.value}`) } } 可以看出，for...of...其实就是iterator循环调用换了种写法。在ES6中我们之所以能够开心地用for...of...遍历各种各种的集合，全靠迭代器模式在背后给力。 ps：此处推荐阅读迭代协议，相信大家读过后会对迭代器在ES6中的实现有更深的理解。 一起实现一个迭代器生成函数吧! ok，看过了迭代器从古至今的操作，我们一起来实现一个自定义的迭代器。 楼上我们说迭代器对象全凭迭代器生成函数帮我们生成。在ES6中，实现一个迭代器生成函数并不是什么难事儿，因为ES6早帮我们考虑好了全套的解决方案，内置了贴心的生成器（Generator）供我们使用： 注：本小册不要求ES6基础，但生成器语法比较简单，推荐不了解的同学阅读阮老师的生成器教学光速入门 // 编写一个迭代器生成函数 function *iteratorGenerator() { yield '1号选手' yield '2号选手' yield '3号选手' } const iterator = iteratorGenerator() iterator.next() iterator.next() iterator.next() 丢进控制台，不负众望： 写一个生成器函数并没有什么难度，但在面试的过程中，面试官往往对生成器这种语法糖背后的实现逻辑更感兴趣。下面我们要做的，不仅仅是写一个迭代器对象，而是用ES5去写一个能够生成迭代器对象的迭代器生成函数（解析在注释里）： // 定义生成器函数，入参是任意集合 function iteratorGenerator(list) { // idx记录当前访问的索引 var idx = 0 // len记录传入集合的长度 var len = list.length return { // 自定义next方法 next: function() { // 如果索引还没有超出集合长度，done为false var done = idx >= len // 如果done为false，则可以继续取值 var value = !done ? list[idx++] : undefined // 将当前值与遍历是否完毕（done）返回 return { done: done, value: value } } } } var iterator = iteratorGenerator(['1号选手', '2号选手', '3号选手']) iterator.next() iterator.next() iterator.next() 此处为了记录每次遍历的位置，我们实现了一个闭包，借助自由变量来做我们的迭代过程中的“游标”。运行一下我们自定义的迭代器，结果符合预期： 小结 迭代器模式比较特别，它非常重要，重要到语言和框架都争着抢着帮我们实现。但也正因为如此，大家业务开发中需要手动写迭代器的场景几乎没有，所以很少有同学会去刻意留意迭代器模式、思考它背后的实现机制。通过阅读本节，希望大家可以领略迭代器模式的妙处（为什么会有，为什么要用）和迭代器模式的实现思路（方便面试）。至此，我们的设计模式之旅就告一段落了~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"JavaScript设计模式核⼼原理与应⽤实践/18.前方的路.html":{"url":"JavaScript设计模式核⼼原理与应⽤实践/18.前方的路.html","title":"18.前方的路","keywords":"","body":"致谢 依然是感谢。第一本小册面世后，体会到了作品受人认可、给人启示的成就感，也感受到了读者和阅读量飙升带来的压力和困惑。过去的数月对我个人来说并不轻松，我们整个团队一起不分昼夜、不分节假日地加了很多天的班。这本小册成书于业务压力、研发压力都非常巨大的“危难之时”。这里最要感谢的人是曾经主动与我沟通过的每一位读者。最初写小册只是对外输出的一次尝试，是“新鲜感”。而现在，它是一种责任，是写作者和读者之间的约定，是疲惫生活里的英雄梦想。 不是科班出身，没有大厂经历，我还能翻身吗？ 前段时间我在掘金个人资料一栏更新了自己的读者邮箱。无意之举，没想到很快就有了来信。大家的问题各种各样，除了技术问题，还有很多是生涯问题、甚至生活问题。因为加班太猛，我的碎片时间基本回答完上本小册评论区的提问后就所剩无几，很多邮件和微信消息到现在都还没有来得及回复。这其中印象最深的问题有两类，一类是说裁员了，不知道自己现在该咋整。裁员的话题，每次聊起来都非常沉重，我读了也很难受，所以在本册的开头，我就和大家聊了聊这个事情；另外一类，就是我们小标题描述的这个问题。 先说答案——答案是可以。但这个答案有一个非常重要的大前提——你要学会正视那些正在让这个阶段的你耿耿于怀的东西——学历不好，我愁。愁没有办法使你变成C9硕士，况且C9也不教前端。在BAT，前端这个工种，有非常多的“草根英雄”，学历不好、甚至没读过大学的大有人在，他们靠自学能力、优秀的项目经验和职业素养服人；没有大厂经历，只能说明你在过去没有足够的积累、或者说仅仅是错过了一些机遇。人作为具有主观能动性的生物，是始终处于动态中的，是会不断发展变化的。你过去的失误和当下的处境不能代表你，更不能定义你的未来。我接触过的很多同事，包括我自己也是从在小团队写jQuery做起，一步一步成长起来的。所以说没关系，别丧气，“没有坑，就先让自己成为萝卜”。 如何成为“萝卜”？这又是另一个巨大的命题。笔者相信每个人都有属于他自己的变强的方法，从这个角度来说，笔者没有立场插手任何一位同学的成长。但如果你确实处于职业生涯的焦虑期，渴望变强却暂时还不知道怎么做，不妨试试从这三件事开始做起： 找人。找出你所在团队/圈子里最厉害的人，和他保持技术/工作上的交流，尝试争取/创造和他共事的机会。如果你身边没有这样的人，优秀的技术社区（比如掘金）里一定有。996无法使你迅速成长，但和大牛一起解决问题必定使你受益良多。 阅读。读好的书，更要读好的代码。我们平时使用频率最高的那些库和框架，就是最好的阅读材料。静下心，不要急。读不下去是正常的，多试几次——学习的本质不就是在不断的重复中形成自己的理解吗？ 不挑剔。干活的时候，不要挑简单的做；读书的时候，不要挑“xx21天迅速上手”这样的读——容易的事情任谁都做得来，但日日如此，自己或许也只能沦为芸芸众生中极为平庸而懦弱的那一个。 前方的路 回到我们这本书的主题。设计模式这玩意儿，和算法一样，是许多非科班同学的软肋，而很多公司恰恰就喜欢用这些东西来淘汰非科班的受试者。一些半路出家的前端会给自己扣上这样一顶帽子——我擅长动手，不喜欢理论，所以我不学理论。这种想法并不酷，它往往是出于恐惧，是一种对知识的逃避。 在读完本书之后，我相信大家不会再觉得设计模式有什么神秘的，更不会闻之色变了。克服了面对理论知识的畏难情绪后，我希望大家可以把这份勇气继续下去，去攻克更多曾经的自己不敢去面对的难题，去读更多看似艰深恐怖、实则造福大众的好书。设计模式读书不需太多，重在经典。在拓展阅读材料方面，我这儿有一些推荐： 设计模式：可复用面向对象软件的基础 如果你的时间只允许你读一本书，我会推荐这一本。这是一本需要反复翻阅、反复理解的好书。它同时是设计模式的开山鼻祖，堪称“金科玉律”。很多人反映读这本书第一遍会读不懂，这很正常，和你对设计模式毫无了解时去强读这本小册的第二节效果是一样的。但有了这本小册的加持，我相信各位在阅读过程中的障碍会小很多。 Head First 设计模式（中文版） 如果反复尝试后仍觉得自己啃不下《设计模式：可复用面向对象软件的基础》这本书，可以把它放一放，读一读这本《Head First 设计模式》。这本书是一本优秀的入门读物，通俗易懂、专注于说人话，被我推荐给了家族中每一个对编程有兴趣的学生仔。 结语 设计模式的征程，到此就告一段落了。但对各位来说，真正的战斗才刚刚开始。设计模式的魅力，不在纸面上，而在实践中。学设计模式，一在多读——读源码，读资料，读好书；二在多练——把你学到的东西还原到业务开发里去，看看它是否OK，有没有问题。如果有问题，如何修复、如何优化？没有一种设计模式是完美的，设计模式和人一样，处在动态发展的过程中。并不是只有GOF提出的23种设计模式可以称之为设计模式，只要一种方案遵循了设计原则、解决了一类问题，那么它都可以被冠以“设计模式”的殊荣。 在各位从设计模式小册毕业之际，希望大家带走的不止是知识，还有好的学习习惯、阅读习惯。最重要的，是深挖理论知识的勇气和技术攻关的决心。这些东西不是所谓“科班”的专利，而是一个优秀工程师的必须。 寒冬已至，春花可期，大家加油！ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"React组合式开发实践：打造企业管理系统五大核心模块/以史为鉴：前端开发的四个时代.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/以史为鉴：前端开发的四个时代.html","title":"以史为鉴：前端开发的四个时代","keywords":"","body":"以史为鉴：前端开发的四个时代 在前端整体进入组件化开发时代后，手写各种 UI 组件成为了许多前端工程师入门后的第一课。而对于工作了几年的资深工程师来说，手写组件已经不再是问题，但对于如何帮助团队提升整体开发效率以及个人接下来的技术成长方向却开始变得非常迷茫。 以铜为鉴，可以正衣冠；以人为鉴，可以明得失；以史为鉴，可以知兴替。 想要摆脱对未来的迷茫，最好的方法就是向后看，看一路走来前端开发是如何从服务端主导的静态网站一步步发展到现在由客户端主导的单页应用。只有了解了过去前端分别在不同的阶段解决了怎样的问题，才能更好地看清楚未来要向哪里去。 四个时代 黑铁时代 - 插件化 在前端界大名鼎鼎的 jQuery 诞生于 2006 年，那时还没有 Google Chrome，微软刚刚发布了直到现在还在令许多前端开发者头疼的 IE 7。 jQuery 作为试图抹平不同浏览器之间 API 差异的先锋进入了人们的视野，并在之后很长的一段时间内占据了 Web 开发领域统治性的地位。那时开发一个网站并不需要先配置一个复杂的脚手架，只需要新建一个 HTML 文件即可，开发者们也远未意识到未来前端开发究竟会复杂到什么样的程度，以页面为单位的开发方式在当时看起来并没有什么问题。 那时还没有人提出组件的概念，基于 jQuery 的 UI 组件都被称为 jQuery 插件（plugin），代表着在任何浏览器环境下都可以即插即用。 项目的开发速度完全取决于页面数量的多少及布局的复杂程度，所有的变量都挂载在全局之下，引用的各个插件之间相互独立，这样的开发方式似乎并没有给开发者们留下多少可以优化的空间。 青铜时代 - 模块化 随着 Ajax) 等技术的普及，客户端 JavaScript 的代码量也越来越大，开发者们开始无法忍受全局变量带来的命名冲突，各个插件之间虽然相互独立但多个插件之间的依赖关系却也变得越来越复杂。这时前端开发对于模块化的需求变得非常强烈，于是便涌现出了 RequireJS 和 Sea.js 两大专注于解决前端模块化问题的类库，以 Sea.js 发布 1.0 正式版的时间为参考，那时是 2011 年 7 月。 解决了命名空间和文件依赖的问题，前端终于可以轻装上阵。配合着日趋成熟的各种 UI 插件库，这时前端项目的开发速度有了第一次质的提升。 摆脱了全局变量的限制，越来越多的前端插件被沉淀了下来。页面数量虽然依然被作为衡量开发量的一个重要指标，但在开发流程中各个模块之间已经开始了协作，开发一个新页面的工作量也不再完全等于页面本身。与此同时，npm) 的出现也让这些沉淀下来的前端插件有了栖身之处，却也为今天前端类库小而分散的现状埋下了隐患。 白银时代 - 组件化 在前端模块化进行得如火如荼的同时，由谷歌开发的 AngularJS 也于 2010 年 10 月发布，这是第一次 JavaScript 框架试图接管所有的 DOM 操作。不过由于在当时过于超前的设计和后续断崖式的升级，AngularJS 一直没能打破 jQuery 在前端开发界的统治地位，直到 2013 年 Facebook 发布 React。 专注于 View 层的 React 虽然提出了 JSX 这样不符合传统前端开发习惯的新概念，但基于虚拟 DOM 的重绘效率确实要比 AngularJS 的脏检查高出一个数量级。这着实吸引了许多前端开发者的目光，也让前端开发真正进入了组件化时代。 摆脱了 DOM 的限制，组件与组件之间的数据传递第一次变得如此轻松，这让开发功能强大的大型复杂组件及沉淀能够覆盖大部分底层需求的 UI 组件库变为了可能。 过去的几年中，以 ant-design、material-ui 等为代表的优秀的开源前端组件库如雨后春笋般冒了出来，MVVM 框架配合其生态内的组件库成为了现代前端开发的标配。与此同时，前端工程化的浪潮也汹涌袭来，以 Babel、webpack 和 TypeScript 等为代表的 JavaScript 增强工具帮助 JavaScript 摆脱了脚本语言的定位，JavaScript 也开始成为编写大型工程项目的可选项。 但这时开发者们突然发现，以前只需要打开 Notepad++ 就可以轻松写前端的日子不在了，开始一个前端项目变得异常复杂。在组件库的帮助下，虽然项目的复杂度被大幅降低了，但花在写代码上的时间却一点也没有减少，用组件拼出一个个页面的世界似乎并没有想象中那么美好。 黄金时代 - 专业化 时间来到 2017 年，作为前端组件库界标杆的 ant-design 先后发布了 ant-design-mobile 及 ant-design-pro，淘宝系也发布了飞冰（以下称为 ice）。 其中 ant-design-mobile 是一套专注于移动端混合应用开发的前端组件库，现在又推出了 React Native 的版本。曾经在前端开发界流行过一段时间响应式设计的风潮，即一套代码适配所有终端。但慢慢大家发现，一套代码支持所有终端终究只是一个美丽的梦想，移动端和桌面端之间页面尺寸及操作交互的巨大差异，导致二者都需要更专业的解决方案来应对。 ant-design-mobile 想要解决的是移动端的问题，而 ant-design-pro 想要解决的则是企业中后台管理系统搭建这样一个问题。这些被抽象出来后针对中后台系统优化的组件并不能够直接用于搭建前台项目，但牺牲了通用性所换来的专业性也代表着前端在向着细分领域的专业化解决方案靠拢。ice 与 ant-design-pro 类似，所不同的是 ice 还集成了项目的脚手架部分，致力于实现一套纯 GUI 的前端开发模式。 这里我们先按下这些垂直领域的解决方案是否能够解决相应的问题不表，但我们从这些事例中可以看出的趋势是清晰的：区别于之前大力建设作为前端基础设施的组件库，前端的下一个方向就是要在这些基础设施之上同时向多个细分领域进军，如上面提到的移动端、企业中后台，又如富文本编辑、数据可视化等这些对于专业深度要求更高的领域。 资深工程师的下一站 随着我们对未来的认知越来越清晰问题也随之而来：在这么多的细分领域中应该专攻哪一个呢？ 对于这个问题我们很难给出一个确定的答案，因为每个人所擅长的领域都不尽相同。但有一点可以确定的是，对于资深工程师来说，除了抽象 UI 组件的能力，对业务组件的良好抽象也是一个非常值得去培养的能力。有人可能会提出异议：“我每天写的不就是业务组件？业务组件因为其本身复用价值比较低所以不值得去抽象难道不是前端开发界的共识吗？” 如果你也有着同样的困惑，那么你很可能走入了一个认知误区，即业务组件等同于商品详情页这样具体的需求。事实并不是这样，对业务的抽象代表的是页面的布局、应用的鉴权、产品的国际化等这些更高维度上的问题，只有解决好了这些问题，配合上基础组件库才可以真正做到保质保量地完成一个又一个前端项目，最终推动公司业务向前发展。 小结 在本节中我们一起回顾了从 2006 年至今 12 年来前端开发所走过的四个阶段，即插件化、模块化、组件化和专业化。在前端专业化的趋势逐渐清晰的今天，抛去跨领域、跨学科的新技术不谈，希望继续在前端领域深耕的资深工程师培养自己对于复杂业务的抽象能力就变得尤为重要。 在这本小册中我们将以企业管理系统为切入点，一起来探讨如何从布局、权限、菜单、通知、多语言等五个方面提升自己抽象复杂业务逻辑的能力。而在这之前，让我们先一起来看一下企业管理系统的前世今生，以及前端组件库为什么不是解决企业管理系统这样一个历史难题的银弹。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/似水流年：企业管理系统的前世今生.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/似水流年：企业管理系统的前世今生.html","title":"似水流年：企业管理系统的前世今生","keywords":"","body":"似水流年：企业管理系统的前世今生 站在 2018 年 7 月这样一个时间点上，工程师们在谈起 Web 应用开发时已经很少再会提起如 JSP（JavaServer Pages）、ASP.NET（Active Server Pages）等这些传统的服务端 Web 应用开发方案，与此同时像 jQuery、Bootstrap 等这些直接处理样式及交互的工具库也逐渐淡出了历史舞台。随着 React、Angular 及 Vue 这些 MVVM 框架的流行，使用组件去组合页面逐渐代替了 Web 应用过去以页面为单位的开发方式，各种各样的组件库也应运而生成为了支撑现代 Web 应用开发的中坚力量。 历史 时间退回到 2011 年，那是千团大战（团购）的元年，也是移动互联网开始真正进入人们日常生活的开始。从那之后，不论是 O2O、垂直电商，还是互联网金融等风靡全国的商业模式，各家创业公司都进入了一个 App 就可以创业的时代，同时也催生了技术领域学习 iOS 和 Android 开发的热潮，会用 Xcode 就可以月薪过万的 iOS 工程师成为了那个时代最好的代名词。但后来随着各大互联网巨头之间的合纵连横，能够不依赖投资机构独立运营的创业公司越来越少，客户端开发的需求也开始大量萎缩。在大起大落的移动端开发之外，其实这几年 Web 端开发的日子也并不好过。传统公司的官网项目连外包公司都喂不饱，除去个别大厂外又有多少公司一定要开发一个 Web 端的应用才能做生意呢？ 传统企业管理系统（ERP） 抛开一直在走下坡路的面向用户的客户端应用不谈，长期占据 Web 应用开发需求主流的各种企业管理系统却从来都没有沉寂过，只是因为这些内部应用的使用者通常来讲不过是内部员工而已，人们对这些管理系统的期待与忍耐度都已经被培养到了一种近乎变态的地步。 但事实上对于企业管理系统开发方式的改良从未停止过。 随着互联网在办公领域的深度普及，几乎所有的传统企业都在将老旧的 CS（client/server）架构的内部系统迁移至更方便灵活的 BS（browser/server）架构。但令人遗憾的是，很多这样的升级只是将原来 C# 写的代码转换成了 JavaScript 而已，相较于现在各种交互流畅、动画炫酷的面向终端用户的应用，大部分企业管理系统的设计与交互依然停留在 Win97 时代。 雕版印刷术 vs. 活字印刷术 发明于唐朝的雕版印刷术一直到明清时期都还在被广泛使用，而更为人所称道的宋代毕昇所发明的活字印刷术却一直都没有成为古代中国主流的印刷技术。这其中最主要的原因一方面是古代所要印刷的书大部分都是比较固定的（如四书五经等），雕版印刷的可复用性并不比活字印刷低多少。另一方面是制造和使用一块雕版还是几千个活字模在成本与复杂度上也是不可同日而语的。换句话说，如果现在就是要印 1000 册《论语》，你是会选择做一块雕版印 1000 次，还是先做几千个活字模并把它们组装好再印上 1000 次呢？答案不言而喻。而且别忘了印完这 1000 册《论语》后，接下来要印的可能是《大学》也可能是《中庸》，上次积累的这几千个活字模并不能够完全覆盖到其他的书，额外的拆卸与组装成本也是一笔不小的开销。再者而言，组装和拆卸活字模要求所有的印刷工人都必须识字，相反雕版印刷对于印刷工人来说几乎是零门槛的，任何人在接受了一定的训练后都可以把这个活儿干好。又由于一个个活字模本身是独立制造的，将几千个活字模组装好后印出的书也难免会出现字与字之间风格或样式不统一的问题，而统一制造的雕版就不存在这个缺陷。在古代，人们所达成的共识也是雕版印刷书的质量和美观程度都要远远胜过活字印刷。 聪明的你可能已经猜到了，上面我们提到的活字印刷术就像是现代前端开发中的组件库，活字模就是一个个独立的组件。如果说我们要解决的是整个 Web 应用领域的终极问题，我们自然需要应用活字印刷的思想在最细的粒度上去进行抽象，以达到边做新项目边充实组件库的目的。但如果我们要解决的就是企业管理系统这样一个具体的问题，应用雕版印刷的思想在更粗的粒度上进行抽象，完成任务所需要的时间和人工成本可能只是原来的百分之一甚至千分之一。 机遇 积重难返的企业管理系统同样是一片充满了变革机遇的绿洲，但有机遇的地方就会有挑战。 企业管理系统作为一个已经存在了几十年的传统行业，一直以来都没有人能够总结出一套较为通用的解决方案，这也从侧面说明了解决这一问题要面临着多大的挑战。相较于注重展示的面向终端用户的应用，企业管理系统的核心在于对工作流程的抽象，这一部分根据企业的不同，其复杂度也不尽相同。这导致了抽取不同系统之间的共性变得异常困难，经验或者说知识很难沉淀下来。另一方面，再小的企业管理系统也都是“麻雀虽小，五脏俱全”，通用布局、用户登录、权限管理、菜单路由、消息通知、操作反馈、多语言支持等等这些模块一个都不能少。这样分散且琐碎的组成形式，让解决企业管理系统开发这个问题不仅需要强大的技术背景支持更需要耐心与细心。 当然，目前在这个领域也有着许多优秀的先行者，我们一起来看几个开源的企业管理系统。 react-admin ngx-admin blur-admin ant-design-pro 工程师 vs. 设计师 对于上面提到的这些优秀的开源项目，许多开发者所抱的态度很多时候都是又爱又恨。在网络讨论中，一个经常被人拿来讨论的问题是，互联网大厂的工程师和传统公司的工程师之间有什么区别？但其实除了工程师之间存在着不同外，互联网大厂设计师与传统公司设计师之间的区别才是最为巨大的。 在传统公司中绝大部分的设计师都是项目导向的，这导致设计师很少有时间去思考和沉淀所做过的东西。素材库、图标库、设计理念及交互方式等这些本该有确定答案的部分几乎都是缺失的。造成这一结果的除了设计师自身的原因之外，“罪魁祸首”其实是公司内部的管理机制，即外行领导内行。许多非软件开发行业出身的项目经理经常简单粗暴地认为两个系统之间长得像就是偷懒，一个系统用了栅格式布局，另一个系统就非得是列表式，这不仅造成了巨大的资源浪费，更带坏了许多设计师的设计思想，将设计系统变成了设计广告，力求标新立异，推陈出新。 说回企业管理系统，许多认可这些开源项目的开发者在新项目开始时遇到的第一个问题就是，设计师已经给出了第一版的设计稿，如果我现在要拿上面这样大而全的解决方案去实现的话要怎么才能跟设计师交代呢？如果要深入内部去把这些开源项目不符合设计要求的部分都改成自己这边的实现，是否还不如另起炉灶再做一个？ 是的，在非一线的互联网公司中，困扰程序员的关键往往不是技术，而是不同部门之间因为各自背景、诉求、视野等不同而产生的不协调。大而全的方案看起来很美，但实践起来却困难重重。 组合式开发 为了解决大而全的方案在实践中不够灵活的问题，我们是不是可以将其中包含的各个模块解耦后，独立发布出来供开发者们按需取用呢？让我们先来看一段理想中完整的企业管理系统应用架构部分的伪代码： const App = props => ( // react-redux bind // react-router-redux bind // intl support // router with access control list // route that doesn't need authentication // layout component // page content (view component) ... // more routes that don't need authentication // route that needs authentication // hoc for user login check // layout component // sider menu // page header // page content (view component) // page footer ... // more routes that need authentication 404} /> // 404 page ); 在上面的这段伪代码中，我们抽象出了多语言支持、基于路由的权限管理、登录鉴权、基础布局、侧边栏菜单等多个独立模块，可以根据需求添加或删除任意一个模块，而且添加或删除任意一个模块都不会对应用的其他部分产生不可接受的副作用。这让我们对接下来要做的事情有了一个大体的认识，但在具体的实践中，如 props 如何传递、模块之间如何共享数据、如何灵活地让用户自定义某些特殊逻辑等都仍然面临着巨大的挑战。我们需要时刻注意，在处理一个具体问题时哪些部分应当放在某个独立模块内部去处理，哪些部分应当暴露出接口供使用者自定义，模块与模块之间如何做到零耦合以至于使用者可以随意插拔任意一个模块去适应当前项目的需要。 小结 在本节中我们从企业管理系统的历史讲起，一起探讨了为什么活字印刷式的组件库并不能够很好地解决企业管理系统这样一个需要更高层抽象的问题，并由此引出了组合式开发的概念，即将不同的核心模块分别抽象再根据项目需要最终组合在一起的开发方式。 在下一节中我们将从最基础的项目脚手架讲起，一起来搭建一个简单却功能齐全的项目脚手架。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇01：开发前准备.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇01：开发前准备.html","title":"实战篇01：开发前准备","keywords":"","body":"实战篇 01：开发前准备 为什么选择 React 企业管理系统作为供企业内部人员使用的应用，在浏览器适配性方面的要求并没有供普通用户使用的应用那么严格，这为我们选择现代的 JavaScript 框架提供了一定的便利。于是接下来的问题就变为了在 React、Angular、Vue 这三大 JavaScript 框架中应当选择哪一个？ 其实这个问题在具体技术层面并没有一个确定的答案，更多的还是要看团队成员们的背景。如果专业前端比较多的话，React 和 Vue 都是不错的选择。如果团队中后端背景的全栈比较多的话，大而全且接近 Java 思想的 Angular 可能是最优的选择。 至于 React 的 Vue 之间的选择可以说虽然二者在写法上有着许多的不同，但核心的区别却是在于二者的社区构成。React 的社区更加去中心化，许多常用的第三方库都不是由官方提供的。这让 React 社区非常得活跃，在一个问题上大家可能会产生出许多种不同的解决方案。Vue 的社区则相对而言更中心化一些，除了 Vue 本身支持的功能要比 React 多之外，如 Vuex、Vue Router 这样由官方维护的第三方库也让 Vue 的社区更多地是在官方的指导下去解决问题。简而言之的话，React 选择更多，Vue 更标准化，但二者之间并没有好坏之分。 最后还有一点值得比较的就是二者对于 TypeScript 的友好程度。React 社区在 TypeScript 方面的探索以及积累的经验相对而言要比 Vue 社区更多一些，而 Vue 则是在 2.5 版本之后才完善了自身对于 TypeScript 的支持。所以如果你的技术选型中有 TypeScript 的话，在渲染框架层面 React 可能会是一个更好的选择。 示例项目列表 在进入具体的实战篇之前，先交代下后面实战篇中会涉及的示例项目： 基础脚手架：react-boilerplate 企业管理系统脚手架：react-boilerplate-pro 侧边栏组件：react-sider 包含鉴权的路由：react-acl-router 国际化多语言文件注入：react-intl-context 这其中前两个是完整的示例项目，在把项目 clone 到本地后根据 README.md 文件中的指导就可以运行起来。后三个是企业管理系统中常用模块的组件抽象，全部都应用在了 react-boilerplate-pro 项目中，推荐搭配着 demo 一起研究。 Node.js 笔者本地的 Node.js 版本是 8.11.3。推荐使用 8.10.0 或 9.10.0 以上的版本，否则将不能够兼容 ESLint 当前最新的 5.0 版本。 包管理工具 各位在安装项目依赖时可以使用默认的 npm，但在这里推荐使用 Yarn 作为项目的包管理工具，在所有的项目中也都提供了相应的 yarn.lock 文件。这样可以确保大家使用的第三方依赖与笔者本地的保持一致，而且 Yarn 自身强大的 cache 功能也可以在重复安装相同依赖时起到一定的加速作用。 第三方依赖 所有项目中需要用到的第三方依赖都在项目的 package.json 以及 yarn.lock 中有所体现，大家使用 yarn install（或 npm install）安装即可。 这里列出一些使用的重要依赖的版本，供大家参考： react: 16.4.2 react-dom: 16.4.2 redux: 4.0.0 redux-thunk: 2.3.0 react-router-dom: 4.3.1 connected-react-router: 4.3.0 antd: 3.6.6 webpack: 4.16.5 babel-core: 6.26.3 eslint: 5.3.0 jest: 23.4.2 示例项目会定时对使用的第三方依赖进行升级，但因为第三方依赖的更新速度较快，所以上面列出的第三方依赖版本可能会与实际示例项目中的有所出入，一切以实际示例项目中的 package.json 和 yarn.lock 为准。 建议学习方式 小册以「企业管理系统」为切入点，希望向读者传达的是对于某一类特定的需求，过于原子化的组件化开发方式并不能够彻底地解决开发效率问题，从抽象的业务需求中能够具象出较为通用的可插拔可组合的技术方案才是解决实际问题的终极答案。 在之后的六个小节中我们将分别从项目脚手架、页面布局、权限管理、菜单匹配、消息通知以及多语言支持六个方面讲述在搭建企业管理系统应用中的最佳实践。但因为企业管理系统涉及的内容颇多，小册难免挂一漏万，没有涉及或遗漏的部分欢迎各位向笔者反馈。 在小册之外笔者还提供了 5 个示例项目，帮助大家从源码层面理解笔者的思路。强烈建议大家将项目 clone 下来，配合着小册中的内容自己运行一遍，相信会有更多的收获。 最后，小册中重点提及的一些开发理念及开发思想都并不局限于 React 这个框架本身，希望大家在阅读时可以抛去框架、语言的偏见，站在更高的层面和笔者一起去寻找通用业务问题的解决方案。 感谢各位的时间，也祝大家阅读、学习愉快。 拓展学习资料 AlanWei/blog：笔者的 GitHub 博客，里面有更多关于 React、组件库、前端数据层、服务端渲染的资料。 pure render：阿里数据中台前端团队分享前端相关经验。 前端精读评论：阿里数据中台前端团队分享前端界的好文精读。 前端新能源：分享前端有深度的新思想和新方法。 蚂蚁金服体验科技：探索极致用户体验与最佳工程实践。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇02：项目脚手架.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇02：项目脚手架.html","title":"实战篇02：项目脚手架","keywords":"","body":"实战篇 02：项目脚手架 本节参考代码：react-boilerplate 经过了刀耕火种的插件化时代，伴随着越来越繁荣的 npm 生态，近几年来前端开发的三大件 HTML、CSS 及 JavaScript 都发生了不同程度上的进化，这也让开发或选择一个合适的项目脚手架（boilerplate）成为了前端项目的第一个难点。在 React 生态中，虽然已经有了像 create-react-app 这样官方指定的脚手架项目，但为了深入理解一个前端脚手架所需要承担的责任与能够解决的问题，不妨让我们删繁就简一起来搭建一个只包含最少依赖的功能齐全的项目脚手架。 HTML 部分 在 JavaScript 框架接管了所有 DOM 相关的操作与更新后，HTML 方面的工作量就大量地减少了，很多时候只需要为框架提供一个可以注入 DOM 元素的根节点即可。 为了让页面的缩放比例与当前用户设备的屏幕尺寸保持一致，我们可以在模板中添加 HTML5 新引入的 viewport 属性，这对于需要支持移动端的项目非常重要。 接下来再在 HTML 中添加应用标题 title，这里需要注意的是，因为我们不希望采用硬编码的方式来处理应用标题，而是希望将应用标题作为 webpack 插件中的一个变量注入到 HTML 模板中，所以需要选择一个模板语言来增强普通 HTML 的功能。这里我们以 EJS 为例讲解如何实现变量注入。 除了 title 部分，我们还需要将 webpack 编译完成后的 JavaScript 与 CSS 的文件路径也注入到 HTML 模板中。 \" as=\"style\"> \" as=\"script\"> 除去变量注入外，EJS 等这类 HTML 模板语言还支持条件判断等编程语言的功能，如下面这段代码就实现了根据 webpack 配置来决定应用是否可以被搜索引擎检索。 根据项目的需要我们还可以在模板中定义应用 favicon 等传统 HTML 支持的属性，这里不再赘述。 CSS 部分 相较于 HTML，CSS 作为前端应用的另一核心组成部分受到 JavaScript 发展的冲击要小得多。以 Sass、Less 为代表的 CSS 预处理工具极大地增强了 CSS 的功能，也让 CSS 保持了自己原先独立的地位。 但为了打通基于 webpack 的整体项目编译流程，我们也需要在 webpack 中合理地配置 CSS 的编译方式，使得 Sass（Less）、CSS 及 webpack 可以无缝衔接。 区别对待项目中的 CSS 与 node_modules 中的 CSS 项目中的 CSS： { test: /\\.scss$/, exclude: /node_modules/, use: IS_PROD ? [ MiniCssExtractPlugin.loader, { loader: 'css-loader', options: { minimize: true }, }, { loader: 'postcss-loader', options: { plugins: () => [autoprefixer({ browsers: 'last 5 versions' })], sourceMap: true, }, }, { loader: 'sass-loader', options: { includePaths: [ SOURCE_DIR, ], }, }, ] : [ { loader: 'style-loader', options: { singleton: true }, }, 'css-loader', { loader: 'postcss-loader', options: { plugins: () => [autoprefixer({ browsers: 'last 5 versions' })], sourceMap: true, }, }, { loader: 'sass-loader', options: { includePaths: [ SOURCE_DIR, ], }, }, ], } 这里需要注意的有两点，一是 sass-loader 的 includePaths 设置为 src/ 目录，这是为了项目中的 scss 文件可以方便地使用绝对路径相互引用，而不需要使用较为繁琐且不利用重构的相对路径。二是开发时使用 style-loader 而不是 css-loader 来加载 CSS，这是为了结合 webpack-dev-server 的热更新（hot reload）功能，在本地开发时将所有的 CSS 都直接内嵌至 HTML 中以加快热更新的速度。 node_modules 中的 CSS： { test: /\\.css$/, include: /node_modules/, use: [ MiniCssExtractPlugin.loader, 'css-loader', { loader: 'postcss-loader', options: { plugins: () => [autoprefixer({ browsers: 'last 5 versions' })], sourceMap: true, }, }, ], } 在项目开发的过程中，我们很有可能还需要引入一些包含 CSS 的第三方库。这里需要注意的是，为了避免有些第三方库提供的 CSS 没有做浏览器兼容性处理，我们在加载 node_moduels 中的 CSS 之前还要使用 postcss-loader 再统一处理一遍，以确保所有进入生产环境的 CSS 都经过了相应的浏览器兼容性处理。 样式变量与 mixin 正如前文中所提到的，CSS 作为独立的一部分一直以来受到前端工程化的影响都比较小。但与此同时许多开发者一味地追求开发效率，很多时候忽略了应该以一门编程语言的态度去对待 CSS。 最常见的例子就是对于 CSS 中颜色的处理，许多开发者都是直接复制设计稿中的十六进制代码，丝毫没有考虑到不同颜色在整体项目中的复用性与统一性。对于 mixin 的使用也是一样，例如卡片阴影等这些需要多个 CSS 属性组合的样式，很多时候也都是采取复制粘贴 CSS 代码的方式解决。 这些都是我们在实际开发中应该尽量去避免出现的问题。在样式表的根目录 styles/ 文件夹中我们完全可以将这些通用的变量与 mixin 提前定义好： // variables.scss $grey-1: #ffffff !default; $grey-2: #fafafa !default; $grey-3: #f5f5f5 !default; $grey-4: #e8e8e8 !default; $grey-5: #d9d9d9 !default; $grey-6: #bfbfbf !default; $grey-7: #8c8c8c !default; $grey-8: #595959 !default; $grey-9: #262626 !default; $grey-10: #000000 !default; $blue-1: #e6f7ff !default; $blue-2: #bae7ff !default; $blue-3: #91d5ff !default; $blue-4: #69c0ff !default; $blue-5: #40a9ff !default; $blue-6: #1890ff !default; $blue-7: #096dd9 !default; $blue-8: #0050b3 !default; $blue-9: #003a8c !default; $blue-10: #002766 !default; $red-1: #fff1f0 !default; $red-2: #ffccc7 !default; $red-3: #ffa39e !default; $red-4: #ff7875 !default; $red-5: #ff4d4f !default; $red-6: #f5222d !default; $red-7: #cf1322 !default; $red-8: #a8071a !default; $red-9: #820014 !default; $red-10: #5c0011 !default; // mixins.scss @mixin text-ellipsis() { overflow: hidden; white-space: nowrap; text-overflow: ellipsis; } 并在编写具体的页面样式时坚持不使用任何硬编码的值来保证项目样式的统一性，为后续维护中的样式变更打下良好的基础。 JavaScript 部分 JavaScript 作为近几年来变化最大的一部分，总结下来的改变主要集中在三个方面：一是需要将使用 ES2015、ES2016、ES2017 特性的 JavaScript 代码编译至大多数浏览器普遍支持的 ES5（对应工具为 Babel），二是需要将编译好的 JavaScript、CSS 及 HTML 整合起来，也就是我们常说的打包（对应工具为 webpack），三是需要对代码风格及规范进行检查（对应工具为 ESLint）。 Babel 配置 .babelrc 作为 Babel 的配置文件，最核心的两部分就是 presets 以及 plugins。 presets 代表了 Babel 配置的核心部分。其中 babel-preset-env 整合了 es2015、es2016、es2017 三个原先独立的 preset，开发者只需要引入 env 这样一个 preset 就可以安全地使用上述三个版本中包含的 JavaScript 新特性。 plugins 更像是对 presets 的一个补充，供开发者们去自定义一些 presets 之外的功能，其中比较常用的如对象扩展符 ... 就需要引入 babel-plugin-transform-object-rest-spread 开启。除了 JavaScript 部分的扩展外，Babel 对 React 也有着相应的支持，如将 JSX 编译为 React 原生的 React.createElement 方法以及为 React 组件添加 displayName 属性等。 Babel 作为一个基于插件系统打造的 JavaScript 编译工具，其可定制度是非常高的，开发者们完全可以根据自己的使用需要与编码习惯去选择或开发合适的插件以达到提升开发效率的效果。 webpack 配置 webpack 作为现在最流行的前端打包工具，其一路走来的发展史也是许多前端开发者的血泪史。webpack 1 到 webpack 2 时破坏式的升级导致了许多前端项目直到今天都仍然停留在 webpack 1，而 webpack 3 到 webpack 4 时彻底重构了的内部插件系统又导致了第二次断崖式升级。但值得庆幸的是，webpack 在最新的 4+ 版本中终于承认了「约定大于配置」并大幅减少了在功能与插件方面配置代码的数量。 webpack 配置的核心一是源代码的入口（entry）与打包后代码的出口（output），二是不同资源的加载器（loader），三是插件，常用的如处理 CSS 的 mini-css-extract-plugin，处理 HTML 的 html-webpack-plugin 等。具体实用的 webpack 配置大家可以参考示例项目 react-boilerplate 中的 webpack.config.js 部分。 ESLint 配置 相较于 Babel 与 webpack，ESLint 更像是一个可选项，因为它并不会直接影响最终编译完成的代码，而是在编写阶段对开发者的编码风格进行约束，帮助开发者写出更好的 JavaScript 代码。 写代码是一门手艺，对于手艺人来说从资深手艺人那里学来的经验就是自己成长路上最宝贵的财富。ESLint 让你可以不需要师从哪一位或哪几位优秀的程序员，只需要遵守他们定下的代码规范就可以写出和他们一样优秀的代码。现在市面上最流行的 ESLint 配置就是由 Airbnb 所提供的，我们只需要在 .eslintrc 中配置 extends 为 airbnb 就可以开启 Airbnb 的 JavaScript 编写规范。当然，为了满足自定义的需求，在 .eslintrc 的 rules 中我们也可以独立地开启或关闭任意一条代码检查规则。 文件目录 介绍完了 HTML、CSS、JavaScript 三个部分后，项目脚手架已经初见雏形，让我们先来写一个 Hello World。 脚手架除了能够帮助团队一次性地解决上述提到的这些技术栈配置问题外，还有一个重要的责任就是梳理项目的标准目录组织结构。从通用的角度来讲，一般一个完整的前端项目都至少需要包含以下九个部分： layouts/: 存放布局级别的组件 views/: 存放页面级别的组件 components/: 存放业务级别的 UI 组件 hocs/: 存放业务级别的逻辑组件（看情况可与 components/ 合并，但建议分开） app/: 存放应用级别的配置信息，如菜单、路由等，以及应用初始化的相关代码，如初始化 redux store 等 utils/: 存放通用的功能性函数，如数据聚合、处理等 styles/: 存放全局的 CSS 样式、变量、mixins 等 assets/: 存放静态资源，如图标、图片等 i18n/: 存放应用国际化需要的多语言文件 在将这些文件夹都添加到我们的脚手架后，让我们来写一个复杂点的页面。 最后关于 redux 部分的设置，根据业务需要可能会有所区别，大家可以参考以下的几个条件渐进式地选择数据流工具。 redux 我需要一个全局数据源且其他组件可以直接获取/改变全局数据源中的数据 我需要全程跟踪/管理 action 的分发过程/顺序 redux-thunk 我需要一个全局数据源且其他组件可以直接获取/改变全局数据源中的数据 我需要全程跟踪/管理 action 的分发过程/顺序 我需要组件对同步或异步的 action 无感，调用异步 action 时不需要显式地传入 dispatch redux-saga 我需要一个全局数据源且其他组件可以直接获取/改变全局数据源中的数据 我需要全程跟踪/管理 action 的分发过程/顺序 我需要组件对同步或异步的 action 无感，调用异步 action 时不需要显式地传入 dispatch 我需要声明式地来表述复杂异步数据流（如长流程表单、请求失败后重试等），命令式的 thunk 对于复杂异步数据流的表现力有限 脚手架的维护 虽然在设计脚手架时的一大原则就是尽可能少地引入第三方依赖，但因为 React 并不是一个大而全的框架，所以在搭建脚手架时还是难免需要引入 redux、react-router、babel、webpack 等这些必需的第三方依赖。而在后续维护中，根据业务场景的不同我们可以有以下两种不同的维护方式。 一是稳定压倒一切，即不更新依赖，使用搭建完成的脚手架直到不能够满足业务的需要时再推倒重来。二是及时更新，即对脚手架所有的第三方依赖进行定期（半个月或一个月）的升级，保证脚手架所使用的第三方依赖永远都是最新的稳定版本。对于业务场景并不复杂的企业来说，稳定压倒一切是提升生产力的不二法门。而对于大厂或者说业务场景较为复杂的企业来说，及时更新却是必须的。做好技术基础设施建设是解决未来不可预见的技术难题的基础，技术项目的落后很多时候是一步落后，步步落后，在遇到具体问题时再去寻求完美的解决方案是不现实的。 小结 在本节中我们从 HTML、CSS、JavaScript 三个方面分析了近年来前端开发界发生的变化以及如何使用最新的技术栈搭建出一个扩展性良好的自研脚手架。 在下一节中我们将正式进入企业管理系统搭建的讨论，从页面的基础布局开始一步步剖析企业管理系统中的痛点与解决方案。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇03：页面布局方案.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇03：页面布局方案.html","title":"实战篇03：页面布局方案","keywords":"","body":"实战篇 03：页面布局方案 本节参考代码： react-boilerplate-pro/src/layouts/BasicLayout.jsx react-boilerplate-pro/src/layouts/NormalLayout.jsx react-acl-router/src/AclRouter.jsx 在传统的前端开发中提到布局我们可能第一时间会想到「圣杯布局」或「双飞燕布局」这些跟 CSS 相关的页面布局方式。而在现代前端开发中，更准确地说在组件化开发逐渐成为现代前端开发主流之后对于布局这一概念又有了新的定义，那就是多个页面中共同的部分，也可以叫做页面的骨架。 如下图，在不同页面中都会包含的侧边栏菜单就是页面基础布局的一部分： 布局与路由 在讨论具体的布局组件设计前，我们首先要解决一个更为基础的问题，那就是如何将布局组件与应用路由结合起来。 下面的这个例子是 react-router 官方提供的侧边栏菜单与路由结合的例子，笔者这里做了一些简化： const SidebarExample = () => ( Home Bubblegum Shoelaces {routes.map((route, index) => ( ))} ); 抽象为布局的思想，写成简单的伪代码就是： // with sidebar {routes.map(route => ( ))} 这样的确是一种非常优雅的解决方案，但它的局限性在于无法支持多种不同的布局。受限于一个 Router 只能包含一个子组件，即使我们将多个布局组件包裹在一个容器组件中，如： // with sidebar {routes.map(route => ( )} // with footer {routes.map(route => ( )} 路由在匹配到 FlexLayout 下的页面时，BasicLayout 中的 sidebar 也会同时显示出来，这显然不是我们想要的结果。换个思路，我们可不可以将布局组件当做 children 直接传给更底层的 Route 组件呢？代码如下： {basicLayoutRoutes.map(route => ( ))} {flexLayoutRoutes.map(route => ( ))} 这里我们将不同的布局组件当做高阶组件，相应地包裹在了不同的页面组件上，这样就实现了对多种不同布局的支持。还有一点需要注意的是，react-router 默认会将 match、location、history 等路由信息传递给 Route 的下一级组件，由于在上述方案中，Route 的下一级组件并不是真正的页面组件而是布局组件，因而我们需要在布局组件中手动将这些路由信息传递给页面组件，或者统一改写 Route 的 render 方法为： ( // props contains match, location, history )} /> 另外一个可能会遇到的问题是，connected-react-router 并不会将路由中非常重要的 match 对象（包含当前路由的 params 等数据 ）同步到 redux store 中，所以我们一定要保证布局及页面组件在路由部分就可以接收到 match 对象，否则在后续处理页面页眉等与当前路由参数相关的需求时就会变得非常麻烦。 页眉 & 页脚 解决了与应用路由相结合的问题，具体到布局组件内部，其中最重要的两部分就是页面的页眉和页脚部分，而页眉又可以分为应用页眉与页面页眉两部分。 应用页眉指的是整个应用层面的页眉，与具体的页面无关，一般来说会包含用户头像、通知栏、搜索框、多语言切换等这些应用级别的信息与操作。页面页眉则一般来讲会包含页面标题、面包屑导航、页面通用操作等与具体页面相关的内容。 在以往的项目中，尤其是在项目初期许多开发者因为对项目本身还没有一个整体的认识，很多时候会倾向于将应用页眉做成一个展示型组件并在不同的页面中直接调用。这样做当然有其方便之处，比如说页面与布局之间的数据同步环节就被省略掉了，每个页面都可以直接向页眉传递自己内部的数据。 但从理想的项目架构角度来讲这样做却是一个反模式（anti-pattern）。因为应用页眉实际是一个应用级别的组件，但按照上述做法的话却变成了一个页面级别的组件，伪代码如下： 从应用数据流的角度来讲也存在着同样的问题，那就是应用页眉应该是向不同的页面去传递数据的，而不是反过来去接收来自页面的数据。这导致应用页眉丧失了控制自己何时 rerender（重绘) 的机会，作为一个纯展示型组件，一旦接收到的 props 发生变化页眉就需要进行一次重绘。 另一方面，除了通用的应用页眉外，页面页眉与页面路由之间是有着严格的一一对应的关系的，那么我们能不能将页面页眉部分的配置也做到路由配置中去，以达到新增加一个页面时只需要在 config/routes.js 中多配置一个路由对象就可以完成页面页眉部分的创建呢？理想情况下的伪代码如下： // with app & page header already 配置优于代码 在过去关于组件库的讨论中我们曾经得出过代码优于配置的结论，即需要使用者自定义的部分，应该尽量抛出回调函数让使用者可以使用代码去控制自定义的需求。这是因为组件作为极细粒度上的抽象，配置式的使用模式往往很难满足使用者多变的需求。但在企业管理系统中，作为一个应用级别的解决方案，能使用配置项解决的问题我们都应该尽量避免让使用者编写代码。 配置项（配置文件）天然就是一种集中式的管理模式，可以极大地降低应用复杂度。以页眉为例来说，如果我们每个页面文件中都调用了页眉组件，那么一旦页眉组件出现问题我们就需要修改所有用到页眉组件页面的代码。除去 debug 的情况外，哪怕只是修改一个页面标题这样简单的需求，开发者也需要先找到这个页面相对应的文件，并在其 render 函数中进行修改。这些隐性成本都是我们在设计企业管理系统解决方案时需要注意的，因为就是这样一个个的小细节造成了本身并不复杂的企业管理系统在维护、迭代了一段时间后应用复杂度陡增。理想情况下，一个优秀的企业管理系统解决方案应该可以做到 80% 以上非功能性需求变更都可以使用修改配置文件的方式解决。 配置式页眉 import { matchRoutes } from 'react-router-config'; // routes config const routes = [{ path: '/outlets', exact: true, permissions: ['admin', 'user'], component: Outlets, unauthorized: Unauthorized, pageTitle: '门店管理', breadcrumb: ['/outlets'], }, { path: '/outlets/:id', exact: true, permissions: ['admin', 'user'], component: OutletDetail, unauthorized: Unauthorized, pageTitle: '门店详情', breadcrumb: ['/outlets', '/outlets/:id'], }]; // find current route object const pathname = get(state, 'router.location.pathname', ''); const { route } = head((matchRoutes(routes, pathname))); 基于这样一种思路，我们可以在通用的布局组件中根据当前页面的 pathname 使用 react-router-config 提供的 matchRoutes 方法来获取到当前页面 route 对象的所有配置项，也就意味着我们可以对所有的这些配置项做统一的处理。这不仅为处理通用逻辑带来了方便，同时对于编写页面代码的同事来说也是一种约束，能够让不同开发者写出的代码带有更少的个人色彩，方便对于代码库的整体管理。 页面标题 renderPageHeader = () => { const { prefixCls, route: { pageTitle }, intl } = this.props; if (isEmpty(pageTitle)) { return null; } const pageTitleStr = intl.formatMessage({ id: pageTitle }); return ( {this.renderBreadcrumb()} {pageTitleStr} ); } 面包屑导航 renderBreadcrumb = () => { const { route: { breadcrumb }, intl, prefixCls } = this.props; const breadcrumbData = generateBreadcrumb(breadcrumb); return ( {map(breadcrumbData, (item, idx) => ( idx === breadcrumbData.length - 1 ? {intl.formatMessage({ id: item.text })} : {intl.formatMessage({ id: item.text })} ))} ); } 知识点：组件与 redux 在以上的讨论中我们发现布局组件与应用路由之间有着千丝万缕的联系，那么我们能不能抽象出一个通用的布局组件并直接将它作为应用路由的一部分包含在路由中呢？这样开发者在使用这个「高级路由」时，只需要配置每个页面的路由属性就可以自动获得页面的基础布局，岂不是非常方便？ 关于这点笔者也做过相关的尝试，但目前得出的结论是布局组件最好还是要做在应用层。因为如果想做一个非展示型的功能强大的布局组件的话，将它 connect 到 redux store 几乎是一件不可避免的事。如果硬要把所有可以从 redux store 中拿到的数据当做 props 再传给抽象出的布局组件的话，props 的设计会非常难做，因为随时的一个需求变更都有可能导致要增加新的 props。这是因为布局组件作为承接全局应用和具体页面之间的一个中间层，需要能够很灵活地向下传递数据。这些数据的处理逻辑都是因具体需求而异的，强行抽象往往会起到适得其反的效果。 延伸来讲，一个组件如果必须要 connect 到 redux store 后才能使用的话，严格意义上来说它就不再是一个组件了，因为这时它就对自己所处的上下文环境有了要求，一旦脱离了当前应用它就无法再顺利地完成自身内部的一些功能，组件所应当拥有的可复用性也就不存在了。 这其中隐含的道理是 UI 与数据在架构时应当是分离的，redux 作为二者之间的粘合剂，一旦二者通过 redux 被连接到了一起，那么这个组件也就不再纯净（pure）了，变为了只隶属于当前项目的一个业务组件且不再具备通用性。一般而言，前端应用中的每一个页面都是这样的业务组件。这又涉及到不同组件的抽象级别，一般而言到了页面这个级别，我们就不再追求组件的通用性，转而更多地追求尽量在组件中简化当前项目内的业务需求，于是将组件 connect 到 redux store 以方便组件获取各个 reducer 中的数据就是可以接受的一种做法了。 组合式开发：页面布局 对于常见的前端应用来说，应用是由页面直接通过路由组成的。又因为页面与页面之间是互相平行的关系，所以不同页面之间的共性很难被抽取出来，从而使得应用中出现了大量的重复代码却又因为它们会直接影响到页面的渲染逻辑而无法被删除。 页面布局作为应用与页面之间的连接层很好地缓冲了应用和页面之间的巨大差异，使得我们有了一个恰当的地方来处理同类页面的基础布局以及应用与页面之间的数据交换。举例来说，如果应用中的搜索框只存在于个别几个页面的话，我们就可以为这几个页面专门抽象出一个包含搜索框的布局组件。这样一来，需要搜索框的页面只需要应用这个专用布局即可，不需要搜索框的页面则不需要做任何逻辑判断。相较于在每个页面都需要判断是否渲染搜索框的组件化解法，页面布局的解法显然要优雅得多。 另一方面，页面布局这一层同时也是可插拔的。假设我们现在拿掉了页面布局这一层，具体页面中的渲染逻辑和核心数据并不会受到任何影响，我们可以很方便地将这个页面移植到其他的应用中去，而不需要担心页面和应用之间耦合过深。同理，被抽取出来的布局层也可以轻松地被移植到其他的应用中，而不需要担心其下属页面的具体内容。而在抽掉了页面，布局之后，所留下来的应用层就是上一节中提到的脚手架部分，其中将不包含任何的业务逻辑，可以被应用到任意前端项目。这样一来，应用、布局、页面三者各司其职，在增加了一层抽象后反而更加合理地重新分配了工程复杂度，大大增强了每一层代码的可复用性。 小结 在本节中我们从布局组件与应用路由的关系讲起，一起探讨了应用页眉、页面页眉等页面中的通用部分并得出了在企业管理系统搭建中「配置优于代码」的结论。 在下一节中我们将会继续深入探讨企业管理系统中页面级别的权限管理设计。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇04：权限管理机制.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇04：权限管理机制.html","title":"实战篇04：权限管理机制","keywords":"","body":"实战篇 04：权限管理机制 本节参考代码： react-acl-router react-boilerplate-pro/src/app/init/router.js react-boilerplate-pro/src/app/config/routes.js 权限管理作为企业管理系统中非常核心的一个部分，一直以来因为业务方很多时候无法使用准确的术语来描述需求成为了困扰开发者们的一大难题。这里我们先来介绍两种常见的权限管理设计模式，即基于角色的访问控制以及访问控制列表。 设计策略 基于角色的访问控制（Role-based access control） 基于角色的访问控制不直接将系统操作的各种权限赋予具体用户，而是在用户与权限之间建立起角色集合，将权限赋予角色再将角色赋予用户。这样就实现了对于权限和角色的集中管理，避免用户与权限之间直接产生复杂的多对多关系。 访问控制列表（Access control list） 具体到角色与权限之间，访问控制列表指代的是某个角色所拥有的系统权限列表。在传统计算机科学中，权限一般指的是对于文件系统进行增删改查的权力。而在 Web 应用中，大部分系统只需要做到页面级别的权限控制即可，简单来说就是根据当前用户的角色来决定其是否拥有查看当前页面的权利。 下面就让我们按照这样的思路实现一个基础版的包含权限管理功能的应用路由。 实战代码 路由容器 在编写权限管理相关的代码前，我们需要先为所有的页面路由找到一个合适的容器，即 react-router 中的 Switch 组件。与多个独立路由不同的是，包裹在 Switch 中的路由每次只会渲染路径匹配成功的第一个，而不是所有符合路径匹配条件的路由。 以上面两段代码为例，如果当前页面路径是 /about 的话，因为 、 及 这三个路由的路径都符合 /about，所以它们会同时被渲染在当前页面。而将它们包裹在 Switch 中后，react-router 在找到第一个符合条件的 路由后就会停止查找直接渲染 组件。 在企业管理系统中因为页面与页面之间一般都是平行且排他的关系，所以利用好 Switch 这个特性对于我们简化页面渲染逻辑有着极大的帮助。 另外值得一提的是，在 react-router 作者 Ryan Florence 的新作 @reach/router 中，Switch 的这一特性被默认包含了进去，而且 @reach/router 会自动匹配最符合当前路径的路由。这就使得使用者不必再去担心路由的书写顺序，感兴趣的朋友可以关注一下。 权限管理 现在我们的路由已经有了一个大体的框架，下面就让我们为其添加具体的权限判断逻辑。 对于一个应用来说，除去需要鉴权的页面外，一定还存在着不需要鉴权的页面，让我们先将这些页面添加到我们的路由中，如登录页。 对于需要鉴权的路由，我们需要先抽象出一个判断当前用户是否有权限的函数来作为判断依据，而根据具体的需求，用户可以拥有单个角色或多个角色，抑或更复杂的一个鉴权函数。这里笔者提供一个最基础的版本，即我们将用户的角色以字符串的形式存储在后台，如一个用户的角色是 admin，另一个用户的角色是 user。 import isEmpty from 'lodash/isEmpty'; import isArray from 'lodash/isArray'; import isString from 'lodash/isString'; import isFunction from 'lodash/isFunction'; import indexOf from 'lodash/indexOf'; const checkPermissions = (authorities, permissions) => { if (isEmpty(permissions)) { return true; } if (isArray(authorities)) { for (let i = 0; i 在上一节中我们提到了路由的配置文件，这里我们为每一个需要鉴权的路由再添加一个属性 permissions，即哪些角色可以访问该页面。 const routes = [{ path: '/outlets', exact: true, permissions: ['admin', 'user'], component: Outlets, unauthorized: Unauthorized, pageTitle: 'Outlet Management', breadcrumb: ['/outlets'], }, { path: '/outlets/:id', exact: true, permissions: ['admin'], component: OutletDetail, redirect: '/', pageTitle: 'Outlet Detail', breadcrumb: ['/outlets', '/outlets/:id'], }]; 在上面的配置中，admin 和 user 都可以访问门店列表页面，但只有 admin 才可以访问门店详情页面。 对于没有权限查看当前页面的情况，一般来讲有两种处理方式，一是直接重定向到另一个页面（如首页），二是渲染一个无权限页面，提示用户因为没有当前页面的权限所以无法查看。二者是排他的，即每个页面只需要使用其中一种即可，于是我们在路由配置中可以根据需要去配置 redirect 或 unauthorized 属性，分别对应无权限重定向及无权限显示无权限页面两种处理方式。具体代码大家可以参考示例项目 react-acl-router 中的实现，这里摘录一小段核心部分。 renderRedirectRoute = route => ( } /> ); renderAuthorizedRoute = (route) => { const { authorizedLayout: AuthorizedLayout } = this.props; const { authorities } = this.state; const { permissions, path, component: RouteComponent, unauthorized: Unauthorized, } = route; const hasPermission = checkPermissions(authorities, permissions); if (!hasPermission && route.unauthorized) { return ( ( )} /> ); } if (!hasPermission && route.redirect) { return this.renderRedirectRoute(route); } return ( ( )} /> ); } 于是，在最终的路由中，我们会优先匹配无需鉴权的页面路径，保证所有用户在访问无需鉴权的页面时，第一时间就可以看到页面。然后再去匹配需要鉴权的页面路径，最终如果所有的路径都匹配不到的话，再渲染 404 页面告知用户当前页面路径不存在。 {map(normalRoutes, route => ( this.renderNormalRoute(route) ))} {map(authorizedRoutes, route => ( this.renderAuthorizedRoute(route) ))} {this.renderNotFoundRoute()} 需要鉴权的路由和不需要鉴权的路由作为两种不同的页面，一般而言它们的页面布局也是不同的。如登录页面使用的就是普通页面布局： 在这里我们可以将不同的页面布局与鉴权逻辑相结合以达到只需要在路由配置中配置相应的属性，新增加的页面就可以同时获得鉴权逻辑和基础布局的效果。这将极大地提升开发者们的工作效率，尤其是对于项目组的新成员来说纯配置的上手方式是最友好的。 应用集成 至此一个包含基础权限管理的应用路由就大功告成了，我们可以将它抽象为一个独立的路由组件，使用时只需要配置需要鉴权的路由和不需要鉴权的路由两部分即可。 const authorizedRoutes = [{ path: '/outlets', exact: true, permissions: ['admin', 'user'], component: Outlets, unauthorized: Unauthorized, pageTitle: 'pageTitle_outlets', breadcrumb: ['/outlets'], }, { path: '/outlets/:id', exact: true, permissions: ['admin', 'user'], component: OutletDetail, unauthorized: Unauthorized, pageTitle: 'pageTitle_outletDetail', breadcrumb: ['/outlets', '/outlets/:id'], }, { path: '/exception/403', exact: true, permissions: ['god'], component: WorkInProgress, unauthorized: Unauthorized, }]; const normalRoutes = [{ path: '/', exact: true, redirect: '/outlets', }, { path: '/login', exact: true, component: Login, }]; const Router = props => ( // the router component ); const mapStateToProps = state => ({ user: state.app.user, }); Router.propTypes = propTypes; export default connect(mapStateToProps)(Router); 在实际项目中，我们可以使用 react-redux 提供的 connect 组件将应用路由 connect 至 redux store，以方便我们直接读取当前用户的角色信息。一旦登录用户的角色发生变化，客户端路由就可以进行相应的判断与响应。 组合式开发：权限管理 对于页面级别的权限管理来说，权限管理部分的逻辑是独立于页面的，是与页面中的具体内容无关的。也就是说，权限管理部分的代码并不应该成为页面中的一部分，而是应该在拿到用户权限后创建应用路由时就将没有权限的页面替换为重定向或无权限页面。 这样一来，页面部分的代码就可以实现与权限管理逻辑的彻底解耦，以至于如果抽掉权限管理这一层后，页面就变成了一个无需权限判断的页面依然可以独立运行。而通用部分的权限管理代码也可以在根据业务需求微调后服务于更多的项目。 小结 在本节中我们从权限管理的基础设计思想讲起，实现了一套基于角色的页面级别的应用权限管理系统并分别讨论了无权限重定向及无权限显示无权限页面两种无权限查看时的处理方法。 在下一节中我们将会探讨当前页面如何匹配企业管理系统中的多级菜单以及如何让路径较深的子页面高亮其隶属于的父级菜单。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇05：菜单匹配逻辑.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇05：菜单匹配逻辑.html","title":"实战篇05：菜单匹配逻辑","keywords":"","body":"实战篇 05：菜单匹配逻辑 本节参考代码：react-sider 在大部分企业管理系统中，页面的基础布局所采取的一般都是侧边栏菜单加页面内容这样的组织形式。在成熟的组件库支持下，UI 层面想要做出一个漂亮的侧边栏菜单并不困难，但因为在企业管理系统中菜单还承担着页面导航的功能，于是就导致了两大难题，一是多级菜单如何处理，二是菜单项的子页面（如点击门店管理中的某一个门店进入的门店详情页在菜单中并没有对应的菜单项）如何高亮其隶属于的父级菜单。 多级菜单 为了增强系统的可扩展性，企业管理系统中的菜单一般都需要提供多级支持，对应的数据结构就是在每一个菜单项中都要有 children 属性来配置下一级菜单项。 const menuData = [{ name: '仪表盘', icon: 'dashboard', path: 'dashboard', children: [{ name: '分析页', path: 'analysis', children: [{ name: '实时数据', path: 'realtime', }, { name: '离线数据', path: 'offline', }], }], }]; 递归渲染父菜单及子菜单 想要支持多级菜单，首先要解决的问题就是如何统一不同级别菜单项的交互。 在大多数的情况下，每一个菜单项都代表着一个不同的页面路径，点击后会触发 url 的变化并跳转至相应页面，也就是上面配置中的 path 字段。 但对于一个父菜单来说，点击还意味着打开或关闭相应的子菜单，这就与点击跳转页面发生了冲突。为了简化这个问题，我们先统一菜单的交互为点击父菜单（包含 children 属性的菜单项）为打开或关闭子菜单，点击子菜单（不包含 children 属性的菜单项）为跳转至相应页面。 首先，为了成功地渲染多级菜单，菜单的渲染函数是需要支持递归的，即如果当前菜单项含有 children 属性就将其渲染为父菜单并优先渲染其 children 字段下的子菜单，这在算法上被叫做深度优先遍历。 renderMenu = data => ( map(data, (item) => { if (item.children) { return ( {item.name} } > {this.renderMenu(item.children)} ); } return ( {item.name} ); }) ) 这样我们就拥有了一个支持多级展开、子菜单分别对应页面路由的侧边栏菜单。细心的朋友可能还发现了，虽然父菜单并不对应一个具体的路由但在配置项中依然还有 path 这个属性，这是为什么呢？ 处理菜单高亮 在传统的企业管理系统中，为不同的页面配置页面路径是一件非常痛苦的事情，对于页面路径，许多开发者唯一的要求就是不重复即可，如上面的例子中，我们把菜单数据配置成这样也是可以的。 const menuData = [{ name: '仪表盘', icon: 'dashboard', children: [{ name: '分析页', children: [{ name: '实时数据', path: '/realtime', }, { name: '离线数据', path: '/offline', }], }], }]; } } 用户在点击菜单项时一样可以正确地跳转到相应页面。但这样做的一个致命缺陷就是，对于 /realtime 这样一个路由，如果只根据当前的 pathname 去匹配菜单项中 path 属性的话，要怎样才能同时也匹配到「分析页」与「仪表盘」呢？因为如果匹配不到的话，「分析页」和「仪表盘」就不会被高亮了。我们能不能在页面的路径中直接体现出菜单项之间的继承关系呢？来看下面这个工具函数。 import map from 'lodash/map'; const formatMenuPath = (data, parentPath = '/') => ( map(data, (item) => { const result = { ...item, path: `${parentPath}${item.path}`, }; if (item.children) { result.children = formatMenuPath(item.children, `${parentPath}${item.path}/`); } return result; }) ); 这个工具函数把菜单项中可能有的 children 字段考虑了进去，将一开始的菜单数据传入就可以得到如下完整的菜单数据。 [{ name: '仪表盘', icon: 'dashboard', path: '/dashboard', // before is 'dashboard' children: [{ name: '分析页', path: '/dashboard/analysis', // before is 'analysis' children: [{ name: '实时数据', path: '/dashboard/analysis/realtime', // before is 'realtime' }, { name: '离线数据', path: '/dashboard/analysis/offline', // before is 'offline' }], }], }]; 然后让我们再对当前页面的路由做一下逆向推导，即假设当前页面的路由为 /dashboard/analysis/realtime，我们希望可以同时匹配到 ['/dashboard', '/dashboard/analysis', '/dashboard/analysis/realtime']，方法如下： import map from 'lodash/map'; const urlToList = (url) => { if (url) { const urlList = url.split('/').filter(i => i); return map(urlList, (urlItem, index) => `/${urlList.slice(0, index + 1).join('/')}`); } return []; }; 上面的这个数组代表着不同级别的菜单项，将这三个值分别与菜单数据中的 path 属性进行匹配就可以一次性地匹配到所有当前页面应当被高亮的菜单项了。 这里需要注意的是，虽然菜单项中的 path 一般都是普通字符串，但有些特殊的路由也可能是正则的形式，如 /outlets/:id。所以我们在对二者进行匹配时，还需要引入 path-to-regexp 这个库来处理类似 /outlets/1 和 /outlets/:id 这样的路径。又因为初始时菜单数据是树形结构的，不利于进行 path 属性的匹配，所以我们还需要先将树形结构的菜单数据扁平化，然后再传入 getMeunMatchKeys 中。 import pathToRegexp from 'path-to-regexp'; import reduce from 'lodash/reduce'; import filter from 'lodash/filter'; const getFlatMenuKeys = menuData => ( reduce(menuData, (keys, item) => { keys.push(item.path); if (item.children) { return keys.concat(getFlatMenuKeys(item.children)); } return keys; }, []) ); const getMeunMatchKeys = (flatMenuKeys, paths) => reduce(paths, (matchKeys, path) => ( matchKeys.concat(filter(flatMenuKeys, item => pathToRegexp(item).test(path))) ), []); 在这些工具函数的帮助下，多级菜单的高亮也不再是问题了。 知识点：记忆化（Memoization） 在侧边栏菜单中，有两个重要的状态：一个是 selectedKeys，即当前选定的菜单项；另一个是 openKeys，即多个多级菜单的打开状态。这二者的含义是不同的，因为在 selectedKeys 不变的情况下，用户在打开或关闭其他多级菜单后，openKeys 是会发生变化的，如下面二图所示，selectedKeys 相同但 openKeys 不同。 对于 selectedKeys 来说，由于它是由页面路径（pathname）决定的，所以每一次 pathname 发生变化都需要重新计算 selectedKeys 的值。又因为通过 pathname 以及最基础的菜单数据 menuData 去计算 selectedKeys 是一件非常昂贵的事情（要做许多数据格式处理和计算），有没有什么办法可以优化一下这个过程呢？ Memoization 可以赋予普通函数记忆输出结果的功能，它会在每次调用函数之前检查传入的参数是否与之前执行过的参数完全相同，如果完全相同则直接返回上次计算过的结果，就像常用的缓存一样。 import memoize from 'memoize-one'; constructor(props) { super(props); this.fullPathMenuData = memoize(menuData => formatMenuPath(menuData)); this.selectedKeys = memoize((pathname, fullPathMenu) => ( getMeunMatchKeys(getFlatMenuKeys(fullPathMenu), urlToList(pathname)) )); const { pathname, menuData } = props; this.state = { openKeys: this.selectedKeys(pathname, this.fullPathMenuData(menuData)), }; } 在组件的构造器中我们可以根据当前 props 传来的 pathname 及 menuData 计算出当前的 selectedKeys 并将其当做 openKeys 的初始值初始化组件内部 state。因为 openKeys 是由用户所控制的，所以对于后续 openKeys 值的更新我们只需要配置相应的回调将其交给 Menu 组件控制即可。 import Menu from 'antd/lib/menu'; handleOpenChange = (openKeys) => { this.setState({ openKeys, }); }; {this.renderMenu(this.fullPathMenuData(menuData))} 这样我们就实现了对于 selectedKeys 及 openKeys 的分别管理，开发者在使用侧边栏组件时只需要将应用当前的页面路径同步到侧边栏组件中的 pathname 属性即可，侧边栏组件会自动处理相应的菜单高亮（selectedKeys）和多级菜单的打开与关闭（openKeys）。 知识点：正确区分 prop 与 state 上述这个场景也是一个非常经典的关于如何正确区分 prop 与 state 的例子。 selectedKeys 由传入的 pathname 决定，于是我们就可以将 selectedKeys 与 pathname 之间的转换关系封装在组件中，使用者只需要传入正确的 pathname 就可以获得相应的 selectedKeys 而不需要关心它们之间的转换是如何完成的。而 pathname 作为组件渲染所需的基础数据，组件无法从自身内部获得，所以就需要使用者通过 props 将其传入进来。 另一方面， openKeys 作为组件内部的 state，初始值可以由 pathname 计算而来，后续的更新则与组件外部的数据无关而是会根据用户的操作在组件内部完成，那么它就是一个 state，与其相关的所有逻辑都可以彻底地被封装在组件内部而不需要暴露给使用者。 简而言之，一个数据如果想成为 prop 就必须是组件内部无法获得的，而且在它成为了 prop 之后，所有可以根据它的值推导出来的数据都不再需要成为另外的 props，否则将违背 React 单一数据源的原则。对于 state 来说也是同样，如果一个数据想成为 state，那么它就不应该再能够被组件外部的值所改变，否则也会违背单一数据源的原则而导致组件的表现不可预测，产生难解的 bug。 组合式开发：应用菜单 严格来说，在这一小节中着重探讨的应用菜单部分的思路并不属于组合式开发思想的范畴，更多地是如何写出一个支持无限级子菜单及自动匹配当前路由的菜单组件。组件当然是可以随意插拔的，但前提是应用该组件的父级部分不依赖于组件所提供的信息。这也是我们在编写组件时所应当遵循的一个规范，即组件可以从外界获取信息并在此基础上进行组件内部的逻辑判断。但当组件向其外界抛出信息时，更多的时候应该是以回调的形式让调用者去主动触发，然后更新外部的数据再以 props 的形式传递给组件以达到更新组件的目的，而不是强制需要在外部再配置一个回调的接收函数去直接改变组件的内部状态。 从这点上来说，组合式开发与组件封装其实是有着异曲同工之妙的，关键都在于对内部状态的严格控制。不论一个模块或一个组件需要向外暴露多少接口，在它的内部都应该是解决了某一个或某几个具体问题的。就像工厂产品生产流水线上的一个环节，在经过了这一环节后产品相较于进入前一定产生了某种区别，不论是增加了某些功能还是被打上某些标签，产品一定会变得更利于下游合作者使用。更理想的情况则是即使删除掉了这一环节，原来这一环节的上下游依然可以无缝地衔接在一起继续工作，这就是我们所说的模块或者说组件的可插拔性。 小结 在本节中我们讨论了配置式菜单的数据结构设计以及基于这样的数据结构，如何做到在页面路径中体现页面与页面之间的父子级关系并在侧边栏菜单中高亮其对应的菜单项，还引出了「记忆化」的概念，为各位在处理组件中的复杂计算提供了一种优化方案以及如何正确地区分组件的 props 与 state，如何在不牺牲组件功能的前提下降低组件使用时的复杂度并提升组件的稳定性。 在下一节中我们将会探讨如何处理企业管理系统中的系统通知以及全局级别的用户操作反馈。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇06：消息通知设计.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇06：消息通知设计.html","title":"实战篇06：消息通知设计","keywords":"","body":"实战篇 06：消息通知设计 本节参考代码：react-boilerplate-pro 在传统的企业管理系统中一个经常被忽略掉的细节就是对于用户操作的反馈。一方面是因为复杂的业务流程边界条件太多，每一个分支都给予适当的反馈是一件非常烦琐的事情。另一方面往往是因为系统架构设计得不够灵活，只是显示一个操作成功或失败的通知就要写大量重复的逻辑代码，导致专注于业务流程的开发者不愿意花时间去处理操作反馈这一“可有可无”的需求。 在操作反馈通知（Notification）之外，完善的企业管理系统还需要一个全局的消息系统以方便系统管理员向某些或全部成员发送系统消息（Notice），即应用页眉中的通知栏，如 ant-design-pro 中的例子。 全局通知栏与应用初始化 与前端主导的通知系统不同，系统消息更依赖后端的实现。这里我们假设后端提供了获取当前用户未读消息的接口 /notices，创建相应的 redux action 为： const getNotices = () => ( createAsyncAction('APP_GET_NOTICES', () => ( api.get('/notices') )) ); 应用数据初始化 在实现系统消息之前，我们首先要解决应用数据初始化的问题。以系统消息为例，用户在登录系统后点击应用页眉中的通知栏就应当立刻可以看到当前的未读消息。但获取用户未读消息是一个异步的过程，这里的异步请求应该在什么时候发出呢？ 最简单的解决方案当然是在用户点击通知栏时发出，但这样做的弊端是用户在阅读消息前需要等待时间，没有充分利用到用户登录系统后但未点击通知栏这段空闲时间，而且如果用户频繁点击通知栏的话还会导致大量的冗余异步请求被发送至后端。 另一个解决方案就是在用户成功登录后发送请求去取得最新的未读消息： const login = (username, password) => ( createAsyncAction('APP_LOGIN', () => ( api.post('/login', { username, password, }) )) ); const loginUser = (username, password) => { const action = login(username, password); return dispatch => ( action(dispatch) .then(((callbackAction) => { if (callbackAction.type === 'APP_LOGIN_SUCCESS') { return getNotices()(dispatch); } return null; })) ); }; 但这样做会有一个例外就是因为系统会记录用户的登录状态，在鉴权过期前用户刷新页面是不需要重新登录的。这时我们就需要在系统初始化时，判断如果用户已经登录就发送获取系统消息的请求。 const initClient = (dispatch) => { const commonActions = [ dispatch(appAction.getLocale()), ]; const isLogin = !isNil(Cookie.get('user')); if (isLogin) { commonActions.push(dispatch(appAction.getNotices())); } return commonActions; }; 并在应用的入口文件中将 redux 的 dispatch 方法传入 initClient： const { store, history } = createStore(createBrowserHistory(), {}); const application = createApp(store, history); initClient(store.dispatch); ReactDOM.render(application, window.document.getElementById('app')); 按照同样的逻辑，我们可以将这一解决方案拓展到更多的需求，如在应用初始化时获取用户信息、国家时区信息等。 更新消息列表 在解决了数据获取的问题后，我们的布局组件就可以直接访问 redux store 中 app reducer 下的 notices 数据了。这里关于把 notices 存在哪个 reducer 中可能会有争议，比如它可以属于 app 的 reducer，即存放全局数据的地方，也可以单独创建一个 basicLayout 的 reducer 来存放布局组件所需要的数据，两种方案都是可行的。 接下来我们要实现的需求是在用户点击某一条消息后将其从消息列表中删除，因为系统消息列表是由后端控制的，所以这时我们需要向后端发送一个 DELETE 的请求以删除当前用户点击的某条消息。这时又会出现一个分歧是，后端在接收到 DELETE 请求后会不会将最新的消息列表再返回给前端。如果后端能够返回的话，我们只需要在 reducer 中替换掉原先的消息列表即可，但如果后端只返回操作成功或失败的话，我们还需要再发送一遍 getNotices 请求去拉取最新的消息列表。 最后，我们还需要处理无未读消息时的情况。 全局通知 回到一开始提到的操作反馈部分。 如果系统中的每个页面都需要独立去处理操作反馈的话，可以预见的是 组件几乎会出现在所有的页面。这样的解决方案不仅非常烦琐而且不利于统一处理通用的逻辑。 既然通知组件可以使用绝对定位的方式出现在不同页面的同一位置，那么我们能不能将它的显示和隐藏逻辑也放在全局的层面上进行处理呢？ 在回答这个问题前，我们先来写一个简单的基于绝对定位、支持自动隐藏的 UI 通知组件。 class Notification extends Component { componentDidMount() { this.timeout = setTimeout(this.props.onDismiss, this.props.timeout); } componentWillUnmount() { clearTimeout(this.timeout); } render() { const { prefixCls, title, content, onDismiss, } = this.props; return ( {title} {content} ); } } 从上述代码中可以看出，onDismiss 回调就是为使用者隐藏全局通知时准备的。为了在全局的层面上解决通知的问题，让我们在 app reducer 中为通知提供一个存放数据的位置，暂且称为 notification，其中包含 title 及 content 两个字段。 // app reducer const defaultState = () => ({ isLogin: false, user: {}, notification: { title: '', content: '', }, }); // app action const updateNotification = notification => ({ type: 'APP_UPDATE_NOTIFICATION', payload: notification, }); const resetNotification = () => ({ type: 'APP_RESET_NOTIFICATION', }); // app reducer const updateNotification = (state, action) => ({ ...state, notification: action.payload, }); const resetNotification = state => ({ ...state, notification: { title: '', content: '', }, }); 再将通知的渲染逻辑添加到 BasicLayout 布局组件中： renderNotification = () => { const { notification: { title, content }, resetNotification } = this.props; if (isEmpty(title) && isEmpty(content)) { return null; } return ( ); } 即如果 notification 的 title 和 content 字段都不为空的话，就显示全局通知。同时我们也将重置通知的 action 配置给了 Notification 组件的 onDismiss 回调，即关闭通知相当于重置 notification 字段为空对象。 等这些准备工作都做好后，在具体的页面中显示通知就变得非常容易了： const mapDispatchToProps = { updateNotification: appAction.updateNotification, }; this.props.updateNotification({ title: 'Notification Title', content: 'Notification will dismiss after 4.5s.', })} > > 将 app action 中的 updateNotification 函数 connect 至相应的页面组件即可。然后在这个页面中，使用者就可以直接调用 this.props.updateNotification 来显示相应的通知了。又因为通知组件本身就支持自动隐藏的功能，使用者也不再需要去处理隐藏的逻辑。 知识点：数据驱动视图 全局通知这个例子很好地为我们诠释了「数据驱动视图」的含义，即根据数据中心是否存在 notification 对象来决定是否渲染通知组件。这打破了原先显示或隐藏通知这样命令式的代码逻辑，让每一次的用户操作从执行命令变为了修改数据，然后再由更新后的新数据去驱动视图进行相应的更新。 熟悉 React 的朋友一定看过下面这个公式： view = f(state) 即视图是由当前应用状态推导而来。我们再尝试将 redux 也包含进来，在这个公式的基础上进行一下拓展。 根据 view = f1(state) && nextState = f2(currentState, action) 可以推导出 view = f1(f2(currentState, action)) 对应到全局通知的例子，f2 就是 app reducer 中处理数据的逻辑，而 f1 就是 BasicLayout 中的渲染逻辑。有了这两个函数，currentState 是确定的一份数据，在具体 action 的驱动下视图就可以自动地进行更新。 因为视图的不可枚举性（无限种可能），命令式的编码方式一直以来都非常不适合前端应用的开发，因为它会导致非常多的边界情况且不可测试。在传统的前端开发中我们很难说出「在什么情况下视图一定是什么样」这样的话，但根据上面的公式推导，如果我们善加利用 React + Redux 的特性的话前端开发也是可以有底气做到「视图结果可预测」的。 组合式开发：消息通知 组合式开发从本质上来说应用的是分层的思想，合理的分层可以明显地降低应用复杂度并且在应用出现问题时也可以帮助开发者快速定位问题发生的位置。而在分层固定下来后，开发新需求时第一个要去考虑的问题就是新需求应当被放在应用的哪一层去解决。如这一小节中的操作通知，如果被错误地放在页面层去处理的话就会导致许多冗余的代码，以及出现问题时页面的其他逻辑和操作通知的显示逻辑互相混淆，而放在应用层处理就可以帮助页面层屏蔽掉这些问题。 另一方面，在应用层增加了「显示操作通知」这样一个 action 后，对于其下属的页面层来说相当于是增加了一种「显示操作通知」的能力，是否要使用这种能力以及何时使用这种能力的决定权是在页面层手中的。也就是说在增加了这样一种能力之后并没有加重页面层的负担，页面层可以自己决定在适当的时候使用这种能力，而不需要担心不使用这种能力会带来任何的副作用。这种无副作用的特性也从另一个侧面解释了组合式开发中的可插拔性。 小结 在本节中我们以系统消息为例引出了应用数据初始化的解决方案，并结合 React + Redux 实现了一套基于数据驱动的全局操作通知系统，简化了在页面组件中显示全局通知的逻辑。 在下一节中我们将会探讨需要支持多种语言的前端应用架构。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/实战篇07：多语言支持.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/实战篇07：多语言支持.html","title":"实战篇07：多语言支持","keywords":"","body":"实战篇 07：多语言支持 本节参考代码： react-intl-context react-boilerplate-pro/src/app/init/router.js react-boilerplate-pro/src/views/login/index.js 随着国内市场的逐渐饱和越来越多的中国公司开始将目光投向了国际市场，其中竞争最为激烈的莫过于东南亚。拥有 6.5 亿人口的东南亚，整个地区的 GDP 总和高达 2.6 万亿美元，作为一个互联网行业刚刚进入快速发展阶段的市场其未来的想象空间十分巨大。但与此同时，在这块面积并不算庞大的土地上却分布着大大小小 11 个国家，说着印尼语、马来语、英语、泰语、越南语、中文等几十种不同的语言。 互联网作为一个规模效应非常明显的行业天然就带有扩张的属性，但许多中国公司在出海后面临的第一个挑战就是产品不支持多种语言无法直接进入相应国家的市场。又因为现有系统在架构初期并没有将多语言支持的需求考虑进去，所以临时增加这个功能就变成了一件牵一发而动全身的事情，最后往往无功而返只得重新再做一个新的国际版，也就在这样来来回回的反复中白白浪费掉了许多宝贵的竞争机会。在吃过了这样的亏后，许多公司现在在开始一个新项目时就非常重视产品国际化的需求，希望能在架构初期就打下坚实的基础以至于在需要时可以轻松地产出多个不同语言的版本。 语言文件 语言文件，顾名思义就是一套对应不同语言翻译的键值对匹配。如果我们要把多语言支持的工作放在前端来做的话，最简单的一个方法就是以 JSON 的格式存储这些语言文件以方便应用在运行时读取相应的翻译值。 locale.json { \"en-us\": { \"appName\": \"React App Pro\", \"siderMenu_dashboard\": \"Dashboard\", \"siderMenu_analysis\": \"Analysis\", ... }, \"zh-cn\": { \"appName\": \"React 中后台应用\", \"siderMenu_dashboard\": \"仪表盘\", \"siderMenu_analysis\": \"分析页\", ... } } 在存储方面对于追求开发效率的团队来说，将语言文件直接 commit 到项目的代码仓库是一种可行的做法。但如果有条件的话还是应该将下载语言文件这一步放在项目持续集成的流程中，每一次构建项目时从存放语言文件的远端服务器拉取最新的版本，以保证发布到生产环境中的语言文件永远是最新的。 多语言版本切换 vs. 多语言版本构建 在讨论具体的产品国际化方案前，首先要明确的一点是，多语言支持这样一个需求根据具体的产品形态可以有两种不同的解决方案。 一是多语言版本切换，也就是在同一个应用中支持用户切换产品的不同语言版本。 二是多语言版本构建，即将同一个应用打包成不同语言的版本，分别发布到不同的生产环境中，但在应用内部不支持多语言切换。 对于多语言版本切换来说，因为在运行时可能会用到所有不同的语言，所以建议将所有语言的翻译都存在同一个 JSON 文件中，这里我们暂且将它命名为 locale.json，并将不同语言的区域码设置为第一层的 key 值，第二层则为具体页面占位符的 key 值，命名时建议采取页面_模块_值（login_loginPanel_usernameplaceholder）的方式扁平化地存储这些值以加快查询时的速度。如果有跨平台需求的话，也可以在页面前面加上平台，如 web_login_loginPanel_usernamePlaceholder、mobileWeb_login_loginPanel_usernamePlaceholder，便于统一管理不同平台之间语言文件的 key 值。 对于多语言版本构建来说就没有必要把所有的语言翻译都存在一个文件中了，可以将不同的翻译分别存在各自的语言文件中。 en-us.json { \"appName\": \"React App Pro\", \"siderMenu_dashboard\": \"Dashboard\", \"siderMenu_analysis\": \"Analysis\", ... } zh-cn.json { \"appName\": \"React 中后台应用\", \"siderMenu_dashboard\": \"仪表盘\", \"siderMenu_analysis\": \"分析页\", ... } 在应用构建过程中加载语言文件 准备好了语言文件，下一步就是将它集成到由 webpack 主导的应用构建过程中。 首先将语言文件 import 到 webpack.config.js 中，然后再通过 webpack 本身提供的 webpack.DefinePlugin 将它注入为应用的一个全局常量。 const localeMessages = require('./src/i18n/locale.json'); new webpack.DefinePlugin({ 'process.env.BUILD_LOCALE_MESSAGES': JSON.stringify(localeMessages), }) 在这里，上面提到的多语言版本切换以及多语言版本构建的区别就体现出来了。对于多语言版本切换来说，像上面这样直接将唯一的语言文件注入为应用常量即可。但如果我们想要构建多个不同语言版本应用的话，又该怎么做呢？ 为了解决这一问题，让我们再引入一个应用构建时的配置文件，称为 buildConfig.js。 module.exports = { 'PROD-US': { locale: 'en-us', }, 'PROD-CN': { locale: 'zh-cn', }, localhost: { locale: 'zh-cn', }, }; 并在 package.json 中分别配置不同语言版本的构建命令。 \"scripts\": { \"build:PROD-US\": \"cross-env NODE_ENV=production BUILD_DOMAIN=PROD-US webpack -p --progress --colors\", \"build:PROD-CN\": \"cross-env NODE_ENV=production BUILD_DOMAIN=PROD-CN webpack -p --progress --colors\", } 这样就可以在 webpack 的配置中读取到当前要构建的目标版本语言，然后再据此去匹配相应的语言文件，如 en-us.json。 const BUILD_DOMAIN = process.env.BUILD_DOMAIN || 'localhost'; const config = buildConfig[BUILD_DOMAIN]; const localeMessages = require(`./src/i18n/${config.locale}.json`); new webpack.DefinePlugin({ 'process.env.BUILD_LOCALE_MESSAGES': JSON.stringify(localeMessages), }) 在应用初始化时读取语言文件 在成功通过 webpack 将语言文件注入为全局常量后，我们就可以在应用中读取到构建时传入的语言文件了。这里为了方便其他文件引用构建配置及语言文件，我们可以提供一个统一的接口。 src/app/config/buildConfig.js const buildConfig = process.env.BUILD_CONFIG; const messages = process.env.BUILD_LOCALE_MESSAGES; export { messages, buildConfig, }; src/app/init/router.js import { messages, buildConfig } from '../config/buildConfig'; const { locale } = buildConfig; const Router = props => ( ... ); 在页面中注入翻译值 React 在 16.3 版本中引入了新的声明式、可透传 props 的 Context API。受益于这次改动 React 开发者们终于拥有了一个官方提供的安全稳定的 global store，子组件跨层级获取父组件数据及后续的更新都不再是问题。 语言文件注入恰巧就是一个非常适合使用 Context API 来解决的用例，因为：第一，语言文件需要能够跨层级传递到每一个组件中因为每一个组件中都可能存在需要翻译的部分；第二，语言文件并不会经常更新。这里的不经常更新指的是在应用运行时而不是开发过程中不经常更新，于是也就避免了 Context 中的数据变化引起应用整体重绘所带来的性能问题。 让我们先来创建一个存放语言文件的 Context。 import React from 'react'; const { Provider, Consumer } = React.createContext({ locale: '', messages: {}, formatMessage: () => {}, }); export { Provider, Consumer, }; 再将通过 props 传入的国家码、语言文件及读取语言文件中某一个 key 值的函数注入到 Context 的 value 对象中。 import { Provider } from './IntlContext'; class IntlProvider extends Component { constructor(props) { super(props); this.state = { value: { locale: props.locale, messages: props.messages, formatMessage: this.formatMessage, }, }; } formatMessage = (config) => { const { id } = config; const message = this.state.value.messages[id]; if (message === undefined) { console.warn(`[react-intl-context]: Message key ${id} is undefined. Fallback to empty string.`); return ''; } return message; } render() { return ( {this.props.children} ); } } 然后再写一个高阶组件作为 Context 的 Consumer。 import React from 'react'; import { Consumer } from './IntlContext'; const injectIntl = (WrappedComponent) => { const InjectIntl = props => ( {value => } ); return InjectIntl; }; export default injectIntl; 最后我们只需要将页面组件包裹在 injectIntl 这个高阶组件中，页面组件就可以多接收到一个名为 intl 的 props，直接调用 this.props.intl.formatMessage 并传入相应的占位符 key 值即可读取到语言文件中的相应翻译。 import { injectIntl } from 'react-intl-context'; class OutletDetail extends Component { render() { const { intl } = this.props; return ( {intl.formatMessage({ id: 'outletDetail_showNotification' })} ); } } export default injectIntl(OutletDetail); 在读取语言文件 key 值的方法上，多语言版本切换与多语言版本构建之间也有着细微的差别，具体的处理方法可以参考 react-intl-context 中的 MultiIntlProvider 和 IntlProvider。 来看一下最终的效果。 英文： 中文： 组合式开发：多语言支持 在处理多语言支持这样一个需求时，我们再次印证了组合式开发其实是一个赋能的过程，即在增加了某一层或某一个模块后，实际上为其下游使用者赋予了某种没有副作用的能力。如多语言支持中的 formatMessage 方法，在页面有国际化的需求时可以随时调用它来获取翻译值，而在页面没有国际化的需求时又可以安全地忽略它。甚至在抽掉 IntlContext 后其下属的页面层虽然失去了获取翻译的能力，却并不会影响到页面层原先拥有的其他能力。 这也就是组合式开发思想的精髓所在，它不需要外部为了它去进行复杂的适配而是通过自身向外部赋能。如果应用中的每一个模块都可以达到可组合、可插拔的程度，那么很多时候我们解决一个问题的方式就会从增加一个新模块变为灵活地组合已有模块，这将大大减少所需要的开发时间并降低 bug 出现的几率。 小结 在本节中我们剖析了多语言版本切换及多语言版本构建之间的相同与不同，为搭建一个支持多种语言的前端应用打下了良好的基础。 如果你想参与到文章中内容的讨论，欢迎在下面的评论区留言，期待与大家的交流。 "},"React组合式开发实践：打造企业管理系统五大核心模块/总结.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/总结.html","title":"总结","keywords":"","body":"总结 至此，小册的核心内容部分就已经完结了，感谢每一位能够坚持读到这里的朋友，也推荐各位在读小册的同时再多花点时间将小册中提到的五个示例项目 clone 到本地跑一遍并阅读下相关的源码，相信会有更多的收获。 这本小册从如何搭建一个前端项目的脚手架讲起，一步步带领大家完成了一个基础的企业管理系统脚手架，其中包含了页面基础布局、页面级别的前端权限管理系统、自动匹配路由的无限级菜单、数据驱动的全局通知以及支持按需加载的系统多语言切换。这些当然不是企业管理系统的全部，但希望大家都能够在消化吸收了这些模块中的最佳实践后，举一反三地将这些知识与经验迁移到更多具体的业务需求中去。 更重要的是希望大家能够理解「组合式开发」的真正含义。软件应用作为一个复杂系统，归根结底其降低内部复杂度的方式就是分层。通过不断地分层将整体复杂度合理地分散在每一个模块中并将其封装起来，从而达到极大地降低拼接不同模块时复杂度的目的。 而对于任意一个模块来说，衡量其优秀程度的维度除了能否和当前系统配合起来完成具体任务外还有两个重要的维度。 一是这个模块是否和其上下游的模块强耦合，即其他模块是否需要为了适应它而做出特殊的调整。好的模块是为其他模块赋能的，即赋予其他模块更多的能力而不需要其他模块做出任何的妥协或牺牲。 二是这个模块是否能够无缝地迁移到其他的系统并完成同样的工作。这就涉及软件工程中经常讲的可复用性，即一个模块自身的封装是否足够优秀以至于并不会因为所处系统的不同而需要做特殊的调整。 在这三个维度上都能够达标的模块才称得上是优秀的模块。但有时因为具体的业务需求我们可能会在这三个维度上有所取舍，比如牺牲一些可复用性去追求和上下游模块的弱耦合，这就需要具体情况具体分析了。 在小册的开篇我们提到过「组件化」并不是解决软件开发的银弹，同样的「组合式开发」也不是。它们都是工程师们在开发项目中积累下来的经验，只有在领会了其中要领并将多种方法与经验融会贯通后，才能够真正地在日常工作中不断提升自己。 学习路线 这个小册由于是从一个具体的前端应用直接切入开发技巧与理念的讲解，所以对于刚入门 React 的朋友来说可能存在着一定的基础知识部分梳理的缺失，这里为大家提供一份较为详细的 React 开发者学习路线图，希望能够为刚入门 React 的朋友提供一条规范且便捷的学习之路。 react-developer-roadmap 读者反馈 在小册上线后笔者收到许多非常认真的读者反馈，在这里先统一向大家表示感谢。 其中被提及最多的一点是小册选题太大但内容却有些单薄，并没有涉及「企业管理系统」中所有重要的部分。关于这个问题笔者除了会继续优化更新小册内容外，还有一些个人的想法希望与大家分享。 企业管理系统的确是一个非常宏大的命题，也正如许多朋友所说，其中的任意一点拿出来都可以写一本小册。所以笔者在构思这本小册时，更多考虑的是如何从几个具体的侧面来描述企业管理系统这样一个宏大的命题，好让大家虽然是管中窥豹但仍能触达核心。 这也就引出了下一个问题，那就是如何定义什么是企业管理系统中的核心？关于这个问题，每个人根据自身经验和所处场景的不同，对于核心的定义与理解也不尽相同。笔者挑选出来的布局、权限、菜单、通知、多语言这五个部分是基于笔者在过去几年中的工作经验，抽取出的相对而言笔者认为应当有统一解法却还没有人将这个统一解法提炼出来的五个模块。其他的比如表单部分，也是企业管理系统中非常核心的一环，但因为已经有了如 redux-form 这样优秀的开源解决方案存在，笔者也并不能够在此基础上提出更新更好的方案，所以就没有将这一部分放入小册的内容中。目的是希望小册不要成为成熟解决方案的搬运工，而是可以为读者提供独家的解法。所以大家在小册中看到的所有示例项目都是笔者的原创项目，笔者也认为这样才是一种对读者更加负责任的做法。 学习是一个不断融会贯通的过程，正如小册中的最佳实践也并不是笔者凭空想象出来的，而是在阅读了大量的开源项目后结合自身工作经验所做出的一个总结。框架也许会过时，甚至语言有一天也会被淘汰，但在使用框架、语言去做项目时积累下来的知识与经验是永远都不会过时的，也希望大家在阅读任何技术文章时不要将注意力全部集中在可以直接拿来用的代码上，而是更多地尝试去理解作者在文章背后想要传达的思想与理念，这样才能够不断地将他人的经验内化为自己的能力持续进步。 交流互动 目前小册已经有了 3 个微信群，有超过 1000 位的读者在微信群中和其他志同道合的朋友一起交流阅读心得，讨论在阅读小册及日常开发中遇到的问题。我们鼓励「去中心化」的讨论，每一位微信群中的朋友都可以是问题的提问者或回答者，相信在这样良性的互动中大家一定可以教学相长，共同进步。 致谢 首先感谢每一位读者对小册的支持，你们是小册的全部价值所在，也希望在阅读的过程中每一个人都能够有所收获。 其次感谢流形、染陌两位老师为小册撰写推荐语，正是因为有了你们的背书小册才能够吸引到如此多的读者，非常感谢。 最后要着重感谢的是掘金小册的全体编辑团队，尤其是小册的责任编辑 cilluo。没有你们在背后默默地付出与支持就不会有这本小册，也期待以后更加深度的合作。 更新记录 2018.08.05: 增加小册「总结」，总结小册内容及想传达给读者的核心思想，提供 React 学习路线图，回复读者反馈及致谢。 2018.08.01: 更新「实践篇 03：页面布局方案」、「实战篇 05：菜单匹配逻辑」，增加对于该小节中涉及的知识点详解。 2018.07.31: 更新「实践篇 03：页面布局方案」、「实战篇 04：权限管理机制」、「实战篇 05：菜单匹配逻辑」、「实战篇 06：消息通知设计」、「实战篇 07：多语言支持」，增加该小节与「组合式开发」之间的关系，并结合案例详解「组合式开发」中的核心概念。 2018.07.27: 更新「实战篇 01：开发前准备」，增加简单框架选型介绍，小册建议学习方式及拓展学习资料。 2018.07.24: 更新「继往开来：可视化页面搭建工具」，增加「动态路由」部分。 2018.07.23: 更新「小册介绍」，增加对于「进阶」一词的详细解释及其他文字优化。 "},"React组合式开发实践：打造企业管理系统五大核心模块/继往开来：可视化页面搭建工具.html":{"url":"React组合式开发实践：打造企业管理系统五大核心模块/继往开来：可视化页面搭建工具.html","title":"继往开来：可视化页面搭建工具","keywords":"","body":"继往开来：可视化页面搭建工具 在人们的传统印象中，前端一直都是很薄的一层，向上不能影响后端数据，向下不能改变产品设计，只是相当于数据与界面之间的一个连接层，单独拿出来后就将失去其大部分的价值。但随着单页应用的普及，越来越多的重型前端应用被开发了出来并逐渐成为了人们常用的生产力工具中重要的组成部分。 这其中最经典的一个应用莫过于「可视化页面搭建工具」。 对于任何一家有运营需求的公司，「可视化页面搭建工具」都是一个刚需，我们很难想象有哪家公司的前端工程师每天的工作就是做生命周期只有几天甚至几小时的活动页。所以一直以来「可视化页面搭建工具」在前端开发界都不是一个新鲜的议题。从 20 年前的 Dreamweaver 开始，一直到最近淘宝推出的 飞冰（ice），其本质上的思路都是类似的，即基于组件的模块化页面搭建。 三个阶段 在讨论具体的页面搭建工具之前，我们首先要明确一个问题，那就是谁是页面搭建工具的目标用户以及页面搭建工具能够帮助这些目标用户解决什么问题？ 结合目前市面上已经推出的产品，可视化页面搭建工具的目标用户大致可以分为两类：一类是非技术的运营（产品）人员，主要使用场景为更新较为频繁的促销页、活动页等；另一类是非前端开发的技术人员，主要使用场景为简单的内部管理系统搭建。而根据不同的使用场景及需求，页面搭建工具最终交付的成品也不尽相同。 静态页面 常见的可视化页面搭建工具一般都会包含页面预览区、组件选择区及布局调整区（如调整组件顺序等）等三个部分。在从组件选择区选择了某几个组件后，每个被选用的组件还会有各自的属性编辑界面，一般为弹窗的形式，如下图所示的表格组件编辑界面。 最终的产出就是一段描述当前页面布局与内容的 DSL，通常以 JSON 的格式存储。 { \"pageId\": 1, \"pageUrl\": \"/11-11-promo/electronics\", \"pageTitle\": \"双十一大促 - 家电专场\", \"layout\": \"two-columns\", \"components\": { \"two-columns\": { \"firstCol\": [{ \"componentName\": \"list\", \"componentProps\": [{ \"title\": \"促销家电列表\", \"data\": [{ \"name\": \"电视机\" }, { \"name\": \"洗衣机\" }, { \"name\": \"冰箱\" }] }] }], \"secondCol\": [{ \"componentName\": \"list\", \"componentProps\": [{ \"title\": \"促销家电列表\", \"data\": [{ \"name\": \"电视机\" }, { \"name\": \"洗衣机\" }, { \"name\": \"冰箱\" }] }] }] } } } 与之相配合的在客户端代码中还需要有两个解析器。第一个解析器是路由解析器，即根据当前页面路径向后端发送请求拿到对应页面的 DSL 数据。第二个解析器是在拿到这段 DSL 数据后对 components 字段进行解析然后按照设置的布局逐个渲染配置好的组件。 这种架构非常适合处理内容展示页面的需求，从技术角度来讲也很适合做服务端渲染因为每个页面的渲染结果完全是数据驱动的，后端返回的服务端渲染结果就是最终前端展示的 HTML。但这种方案的局限性在于无法动态更新页面数据，因为数据和组件的配置是完全绑定的想要更新页面数据就需要去更改组件的配置。 动态页面 为了实现动态更新数据的需求，我们需要将组件的数据源与组件的配置解耦，也就是说我们需要将原先组件中配置好的数据替换为一个后端的数据接口，让后端的数据接口可以直接与组件进行对接。这样就实现了数据与配置之间的解耦，即不需要更新组件的配置就可以直接更新组件的展示数据。这样的灵活性对于促销页、活动页等数据变动频繁的业务场景来说是非常有帮助的。 { \"pageId\": 1, \"pageUrl\": \"/11-11-promo/electronics\", \"pageTitle\": \"双十一大促 - 家电专场\", \"layout\": \"two-columns\", \"components\": { \"two-columns\": { \"firstCol\": [{ \"componentName\": \"list\", \"componentApi\": \"/api/11-11-promo/electronics/list\", \"componentProps\": [{ \"title\": \"促销家电列表\" }] }], \"secondCol\": [{ \"componentName\": \"list\", \"componentApi\": \"/api/11-11-promo/electronics/list\", \"componentProps\": [{ \"title\": \"促销家电列表\" }] }] } } } 除了直接配置数据接口外，另一种常见的做法是将数据接口统一处理为数据资产，在使用者配置组件的数据源时，让其可以在所有相关的数据资产中选择需要的部分，然后再转化为具体的数据接口，保存在组件配置中。 但在引入了异步数据之后，有一个必须要解决的问题就是何时发出这些数据请求。这里推荐使用高阶组件的方法来解决这一问题，即抽象出一个专门根据组件的 componentApi 属性发送请求的高阶组件，并将它包裹在所有需要发送异步请求的组件之上。 function fetchData(WrappedComponent) { class FetchData extends Component { state = { data: {}, } componentDidMount() { const { componentApi } = this.props; api.get(componentApi) .then((response) => { this.setState({ data: response, }); }); } render() { return ; } } return FetchData; } 动态可交互页面 上面提到的动态页面虽然做到了动态更新数据，但组件与组件之间却仍是独立工作的沙盒模式无法交换数据，也无法感知或响应其他组件的变化。 为了实现组件之间的通信与简单交互，我们需要将不同的组件通过一些自定义的钩子 hook 起来。如下面这个例子中，list 组件 componentQuery 中的 type 字段就来自于 dropdown 组件的 activeKey。用户在改变 dropdown 组件的 activeKey 时，也会更新 list 组件获取数据所调用的 API，如 \"/api/11-11-promo/electronics/list?type=kitchen\" 或 \"/api/11-11-promo/electronics/list?type=living\" 等。 { \"pageId\": 1, \"pageUrl\": \"/11-11-promo/electronics\", \"pageTitle\": \"双十一大促 - 家电专场\", \"layout\": \"two-columns\", \"components\": { \"two-columns\": { \"firstCol\": [{ \"componentName\": \"dropdown\", \"componentProps\": [{ \"title\": \"选择家电种类\", \"defaultActiveKey\": \"kitchen\", \"data\": [{ \"key\": \"kitchen\", \"value\": \"厨房\" }, { \"key\": \"living\", \"value\": \"客厅\" }, { \"key\": \"bedroom\", \"value\": \"卧室\" }] }] }], \"secondCol\": [{ \"componentName\": \"list\", \"componentApi\": \"/api/11-11-promo/electronics/list\", \"componentQuery\": { \"type\": \"dropdown_activeKey\" }, \"componentProps\": [{ \"title\": \"促销家电列表\" }] }] } } } 这样我们就实现了组件与组件之间的联动，大大拓展了页面搭建工具可覆盖的需求范围。在达到了这个阶段之后，我们甚至可以说使用页面搭建工具搭建出来的页面与日常工程师手写的页面之间区别已经不大了。但与此同时随着业务需求的复杂程度越来越高，使用页面搭建工具生成的 DSL 也会越来越复杂，它的表现力相较于代码究竟孰优孰劣，这就很考验平台设计者的内功了。 动态路由 可视化页面搭建工具的核心价值就是以最小的代价快速创建大量时效性较强的页面，在创建页面不再是一个问题后，如何管理这些被创建出来的页面成为了下一个待解决的问题。 假设我们现在已经创建了一个营销页面的 MongoDB 集合，每个页面都有一个自己的 uuid 如 580d69e57f038c01cc41127e 。最简单的情况下，我们可以在应用中创建一个例如 /promotion/:id 这样的路由，然后根据每个页面的 uuid 来获取页面的 DSL 数据。这样的做法非常简洁，但存在的问题是所有营销页的 url 都是无含义的 uuid，既不利于 SEO，也不利于用户以输入 url 的方式到达页面。 针对这个问题，我们需要在页面的 url 和 uuid 之间再建立起一个一一对应的关系，即后端除了要提供获取页面 DSL 数据的接口外，还需要再提供一个处理动态路由的接口。如 580d69e57f038c01cc41127e 对应的页面 url 为 /double11-promotion，那么在用户到达 /double11-promotion 页面后，前端需要先将页面的 url 发送至后端的动态路由接口以拿到页面真正的 uuid，然后再调用获取页面 DSL 数据的接口拿到页面中配置好的组件数据并渲染。 这时另一个问题出现了，前端如何区分 /double11-promotion 这种动态路由和 /home 这种固定路由呢？在前文中我们提到过 react-router 是按照所有路由定义的顺序逐一去匹配路由的，如果当前的页面路径和所有的路由都匹配不上的话，则会渲染在最后定义的 404 页面。换句话说，在简单的应用中路由只分为两种，一种是定义好的固定路由，另一种是会由 404 页面统一处理的其他路由。 const Router = ({ history }) => ( // try to query the url from backend ); 但在引入了动态路由后，第三种路由就出现了，首先它需要和定义好的固定路由之间没有冲突，即如果应用中已经定义了 /home 的话，由页面搭建平台搭建出来的页面的 url 就不能够再是 /home。否则的话因为固定路由 /home 的匹配优先级较高，用户在到达 /home 页面后永远都只会看到固定路由 /home 的界面。其次在和所有固定路由尝试匹配失败后，我们不再直接将当前 url 交给 404 页面处理，而是交给动态路由组件，由动态路由组件尝试将当前 url 发送至后端的路由服务，查找当前 url 是否是页面集合中的一个有效 url，如果是则返回页面的 uuid，如果不是则返回查找失败再由前端主动地将页面 url 替换为 /404 并渲染 404 页面。也就是说，对于所有无法和固定路由相匹配的 url，我们都先假定它是一个动态路由，尝试调用后端的路由服务来获取页面数据，如果后端的路由服务也查找不到它的话，再将其认定为是 404 的情况。 后端路由服务的意义 在前后端分离架构的背景下，前端已经逐渐代替后端接管了所有固定路由的判断与处理，但在动态路由这样一个场景下，我们会发现单纯前端路由服务的灵活度是远远不够的。在用户到达某个页面后，可供下一步逻辑判断的依据就只有当前页面的 url，而根据 url 后端的路由服务是可以返回非常丰富的数据的。 常见的例子如页面的类型。假设应用中营销页和互动页的渲染逻辑并不相同，那么在页面的 DSL 数据之外，我们就还需要获取到页面的类型以进行相应的渲染。再比如页面的 SEO 数据，创建和更新时间等等，这些数据都对应用能够在前端灵活地展示页面，处理业务逻辑有着巨大的帮助。 甚至我们还可以推而广之，彻底抛弃掉由 react-router 等提供的前端路由服务，转而写一套自己的路由分发器，即根据页面类型的不同分别调用不同的页面渲染服务，以多种类型页面的方式来组成一个完整的前端应用。 展望未来 在了解了可视化页面搭建工具大体的工作流程后，我们不得不承认目前的可视化页面搭建工具仍存在着诸多不足。尤其是在搭建动态可交互页面方面，组件之间烦琐的依赖关系甚至比源代码更难管理，出了问题之后 debug 的过程也非常令人头痛。另一方面，上述提到的这种页面搭建方式最终都要落地到一个具体的包含两个特殊解析器的应用中，再加上应用本身的构建和部署过程全程无专业前端开发参与几乎是不可能的。 为了解决这一问题，许多专业的前端团队也在尝试着从工程的角度出发，将项目脚手架部分也一并 GUI 化，提供可视化的操作界面并覆盖项目构建、打包、发布的全过程。但这让整个工具的使用复杂度又上升了一个等级，虽然拥有了对于最终产出结果源码级别的控制能力，但对非技术人员非常不友好，极大地限制了工具可以覆盖到的用户群体。 关于这一问题，笔者这里提供另一种不成熟的思路供各位一起讨论。 其实从本质上讲，项目脚手架及后续的打包、发布与页面搭建之间是没有直接的联系的，也就是说我们能不能将二者完全拆分开来当成两个独立的工具分别开发？让页面的归页面，应用的归应用。再结合小册中一直强调的组合式开发的理念，假设我们现在已经拥有了一个可以很好地解决独立页面开发的工具，使用者在配置完了应用中所有的页面（只包含页面的具体内容，不包含菜单、页眉、页脚等全局组件）后，再使用另一个应用构建工具将配置好的页面嵌入应用路由中，然后选择性地开启一些全局功能，如页面布局、权限配置、菜单管理等，并最终将配置好的应用通过 webpack 等打包工具编译成生产环境中可以运行的 HTML、CSS 和 JavaScript，再通过持续集成工具打上版本 tag 发布到服务器上。 当然，目前这些都仍只是抽象的想法，具体落地时一定还会遇到各种各样的问题。但简而言之，软件工程行业与传统行业最大的区别就是软件工程行业从不重复自己，我们坚信同样的事情在第二次做时受益于第一次积累下来的经验，我们一定会做得比上一次更好。 "},"Vue.js组件精讲/01.开篇：Vue.js的精髓——组件.html":{"url":"Vue.js组件精讲/01.开篇：Vue.js的精髓——组件.html","title":"01.开篇：Vue.js的精髓——组件","keywords":"","body":"开篇：Vue.js 的精髓——组件 写在前面 Vue.js，无疑是当下最火热的前端框架 Almost，而 Vue.js 最精髓的，正是它的组件与组件化。写一个 Vue 工程，也就是在写一个个的组件。 业务场景是千变万化的，而不变的是 Vue.js 组件开发的核心思想和使用技巧，掌握了 Vue.js 组件的各种开发模式，再复杂的业务场景也可以轻松化解。本小册则着重介绍笔者在 3 年的 Vue.js 开发及两年的 iView 开源中积累和沉淀的对 Vue.js 组件的见解和经验。 本小册不会介绍 Vue.js 的基础用法，因为市面上已经沉淀了大量的相关技术资料，而且 Vue.js 的文档已经足够详细。如果您尚未接触 Vue.js 或正打算开始了解，推荐您先阅读笔者出版的《Vue.js 实战》（清华大学出版社）一书，它适合刚接触 Vue.js 的开发者。因此，本小册适合已经了解或使用过 Vue.js 的开发者。 这一节，我们先笼统地聊聊 Vue.js 组件和组件化以及本小册各章节的梳理。 组件的分类 一般来说，Vue.js 组件主要分成三类： 由 vue-router 产生的每个页面，它本质上也是一个组件（.vue），主要承载当前页面的 HTML 结构，会包含数据获取、数据整理、数据可视化等常规业务。整个文件相对较大，但一般不会有 props 选项和 自定义事件，因为它作为路由的渲染，不会被复用，因此也不会对外提供接口。 在项目开发中，我们写的大部分代码都是这类的组件（页面），协同开发时，每人维护自己的页面，很少有交集。这类组件相对是最好写的，因为主要是还原设计稿，完成需求，不需要太多模块和架构设计上的考虑。 不包含业务，独立、具体功能的基础组件，比如日期选择器、模态框等。这类组件作为项目的基础控件，会被大量使用，因此组件的 API 进行过高强度的抽象，可以通过不同配置实现不同的功能。比如笔者开源的 iView，就是包含了 50 多个这样基础组件的 UI 组件库。 每个公司都有自己的组件使用规范或组件库，但要开发和维护一套像 iView 这样的组件库，投入的人力和精力还是很重的，所以出于成本考虑，很多项目都会使用已有的开源组件库。 独立组件的开发难度要高于第一类组件，因为它的侧重点是 API 的设计、兼容性、性能、以及复杂的功能。这类组件对 JavaScript 的编程能力有一定要求，也会包含非常多的技巧，比如在不依赖 Vuex 和 Bus（因为独立组件，无法依赖其它库）的情况下，各组件间的通信，还会涉及很多脑壳疼的逻辑，比如日期选择器要考虑不同时区、国家的日历习惯，支持多种日期格式。 本小册也会重点介绍此类组件的各种开发模式和技巧，对应不同的模式，会带有具体的组件实战。 业务组件。它不像第二类独立组件只包含某个功能，而是在业务中被多个页面复用的，它与独立组件的区别是，业务组件只在当前项目中会用到，不具有通用性，而且会包含一些业务，比如数据请求；而独立组件不含业务，在任何项目中都可以使用，功能单一，比如一个具有数据校验功能的输入框。 业务组件更像是介于第一类和第二类之间，在开发上也与独立组件类似，但寄托于项目，你可以使用项目中的技术栈，比如 Vuex、axios、echarts 等，所以它的开发难度相对独立组件要容易点，但也有必要考虑组件的可维护性和复用性。 小册的内容 因为本小册是围绕 Vue.js 组件展开的，所以第二节会讲解 Vue.js 组件的三个 API：prop、event、slot，当然，如果你已经开发过一些独立组件，完全可以跳过这节内容。 3 - 7 小节会介绍组件间通信的一些方法和黑科技，一部分是 Vue.js 内置的，一部分是自行实现的，在实际开发中，会非常实用。同时也利用这些方法完成了两个具体的实战案例： 具有数据校验功能的表单组件 —— Form； 组合多选框组件 —— CheckboxGroup & Checkbox。 本小册都会以这种核心科技 + 对应实战的形式展开。 8 - 10 小节介绍 Vue 的构造器 extend 和手动挂载组件 $mount 的用法及案例。Vue.js 除了我们正常 new Vue() 外，还可以手动挂载的，这 3 节将介绍手动挂载一个 Vue 组件的使用场景。其中涉及到两个案例： 动态渲染 .vue 文件的组件 —— Display； 全局通知组件 —— $Alert。 Display 组件用于将 .vue 文件渲染出来，线上的案例是 iView Run，它不需要你重新编译项目，就可以渲染一个标准的 Vue.js 组件。 $Alert 是全局的通知组件，它的调用方法不同于常规组件。常规组件使用方法形如： import Alert from '../components/alert.vue'; export default { components: { Alert } } 而 $Alert 的调用更接近 JS 语法： export default { methods: { showMessage () { this.$Alert({ content: '通知内容', duration: 3 }); } } } 虽然与常规 Vue 组件调用方式不同，但底层仍然由 Vue 组件构成和维护。 11 - 12 小节介绍 Render 函数与 Functional Render，并完成一个能够渲染自定义列的 Table 组件。Render 函数也是 Vue.js 组件重要的一部分，只不过在大多数业务中不常使用。本小节会介绍它的使用场景。 13 小节介绍作用域 slot（slot-scope），并基于这种方法同样实现 Table 组件。slot 用的很多，但 slot-scope 在业务中并不常用，但在一些特定场景下，比如组件内部有循环体时，会非常实用。 14 - 15 小节介绍递归组件，并完成树形控件 —— Tree。 16 - 19 小节是综合拓展，会着重讲解 Vue.js 容易忽略却很重要的 API，以及对 Vue.js 面试题的详细分析。除此之外，还会总结笔者在两年的 iView 开源经历中的经验，除了技术细节外，还包括开源项目的持续性发展、推广等。 结语 三年前，我开始接触 Vue.js 框架，当时就被它的轻量、组件化和友好的 API 所吸引。与此同时，我也开源了 iView 项目。三年的磨(cǎi )砺(kēng)，沉淀了不少关于 Vue.js 组件的经验。 本小册的内容也许不会让你的技术一夜间突飞猛进，但绝对使你醍醐灌顶。 那么，请准备好一台电脑和一杯咖啡，一起来探索 Vue.js 的精髓吧。 "},"Vue.js组件精讲/02.基础：Vue.js组件的三个API：prop、event、slot.html":{"url":"Vue.js组件精讲/02.基础：Vue.js组件的三个API：prop、event、slot.html","title":"02.基础：Vue.js组件的三个API：prop、event、slot","keywords":"","body":"基础：Vue.js 组件的三个 API：prop、event、slot 如果您已经对 Vue.js 组件的基础用法了如指掌，可以跳过本小节，不过当做复习稍读一下也无妨。 组件的构成 一个再复杂的组件，都是由三部分组成的：prop、event、slot，它们构成了 Vue.js 组件的 API。如果你开发的是一个通用组件，那一定要事先设计好这三部分，因为组件一旦发布，后面再修改 API 就很困难了，使用者都是希望不断新增功能，修复 bug，而不是经常变更接口。如果你阅读别人写的组件，也可以从这三个部分展开，它们可以帮助你快速了解一个组件的所有功能。 属性 prop prop 定义了这个组件有哪些可配置的属性，组件的核心功能也都是它来确定的。写通用组件时，props 最好用对象的写法，这样可以针对每个属性设置类型、默认值或自定义校验属性的值，这点在组件开发中很重要，然而很多人却忽视，直接使用 props 的数组用法，这样的组件往往是不严谨的。比如我们封装一个按钮组件 ： // 判断参数是否是其中之一 function oneOf (value, validList) { for (let i = 0; i 使用组件： 组件中定义了两个属性：尺寸 size 和 是否禁用 disabled。其中 size 使用 validator 进行了值的自定义验证，也就是说，从父级传入的 size，它的值必须是指定的 small、large、default 中的一个，默认值是 default，如果传入这三个以外的值，都会抛出一条警告。 要注意的是，组件里定义的 props，都是单向数据流，也就是只能通过父级修改，组件自己不能修改 props 的值，只能修改定义在 data 里的数据，非要修改，也是通过后面介绍的自定义事件通知父级，由父级来修改。 在使用组件时，也可以传入一些标准的 html 特性，比如 id、class： 这样的 html 特性，在组件内的 元素上会继承，并不需要在 props 里再定义一遍。这个特性是默认支持的，如果不期望开启，在组件选项里配置 inheritAttrs: false 就可以禁用了。 插槽 slot 如果要给上面的按钮组件 添加一些文字内容，就要用到组件的第二个 API：插槽 slot，它可以分发组件的内容，比如在上面的按钮组件中定义一个插槽： 这里的 节点就是指定的一个插槽的位置，这样在组件内部就可以扩展内容了： 按钮 1 按钮 2 当需要多个插槽时，会用到具名 slot，比如上面的组件我们再增加一个 slot，用于设置另一个图标组件： 按钮 1 这样，父级内定义的内容，就会出现在组件对应的 slot 里，没有写名字的，就是默认的 slot。 在组件的 里也可以写一些默认的内容，这样在父级没有写任何 slot 时，它们就会出现，比如： 提交 自定义事件 event 现在我们给组件 加一个点击事件，目前有两种写法，我们先看自定义事件 event（部分代码省略）： export default { methods: { handleClick (event) { this.$emit('on-click', event); } } } 通过 $emit，就可以触发自定义的事件 on-click ，在父级通过 @on-click 来监听： 上面的 click 事件，是在组件内部的 元素上声明的，这里还有另一种方法，直接在父级声明，但为了区分原生事件和自定义事件，要用到事件修饰符 .native，所以上面的示例也可以这样写： 如果不写 .native 修饰符，那上面的 @click 就是自定义事件 click，而非原生事件 click，但我们在组件内只触发了 on-click 事件，而不是 click，所以直接写 @click 会监听不到。 组件的通信 一般来说，组件可以有以下几种关系： A 和 B、B 和 C、B 和 D 都是父子关系，C 和 D 是兄弟关系，A 和 C 是隔代关系（可能隔多代）。组件间经常会通信，Vue.js 内置的通信手段一般有两种： ref：给元素或组件注册引用信息； $parent / $children：访问父 / 子实例。 这两种都是直接得到组件实例，使用后可以直接调用组件的方法或访问数据，比如下面的示例中，用 ref 来访问组件（部分代码省略）： // component-a export default { data () { return { title: 'Vue.js' } }, methods: { sayHello () { window.alert('Hello'); } } } export default { mounted () { const comA = this.$refs.comA; console.log(comA.title); // Vue.js comA.sayHello(); // 弹窗 } } $parent 和 $children 类似，也是基于当前上下文访问父组件或全部子组件的。 这两种方法的弊端是，无法在跨级或兄弟间通信，比如下面的结构： // parent.vue 我们想在 component-a 中，访问到引用它的页面中（这里就是 parent.vue）的两个 component-b 组件，那这种情况下，就得配置额外的插件或工具了，比如 Vuex 和 Bus 的解决方案，本小册不再做它们的介绍，读者可以自行阅读相关内容。不过，它们都是依赖第三方插件的存在，这在开发独立组件时是不可取的，而在小册的后续章节，会陆续介绍一些黑科技，它们完全不依赖任何三方插件，就可以轻松得到任意的组件实例，或在任意组件间进行通信，且适用于任意场景。 结语 本小节带您复习了 Vue.js 组件的核心知识点，虽然这并没有完全覆盖 Vue.js 的 API，但对于组件开发来说已经足够了，后续章节也会陆续扩展更多的用法。 基于 Vue.js 开发独立组件，并不是新奇的挑战，坦率地讲，它本质上还是 JavaScript。掌握了 Vue.js 组件的这三个 API 后，剩下的便是程序的设计。在组件开发中，最难的环节应当是解耦组件的交互逻辑，尽量把复杂的逻辑分发到不同的子组件中，然后彼此建立联系，在这其中，计算属性（computed）和混合（mixins）是两个重要的技术点，合理利用，就能发挥出 Vue.js 语言的最大特点：把状态（数据）的维护交给 Vue.js 处理，我们只专注在交互上。 当您最终读完本小册时，应该会总结出和笔者一样的感悟：Vue.js 组件开发，玩到最后还是在拼 JavaScript 功底。对于每一位使用 Vue.js 的开发者来说，阅读完本小册都可以尝试开发和维护一套属于自己的组件库，并乐在其中，而且你会越发觉得，一个组件或一套组件库，就是融合了前端精髓的产出。 扩展阅读 Vue 组件通信之 Bus Vuex 通俗版教程 "},"Vue.js组件精讲/03.组件的通信1：provideinject.html":{"url":"Vue.js组件精讲/03.组件的通信1：provideinject.html","title":"03.组件的通信1：provideinject","keywords":"","body":"组件的通信 1：provide / inject 上一节中我们说到，ref 和 $parent / $children 在跨级通信时是有弊端的。当组件 A 和组件 B 中间隔了数代（甚至不确定具体级别）时，以往会借助 Vuex 或 Bus 这样的解决方案，不得不引入三方库来支持。本小节则介绍一种无依赖的组件通信方法：Vue.js 内置的 provide / inject 接口。 什么是 provide / inject provide / inject 是 Vue.js 2.2.0 版本后新增的 API，在文档中这样介绍 ： https://cn.vuejs.org/v2/api/#provide-inject 这对选项需要一起使用，以允许一个祖先组件向其所有子孙后代注入一个依赖，不论组件层次有多深，并在起上下游关系成立的时间里始终生效。如果你熟悉 React，这与 React 的上下文特性很相似。 并且文档中有如下提示： provide 和 inject 主要为高阶插件/组件库提供用例。并不推荐直接用于应用程序代码中。 看不懂上面的介绍没有关系，不过上面的这句提示应该明白，就是说 Vue.js 不建议在业务中使用这对 API，而是在插件 / 组件库（比如 iView，事实上 iView 的很多组件都在用）。不过建议归建议，如果你用好了，这个 API 会非常有用。 我们先来看一下这个 API 怎么用，假设有两个组件： A.vue 和 B.vue，B 是 A 的子组件。 // A.vue export default { provide: { name: 'Aresn' } } // B.vue export default { inject: ['name'], mounted () { console.log(this.name); // Aresn } } 可以看到，在 A.vue 里，我们设置了一个 provide: name，值为 Aresn，它的作用就是将 name 这个变量提供给它的所有子组件。而在 B.vue 中，通过 inject 注入了从 A 组件中提供的 name 变量，那么在组件 B 中，就可以直接通过 this.name 访问这个变量了，它的值也是 Aresn。这就是 provide / inject API 最核心的用法。 需要注意的是： provide 和 inject 绑定并不是可响应的。这是刻意为之的。然而，如果你传入了一个可监听的对象，那么其对象的属性还是可响应的。 所以，上面 A.vue 的 name 如果改变了，B.vue 的 this.name 是不会改变的，仍然是 Aresn。 替代 Vuex 我们知道，在做 Vue 大型项目时，可以使用 Vuex 做状态管理，它是一个专为 Vue.js 开发的状态管理模式，用于集中式存储管理应用的所有组件的状态，并以相应的规则保证状态以一种可预测的方式发生变化。 那了解了 provide / inject 的用法，下面来看怎样替代 Vuex。当然，我们的目的并不是为了替代 Vuex，它还是有相当大的用处，这里只是介绍另一种可行性。 使用 Vuex，最主要的目的是跨组件通信、全局数据维护、多人协同开发。需求比如有：用户的登录信息维护、通知信息维护等全局的状态和数据。 一般在 webpack 中使用 Vue.js，都会有一个入口文件 main.js，里面通常导入了 Vue、VueRouter、iView 等库，通常也会导入一个入口组件 app.vue 作为根组件。一个简单的 app.vue 可能只有以下代码： export default { } 使用 provide / inject 替代 Vuex，就是在这个 app.vue 文件上做文章。 我们把 app.vue 理解为一个最外层的根组件，用来存储所有需要的全局数据和状态，甚至是计算属性（computed）、方法（methods）等。因为你的项目中所有的组件（包含路由），它的父组件（或根组件）都是 app.vue，所以我们把整个 app.vue 实例通过 provide 对外提供。 app.vue： export default { provide () { return { app: this } } } 上面，我们把整个 app.vue 的实例 this 对外提供，命名为 app（这个名字可以自定义，推荐使用 app，使用这个名字后，子组件不能再使用它作为局部属性）。接下来，任何组件（或路由）只要通过 inject 注入 app.vue 的 app 的话，都可以直接通过 this.app.xxx 来访问 app.vue 的 data、computed、methods 等内容。 app.vue 是整个项目第一个被渲染的组件，而且只会渲染一次（即使切换路由，app.vue 也不会被再次渲染），利用这个特性，很适合做一次性全局的状态数据管理，例如，我们将用户的登录信息保存起来： app.vue，部分代码省略： export default { provide () { return { app: this } }, data () { return { userInfo: null } }, methods: { getUserInfo () { // 这里通过 ajax 获取用户信息后，赋值给 this.userInfo，以下为伪代码 $.ajax('/user/info', (data) => { this.userInfo = data; }); } }, mounted () { this.getUserInfo(); } } 这样，任何页面或组件，只要通过 inject 注入 app 后，就可以直接访问 userInfo 的数据了，比如： {{ app.userInfo }} export default { inject: ['app'] } 是不是很简单呢。除了直接使用数据，还可以调用方法。比如在某个页面里，修改了个人资料，这时一开始在 app.vue 里获取的 userInfo 已经不是最新的了，需要重新获取。可以这样使用： 某个页面： {{ app.userInfo }} export default { inject: ['app'], methods: { changeUserInfo () { // 这里修改完用户数据后，通知 app.vue 更新，以下为伪代码 $.ajax('/user/update', () => { // 直接通过 this.app 就可以调用 app.vue 里的方法 this.app.getUserInfo(); }) } } } 同样非常简单。只要理解了 this.app 是直接获取整个 app.vue 的实例后，使用起来就得心应手了。想一想，配置复杂的 Vuex 的全部功能，现在是不是都可以通过 provide / inject 来实现了呢？ 进阶技巧 如果你的项目足够复杂，或需要多人协同开发时，在 app.vue 里会写非常多的代码，多到结构复杂难以维护。这时可以使用 Vue.js 的混合 mixins，将不同的逻辑分开到不同的 js 文件里。 比如上面的用户信息，就可以放到混合里： user.js： export default { data () { return { userInfo: null } }, methods: { getUserInfo () { // 这里通过 ajax 获取用户信息后，赋值给 this.userInfo，以下为伪代码 $.ajax('/user/info', (data) => { this.userInfo = data; }); } }, mounted () { this.getUserInfo(); } } 然后在 app.vue 中混合： app.vue： import mixins_user from '../mixins/user.js'; export default { mixins: [mixins_user], data () { return { } } } 这样，跟用户信息相关的逻辑，都可以在 user.js 里维护，或者由某个人来维护，app.vue 也就很容易维护了。 独立组件中使用 如果你顾忌 Vue.js 文档中所说，provide / inject 不推荐直接在应用程序中使用，那没有关系，仍然使用你熟悉的 Vuex 或 Bus 来管理你的项目就好。我们介绍的这对 API，主要还是在独立组件中发挥作用的。 只要一个组件使用了 provide 向下提供数据，那其下所有的子组件都可以通过 inject 来注入，不管中间隔了多少代，而且可以注入多个来自不同父级提供的数据。需要注意的是，一旦注入了某个数据，比如上面示例中的 app，那这个组件中就不能再声明 app 这个数据了，因为它已经被父级占有。 独立组件使用 provide / inject 的场景，主要是具有联动关系的组件，比如接下来很快会介绍的第一个实战：具有数据校验功能的表单组件 Form。它其实是两个组件，一个是 Form，一个是 FormItem，FormItem 是 Form 的子组件，它会依赖 Form 组件上的一些特性（props），所以就需要得到父组件 Form，这在 Vue.js 2.2.0 版本以前，是没有 provide / inject 这对 API 的，而 Form 和 FormItem 不一定是父子关系，中间很可能间隔了其它组件，所以不能单纯使用 $parent 来向上获取实例。在 Vue.js 2.2.0 之前，一种比较可行的方案是用计算属性动态获取： computed: { form () { let parent = this.$parent; while (parent.$options.name !== 'Form') { parent = parent.$parent; } return parent; } } 每个组件都可以设置 name 选项，作为组件名的标识，利用这个特点，通过向上遍历，直到找到需要的组件。这个方法可行，但相比一个 inject 来说，太费劲了，而且不那么优雅和 native。如果用 inject，可能只需要一行代码： export default { inject: ['form'] } 不过，这一切的前提是你使用 Vue.js 2.2.0 以上版本。 结语 如果这是你第一次听说 provide / inject 这对 API，一定觉得它太神奇了，至少笔者第一时间知晓时是这样的。它解决了独立组件间通信的问题，用好了还有出乎意料的效果。笔者在开发 iView Developer 时，全站就是使用这种方法来做全局数据的管理的，如果你有机会一个人做一个项目时，不妨试试这种方法。 下一节，将介绍另一种组件间通信的方法，不同于 provide / inject 的是，它们不是 Vue.js 内置的 API。 "},"Vue.js组件精讲/04.组件的通信2：派发与广播——自行实现dispatch和broadcast方法.html":{"url":"Vue.js组件精讲/04.组件的通信2：派发与广播——自行实现dispatch和broadcast方法.html","title":"04.组件的通信2：派发与广播——自行实现dispatch和broadcast方法","keywords":"","body":"组件的通信 2：派发与广播——自行实现 dispatch 和 broadcast 方法 上一讲的 provide / inject API 主要解决了跨级组件间的通信问题，不过它的使用场景，主要是子组件获取上级组件的状态，跨级组件间建立了一种主动提供与依赖注入的关系。然后有两种场景它不能很好的解决： 父组件向子组件（支持跨级）传递数据； 子组件向父组件（支持跨级）传递数据。 这种父子（含跨级）传递数据的通信方式，Vue.js 并没有提供原生的 API 来支持，而是推荐使用大型数据状态管理工具 Vuex，而我们之前已经介绍过 Vuex 的场景与在独立组件（或库）中使用的限制。本小节则介绍一种在父子组件间通信的方法 dispatch 和 broadcast。 $on 与 $emit 如果您使用过较早的 Vue.js 1.x 版本，肯定对 $dispatch 和 $broadcast 这两个内置的方法很熟悉，不过它们都在 Vue.js 2.x 里废弃了。在正式介绍主角前，我们先看看 $on 与 $emit 这两个 API，因为它们是本节内容的基础。 $emit 会在当前组件实例上触发自定义事件，并传递一些参数给监听器的回调，一般来说，都是在父级调用这个组件时，使用 @on 的方式来监听自定义事件的，比如在子组件中触发事件： // child.vue，部分代码省略 export default { methods: { handleEmitEvent () { this.$emit('test', 'Hello Vue.js'); } } } 在父组件中监听由 child.vue 触发的自定义事件 test： export default { methods: { handleEvent (text) { console.log(text); // Hello Vue.js } } } 这里看似是在父组件 parent.vue 中绑定的自定义事件 test 的处理句柄，然而事件 test 并不是在父组件上触发的，而是在子组件 child.vue 里触发的，只是通过 v-on 在父组件中监听。既然是子组件自己触发的，那它自己也可以监听到，这就要使用 $on 来监听实例上的事件，换言之，组件使用 $emit 在自己实例上触发事件，并用 $on 监听它。 听起来这种神（sāo）操作有点多此一举，我们不妨先来看个示例： （也可通过在线链接 https://run.iviewui.com/ggsomfHM 直接运行该示例） 触发自定义事件 export default { methods: { handleEmitEvent () { // 在当前组件上触发自定义事件 test，并传值 this.$emit('test', 'Hello Vue.js') } }, mounted () { // 监听自定义事件 test this.$on('test', (text) => { window.alert(text); }); } } $on 监听了自己触发的自定义事件 test，因为有时不确定何时会触发事件，一般会在 mounted 或 created 钩子中来监听。 仅上面的示例，的确是多此一举的，因为大可在 handleEmitEvent 里直接写 window.alert(text)，没必要绕一圈。 之所以多此一举，是因为 handleEmitEvent 是当前组件内的 调用的，如果这个方法不是它自己调用，而是其它组件调用的，那这个用法就大有可为了。 了解了 $on 和 $emit 的用法后，我们再来看两个“过时的” API。 Vue.js 1.x 的 $dispatch 与 $broadcast 虽然 Vue.js 1.x 已经成为过去时，但为了充分理解本节通信方法的使用场景，还是有必要来了解一点它的历史。 在 Vue.js 1.x 中，提供了两个方法：$dispatch 和 $broadcast ，前者用于向上级派发事件，只要是它的父级（一级或多级以上），都可以在组件内通过 $on （或 events，2.x 已废弃）监听到，后者相反，是由上级向下级广播事件的。 来看一个简单的示例： 派发事件 export default { methods: { handleDispatch () { this.$dispatch('test', 'Hello, Vue.js'); } } } export default { mounted () { this.$on('test', (text) => { console.log(text); // Hello, Vue.js }); } } $broadcast 类似，只不过方向相反。这两种方法一旦发出事件后，任何组件都是可以接收到的，就近原则，而且会在第一次接收到后停止冒泡，除非返回 true。 这两个方法虽然看起来很好用，但是在 Vue.js 2.x 中都废弃了，官方给出的解释是： 因为基于组件树结构的事件流方式有时让人难以理解，并且在组件结构扩展的过程中会变得越来越脆弱。 虽然在业务开发中，它没有 Vuex 这样专门管理状态的插件清晰好用，但对独立组件（库）的开发，绝对是福音。因为独立组件一般层级并不会很复杂，并且剥离了业务，不会变的难以维护。 知道了 $dispatch 和 $broadcast 的前世今生，接下来我们就在 Vue.js 2.x 中自行实现这两个方法。 自行实现 dispatch 和 broadcast 方法 自行实现的 dispatch 和 broadcast 方法，不能保证跟 Vue.js 1.x 的 $dispatch 和 $broadcast 具有完全相同的体验，但基本功能是一样的，都是解决父子组件（含跨级）间的通信问题。 通过目前已知的信息，我们要实现的 dispatch 和 broadcast 方法，将具有以下功能： 在子组件调用 dispatch 方法，向上级指定的组件实例（最近的）上触发自定义事件，并传递数据，且该上级组件已预先通过 $on 监听了这个事件； 相反，在父组件调用 broadcast 方法，向下级指定的组件实例（最近的）上触发自定义事件，并传递数据，且该下级组件已预先通过 $on 监听了这个事件。 实现这对方法的关键点在于，如何正确地向上或向下找到对应的组件实例，并在它上面触发方法。在设计一个新功能（features）时，可以先确定这个功能的 API 是什么，也就是说方法名、参数、使用样例，确定好 API，再来写具体的代码。 因为 Vue.js 内置的方法，才是以 $ 开头的，比如 $nextTick、$emit 等，为了避免不必要的冲突并遵循规范，这里的 dispatch 和 broadcast 方法名前不加 $。并且该方法可能在很多组件中都会使用，复用起见，我们封装在混合（mixins）里。那它的使用样例可能是这样的： // 部分代码省略 import Emitter from '../mixins/emitter.js' export default { mixins: [ Emitter ], methods: { handleDispatch () { this.dispatch(); // ① }, handleBroadcast () { this.broadcast(); // ② } } } 上例中行 ① 和行 ② 的两个方法就是在导入的混合 emitter.js 中定义的，这个稍后我们再讲，先来分析这两个方法应该传入什么参数。一般来说，为了跟 Vue.js 1.x 的方法一致，第一个参数应当是自定义事件名，比如 “test”，第二个参数是传递的数据，比如 “Hello, Vue.js”，但在这里，有什么问题呢？只通过这两个参数，我们没办法知道要在哪个组件上触发事件，因为自行实现的这对方法，与 Vue.js 1.x 的原生方法机理上是有区别的。上文说到，实现这对方法的关键点在于准确地找到组件实例。那在寻找组件实例上，我们的“惯用伎俩”就是通过遍历来匹配组件的 name 选项，在独立组件（库）里，每个组件的 name 值应当是唯一的，name 主要用于递归组件，在后面小节会单独介绍。 先来看下 emitter.js 的代码： function broadcast(componentName, eventName, params) { this.$children.forEach(child => { const name = child.$options.name; if (name === componentName) { child.$emit.apply(child, [eventName].concat(params)); } else { broadcast.apply(child, [componentName, eventName].concat([params])); } }); } export default { methods: { dispatch(componentName, eventName, params) { let parent = this.$parent || this.$root; let name = parent.$options.name; while (parent && (!name || name !== componentName)) { parent = parent.$parent; if (parent) { name = parent.$options.name; } } if (parent) { parent.$emit.apply(parent, [eventName].concat(params)); } }, broadcast(componentName, eventName, params) { broadcast.call(this, componentName, eventName, params); } } }; 因为是用作 mixins 导入，所以在 methods 里定义的 dispatch 和 broadcast 方法会被混合到组件里，自然就可以用 this.dispatch 和 this.broadcast 来使用。 这两个方法都接收了三个参数，第一个是组件的 name 值，用于向上或向下递归遍历来寻找对应的组件，第二个和第三个就是上文分析的自定义事件名称和要传递的数据。 可以看到，在 dispatch 里，通过 while 语句，不断向上遍历更新当前组件（即上下文为当前调用该方法的组件）的父组件实例（变量 parent 即为父组件实例），直到匹配到定义的 componentName 与某个上级组件的 name 选项一致时，结束循环，并在找到的组件实例上，调用 $emit 方法来触发自定义事件 eventName。broadcast 方法与之类似，只不过是向下遍历寻找。 来看一下具体的使用方法。有 A.vue 和 B.vue 两个组件，其中 B 是 A 的子组件，中间可能跨多级，在 A 中向 B 通信： 触发事件 import Emitter from '../mixins/emitter.js'; export default { name: 'componentA', mixins: [ Emitter ], methods: { handleClick () { this.broadcast('componentB', 'on-message', 'Hello Vue.js'); } } } // B.vue export default { name: 'componentB', created () { this.$on('on-message', this.showMessage); }, methods: { showMessage (text) { window.alert(text); } } } 同理，如果是 B 向 A 通信，在 B 中调用 dispatch 方法，在 A 中使用 $on 监听事件即可。 以上就是自行实现的 dispatch 和 broadcast 方法，相比 Vue.js 1.x，有以下不同： 需要额外传入组件的 name 作为第一个参数； 无冒泡机制； 第三个参数传递的数据，只能是一个（较多时可以传入一个对象），而 Vue.js 1.x 可以传入多个参数，当然，你对 emitter.js 稍作修改，也能支持传入多个参数，只是一般场景传入一个对象足以。 结语 Vue.js 的组件通信到此还没完全结束，如果你想“趁热打铁”一口气看完，可以先阅读第 6 节组件的通信 3。亦或按顺序看下一节的实战，来进一步加深理解 provide / inject 和 dispatch / broadcast 这两对通信方法的使用场景。 注：本节部分代码参考 iView。 "},"Vue.js组件精讲/05.实战1：具有数据校验功能的表单组件——Form.html":{"url":"Vue.js组件精讲/05.实战1：具有数据校验功能的表单组件——Form.html","title":"05.实战1：具有数据校验功能的表单组件——Form","keywords":"","body":"实战 1：具有数据校验功能的表单组件——Form 在第 3 节和第 4 节中，我们介绍了组件间的两种通信方法：provide / inject 和 dispatch / broadcast，前者是 Vue.js 内置的，主要用于子组件获取父组件（包括跨级）的状态；后者是自行实现的一种混合，用于父子组件（包括跨级）间通过自定义事件通信。本小节则基于这两种通信方法，来实现一个具有数据校验功能的表单组件——Form。 Form 组件概览 表单类组件在项目中会大量使用，比如输入框（Input）、单选（Radio）、多选（Checkbox）、下拉选择器（Select）等。在使用表单类组件时，也会经常用到数据校验，如果每次都写校验程序来对每一个表单控件校验，会很低效，因此需要一个能够校验基础表单控件的组件，也就是本节要完成的 Form 组件。一般的组件库都提供了这个组件，比如 iView，它能够校验内置的 15 种控件，且支持校验自定义组件，如下图所示： （也可以在线访问本示例体验：https://run.iviewui.com/jwrqnFss） Form 组件分为两个部分，一个是外层的 Form 表单域组件，一组表单控件只有一个 Form，而内部包含了多个 FormItem 组件，每一个表单控件都被一个 FormItem 包裹。基本的结构看起来像： Form 要用到数据校验，并在对应的 FormItem 中给出校验失败的提示，校验我们会用到一个开源库：async-validator，基本主流的组件库都是基于它做的校验。使用它很简单，只需按要求写好一个校验规则就好，比如： [ { required: true, message: '邮箱不能为空', trigger: 'blur' }, { type: 'email', message: '邮箱格式不正确', trigger: 'blur' } ] 这个代表要校验的数据先判断是否为空（required: true），如果为空，则提示“邮箱不能为空”，触发校验的事件为失焦（trigger: 'blur'），如果第一条满足要求，再进行第二条的验证，判断是否为邮箱格式（type: 'email'）等等，还支持自定义校验规则。更详细的用法可以参看它的文档。 接口设计 我们先使用最新的 Vue CLI 3 创建一个空白的项目（如果你还不清楚 Vue CLI 3 的用法，需要先补习一下了，可以阅读文末的扩展阅读 1），并使用 vue-router 插件，同时安装好 async-validator 库。 在 src/components 下新建一个 form 文件夹，并初始化两个组件 form.vue 和 form-item.vue，然后初始化项目，配置路由，创建一个页面能够被访问到。 本节所有代码可以在 https://github.com/icarusion/vue-component-book 中查看，你可以一边看源码，一边阅读本节；也可以边阅读，边动手实现一遍，遇到问题再参考完整的源码。 第 2 节我们介绍到，编写一个 Vue.js 组件，最重要的是设计好它的接口，一个 Vue.js 组件的接口来自三个部分：props、slots、events。而 Form 和 FormItem 两个组件主要做数据校验，用不到 events。Form 的 slot 就是一系列的 FormItem，FormItem 的 slot 就是具体的表单控件，比如输入框 。那主要设计的就是 props 了。 在 Form 组件中，定义两个 props： model：表单控件绑定的数据对象，在校验或重置时会访问该数据对象下对应的表单数据，类型为 Object。 rules：表单验证规则，即上面介绍的 async-validator 所使用的校验规则，类型为 Object。 在 FormItem 组件中，也定义两个 props： label：单个表单组件的标签文本，类似原生的 元素，类型为 String。 prop：对应表单域 Form 组件 model 里的字段，用于在校验或重置时访问表单组件绑定的数据，类型为 String。 定义好 props，就可以写出大概的用例了： import iForm from '../components/form/form.vue'; import iFormItem from '../components/form/form-item.vue'; import iInput from '../components/input/input.vue'; export default { components: { iForm, iFormItem, iInput }, data () { return { formValidate: { name: '', mail: '' }, ruleValidate: { name: [ { required: true, message: '用户名不能为空', trigger: 'blur' } ], mail: [ { required: true, message: '邮箱不能为空', trigger: 'blur' }, { type: 'email', message: '邮箱格式不正确', trigger: 'blur' } ], } } } } 有两点需要注意的是： 这里的 并不是原生的 输入框，而是一个特制的输入框组件，之后会介讲解的功能和代码； 的属性 prop 是字符串，所以它前面没有冒号（即不是 :prop=\"name\"）。 当前的两个组件只是个框框，还没有实现任何功能，不过万事开头难，定义好接口，剩下的就是补全组件的逻辑，而对于使用者，知道了 props、events、slots，就已经能写出上例的使用代码了。 到此，Form 和 FormItem 的代码如下： export default { name: 'iForm', props: { model: { type: Object }, rules: { type: Object } } } {{ label }} export default { name: 'iFormItem', props: { label: { type: String, default: '' }, prop: { type: String } } } 在 Form 中缓存 FormItem 实例 Form 组件的核心功能是数据校验，一个 Form 中包含了多个 FormItem，当点击提交按钮时，要逐一对每个 FormItem 内的表单组件校验，而校验是由使用者发起，并通过 Form 来调用每一个 FormItem 的验证方法，再将校验结果汇总后，通过 Form 返回出去。大致的流程如下图所示： 因为要在 Form 中逐一调用 FormItem 的验证方法，而 Form 和 FormItem 是独立的，需要预先将 FormItem 的每个实例缓存在 Form 中，这个操作就需要用到第 4 节的组件通信方法。当每个 FormItem 渲染时，将其自身（this）作为参数通过 dispatch 派发到 Form 组件中，然后通过一个数组缓存起来；同理当 FormItem 销毁时，将其从 Form 缓存的数组中移除。相关代码如下： // form-item.vue，部分代码省略 import Emitter from '../../mixins/emitter.js'; export default { name: 'iFormItem', mixins: [ Emitter ], // 组件渲染时，将实例缓存在 Form 中 mounted () { // 如果没有传入 prop，则无需校验，也就无需缓存 if (this.prop) { this.dispatch('iForm', 'on-form-item-add', this); } }, // 组件销毁前，将实例从 Form 的缓存中移除 beforeDestroy () { this.dispatch('iForm', 'on-form-item-remove', this); } } 注意，Vue.js 的组件渲染顺序是由内而外的，所以 FormItem 要先于 Form 渲染，在 FormItem 的 mounted 触发时，我们向 Form 派发了事件 on-form-item-add，并将当前 FormItem 的实例（this）传递给了 Form，而此时，Form 的 mounted 尚未触发，因为 Form 在最外层，如果在 Form 的 mounted 里监听事件，是不可以的，所以要在其 created 内监听自定义事件，Form 的 created 要先于 FormItem 的 mounted。所以 Form 的相关代码为： // form.vue，部分代码省略 export default { name: 'iForm', data () { return { fields: [] }; }, created () { this.$on('on-form-item-add', (field) => { if (field) this.fields.push(field); }); this.$on('on-form-item-remove', (field) => { if (field.prop) this.fields.splice(this.fields.indexOf(field), 1); }); } } 定义的数据 fields 就是用来缓存所有 FormItem 实例的。 触发校验 Form 支持两种事件来触发校验： blur：失去焦点时触发，常见的有输入框失去焦点时触发校验； change：实时输入时触发或选择时触发，常见的有输入框实时输入时触发校验、下拉选择器选择项目时触发校验等。 以上两个事件，都是有具体的表单组件来触发的，我们先来编写一个简单的输入框组件 i-input。在 components 下新建目录 input，并创建文件 input.vue： import Emitter from '../../mixins/emitter.js'; export default { name: 'iInput', mixins: [ Emitter ], props: { value: { type: String, default: '' }, }, data () { return { currentValue: this.value } }, watch: { value (val) { this.currentValue = val; } }, methods: { handleInput (event) { const value = event.target.value; this.currentValue = value; this.$emit('input', value); this.dispatch('iFormItem', 'on-form-change', value); }, handleBlur () { this.dispatch('iFormItem', 'on-form-blur', this.currentValue); } } } Input 组件中，绑定在 元素上的原生事件 @input，每当输入一个字符，都会调用句柄 handleInput，并通过 dispatch 方法向上级的 FormItem 组件派发自定义事件 on-form-change；同理，绑定的原生事件 @blur 会在 input 失焦时触发，并传递事件 on-form-blur。 基础组件有了，接下来要做的，是在 FormItem 中监听来自 Input 组件派发的自定义事件。这里可以在 mounted 中监听，因为你的手速远赶不上组件渲染的速度，不过在 created 中监听也是没任何问题的。相关代码如下： // form-item.vue，部分代码省略 export default { methods: { setRules () { this.$on('on-form-blur', this.onFieldBlur); this.$on('on-form-change', this.onFieldChange); }, }, mounted () { if (this.prop) { this.dispatch('iForm', 'on-form-item-add', this); this.setRules(); } } } 通过调用 setRules 方法，监听表单组件的两个事件，并绑定了句柄函数 onFieldBlur 和 onFieldChange，分别对应 blur 和 change 两种事件类型。当 onFieldBlur 或 onFieldChange 函数触发时，就意味着 FormItem 要对当前的数据进行一次校验。当前的数据，指的就是通过表单域 Form 中定义的 props：model，结合当前 FormItem 定义的 props：prop 来确定的数据，可以回顾上文写过的用例。 因为 FormItem 中只定义了数据源的某个 key 名称（即属性 prop），要拿到 Form 中 model 里的数据，需要用到第 3 节的通信方法 provide / inject。所以在 Form 中，把整个实例（this）向下提供，并在 FormItem 中注入： // form.vue，部分代码省略 export default { provide() { return { form : this }; } } // form-item.vue，部分代码省略 export default { inject: ['form'] } 准备好这些，接着就是最核心的校验功能了。blur 和 change 事件都会触发校验，它们调用同一个方法，只是参数不同。相关代码如下： // form-item.vue，部分代码省略 import AsyncValidator from 'async-validator'; export default { inject: ['form'], props: { prop: { type: String }, }, data () { return { validateState: '', // 校验状态 validateMessage: '', // 校验不通过时的提示信息 } }, computed: { // 从 Form 的 model 中动态得到当前表单组件的数据 fieldValue () { return this.form.model[this.prop]; } }, methods: { // 从 Form 的 rules 属性中，获取当前 FormItem 的校验规则 getRules () { let formRules = this.form.rules; formRules = formRules ? formRules[this.prop] : []; return [].concat(formRules || []); }, // 只支持 blur 和 change，所以过滤出符合要求的 rule 规则 getFilteredRule (trigger) { const rules = this.getRules(); return rules.filter(rule => !rule.trigger || rule.trigger.indexOf(trigger) !== -1); }, /** * 校验数据 * @param trigger 校验类型 * @param callback 回调函数 */ validate(trigger, callback = function () {}) { let rules = this.getFilteredRule(trigger); if (!rules || rules.length === 0) { return true; } // 设置状态为校验中 this.validateState = 'validating'; // 以下为 async-validator 库的调用方法 let descriptor = {}; descriptor[this.prop] = rules; const validator = new AsyncValidator(descriptor); let model = {}; model[this.prop] = this.fieldValue; validator.validate(model, { firstFields: true }, errors => { this.validateState = !errors ? 'success' : 'error'; this.validateMessage = errors ? errors[0].message : ''; callback(this.validateMessage); }); }, onFieldBlur() { this.validate('blur'); }, onFieldChange() { this.validate('change'); } } } 在 FormItem 的 validate() 方法中，最终做了两件事： 设置了当前的校验状态 validateState 和校验不通过提示信息 validateMessage（通过值为空）； 将 validateMessage 通过回调 callback 传递给调用者，这里的调用者是 onFieldBlur 和 onFieldChange，它们只传入了第一个参数 trigger，callback 并未传入，因此也不会触发回调，而这个回调主要是给 Form 用的，因为 Form 中可以通过提交按钮一次性校验所有的 FormItem（后文会介绍）这里只是表单组件触发事件时，对当前 FormItem 做校验。 除了校验，还可以对当前数据进行重置。重置是指将表单组件的数据还原到最初绑定的值，而不是清空，因此需要预先缓存一份初始值。同时我们将校验信息也显示在模板中，并加一些样式。相关代码如下： {{ label }} {{ validateMessage }} export default { props: { label: { type: String, default: '' }, prop: { type: String }, }, data () { return { isRequired: false, // 是否为必填 validateState: '', // 校验状态 validateMessage: '', // 校验不通过时的提示信息 } }, mounted () { // 如果没有传入 prop，则无需校验，也就无需缓存 if (this.prop) { this.dispatch('iForm', 'on-form-item-add', this); // 设置初始值，以便在重置时恢复默认值 this.initialValue = this.fieldValue; this.setRules(); } }, methods: { setRules () { let rules = this.getRules(); if (rules.length) { rules.every((rule) => { // 如果当前校验规则中有必填项，则标记出来 this.isRequired = rule.required; }); } this.$on('on-form-blur', this.onFieldBlur); this.$on('on-form-change', this.onFieldChange); }, // 从 Form 的 rules 属性中，获取当前 FormItem 的校验规则 getRules () { let formRules = this.form.rules; formRules = formRules ? formRules[this.prop] : []; return [].concat(formRules || []); }, // 重置数据 resetField () { this.validateState = ''; this.validateMessage = ''; this.form.model[this.prop] = this.initialValue; }, } } .i-form-item-label-required:before { content: '*'; color: red; } .i-form-item-message { color: red; } 至此，FormItem 代码已经完成，不过它只具有单独校验的功能，也就是说，只能对自己的一个表单组件验证，不能对一个表单域里的所有组件一次性全部校验。而实现全部校验和全部重置的功能，要在 Form 中完成。 上文已经介绍到，在 Form 组件中，预先缓存了全部的 FormItem 实例，自然也能在 Form 中调用它们。通过点击提交按钮全部校验，或点击重置按钮全部重置数据，只需要在 Form 中，逐一调用缓存的 FormItem 实例中的 validate 或 resetField 方法。相关代码如下： // form.vue，部分代码省略 export default { data () { return { fields: [] }; }, methods: { // 公开方法：全部重置数据 resetFields() { this.fields.forEach(field => { field.resetField(); }); }, // 公开方法：全部校验数据，支持 Promise validate(callback) { return new Promise(resolve => { let valid = true; let count = 0; this.fields.forEach(field => { field.validate('', errors => { if (errors) { valid = false; } if (++count === this.fields.length) { // 全部完成 resolve(valid); if (typeof callback === 'function') { callback(valid); } } }); }); }); } }, } 虽然说 Vue.js 的 API 只来自 prop、event、slot 这三个部分，但一些场景下，需要通过 ref 来访问这个组件，调用它的一些内置方法，比如上面的 validate 和 resetFields 方法，就需要使用者来主动调用。 resetFields 很简单，就是通过循环逐一调用 FormItem 的 resetField 方法来重置数据。validate 稍显复杂，它支持两种使用方法，一种是普通的回调，比如： 提交 export default { methods: { handleSubmit () { this.$refs.form.validate((valid) => { if (valid) { window.alert('提交成功'); } else { window.alert('表单校验失败'); } }) } } } 同时也支持 Promise，例如： handleSubmit () { const validate = this.$refs.form.validate(); validate.then((valid) => { if (valid) { window.alert('提交成功'); } else { window.alert('表单校验失败'); } }) } 在 Form 组件定义的 Promise 中，只调用了 resolve(valid)，没有调用 reject()，因此不能直接使用 .catch() ，不过聪明的你稍作修改，肯定能够支持到！ 完整的用例如下： 具有数据校验功能的表单组件——Form 提交 重置 import iForm from '../components/form/form.vue'; import iFormItem from '../components/form/form-item.vue'; import iInput from '../components/input/input.vue'; export default { components: { iForm, iFormItem, iInput }, data () { return { formValidate: { name: '', mail: '' }, ruleValidate: { name: [ { required: true, message: '用户名不能为空', trigger: 'blur' } ], mail: [ { required: true, message: '邮箱不能为空', trigger: 'blur' }, { type: 'email', message: '邮箱格式不正确', trigger: 'blur' } ], } } }, methods: { handleSubmit () { this.$refs.form.validate((valid) => { if (valid) { window.alert('提交成功'); } else { window.alert('表单校验失败'); } }) }, handleReset () { this.$refs.form.resetFields(); } } } 运行效果： 完整的示例源码可通过 GitHub 查看： https://github.com/icarusion/vue-component-book 项目基于 Vue CLI 3 构建，下载安装依赖后，通过 npm run serve 可访问。 结语 组件最终的效果看起来有点 “low”，但它实现的功能却不简单。通过这个实战，你或许已经感受到本小册一开始说的，组件写到最后，都是在拼 JavaScript 功底。的确，Vue.js 组件为我们提供了一种新的代码组织形式，但归根到底，是离不开 JS 的。 这个实战，你应该对独立组件间的通信用法有进一步的认知了吧，不过，这还不是组件通信的终极方案，下一节，我们就来看看适用于任何场景的组件通信方案。 注：本节部分代码参考 iView。 扩展阅读 一份超级详细的Vue-cli3.0使用教程 "},"Vue.js组件精讲/06.组件的通信3：找到任意组件实例——findComponents系列方法.html":{"url":"Vue.js组件精讲/06.组件的通信3：找到任意组件实例——findComponents系列方法.html","title":"06.组件的通信3：找到任意组件实例——findComponents系列方法","keywords":"","body":"组件的通信 3：找到任意组件实例——findComponents 系列方法 概述 前面的小节我们已经介绍了两种组件间通信的方法：provide / inject 和 dispatch / broadcast。它们有各自的使用场景和局限，比如前者多用于子组件获取父组件的状态，后者常用于父子组件间通过自定义事件通信。 本节将介绍第 3 种组件通信方法，也就是 findComponents 系列方法，它并非 Vue.js 内置，而是需要自行实现，以工具函数的形式来使用，它是一系列的函数，可以说是组件通信的终极方案。findComponents 系列方法最终都是返回组件的实例，进而可以读取或调用该组件的数据和方法。 它适用于以下场景： 由一个组件，向上找到最近的指定组件； 由一个组件，向上找到所有的指定组件； 由一个组件，向下找到最近的指定组件； 由一个组件，向下找到所有指定的组件； 由一个组件，找到指定组件的兄弟组件。 5 个不同的场景，对应 5 个不同的函数，实现原理也大同小异。 实现 5 个函数的原理，都是通过递归、遍历，找到指定组件的 name 选项匹配的组件实例并返回。 本节以及后续章节，都是基于上一节的工程来完成，后续不再重复说明。 完整源码地址：https://github.com/icarusion/vue-component-book 在目录 src 下新建文件夹 utils 用来放置工具函数，并新建文件 assist.js，本节所有函数都在这个文件里完成，每个函数都通过 export 对外提供（如果你不了解 export，请查看扩展阅读1）。 向上找到最近的指定组件——findComponentUpward 先看代码： // assist.js // 由一个组件，向上找到最近的指定组件 function findComponentUpward (context, componentName) { let parent = context.$parent; let name = parent.$options.name; while (parent && (!name || [componentName].indexOf(name) findComponentUpward 接收两个参数，第一个是当前上下文，比如你要基于哪个组件来向上寻找，一般都是基于当前的组件，也就是传入 this；第二个参数是要找的组件的 name 。 findComponentUpward 方法会在 while 语句里不断向上覆盖当前的 parent 对象，通过判断组件（即 parent）的 name 与传入的 componentName 是否一致，直到直到最近的一个组件为止。 与 dispatch 不同的是，findComponentUpward 是直接拿到组件的实例，而非通过事件通知组件。比如下面的示例，有组件 A 和组件 B，A 是 B 的父组件，在 B 中获取和调用 A 中的数据和方法： 组件 A import componentB from './component-b.vue'; export default { name: 'componentA', components: { componentB }, data () { return { name: 'Aresn' } }, methods: { sayHello () { console.log('Hello, Vue.js'); } } } 组件 B import { findComponentUpward } from '../utils/assist.js'; export default { name: 'componentB', mounted () { const comA = findComponentUpward(this, 'componentA'); if (comA) { console.log(comA.name); // Aresn comA.sayHello(); // Hello, Vue.js } } } 使用起来很简单，只要在需要的地方调用 findComponentUpward 方法就行，第一个参数一般都是传入 this，即当前组件的上下文（实例）。 上例的 comA，保险起见，加了一层 if (comA) 来判断是否找到了组件 A，如果没有指定的组件而调用的话，是会报错的。 findComponentUpward 只会找到最近的一个组件实例，如果要找到全部符合要求的组件，就需要用到下面的这个方法。 向上找到所有的指定组件——findComponentsUpward 代码如下： // assist.js // 由一个组件，向上找到所有的指定组件 function findComponentsUpward (context, componentName) { let parents = []; const parent = context.$parent; if (parent) { if (parent.$options.name === componentName) parents.push(parent); return parents.concat(findComponentsUpward(parent, componentName)); } else { return []; } } export { findComponentsUpward }; 与 findComponentUpward 不同的是，findComponentsUpward 返回的是一个数组，包含了所有找到的组件实例（注意函数名称中多了一个“s”）。 findComponentsUpward 的使用场景较少，一般只用在递归组件里面（后面小节会介绍），因为这个函数是一直向上寻找父级（parent）的，只有递归组件的父级才是自身。事实上，iView 在使用这个方法也都是用在递归组件的场景，比如菜单组件 Menu。由于递归组件在 Vue.js 组件里面并不常用，那自然 findComponentsUpward 也不常用了。 向下找到最近的指定组件——findComponentDownward 代码如下： // assist.js // 由一个组件，向下找到最近的指定组件 function findComponentDownward (context, componentName) { const childrens = context.$children; let children = null; if (childrens.length) { for (const child of childrens) { const name = child.$options.name; if (name === componentName) { children = child; break; } else { children = findComponentDownward(child, componentName); if (children) break; } } } return children; } export { findComponentDownward }; context.$children 得到的是当前组件的全部子组件，所以需要遍历一遍，找到有没有匹配到的组件 name，如果没找到，继续递归找每个 $children 的 $children，直到找到最近的一个为止。 来看个示例，仍然是 A、B 两个组件，A 是 B 的父组件，在 A 中找到 B： 组件 B export default { name: 'componentB', data () { return { name: 'Aresn' } }, methods: { sayHello () { console.log('Hello, Vue.js'); } } } 组件 A import componentB from './component-b.vue'; import { findComponentDownward } from '../utils/assist.js'; export default { name: 'componentA', components: { componentB }, mounted () { const comB = findComponentDownward(this, 'componentB'); if (comB) { console.log(comB.name); // Aresn comB.sayHello(); // Hello, Vue.js } } } 示例中的 A 和 B 是父子关系，因此也可以直接用 ref 来访问，但如果不是父子关系，中间间隔多代，用它就很方便了。 向下找到所有指定的组件——findComponentsDownward 如果要向下找到所有的指定组件，要用到 findComponentsDownward 函数，代码如下： // assist.js // 由一个组件，向下找到所有指定的组件 function findComponentsDownward (context, componentName) { return context.$children.reduce((components, child) => { if (child.$options.name === componentName) components.push(child); const foundChilds = findComponentsDownward(child, componentName); return components.concat(foundChilds); }, []); } export { findComponentsDownward }; 这个函数实现的方式有很多，这里巧妙使用 reduce 做累加器，并用递归将找到的组件合并为一个数组并返回，代码量较少，但理解起来稍困难。 用法与 findComponentDownward 大同小异，就不再写用例了。 找到指定组件的兄弟组件——findBrothersComponents 代码如下： // assist.js // 由一个组件，找到指定组件的兄弟组件 function findBrothersComponents (context, componentName, exceptMe = true) { let res = context.$parent.$children.filter(item => { return item.$options.name === componentName; }); let index = res.findIndex(item => item._uid === context._uid); if (exceptMe) res.splice(index, 1); return res; } export { findBrothersComponents }; 相比其它 4 个函数，findBrothersComponents 多了一个参数 exceptMe，是否把本身除外，默认是 true。寻找兄弟组件的方法，是先获取 context.$parent.$children，也就是父组件的全部子组件，这里面当前包含了本身，所有也会有第三个参数 exceptMe。Vue.js 在渲染组件时，都会给每个组件加一个内置的属性 _uid，这个 _uid 是不会重复的，借此我们可以从一系列兄弟组件中把自己排除掉。 举个例子，组件 A 是组件 B 的父级，在 B 中找到所有在 A 中的兄弟组件（也就是所有在 A 中的 B 组件）： 组件 A import componentB from './component-b.vue'; export default { name: 'componentA', components: { componentB } } 组件 B import { findBrothersComponents } from '../utils/assist.js'; export default { name: 'componentB', mounted () { const comsB = findBrothersComponents(this, 'componentB'); console.log(comsB); // ① []，空数组 } } 在 ① 的位置，打印出的内容为空数组，原因是当前 A 中只有一个 B，而 findBrothersComponents 的第三个参数默认是 true，也就是将自己除外。如果在 A 中再写一个 B： 组件 A 这时就会打印出 [VueComponent]，有一个组件了，但要注意在控制台会打印两遍，因为在 A 中写了两个 B，而 console.log 是在 B 中定义的，所以两个都会执行到。如果你看懂了这里，那应该明白打印的两遍 [VueComponent]，分别是另一个 （如果没有搞懂，要仔细琢磨琢磨哦）。 如果将 B 中 findBrothersComponents 的第三个参数设置为 false： // component-b.vue export default { name: 'componentB', mounted () { const comsB = findBrothersComponents(this, 'componentB', false); console.log(comsB); } } 此时就会打印出 [VueComponent, VueComponent]，也就是包含自身了。 以上就是 5 个函数的详细介绍，get 到这 5 个，以后就再也不用担心组件通信了。 结语 只有你认真开发过 Vue.js 独立组件，才会明白这 5 个函数的强大之处。 扩展阅读 ES6 Module 的语法 注：本节部分代码参考 iView。 "},"Vue.js组件精讲/07.实战2：组合多选框组件——CheckboxGroup&Checkbox.html":{"url":"Vue.js组件精讲/07.实战2：组合多选框组件——CheckboxGroup&Checkbox.html","title":"07.实战2：组合多选框组件——CheckboxGroup&Checkbox","keywords":"","body":"实战 2：组合多选框组件——CheckboxGroup & Checkbox 在第 5 节，我们完成了具有数据校验功能的组件 Form，本小节继续开发一个新的组件——组合多选框 Checkbox。它作为基础组件，也能集成在 Form 内并应用其验证规则。 Checkbox 组件概览 多选框组件也是由两个组件组成：CheckboxGroup 和 Checkbox。单独使用时，只需要一个 Checkbox，组合使用时，两者都要用到。效果如下图所示： 单独使用，常见的场景有注册时勾选以同意注册条款，它只有一个独立的 Checkbox 组件，并且绑定一个布尔值，示例如下： 单独选项 export default { data () { return { single: false } } } 而组合使用的场景就很多了，填写表单时会经常用到，它的结构如下： 选项 1 选项 2 选项 3 选项 4 export default { data () { return { multiple: ['option1', 'option3'] } } } v-model 用在了 CheckboxGroup 上，绑定的值为一个数组，数组的值就是内部 Checkbox 绑定的 label。 用法看起来比 Form 要简单多，不过也有两个个技术难点： Checkbox 要同时支持单独使用和组合使用的场景； CheckboxGroup 和 Checkbox 内可能嵌套其它的布局组件。 对于第一点，要在 Checkbox 初始化时判断是否父级有 CheckboxGroup，如果有就是组合使用的，否则就是单独使用。而第二点，正好可以用上一节的通信方法，很容易就能解决。 两个组件并行开发，会容易理不清逻辑，不妨我们先开发独立的 Checkbox 组件。 单独使用的 Checkbox 设计一个组件时，还是要从它的 3 个 API 入手：prop、event、slot。 因为要在 Checkbox 组件上直接使用 v-model 来双向绑定数据，那必不可少的一个 prop 就是 value，还有 event input，因为 v-model 本质上是一个语法糖（如果你还不清楚这种用法，可以阅读最后的扩展阅读 1）。 理论上，我们只需要给 value 设置为布尔值即可，也就是 true / false，不过为了扩展性，我们再定义两个 props：trueValue 和 falseValue，它们允许用户指定 value 用什么值来判断是否选中。因为实际开发中，数据库中并不直接保存 true / false，而是 1 / 0 或其它字符串，如果强制使用 Boolean，使用者就要再额外转换一次，这样的 API 设计不太友好。 除此之外，还需要一个 disabled 属性来表示是否禁用。 自定义事件 events 上文已经说了一个 input，用于实现 v-model 语法糖；另一个就是 on-change，当选中 / 取消选中时触发，用于通知父级状态发生了变化。 slot 使用默认的就好，显示辅助文本。 理清楚了 API，先来写一个基础的 v-model 功能，这在大部分组件中都类似。 在 src/components 下新建目录 checkbox，并新建两个文件 checkbox.vue 和 checkbox-group.vue。我们先来看 Checkbox： export default { name: 'iCheckbox', props: { disabled: { type: Boolean, default: false }, value: { type: [String, Number, Boolean], default: false }, trueValue: { type: [String, Number, Boolean], default: true }, falseValue: { type: [String, Number, Boolean], default: false } }, data () { return { currentValue: this.value }; }, methods: { change (event) { if (this.disabled) { return false; } const checked = event.target.checked; this.currentValue = checked; const value = checked ? this.trueValue : this.falseValue; this.$emit('input', value); this.$emit('on-change', value); } } } 因为 value 被定义为 prop，它只能由父级修改，本身是不能修改的，在 触发 change 事件，也就是点击选择时，不能由 Checkbox 来修改这个 value，所以我们在 data 里定义了一个 currentValue，并把它绑定在 ，这样就可以在 Checkbox 内修改 currentValue。这是自定义组件使用 v-model 的“惯用伎俩”。 代码看起来都很简单，但有三个细节需要额外说明： 选中的控件，直接使用了 ，而没有用 div + css 来自己实现选择的逻辑和样式，这样的好处是，使用 input 元素，你的自定义组件仍然为 html 内置的基础组件，可以使用浏览器默认的行为和快捷键，也就是说，浏览器知道这是一个选择框，而换成 div + css，浏览器可不知道这是个什么鬼。如果你觉得原生的 input 丑，没关系，是可以用 css 美化的，不过这不是本小册的重点，在此就不介绍了。 、 都是包裹在一个 元素内的，这样做的好处是，当点击 里的文字时， 选框也会被触发，否则只有点击那个小框才会触发，那样不太容易选中，影响用户体验。 currentValue 仍然是布尔值（true / false），因为它是组件 Checkbox 自己使用的，对于使用者无需关心，而 value 可以是 String、Number 或 Boolean，这取决于 trueValue 和 falseValue 的定义。 现在实现的 v-model，只是由内而外的，也就是说，通过点击 选择，会通知到使用者，而使用者手动修改了 prop value ，Checkbox 是没有做响应的，那继续补充代码： export default { watch: { value (val) { if (val === this.trueValue || val === this.falseValue) { this.updateModel(); } else { throw 'Value should be trueValue or falseValue.'; } } }, methods: { updateModel () { this.currentValue = this.value === this.trueValue; } } } 我们对 prop value 使用 watch 进行了监听，当父级修改它时，会调用 updateModel 方法，同步修改内部的 currentValue 。不过，不是所有的值父级都能修改的，所以用 if 条件判断了父级修改的值是否符合 trueValue / falseValue 所设置的，否则会抛错。 Checkbox 也是一个基础的表单类组件，它完全可以集成到 Form 里，所以，我们使用 Emitter 在 change 事件触发时，向 Form 派发一个事件，这样你就可以用第 5 节的 Form 组件来做数据校验了： import Emitter from '../../mixins/emitter.js'; export default { mixins: [ Emitter ], methods: { change (event) { // ... this.$emit('input', value); this.$emit('on-change', value); this.dispatch('iFormItem', 'on-form-change', value); } }, } 至此，Checkbox 已经可以单独使用了，并支持 Form 的数据校验。下面来看组合使用。 组合使用的 CheckboxGroup 友情提示：请先阅读 Vue.js 文档的 https://cn.vuejs.org/v2/guide/forms.html#复选框 内容。 CheckboxGroup 的 API 很简单： props：value，与 Checkbox 的类似，用于 v-model 双向绑定数据，格式为数组； events：on-change，同 Checkbox； slots：默认，用于放置 Checkbox。 如果写了 CheckboxGroup，那就代表你要组合使用多选框，而非单独使用，两种模式，只能用其一，而判断的依据，就是是否用了 CheckboxGroup 组件。所以在 Checkbox 组件内，我们用上一节的 findComponentUpward 方法判断父组件是否有 CheckboxGroup： import { findComponentUpward } from '../../utils/assist.js'; export default { name: 'iCheckbox', props: { label: { type: [String, Number, Boolean] } }, data () { return { model: [], group: false, parent: null }; }, mounted () { this.parent = findComponentUpward(this, 'iCheckboxGroup'); if (this.parent) { this.group = true; } if (this.group) { this.parent.updateModel(true); } else { this.updateModel(); } }, } 在 mounted 时，通过 findComponentUpward 方法，来判断父级是否有 CheckboxGroup 组件，如果有，就将 group 置为 true，并触发 CheckboxGroup 的 updateModel 方法，下文会介绍它的作用。 在 template 里，我们又写了一个 来区分是否是 group 模式。Checkbox 的 data 里新增加的 model 数据，其实就是父级 CheckboxGroup 的 value，会在下文的 updateModel 方法里给 Checkbox 赋值。 Checkbox 新增的 prop： label 只会在组合使用时有效，结合 model 来使用，用法已在 Vue.js 文档中介绍了 https://cn.vuejs.org/v2/guide/forms.html#复选框。 在组合模式下，Checkbox 选中，就不用对 Form 派发事件了，应该在 CheckboxGroup 中派发，所以对 Checkbox 做最后的修改： export default { methods: { change (event) { if (this.disabled) { return false; } const checked = event.target.checked; this.currentValue = checked; const value = checked ? this.trueValue : this.falseValue; this.$emit('input', value); if (this.group) { this.parent.change(this.model); } else { this.$emit('on-change', value); this.dispatch('iFormItem', 'on-form-change', value); } }, updateModel () { this.currentValue = this.value === this.trueValue; }, }, } 剩余的工作，就是完成 checkbox-gourp.vue 文件： import { findComponentsDownward } from '../../utils/assist.js'; import Emitter from '../../mixins/emitter.js'; export default { name: 'iCheckboxGroup', mixins: [ Emitter ], props: { value: { type: Array, default () { return []; } } }, data () { return { currentValue: this.value, childrens: [] }; }, methods: { updateModel (update) { this.childrens = findComponentsDownward(this, 'iCheckbox'); if (this.childrens) { const { value } = this; this.childrens.forEach(child => { child.model = value; if (update) { child.currentValue = value.indexOf(child.label) >= 0; child.group = true; } }); } }, change (data) { this.currentValue = data; this.$emit('input', data); this.$emit('on-change', data); this.dispatch('iFormItem', 'on-form-change', data); } }, mounted () { this.updateModel(true); }, watch: { value () { this.updateModel(true); } } }; 代码很容易理解，需要介绍的就是 updateModel 方法。可以看到，一共有 3 个地方调用了 updateModel，其中两个是 CheckboxGroup 的 mounted 初始化和 watch 监听的 value 变化时调用；另一个是在 Checkbox 里的 mounted 初始化时调用。这个方法的作用就是在 CheckboxGroup 里通过 findComponentsDownward 方法找到所有的 Checkbox，然后把 CheckboxGroup 的 value，赋值给 Checkbox 的 model，并根据 Checkbox 的 label，设置一次当前 Checkbox 的选中状态。这样无论是由内而外选择，或由外向内修改数据，都是双向绑定的，而且支持动态增加 Checkbox 的数量。 以上就是组合多选组件——CheckboxGroup & Checkbox 的全部内容，不知道你是否 get 到了呢！ 留两个小作业： 将 CheckboxGroup 和 Checkbox 组件集成在 Form 里完成一个数据校验的示例； 参考本节的代码，实现一个单选组件 Radio 和 RadioGroup。 结语 你看到的简单组件，其实都不简单。 扩展阅读 v-model 指令在组件中怎么玩 注：本节部分代码参考 iView。 "},"Vue.js组件精讲/08.Vue的构造器——extend与手动挂载——$mount.html":{"url":"Vue.js组件精讲/08.Vue的构造器——extend与手动挂载——$mount.html","title":"08.Vue的构造器——extend与手动挂载——$mount","keywords":"","body":"Vue 的构造器——extend 与手动挂载——$mount 本节介绍两个 Vue.js 内置但却不常用的 API——extend 和 $mount，它们经常一起使用。不常用，是因为在业务开发中，基本没有它们的用武之地，但在独立组件开发时，在一些特定的场景它们是至关重要的。 使用场景 我们在写 Vue.js 时，不论是用 CDN 的方式还是在 Webpack 里用 npm 引入的 Vue.js，都会有一个根节点，并且创建一个根实例，比如： const app = new Vue({ el: '#app' }); Webpack 也类似，一般在入口文件 main.js 里，最后会创建一个实例： import Vue from 'vue'; import App from './app.vue'; new Vue({ el: '#app', render: h => h(App) }); 因为用 Webpack 基本都是前端路由的，它的 html 里一般都只有一个根节点 ，其余都是通过 JavaScript 完成，也就是许多的 Vue.js 组件（每个页面也是一个组件）。 有了初始化的实例，之后所有的页面，都由 vue-router 帮我们管理，组件也都是用 import 导入后局部注册（也有在 main.js 全局注册的），不管哪种方式，组件（或页面）的创建过程我们是无需关心的，只是写好 .vue 文件并导入即可。这样的组件使用方式，有几个特点： 所有的内容，都是在 #app 节点内渲染的； 组件的模板，是事先定义好的； 由于组件的特性，注册的组件只能在当前位置渲染。 比如你要使用一个组件 ，渲染时，这个自定义标签就会被替换为组件的内容，而且在哪写的自定义标签，就在哪里被替换。换句话说，常规的组件使用方式，只能在规定的地方渲染组件，这在一些特殊场景下就比较局限了，例如： 组件的模板是通过调用接口从服务端获取的，需要动态渲染组件； 实现类似原生 window.alert() 的提示框组件，它的位置是在 下，而非 ，并且不会通过常规的组件自定义标签的形式使用，而是像 JS 调用函数一样使用。 一般来说，在我们访问页面时，组件就已经渲染就位了，对于场景 1，组件的渲染是异步的，甚至预先不知道模板是什么。对于场景 2，其实并不陌生，在 jQuery 时代，通过操作 DOM，很容易就能实现，你可以沿用这种思路，只是这种做法不那么 Vue，既然使用 Vue.js 了，就应该用 Vue 的思路来解决问题。对于这两种场景，Vue.extend 和 vm.$mount 语法就派上用场了。 用法 上文我们说到，创建一个 Vue 实例时，都会有一个选项 el，来指定实例的根节点，如果不写 el 选项，那组件就处于未挂载状态。Vue.extend 的作用，就是基于 Vue 构造器，创建一个“子类”，它的参数跟 new Vue 的基本一样，但 data 要跟组件一样，是个函数，再配合 $mount ，就可以让组件渲染，并且挂载到任意指定的节点上，比如 body。 比如上文的场景，就可以这样写： import Vue from 'vue'; const AlertComponent = Vue.extend({ template: '{{ message }}', data () { return { message: 'Hello, Aresn' }; }, }); 这一步，我们创建了一个构造器，这个过程就可以解决异步获取 template 模板的问题，下面要手动渲染组件，并把它挂载到 body 下： const component = new AlertComponent().$mount(); 这一步，我们调用了 $mount 方法对组件进行了手动渲染，但它仅仅是被渲染好了，并没有挂载到节点上，也就显示不了组件。此时的 component 已经是一个标准的 Vue 组件实例，因此它的 $el 属性也可以被访问： document.body.appendChild(component.$el); 当然，除了 body，你还可以挂载到其它节点上。 $mount 也有一些快捷的挂载方式，以下两种都是可以的： // 在 $mount 里写参数来指定挂载的节点 new AlertComponent().$mount('#app'); // 不用 $mount，直接在创建实例时指定 el 选项 new AlertComponent({ el: '#app' }); 实现同样的效果，除了用 extend 外，也可以直接创建 Vue 实例，并且用一个 Render 函数来渲染一个 .vue 文件： import Vue from 'vue'; import Notification from './notification.vue'; const props = {}; // 这里可以传入一些组件的 props 选项 const Instance = new Vue({ render (h) { return h(Notification, { props: props }); } }); const component = Instance.$mount(); document.body.appendChild(component.$el); 这样既可以使用 .vue 来写复杂的组件（毕竟在 template 里堆字符串很痛苦），还可以根据需要传入适当的 props。渲染后，如果想操作 Render 的 Notification 实例，也是很简单的： const notification = Instance.$children[0]; 因为 Instance 下只 Render 了 Notification 一个子组件，所以可以用 $children[0] 访问到。 如果你还不理解这样做的目的，没有关系，后面小节的两个实战你会感受到它的用武之地。 需要注意的是，我们是用 $mount 手动渲染的组件，如果要销毁，也要用 $destroy 来手动销毁实例，必要时，也可以用 removeChild 把节点从 DOM 中移除。 结语 这两个 API 并不难理解，只是不常使用罢了，因为多数情况下，我们只关注在业务层，并使用现成的组件库。 使用 Vue.js 也有二八原则，即 80% 的人看过 Vue.js 文档教程篇，20% 的人看过 Vue.js 文档 API。 下一节，我们来做点有趣的东西。 扩展阅读 聊聊 Vue.js 的 template 编译 "},"Vue.js组件精讲/09.实战3：动态渲染.vue文件的组件——Display.html":{"url":"Vue.js组件精讲/09.实战3：动态渲染.vue文件的组件——Display.html","title":"09.实战3：动态渲染.vue文件的组件——Display","keywords":"","body":"实战 3：动态渲染 .vue 文件的组件—— Display 你可能用过 jsfiddle 或 jsbin 之类的网站，在里面你可以用 CDN 的形式引入 Vue.js，然后在线写示例，实时运行，比如下面这个例子： https://jsfiddle.net/c87yh92v/ 不过，这类网站主要是一个 html，里面包含 js、css 部分，渲染侧是用 iframe 嵌入你编写的 html，并实时更新。在这些网站写示例，是不能直接写 .vue 文件的，因为没法进行编译。 再来看另一个网站 iView Run（之前小节也有提到），它是能够在线编写一个标准的 .vue 文件，并及时渲染的，它也预置了 iView 环境，你可以使用 iView 组件库全部的组件。本小节，我们就来实现这样一个能够动态渲染 .vue 文件的 Display 组件，当然，用到的核心技术就是上一节的 extend 和 $mount。 接口设计 一个常规的 .vue 文件一般都会包含 3 个部分： ：组件的模板； ：组件的选项，不包含 el； ：CSS 样式。 回忆一下用 extend 来构造一个组件实例，它的选项 template 其实就是上面 的内容，其余选项对应的是 ，样式 事实上与 Vue.js 无关，我们可以先不管。这样的话，当拿到一个 .vue 的文件（整体其实是字符串），只需要把 、、 使用正则分割，把对应的部分传递给 extend 创建的实例就可以。 Display 是一个功能型的组件，没有交互和事件，只需要一个 prop：code 将 .vue 的内容传递过来，其余工作都是在组件内完成的，这对使用者很友好。当然，你也可以设计成三个 props，分别对应 html、js、css，那分割的工作就要使用者来完成。出于使用者优先原则，苦活累活当然是在组件内完成了，因此推荐第一个方案。 实现 在 src/components 目录下创建 display 目录，并新建 display.vue 文件，基本结构如下： export default { props: { code: { type: String, default: '' } }, data () { return { html: '', js: '', css: '' } }, } 父级传递 code 后，将其分割，并保存在 data 的 html、js、css 中，后续使用。 我们使用正则，基于 <> 和 的特性进行分割： // display.vue，部分代码省略 export default { methods: { getSource (source, type) { const regex = new RegExp(`]*>`); let openingTag = source.match(regex); if (!openingTag) return ''; else openingTag = openingTag[0]; return source.slice(source.indexOf(openingTag) + openingTag.length, source.lastIndexOf(``)); }, splitCode () { const script = this.getSource(this.code, 'script').replace(/export default/, 'return '); const style = this.getSource(this.code, 'style'); const template = '' + this.getSource(this.code, 'template') + ''; this.js = script; this.css = style; this.html = template; }, } } getSource 方法接收两个参数： source：.vue 文件代码，即 props: code； type：分割的部分，也就是 template、script、style。 分割后，返回的内容不再包含 等标签，直接是对应的内容，在 splitCode 方法中，把分割好的代码分别赋值给 data 中声明的 html、js、css。有两个细节需要注意： .vue 的 部分一般都是以 export default 开始的，可以看到在 splitCode 方法中将它替换为了 return，这个在后文会做解释，当前只要注意，我们分割完的代码，仍然是字符串； 在分割的 外层套了一个 ，这是为了容错，有时使用者传递的 code 可能会忘记在外层包一个节点，没有根节点的组件，是会报错的。 准备好这些基础工作后，就可以用 extend 渲染组件了，在这之前，我们先思考一个问题：上文说到，当前的 this.js 是字符串，而 extend 接收的选项可不是字符串，而是一个对象类型，那就要先把 this.js 转为一个对象。 不卖关子，来介绍 new Function 用法，先看个示例： const sum = new Function('a', 'b', 'return a + b'); console.log(sum(2, 6)); // 8 new Function 的语法： new Function ([arg1[, arg2[, ...argN]],] functionBody) arg1, arg2, ... argN 是被函数使用的参数名称，functionBody 是一个含有包括函数定义的 JavaScript 语句的字符串。也就是说，示例中的字符串 return a + b 被当做语句执行了。 上文说到，this.js 中是将 export default 替换为 return 的，如果将 this.js 传入 new Function 里，那么 this.js 就执行了，这时因为有 return，返回的就是一个对象类型的 this.js 了。 如果你还不是很理解 new Function，可以到文末的扩展阅读进一步了解。除了 new Function，你熟悉的 eval 函数也可以使用，它与 new Function 功能类似。 知道了这些，下面的内容就容易理解了： import Vue from 'vue'; export default { data () { return { component: null } }, methods: { renderCode () { this.splitCode(); if (this.html !== '' && this.js !== '') { const parseStrToFunc = new Function(this.js)(); parseStrToFunc.template = this.html; const Component = Vue.extend( parseStrToFunc ); this.component = new Component().$mount(); this.$refs.display.appendChild(this.component.$el); } } }, mounted () { this.renderCode(); } } extend 构造的实例通过 $mount 渲染后，挂载到了组件唯一的一个节点 上。 现在 html 和 js 都有了，还剩下 css。加载 css 没有什么奇技淫巧，就是创建一个 标签，然后把 css 写进去，再插入到页面的 中，这样 css 就被浏览器解析了。为了便于后面在 this.code 变化或组件销毁时移除动态创建的 标签，我们给每个 style 标签加一个随机 id 用于标识。 在 src/utils 目录下新建 random_str.js 文件，并写入以下内容： // 生成随机字符串 export default function (len = 32) { const $chars = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890'; const maxPos = $chars.length; let str = ''; for (let i = 0; i 不难理解，这个方法是从指定的 a-zA-Z0-9 中随机生成 32 位的字符串。 补全 renderCode 方法： // display.vue，部分代码省略 import randomStr from '../../utils/random_str.js'; export default { data () { return { id: randomStr() } }, methods: { renderCode () { if (this.html !== '' && this.js !== '') { // ... if (this.css !== '') { const style = document.createElement('style'); style.type = 'text/css'; style.id = this.id; style.innerHTML = this.css; document.getElementsByTagName('head')[0].appendChild(style); } } } } } 当 Display 组件销毁时，也要手动销毁 extend 创建的实例以及上面的 css： // display.vue，部分代码省略 export default { methods: { destroyCode () { const $target = document.getElementById(this.id); if ($target) $target.parentNode.removeChild($target); if (this.component) { this.$refs.display.removeChild(this.component.$el); this.component.$destroy(); this.component = null; } } }, beforeDestroy () { this.destroyCode(); } } 当 this.code 更新时，整个过程要重新来一次，所以要对 code 进行 watch 监听： // display.vue，部分代码省略 export default { watch: { code () { this.destroyCode(); this.renderCode(); } } } 以上就是 Display 组件的所有内容。 使用 新建一条路由，并在 src/views 下新建页面 display.vue 来使用 Display 组件： 动态渲染 .vue 文件的组件—— Display import iDisplay from '../components/display/display.vue'; import defaultCode from './default-code.js'; export default { components: { iDisplay }, data () { return { code: defaultCode } } } // src/views/default-code.js const code = ` {{ message }} export default { data () { return { message: '' } } } `; export default code; 如果使用的是 Vue CLI 3 默认的配置，直接运行时，会抛出下面的错误： [Vue warn]: You are using the runtime-only build of Vue where the template compiler is not available. Either pre-compile the templates into render functions, or use the compiler-included build. 这涉及到另一个知识点，就是 Vue.js 的版本。在使用 Vue.js 2 时，有独立构建（standalone）和运行时构建（runtime-only）两种版本可供选择，详细的介绍请阅读文末扩展阅读 2。 Vue CLI 3 默认使用了 vue.runtime.js，它不允许编译 template 模板，因为我们在 Vue.extend 构造实例时，用了 template 选项，所以会报错。解决方案有两种，一是手动将 template 改写为 Render 函数，但这成本太高；另一种是对 Vue CLI 3 创建的工程做简单的配置。我们使用后者。 在项目根目录，新建文件 vue.config.js： module.exports = { runtimeCompiler: true }; 它的作用是，是否使用包含运行时编译器的 Vue 构建版本。设置为 true 后就可以在 Vue 组件中使用 template 选项了，但是应用额外增加 10kb 左右（还好吧）。 加了这个配置，报错就消失了，组件也能正常显示。 以上就是 Display 组件所有的内容，如果你感兴趣，可以把它进一步封装，做成 iView Run 这样的产品。 结语 这个小小的 Display 组件，能做的事还有很多，比如要写一套 Vue 组件库的文档，传统方法是在开发环境写一个个的 .vue 文件，然后编译打包、上传资源、上线，如果要修改，哪怕一个标点符号，都要重新编译打包、上传资源、上线。有了 Display 组件，只需要提供一个服务来在线修改文档的 .vue，就能实时更新，不用打包、上传、上线。 还有一点很重要的是，可以看到，在 iView Run 里，默认是直接可以写 iView 组件库的全部组件，并没有额外引入，这是因为 Display 所在的工程，已经将 iView 安装在了全局，Vue.extend 在构造实例时，已经可以使用全局安装的插件了，如果你还全局安装了其它插件，比如 axios，都是可以直接使用的。 扩展阅读 new Function Vue.js 2.0 独立构建和运行时构建的区别 "},"Vue.js组件精讲/10.实战4：全局提示组件——$Alert.html":{"url":"Vue.js组件精讲/10.实战4：全局提示组件——$Alert.html","title":"10.实战4：全局提示组件——$Alert","keywords":"","body":"实战 4：全局提示组件——$Alert 有一种 Vue.js 组件，它不同于常规的组件，但组件结构本身很简单，比如下面的全局提示组件： 实现这样一个组件并不难，只需要简单的几行 div 和 css，但使用者可能要这样来显示组件： 这是一条提示信息 显示 import Alert from '../component/alert.vue'; export default { components: { Alert }, data () { return { show: false } } } 这样的用法，有以下缺点： 每个使用的地方，都得注册组件； 需要预先将 放置在模板中； 需要额外的 data 来控制 Alert 的显示状态； Alert 的位置，是在当前组件位置，并非在 body 下，有可能会被其它组件遮挡。 总之对使用者来说是很不友好的，那怎样才能优雅地实现这样一个组件呢？事实上，原生的 JavaScript 早已给出了答案： // 全局提示 window.alert('这是一条提示信息'); // 二次确认 const confirm = window.confirm('确认删除吗？'); if (confirm) { // ok } else { // cancel } 所以，结论是：我们需要一个能用 JavaScript 调用组件的 API。 如果你使用过 iView 之类的组件库，一定对它内置的 $Message、$Notice、$Modal 等组件很熟悉，本节就来开发一个全局通知组件——$Alert。 1/3 先把组件写好 我们期望最终的 API 是这样的： methods: { handleShow () { this.$Alert({ content: '这是一条提示信息', duration: 3 }) } } this.$Alert 可以在任何位置调用，无需单独引入。该方法接收两个参数： content：提示内容； duration：持续时间，单位秒，默认 1.5 秒，到时间自动消失。 最终效果如下： 我们从最简单的入手，不考虑其它，先写一个基本的 Alert 组件。 在 src/component 下新建 alert 目录，并创建文件 alert.vue： 通知可以是多个，我们用一个数组 notices 来管理每条通知： {{ item.content }} export default { data () { return { notices: [] } } } .alert{ position: fixed; width: 100%; top: 16px; left: 0; text-align: center; pointer-events: none; } .alert-content{ display: inline-block; padding: 8px 16px; background: #fff; border-radius: 3px; box-shadow: 0 1px 6px rgba(0, 0, 0, .2); margin-bottom: 8px; } Alert 组件不同于常规的组件使用方式，它最终是通过 JS 来调用的，因此组件不用预留 props 和 events 接口。 接下来，只要给数组 notices 增加数据，这个提示组件就能显示内容了，我们先假设，最终会通过 JS 调用 Alert 的一个方法 add，并将 content 和 duration 传入进来： let seed = 0; function getUuid() { return 'alert_' + (seed++); } export default { data () { return { notices: [] } }, methods: { add (notice) { const name = getUuid(); let _notice = Object.assign({ name: name }, notice); this.notices.push(_notice); // 定时移除，单位：秒 const duration = notice.duration; setTimeout(() => { this.remove(name); }, duration * 1000); }, remove (name) { const notices = this.notices; for (let i = 0; i 在 add 方法中，给每一条传进来的提示数据，加了一个不重复的 name 字段来标识，并通过 setTimeout 创建了一个计时器，当到达指定的 duration 持续时间后，调用 remove 方法，将对应 name 的那条提示信息找到，并从数组中移除。 由这个思路，Alert 组件就可以无限扩展，只要在 add 方法中传递更多的参数，就能支持更复杂的组件，比如是否显示手动关闭按钮、确定 / 取消按钮，甚至传入一个 Render 函数都可以，完成本例后，读者可以尝试”改造“。 2/3 实例化封装 这一步，我们对 Alert 组件进一步封装，让它能够实例化，而不是常规的组件使用方法。实例化组件我们在第 8 节中介绍过，可以使用 Vue.extend 或 new Vue，然后用 $mount 挂载到 body 节点下。 在 src/components/alert 目录下新建 notification.js 文件： // notification.js import Alert from './alert.vue'; import Vue from 'vue'; Alert.newInstance = properties => { const props = properties || {}; const Instance = new Vue({ data: props, render (h) { return h(Alert, { props: props }); } }); const component = Instance.$mount(); document.body.appendChild(component.$el); const alert = Instance.$children[0]; return { add (noticeProps) { alert.add(noticeProps); }, remove (name) { alert.remove(name); } } }; export default Alert; notification.js 并不是最终的文件，它只是对 alert.vue 添加了一个方法 newInstance。虽然 alert.vue 包含了 template、script、style 三个标签，并不是一个 JS 对象，那怎么能够给它扩展一个方法 newInstance 呢？事实上，alert.vue 会被 Webpack 的 vue-loader 编译，把 template 编译为 Render 函数，最终就会成为一个 JS 对象，自然可以对它进行扩展。 Alert 组件没有任何 props，这里在 Render Alert 组件时，还是给它加了 props，当然，这里的 props 是空对象 {}，而且即使传了内容，也不起作用。这样做的目的还是为了扩展性，如果要在 Alert 上添加 props 来支持更多特性，是要在这里传入的。不过话说回来，因为能拿到 Alert 实例，用 data 或 props 都是可以的。 在第 8 节已经解释过，const alert = Instance.$children[0];，这里的 alert 就是 Render 的 Alert 组件实例。在 newInstance 里，使用闭包暴露了两个方法 add 和 remove。这里的 add 和 remove 可不是 alert.vue 里的 add 和 remove，它们只是名字一样。 3/3 入口 最后要做的，就是调用 notification.js 创建实例，并通过 add 把数据传递过去，这是组件开发的最后一步，也是最终的入口。在 src/component/alert 下创建文件 alert.js： // alert.js import Notification from './notification.js'; let messageInstance; function getMessageInstance () { messageInstance = messageInstance || Notification.newInstance(); return messageInstance; } function notice({ duration = 1.5, content = '' }) { let instance = getMessageInstance(); instance.add({ content: content, duration: duration }); } export default { info (options) { return notice(options); } } getMessageInstance 函数用来获取实例，它不会重复创建，如果 messageInstance 已经存在，就直接返回了，只在第一次调用 Notification 的 newInstance 时来创建实例。 alert.js 对外提供了一个方法 info，如果需要各种显示效果，比如成功的、失败的、警告的，可以在 info 下面提供更多的方法，比如 success、fail、warning 等，并传递不同参数让 Alert.vue 知道显示哪种状态的图标。本例因为只有一个 info，事实上也可以省略掉，直接导出一个默认的函数，这样在调用时，就不用 this.$Alert.info() 了，直接 this.$Alert()。 来看一下显示一个信息提示组件的流程： 最后把 alert.js 作为插件注册到 Vue 里就行，在入口文件 src/main.js中，通过 prototype 给 Vue 添加一个实例方法： // src/main.js import Vue from 'vue' import App from './App.vue' import router from './router' import Alert from '../src/components/alert/alert.js' Vue.config.productionTip = false Vue.prototype.$Alert = Alert new Vue({ router, render: h => h(App) }).$mount('#app') 这样在项目任何地方，都可以通过 this.$Alert 来调用 Alert 组件了，我们创建一个 alert 的路由，并在 src/views 下创建页面 alert.vue： 打开提示 1 打开提示 2 export default { methods: { handleOpen1 () { this.$Alert.info({ content: '我是提示信息 1' }); }, handleOpen2 () { this.$Alert.info({ content: '我是提示信息 2', duration: 3 }); } } } duration 如果不传入，默认是 1.5 秒。 以上就是全局通知组件的全部内容。 友情提示 本示例算是一个 MVP（最小化可行方案），要开发一个完善的全局通知组件，还需要更多可维护性和功能性的设计，但离不开本例的设计思路。以下几点是同类组件中值得注意的： Alert.vue 的最外层是有一个 .alert 节点的，它会在第一次调用 $Alert 时，在 body 下创建，因为不在 内，它不受路由的影响，也就是说一经创建，除非刷新页面，这个节点是不会消失的，所以在 alert.vue 的设计中，并没有主动销毁这个组件，而是维护了一个子节点数组 notices。 .alert 节点是 position: fixed 固定的，因此要合理设计它的 z-index，否则可能被其它节点遮挡。 notification.js 和 alert.vue 是可以复用的，如果还要开发其它同类的组件，比如二次确认组件 $Confirm, 只需要再写一个入口 confirm.js，并将 alert.vue 进一步封装，将 notices 数组的循环体写为一个新的组件，通过配置来决定是渲染 Alert 还是 Confirm，这在可维护性上是友好的。 在 notification.js 的 new Vue 时，使用了 Render 函数来渲染 alert.vue，这是因为使用 template 在 runtime 的 Vue.js 版本下是会报错的。 本例的 content 只能是字符串，如果要显示自定义的内容，除了用 v-html 指令，也能用 Functional Render（之后章节会介绍）。 结语 Vue.js 的精髓是组件，组件的精髓是 JavaScript。将 JavaScript 开发中的技巧结合 Vue.js 组件，就能玩出不一样的东西。 注：本节部分代码参考 iView。 "},"Vue.js组件精讲/11.更灵活的组件：Render函数与FunctionalRender.html":{"url":"Vue.js组件精讲/11.更灵活的组件：Render函数与FunctionalRender.html","title":"11.更灵活的组件：Render函数与FunctionalRender","keywords":"","body":"更灵活的组件：Render 函数与 Functional Render Vue.js 2.x 与 Vue.js 1.x 最大的区别就在于 2.x 使用了 Virtual DOM（虚拟 DOM）来更新 DOM 节点，提升渲染性能。 一般来说，我们写 Vue.js 组件，模板都是写在 内的，但它并不是最终呈现的内容，template 只是一种对开发者友好的语法，能够一眼看到 DOM 节点，容易维护，在 Vue.js 编译阶段，会解析为 Virtual DOM。 与 DOM 操作相比，Virtual DOM 是基于 JavaScript 计算的，所以开销会小很多。下图演示了 Virtual DOM 运行的过程： 正常的 DOM 节点在 HTML 中是这样的： 文本内容 文本内容 用 Virtual DOM 创建的 JavaScript 对象一般会是这样的： const vNode = { tag: 'div', attributes: { id: 'main' }, children: [ // p 节点 ] } vNode 对象通过一些特定的选项描述了真实的 DOM 结构。 在 Vue.js 中，对于大部分场景，使用 template 足以应付，但如果想完全发挥 JavaScript 的编程能力，或在一些特定场景下（后文介绍），需要使用 Vue.js 的 Render 函数。 Render 函数 正如上文介绍的 Virtual DOM 示例一样，Vue.js 的 Render 函数也是类似的语法，需要使用一些特定的选项，将 template 的内容改写成一个 JavaScript 对象。 对于初级前端工程师，或想快速建站的需求，直接使用 Render 函数开发 Vue.js 组件是要比 template 困难的，原因在于 Render 函数返回的是一个 JS 对象，没有传统 DOM 的层级关系，配合上 if、else、for 等语句，将节点拆分成不同 JS 对象再组装，如果模板复杂，那一个 Render 函数是难读且难维护的。所以，绝大部分组件开发和业务开发，我们直接使用 template 语法就可以了，并不需要特意使用 Render 函数，那样只会增加负担，同时也放弃了 Vue.js 最大的优势（React 无 template 语法）。 很多学习 Vue.js 的开发者在遇到 Render 函数时都有点”躲避“，或直接放弃这部分，这并没有问题，因为不用 Render 函数，照样可以写出优秀的 Vue.js 程序。不过，Render 函数并没有想象中的那么复杂，只是配置项特别多，一时难以记住，但归根到底，Render 函数只有 3 个参数。 来看一组 template 和 Render 写法的对照： 内容 1 内容 2 export default { data () { return { show: false } } } export default { data () { return { show: false } }, render: (h) => { let childNode; if (this.show) { childNode = h('p', '内容 1'); } else { childNode = h('p', '内容 2'); } return h('div', { attrs: { id: 'main' }, class: { container: true }, style: { color: 'red' } }, [childNode]); } } 这里的 h，即 createElement，是 Render 函数的核心。可以看到，template 中的 v-if / v-else 等指令，都被 JS 的 if / else 替代了，那 v-for 自然也会被 for 语句替代。 h 有 3 个参数，分别是： 要渲染的元素或组件，可以是一个 html 标签、组件选项或一个函数（不常用），该参数为必填项。示例： // 1. html 标签 h('div'); // 2. 组件选项 import DatePicker from '../component/date-picker.vue'; h(DatePicker); 对应属性的数据对象，比如组件的 props、元素的 class、绑定的事件、slot、自定义指令等，该参数是可选的，上文所说的 Render 配置项多，指的就是这个参数。该参数的完整配置和示例，可以到 Vue.js 的文档查看，没必要全部记住，用到时查阅就好：createElement 参数。 子节点，可选，String 或 Array，它同样是一个 h。示例： [ '内容', h('p', '内容'), h(Component, { props: { someProp: 'foo' } }) ] 约束 所有的组件树中，如果 vNode 是组件或含有组件的 slot，那么 vNode 必须唯一。以下两个示例都是错误的： // 局部声明组件 const Child = { render: (h) => { return h('p', 'text'); } } export default { render: (h) => { // 创建一个子节点，使用组件 Child const ChildNode = h(Child); return h('div', [ ChildNode, ChildNode ]); } } { render: (h) => { return h('div', [ this.$slots.default, this.$slots.default ]) } } 重复渲染多个组件或元素，可以通过一个循环和工厂函数来解决： const Child = { render: (h) => { return h('p', 'text'); } } export default { render: (h) => { const children = Array.apply(null, { length: 5 }).map(() => { return h(Child); }); return h('div', children); } } 对于含有组件的 slot，复用比较复杂，需要将 slot 的每个子节点都克隆一份，例如： { render: (h) => { function cloneVNode (vnode) { // 递归遍历所有子节点，并克隆 const clonedChildren = vnode.children && vnode.children.map(vnode => cloneVNode(vnode)); const cloned = h(vnode.tag, vnode.data, clonedChildren); cloned.text = vnode.text; cloned.isComment = vnode.isComment; cloned.componentOptions = vnode.componentOptions; cloned.elm = vnode.elm; cloned.context = vnode.context; cloned.ns = vnode.ns; cloned.isStatic = vnode.isStatic; cloned.key = vnode.key; return cloned; } const vNodes = this.$slots.default === undefined ? [] : this.$slots.default; const clonedVNodes = this.$slots.default === undefined ? [] : vNodes.map(vnode => cloneVNode(vnode)); return h('div', [ vNodes, clonedVNodes ]) } } 在 Render 函数里创建了一个 cloneVNode 的工厂函数，通过递归将 slot 所有子节点都克隆了一份，并对 VNode 的关键属性也进行了复制。 深度克隆 slot 并非 Vue.js 内置方法，也没有得到推荐，属于黑科技，在一些特殊的场景才会使用到，正常业务几乎是用不到的。比如 iView 组件库的穿梭框组件 Transfer，就用到了这种方法： 它的使用方法是： Refresh 示例中的默认 slot 是一个 Refresh 按钮，使用者只写了一遍，但在 Transfer 组件中，是通过克隆 VNode 的方法，显示了两遍。如果不这样做，就要声明两个具名 slot，但是左右两个的逻辑可能是完全一样的，使用者就要写两个一模一样的 slot，这是不友好的。 Render 函数的基本用法还有很多，比如 v-model 的用法、事件和修饰符、slot 等，读者可以到 Vue.js 文档阅读。Vue.js 渲染函数 Render 函数使用场景 上文说到，一般情况下是不推荐直接使用 Render 函数的，使用 template 足以，在 Vue.js 中，使用 Render 函数的场景，主要有以下 4 点： 使用两个相同 slot。在 template 中，Vue.js 不允许使用两个相同的 slot，比如下面的示例是错误的： 解决方案就是上文中讲到的约束，使用一个深度克隆 VNode 节点的方法。 在 SSR 环境（服务端渲染），如果不是常规的 template 写法，比如通过 Vue.extend 和 new Vue 构造来生成的组件实例，是编译不过的，在前面小节也有所介绍。回顾上一节的 $Alert 组件的 notification.js 文件，当时是使用 Render 函数来渲染 Alert 组件，如果改成另一种写法，在 SSR 中会报错，对比两种写法： // 正确写法 import Alert from './alert.vue'; import Vue from 'vue'; Alert.newInstance = properties => { const props = properties || {}; const Instance = new Vue({ data: props, render (h) { return h(Alert, { props: props }); } }); const component = Instance.$mount(); document.body.appendChild(component.$el); const alert = Instance.$children[0]; return { add (noticeProps) { alert.add(noticeProps); }, remove (name) { alert.remove(name); } } }; export default Alert; // 在 SSR 下报错的写法 import Alert from './alert.vue'; import Vue from 'vue'; Alert.newInstance = properties => { const props = properties || {}; const div = document.createElement('div'); div.innerHTML = ``; document.body.appendChild(div); const Instance = new Vue({ el: div, data: props, components: { Alert } }); const alert = Instance.$children[0]; return { add (noticeProps) { alert.add(noticeProps); }, remove (name) { alert.remove(name); } } }; export default Alert; 在 runtime 版本的 Vue.js 中，如果使用 Vue.extend 手动构造一个实例，使用 template 选项是会报错的，在第 9 节中也有所介绍。解决方案也很简单，把 template 改写为 Render 就可以了。需要注意的是，在开发独立组件时，可以通过配置 Vue.js 版本来使 template 选项可用，但这是在自己的环境，无法保证使用者的 Vue.js 版本，所以对于提供给他人用的组件，是需要考虑兼容 runtime 版本和 SSR 环境的。 这可能是使用 Render 函数最重要的一点。一个 Vue.js 组件，有一部分内容需要从父级传递来显示，如果是文本之类的，直接通过 props 就可以，如果这个内容带有样式或复杂一点的 html 结构，可以使用 v-html 指令来渲染，父级传递的仍然是一个 HTML Element 字符串，不过它仅仅是能解析正常的 html 节点且有 XSS 风险。当需要最大化程度自定义显示内容时，就需要 Render 函数，它可以渲染一个完整的 Vue.js 组件。你可能会说，用 slot 不就好了？的确，slot 的作用就是做内容分发的，但在一些特殊组件中，可能 slot 也不行。比如一个表格组件 Table，它只接收两个 props：列配置 columns 和行数据 data，不过某一列的单元格，不是只将数据显示出来那么简单，可能带有一些复杂的操作，这种场景只用 slot 是不行的，没办法确定是那一列的 slot。这种场景有两种解决方案，其一就是 Render 函数，下一节的实战就是开发这样一个 Table 组件；另一种是用作用域 slot（slot-scope），后面小节也会详细介绍。 Functional Render Vue.js 提供了一个 functional 的布尔值选项，设置为 true 可以使组件无状态和无实例，也就是没有 data 和 this 上下文。这样用 Render 函数返回虚拟节点可以更容易渲染，因为函数化组件（Functional Render）只是一个函数，渲染开销要小很多。 使用函数化组件，Render 函数提供了第二个参数 context 来提供临时上下文。组件需要的 data、props、slots、children、parent 都是通过这个上下文来传递的，比如 this.level 要改写为 context.props.level，this.$slots.default 改写为 context.children。 您可以阅读 Vue.js 文档—函数式组件 来查看示例。 函数化组件在业务中并不是很常用，而且也有类似的方法来实现，比如某些场景可以用 is 特性来动态挂载组件。函数化组件主要适用于以下两个场景： 程序化地在多个组件中选择一个； 在将 children、props、data 传递给子组件之前操作它们。 比如上文说过的，某个组件需要使用 Render 函数来自定义，而不是通过传递普通文本或 v-html 指令，这时就可以用 Functional Render，来看下面的示例： 首先创建一个函数化组件 render.js： // render.js export default { functional: true, props: { render: Function }, render: (h, ctx) => { return ctx.props.render(h); } }; 它只定义了一个 props：render，格式为 Function，因为是 functional，所以在 render 里使用了第二个参数 ctx 来获取 props。这是一个中间文件，并且可以复用，其它组件需要这个功能时，都可以引入它。 创建组件： import Render from './render.js'; export default { components: { Render }, props: { render: Function } } 使用上面的 my-compoennt 组件： import myComponent from '../components/my-component.vue'; export default { components: { myComponent }, data () { return { render: (h) => { return h('div', { style: { color: 'red' } }, '自定义内容'); } } } } 这里的 render.js 因为只是把 demo.vue 中的 Render 内容过继，并无其它用处，所以用了 Functional Render。 就此例来说，完全可以用 slot 取代 Functional Render，那是因为只有 render 这一个 prop。如果示例中的 是用 v-for 生成的，也就是多个时，用 一个 slot 是实现不了的，那时用 Render 函数就很方便了，后面章节会专门介绍。 结语 如果想换一种思路写 Vue.js，就试试 Render 函数吧，它会让你“又爱又恨”！ 注：本节部分内容参考了《Vue.js 实战》（清华大学出版社），部分代码参考 iView。 "},"Vue.js组件精讲/12.实战5：可用Render自定义列的表格组件——Table.html":{"url":"Vue.js组件精讲/12.实战5：可用Render自定义列的表格组件——Table.html","title":"12.实战5：可用Render自定义列的表格组件——Table","keywords":"","body":"实战 5：可用 Render 自定义列的表格组件——Table 表格组件 Table 是中后台产品中最常用的组件之一，用于展示大量结构化的数据。大多数组件库都提供了表格组件，比如 iView，功能也是非常强大。正规的表格，是由 、、、、、 这些标签组成，一般分为表头 columns 和数据 data。本小节就来开发一个最基本的表格组件 Table，它支持使用 Render 函数来自定义某一列。 分析 如果表格只是呈现数据，是比较简单的，比如下图： 因为结构简单，我们甚至不需要组件，直接使用标准的 table 系列标签就可以。但有的时候，除了呈现数据，也会带有一些交互，比如有一列操作栏，可以编辑整行的数据： 写一个个的 table 系列标签是很麻烦并且重复的，而组件的好处就是省去这些基础的工作，我们直接给 Table 组件传递列的配置 columns 和行数据 data，其余的都交给 Table 组件做了。 开发 Table 组件前，有必要先了解上文说到的一系列 table 标签。一般的 table 结构是这样的： 姓名 年龄 王小明 18 张小刚 25 table：定义 HTML 表格； thead：定义表头； tbody：定义表格主体； tr：定义表格行； th：定义表头单元格； td：定义表格单元。 标准的表格系列标签，跟 div+css 实现是有很大区别的，比如表格在做单元格合并时，有提供原生属性，用 div 就很麻烦了；再比如渲染原理上也有一定的区别，table 会在内容全部下载完后加载。详细的介绍可以阅读文末的扩展阅读 1。 知道了表格的结构，再来分析如何定制 API。可以看到，表格分为了两部分，表头 thead 和数据 tbody，那 props 也定义两个： columns：列配置，格式为数组，其中每一列 column 是一个对象，用来描述这一列的信息，它的具体说明如下： title：列头显示文字； key：对应列内容的字段名； render：自定义渲染列，使用 Vue 的 Render 函数，不定义则直接显示为文本。 比如： [ { title: '姓名', key: 'name' }, { title: '年龄', key: 'age' } ] data：显示的结构化数据，格式为数组，其中每一个对象，就是一行的数据，比如： [ { name: '王小明', age: 18 }, { name: '张小刚', age: 25 } ] column 定义的 key 值，与 data 是一一对应的，这是一种常见的数据接口定义规则，也是 Vue.js 组件中，用数据驱动而不是 slot 驱动的经典案例。 为什么 Table 组件要用数据驱动，而不是 slot 驱动呢？slot 在很多组件中的确很好用，不过 Table 组件包含了大量的基础表格标签，如果都交给使用者由 slot 承载的话，开发成本不亚于自己实现一个 table 了，而数据驱动就简单的多，数据一般从服务端获取后就可以直接使用（或简单处理），使用者主要来定义每列的配置 columns 就可以了。 因为不确定使用者要对某一列做什么交互，所以不能在 Table 内来实现自定义列。使用 Render 函数可以将复杂的自定义列模板的工作交给使用者来配置，Table 内只用一个 Functional Render 做中转。 完成基础表格 我们先来完成一个基础的表格组件，之后再接入 Render 来配置自定义列。 在 src/components 目录下新建 table-render 目录，并创建 table.vue 文件： {{ col.title }} {{ row[col.key] }} export default { props: { columns: { type: Array, default () { return []; } }, data: { type: Array, default () { return []; } } } } table{ width: 100%; border-collapse: collapse; border-spacing: 0; empty-cells: show; border: 1px solid #e9e9e9; } table th{ background: #f7f7f7; color: #5c6b77; font-weight: 600; white-space: nowrap; } table td, table th{ padding: 8px 16px; border: 1px solid #e9e9e9; text-align: left; } props 中的 columns 和 data 的格式都是数组，这里要注意的是，如果 props 的类型是对象或数组，它的默认值必须从一个工厂函数获取。 tbody 内嵌套使用了两次 v-for，外层循环数据 data，内层循环列 columns，这样就填充了每个单元格。 新建路由 table-render，并在 src/views/ 目录下新建页面 table-render.vue： import TableRender from '../components/table-render/table.vue'; export default { components: { TableRender }, data () { return { columns: [ { title: '姓名', key: 'name' }, { title: '年龄', key: 'age' }, { title: '出生日期', key: 'birthday' }, { title: '地址', key: 'address' }, { title: '操作' } ], data: [ { name: '王小明', age: 18, birthday: '919526400000', address: '北京市朝阳区芍药居' }, { name: '张小刚', age: 25, birthday: '696096000000', address: '北京市海淀区西二旗' }, { name: '李小红', age: 30, birthday: '563472000000', address: '上海市浦东新区世纪大道' }, { name: '周小伟', age: 26, birthday: '687024000000', address: '深圳市南山区深南大道' } ] } } } 运行后的效果如下图： 表格已经能渲染出来了，但现在的单元格只是将 data 当作纯文本来显示，所以出生日期列显示为时间戳，因为服务端对日期有时会保存为时间戳格式。如果要显示正常的日期（如1991-5-14），目前可以另写一个计算属性（computed），手动将时间戳换算为标准日期格式后，来动态修改 data 里的 birthday 字段。这样做对于出生日期这样的数据还好，但对于操作这一列就不可取了，因为它带有业务逻辑，点击编辑按钮，是可以对当前行数据进行修改的。这时就要用到 Render 函数。 使用 Render 自定义列模板 上一节我们已经介绍过函数式组件 Functional Render 的用法，它没有状态和上下文，主要用于中转一个组件，用在本节的 Table 组件非常合适。 先在 src/components/table-render 目录下新建 render.js 文件： // src/components/table-render/render.js export default { functional: true, props: { row: Object, column: Object, index: Number, render: Function }, render: (h, ctx) => { const params = { row: ctx.props.row, column: ctx.props.column, index: ctx.props.index }; return ctx.props.render(h, params); } }; render.js 定义了 4 个 props： row：当前行的数据； column：当前列的数据； index：当前是第几行； render：具体的 render 函数内容。 这里的 render 选项并没有渲染任何节点，而是直接返回 props 中定义的 render，并将 h 和当前的行、列、序号作为参数传递出去。然后在 table.vue 里就可以使用 render.js 组件： {{ col.title }} {{ row[col.key] }} import Render from './render.js'; export default { components: { Render }, props: { columns: { type: Array, default () { return []; } }, data: { type: Array, default () { return []; } } } } 如果 columns 中的某一列配置了 render 字段，那就通过 render.js 完成自定义模板，否则以字符串形式渲染。比如对出生日期这列显示为标准的日期格式，可以这样定义 column： // src/views/table-render.vie，部分代码省略 export default { data () { return { columns: [ // ... { title: '出生日期', render: (h, { row, column, index }) => { const date = new Date(parseInt(row.birthday)); const year = date.getFullYear(); const month = date.getMonth() + 1; const day = date.getDate(); const birthday = `${year}-${month}-${day}`; return h('span', birthday); } } ] } } } 效果如下图： 需要注意的是，columns 里定义的 render，是有两个参数的，第一个是 createElement（即 h），第二个是从 render.js 传过来的对象，它包含了当前行数据（row）、当前列配置（column）、当前是第几行（index），使用者可以基于这 3 个参数得到任意想要的结果。由于是自定义列了，显示什么都是使用者决定的，因此在使用了 render 的 column 里可以不用写字段 key 。 如果你真正理解了，应该知道 columns 里定义的 render 字段，它仅仅是名字叫 render 的一个普通函数，并非 Vue.js 实例的 render 选项，只是我们恰巧把它叫做 render 而已，如果愿意，也可以改为其它名字，比如 renderRow。真正的 Render 函数只有一个地方，那就是 render.js 中的 render 选项，只是它代理了 column 中的 render。这里有点绕，理清这个关系，就对 Functional Render 彻底理解了。 修改当前行 有了 render，Table 组件就已经完成了，剩余工作都是使用者来配置 columns 完成各种复杂的业务逻辑。本例来介绍最常见的表格中对整行数据编辑的功能。 操作这一列，默认是一个修改按钮，点击后，变为保存和取消两个按钮，同时本行其它各列都变为了输入框，并且初始值就是刚才单元格的数据。变为输入框后，可以任意修改单元格数据，点击保存按钮保存整行数据，点击取消按钮，还原至修改前的数据。 当进入编辑状态时，每一列的输入框都要有一个临时的数据使用 v-model 双向绑定来响应修改，所以在 data 里再声明四个数据： // table-render.vue，部分代码省略 { data () { return { // ... editName: '', // 第一列输入框 editAge: '', // 第二列输入框 editBirthday: '', // 第三列输入框 editAddress: '', // 第四列输入框 } } } 同时还要知道是在修改第几行的数据，所以再加一个数据标识当前正在修改的行序号（从 0 开始）： // table-render.vue，部分代码省略 { data () { return { // ... editIndex: -1, // 当前聚焦的输入框的行数 } } } editIndex 默认给了 -1，也就是一个不存在的行号，当点击修改按钮时，再将它置为正确的行号。我们先定义操作列的 render： // table-render.vue，部分代码省略 { data () { columns: [ // ... { title: '操作', render: (h, { row, index }) => { // 如果当前行是编辑状态，则渲染两个按钮 if (this.editIndex === index) { return [ h('button', { on: { click: () => { this.data[index].name = this.editName; this.data[index].age = this.editAge; this.data[index].birthday = this.editBirthday; this.data[index].address = this.editAddress; this.editIndex = -1; } } }, '保存'), h('button', { style: { marginLeft: '6px' }, on: { click: () => { this.editIndex = -1; } } }, '取消') ]; } else { // 当前行是默认状态，渲染为一个按钮 return h('button', { on: { click: () => { this.editName = row.name; this.editAge = row.age; this.editAddress = row.address; this.editBirthday = row.birthday; this.editIndex = index; } } }, '修改'); } } } ] } } render 里的 if / else 可以先看 else，因为默认是非编辑状态，也就是说 editIndex 还是 -1。当点击修改按钮时，把 render 中第二个参数 { row } 中的各列数据赋值给了之前在 data 中声明的 4 个数据，这样做是因为之后点击取消按钮时，editName 等值已经修改了，还没有还原，所以在开启编辑状态的同时，初始化各输入框的值（当然也可以在取消时重置）。最后再把 editIndex 置为了对应的行序号 { index }，此时 render 的 if 条件 this.editIndex === index 为真，编辑列变成了两个按钮：保存和取消。点击保存，直接修改表格源数据 data 中对应的各字段值，并将 editIndex 置为 -1，退出编辑状态；点击取消，不保存源数据，直接退出编辑状态。 除编辑列，其它各数据列都有两种状态： 当 editIndex 等于当前行号 index 时，呈现输入框状态； 当 editIndex 不等于当前行号 index 时，呈现默认数据。 以姓名为例： // table-render.vue，部分代码省略 { data () { columns: [ // ... { title: '姓名', key: 'name', render: (h, { row, index }) => { let edit; // 当前行为聚焦行时 if (this.editIndex === index) { edit = [h('input', { domProps: { value: row.name }, on: { input: (event) => { this.editName = event.target.value; } } })]; } else { edit = row.name; } return h('div', [ edit ]); } } ] } } 变量 edit 根据 editIndex 呈现不同的节点，还是先看 else，直接显示了对应字段的数据。在聚焦时（this.editIndex === index），渲染一个 input 输入框，初始值 value 通过 render 的 domProps 绑定了 row.name（这里也可绑定 editName），并监听了 input 事件，将输入的内容，实时缓存在数据 editName 中，供保存时使用。事实上，这里绑定的 value 和事件 input 就是语法糖 v-model 在 Render 函数中的写法，在 template 中，经常写作 。 其它列与姓名类似，只是对于的字段不同： // table-render.vue，部分代码省略 { data () { return { columns: [ // ... { title: '年龄', key: 'age', render: (h, { row, index }) => { let edit; // 当前行为聚焦行时 if (this.editIndex === index) { edit = [h('input', { domProps: { value: row.age }, on: { input: (event) => { this.editAge = event.target.value; } } })]; } else { edit = row.age; } return h('div', [ edit ]); } }, { title: '出生日期', render: (h, { row, index }) => { let edit; // 当前行为聚焦行时 if (this.editIndex === index) { edit = [h('input', { domProps: { value: row.birthday }, on: { input: (event) => { this.editBirthday = event.target.value; } } })]; } else { const date = new Date(parseInt(row.birthday)); const year = date.getFullYear(); const month = date.getMonth() + 1; const day = date.getDate(); edit = `${year}-${month}-${day}`; } return h('div', [ edit ]); } }, { title: '地址', key: 'address', render: (h, { row, index }) => { let edit; // 当前行为聚焦行时 if (this.editIndex === index) { edit = [h('input', { domProps: { value: row.address }, on: { input: (event) => { this.editAddress = event.target.value; } } })]; } else { edit = row.address; } return h('div', [ edit ]); } }, ] } } } 完整的代码见：https://github.com/icarusion/vue-component-book/blob/master/src/views/table-render.vue 这样，可编辑行的表格示例就完成了： 结语 本示例的 Table 组件，只展现了表格最核心的功能——自定义列模板，一个完整的 Table 组件功能要复杂的多，比如排序、筛选、列固定、表头固定、表头嵌套等。万事开头难，打好了 Table 的地基，后面的功能可以持续开发。 事实上，很多 Vue.js 的开发难题，都可以用 Render 函数来解决，它比 template 模板更灵活，可以完全发挥 JavaScript 的编程能力，因此很多 JS 的开发思想都可以借鉴。如果你习惯 JSX，那完全可以抛弃传统的 template 写法。 Render 函数虽好，但也是有弊端的，通过上面的示例可以发现，写出来的 VNode 对象是很难读的，维护性也比 template 差。下一节，我们将改写 Table 组件，用另一种思想来实现同样的功能。 扩展阅读 Div 和 Table 的区别 "},"Vue.js组件精讲/13.实战6：可用slot-scope自定义列的表格组件——Table.html":{"url":"Vue.js组件精讲/13.实战6：可用slot-scope自定义列的表格组件——Table.html","title":"13.实战6：可用slot-scope自定义列的表格组件——Table","keywords":"","body":"实战 6：可用 slot-scope 自定义列的表格组件——Table 上一节，我们基于 Render 函数实现了在表格中自定义列模板的组件 Table，虽说 Render 函数能够完全发挥 JavaScript 的编程能力，实现几乎所有的自定义工作，但本质上，使用者写的是一个庞大的 JS 对象，它不具备 DOM 结构，可读性和可维护性都比较差。对于大部分写 Vue.js 的开发者来说，更倾向于使用 template 的语法，毕竟它是 Vue.js 独有的特性。本小节则在上一节的 Table 组件基础上修改，实现一种达到同样渲染效果，但对使用者更友好的 slot-scope 写法。 什么是 slot-scope slot（插槽）我们都很熟悉，它是 Vue.js 组件的 3 个 API 之一，用于分发内容。那 slot-scope 是什么呢？先来看一个场景，比如某组件拥有下面的模板： {{ book.name }} 使用者传递一个数组 books，由组件内的 v-for 循环显示，这里的 {{ book.name }} 是纯文本输出，如果想自定义它的模板（即内容分发），就要用到 slot，但 slot 只能是固定的模板，没法自定义循环体中的一个具体的项，事实上这跟上一节的 Table 场景是类似的。 常规的 slot 无法实现对组件循环体的每一项进行不同的内容分发，这就要用到 slot-scope，它本质上跟 slot 一样，只不过可以传递参数。比如上面的示例，使用 slot-scope 封装： {{ book.name }} 在 slot 上，传递了一个自定义的参数 book，它的值绑定的是当前循环项的数据 book，这样在父级使用时，就可以在 slot 中访问它了： 限时优惠 {{ slotProps.book.name }} 使用 slot-scope 指定的参数 slotProps 就是这个 slot 的全部参数，它是一个对象，在 slot-scope 中是可以传递多个参数的，上例我们只写了一个参数 book，所以访问它就是 slotProps.book。这里推荐使用 ES6 的解构，能让参数使用起来更方便： 限时优惠 {{ book.name }} 除了可以传递参数，其它用法跟 slot 是一样的，比如也可以“具名”： {{ book.name }} 限时优惠 {{ book.name }} 这就是作用域 slot（slot-scope），能够在组件的循环体中做内容分发，有了它，Table 组件的自定义列模板就不用写一长串的 Render 函数了。 为了把 Render 函数和 slot-scope 理解透彻，下面我们用 3 种方法来改写 Table，实现 slot-scope 自定义列模板。 方案一 第一种方案，用最简单的 slot-scope 实现，同时也兼容 Render 函数的旧用法。拷贝上一节的 Table 组件目录，更名为 table-slot，同时也拷贝路由，更名为 table-slot.vue。为了兼容旧的 Render 函数用法，在 columns 的列配置 column 中，新增一个字段 slot 来指定 slot-scope 的名称： {{ col.title }} {{ row[col.key] }} 相比原先的文件，只在 'render' in col 的条件下新加了一个 template 的标签，如果使用者的 column 配置了 render 字段，就优先以 Render 函数渲染，然后再判断是否用 slot-scope 渲染。在定义的作用域 slot 中，将行数据 row、列数据 column 和第几行 index 作为 slot 的参数，并根据 column 中指定的 slot 字段值，动态设置了具名 name。使用者在配置 columns 时，只要指定了某一列的 slot，那就可以在 Table 组件中使用 slot-scope。我们以上一节的可编辑整行数据为例，用 slot-scope 的写法实现完全一样的效果： {{ row.name }} {{ row.age }} {{ getBirthday(row.birthday) }} {{ row.address }} 保存 取消 操作 import TableSlot from '../components/table-slot/table.vue'; export default { components: { TableSlot }, data () { return { columns: [ { title: '姓名', slot: 'name' }, { title: '年龄', slot: 'age' }, { title: '出生日期', slot: 'birthday' }, { title: '地址', slot: 'address' }, { title: '操作', slot: 'action' } ], data: [ { name: '王小明', age: 18, birthday: '919526400000', address: '北京市朝阳区芍药居' }, { name: '张小刚', age: 25, birthday: '696096000000', address: '北京市海淀区西二旗' }, { name: '李小红', age: 30, birthday: '563472000000', address: '上海市浦东新区世纪大道' }, { name: '周小伟', age: 26, birthday: '687024000000', address: '深圳市南山区深南大道' } ], editIndex: -1, // 当前聚焦的输入框的行数 editName: '', // 第一列输入框，当然聚焦的输入框的输入内容，与 data 分离避免重构的闪烁 editAge: '', // 第二列输入框 editBirthday: '', // 第三列输入框 editAddress: '', // 第四列输入框 } }, methods: { handleEdit (row, index) { this.editName = row.name; this.editAge = row.age; this.editAddress = row.address; this.editBirthday = row.birthday; this.editIndex = index; }, handleSave (index) { this.data[index].name = this.editName; this.data[index].age = this.editAge; this.data[index].birthday = this.editBirthday; this.data[index].address = this.editAddress; this.editIndex = -1; }, getBirthday (birthday) { const date = new Date(parseInt(birthday)); const year = date.getFullYear(); const month = date.getMonth() + 1; const day = date.getDate(); return `${year}-${month}-${day}`; } } } 示例中在 内的每一个 就对应某一列的 slot-scope 模板，通过配置的 slot 字段，指定具名的 slot-scope。可以看到，基本是把 Render 函数还原成了 html 的写法，这样看起来直接多了，渲染效果是完全一样的。在 slot-scope 中，平时怎么写组件，这里就怎么写，Vue.js 所有的 API 都是可以直接使用的。 方案一是最优解，一般情况下，使用这种方案就可以了，其余两种方案是基于 Render 的。 方案二 第二种方案，不需要修改原先的 Table 组件代码，只是在使用层面修改即可。先来看具体的使用代码，然后再做分析。注意，这里使用的 Table 组件，仍然是上一节 src/components/table-render 的组件，它只有 Render 函数，没有定义 slot-scope： {{ row.name }} {{ row.age }} {{ getBirthday(row.birthday) }} {{ row.address }} 保存 取消 操作 import TableRender from '../components/table-render/table.vue'; export default { components: { TableRender }, data () { return { columns: [ { title: '姓名', render: (h, { row, column, index }) => { return h( 'div', this.$refs.table.$scopedSlots.name({ row: row, column: column, index: index }) ) } }, { title: '年龄', render: (h, { row, column, index }) => { return h( 'div', this.$refs.table.$scopedSlots.age({ row: row, column: column, index: index }) ) } }, { title: '出生日期', render: (h, { row, column, index }) => { return h( 'div', this.$refs.table.$scopedSlots.birthday({ row: row, column: column, index: index }) ) } }, { title: '地址', render: (h, { row, column, index }) => { return h( 'div', this.$refs.table.$scopedSlots.address({ row: row, column: column, index: index }) ) } }, { title: '操作', render: (h, { row, column, index }) => { return h( 'div', this.$refs.table.$scopedSlots.action({ row: row, column: column, index: index }) ) } } ], data: [], editIndex: -1, // 当前聚焦的输入框的行数 editName: '', // 第一列输入框，当然聚焦的输入框的输入内容，与 data 分离避免重构的闪烁 editAge: '', // 第二列输入框 editBirthday: '', // 第三列输入框 editAddress: '', // 第四列输入框 } }, methods: { handleEdit (row, index) { this.editName = row.name; this.editAge = row.age; this.editAddress = row.address; this.editBirthday = row.birthday; this.editIndex = index; }, handleSave (index) { this.data[index].name = this.editName; this.data[index].age = this.editAge; this.data[index].birthday = this.editBirthday; this.data[index].address = this.editAddress; this.editIndex = -1; }, getBirthday (birthday) { const date = new Date(parseInt(birthday)); const year = date.getFullYear(); const month = date.getMonth() + 1; const day = date.getDate(); return `${year}-${month}-${day}`; } }, mounted () { this.data = [ { name: '王小明', age: 18, birthday: '919526400000', address: '北京市朝阳区芍药居' }, { name: '张小刚', age: 25, birthday: '696096000000', address: '北京市海淀区西二旗' }, { name: '李小红', age: 30, birthday: '563472000000', address: '上海市浦东新区世纪大道' }, { name: '周小伟', age: 26, birthday: '687024000000', address: '深圳市南山区深南大道' } ]; } } 在 slot-scope 的使用上（即 template 的内容），与方案一是完全一致的，可以看到，在 column 的定义上，仍然使用了 render 字段，只不过每个 render 都渲染了一个 div 节点，而这个 div 的内容，是指定来在 中定义的 slot-scope： render: (h, { row, column, index }) => { return h( 'div', this.$refs.table.$scopedSlots.name({ row: row, column: column, index: index }) ) } 这正是 Render 函数灵活的一个体现，使用 $scopedSlots 可以访问 slot-scope，所以上面这段代码的意思是，name 这一列仍然是使用 Functional Render，只不过 Render 的是一个预先定义好的 slot-scope 模板。 有一点需要注意的是，示例中的 data 默认是空数组，而在 mounted 里才赋值的，是因为这样定义的 slot-scope，初始时读取 this.$refs.table.$scopedSlots 是读不到的，会报错，当没有数据时，也就不会去渲染，也就避免了报错。 这种方案虽然可行，但归根到底是一种 hack，不是非常推荐，之所以列出来，是为了对 Render 和 slot-scope 有进一步的认识。 方案三 第 3 中方案的思路和第 2 种是一样的，它介于方案 1 与方案 2 之间。这种方案要修改 Table 组件代码，但是用例与方案 1 完全一致。 在方案 2 中，我们是通过修改用例使用 slot-scope 的，也就是说 Table 组件本身没有支持 slot-scope，是我们“强加”上去的，如果把强加的部分，集成到 Table 内，那对使用者就很友好了，同时也避免了初始化报错，不得不把 data 写在 mounted 的问题。 保持方案 1 的用例不变，修改 src/components/table-render 中的代码。为了同时兼容 Render 与 slot-scope，我们在 table-render 下新建一个 slot.js 的文件： // src/components/table-render/slot.js export default { functional: true, inject: ['tableRoot'], props: { row: Object, column: Object, index: Number }, render: (h, ctx) => { return h('div', ctx.injections.tableRoot.$scopedSlots[ctx.props.column.slot]({ row: ctx.props.row, column: ctx.props.column, index: ctx.props.index })); } }; 它仍然是一个 Functional Render，使用 inject 注入了父级组件 table.vue（下文改写） 中提供的实例 tableRoot。在 render 里，也是通过方案 2 中使用 $scopedSlots 定义的 slot，不过这是在组件级别定义，对用户来说是透明的，只要按方案 1 的用例来写就可以了。 table.vue 也要做一点修改： {{ col.title }} {{ row[col.key] }} import Render from './render.js'; import SlotScope from './slot.js'; export default { components: { Render, SlotScope }, provide () { return { tableRoot: this }; }, props: { columns: { type: Array, default () { return []; } }, data: { type: Array, default () { return []; } } } } 因为 slot-scope 模板是写在 table.vue 中的（对使用者来说，相当于写在组件 之间），所以在 table.vue 中使用 provide 向下提供了 Table 的实例，这样在 slot.js 中就可以通过 inject 访问到它，继而通过 $scopedSlots 获取到 slot。需要注意的是，在 Functional Render 是没有 this 上下文的，都是通过 h 的第二个参数临时上下文 ctx 来访问 prop、inject 等的。 方案 3 也是推荐使用的，当 Table 的功能足够复杂，层级会嵌套的比较深，那时方案 1 的 slot 就不会定义在第一级组件中，中间可能会隔许多组件，slot 就要一层层中转，相比在任何地方都能直接使用的 Render 就要麻烦了。所以，如果你的组件层级简单，推荐用第一种方案；如果你的组件已经成型（某 API 基于 Render 函数），但一时间不方便支持 slot-scope，而使用者又想用，那就选方案 2；如果你的组件已经成型（某 API 基于 Render 函数），但组件层级复杂，要按方案 1 那样支持 slot-scope 可能改动较大，还有可能带来新的 bug，那就用方案 3，它不会破坏原有的任何内容，但会额外支持 slot-scope 用法，关键是改动简单。 结语 理论上，绝大多数能用 Render 的地方，都可以用 slot-scope。对于极客来说，喜欢挑战各种新奇的写法，所以会在 Vue.js 中大量使用 Render 函数、JSX 甚至 TS；而对于求稳的开发者来说，常规的 template、slot、slot-scope 写法会是好的选择。如果非要选一种，那要从你团队的整体情况来定，如果团队大部分是写后端为主的，那可能更倾向于 TS；如果写过 React，或许 JSX 是不错的选择；如果实在不知道选什么，那就求稳吧！ "},"Vue.js组件精讲/14.递归组件与动态组件.html":{"url":"Vue.js组件精讲/14.递归组件与动态组件.html","title":"14.递归组件与动态组件","keywords":"","body":"递归组件与动态组件 递归组件 递归组件就是指组件在模板中调用自己，开启递归组件的必要条件，就是在组件中设置一个 name 选项。比如下面的示例： export default { name: 'my-component' } 在 Webpack 中导入一个 Vue.js 组件，一般是通过 import myComponent from 'xxx' 这样的语法，然后在当前组件（页面）的 components: { myComponent } 里注册组件。这种组件是不强制设置 name 字段的，组件的名字都是使用者在 import 进来后自定义的，但递归组件的使用者是组件自身，它得知道这个组件叫什么，因为没有用 components 注册，所以 name 字段就是必须的了。除了递归组件用 name，我们在之前的小节也介绍过，用一些特殊的方法，通过遍历匹配组件的 name 选项来寻找组件实例。 不过呢，上面的示例是有问题的，如果直接运行，会抛出 max stack size exceeded 的错误，因为组件会无限递归下去，死循环。解决这个问题，就要给递归组件一个限制条件，一般会在递归组件上用 v-if 在某个地方设置为 false 来终结。比如我们给上面的示例加一个属性 count，当大于 5 时就不再递归： export default { name: 'my-component', props: { count: { type: Number, default: 1 } } } 所以，总结下来，实现一个递归组件的必要条件是： 要给组件设置 name； 要有一个明确的结束条件 递归组件常用来开发具有未知层级关系的独立组件，在业务开发中很少使用。比如常见的有级联选择器和树形控件： 这类组件一般都是数据驱动型的，父级有一个字段 children，然后递归。下一节的实战，会开发一个树形控件 Tree。 动态组件 有的时候，我们希望根据一些条件，动态地切换某个组件，或动态地选择渲染某个组件。在之前小节介绍函数式组件 Functional Render 时，已经说过，它是一个没有上下文的函数，常用于程序化地在多个组件中选择一个。使用 Render 或 Functional Render 可以解决动态切换组件的需求，不过那是基于一个 JS 对象（Render 函数），而 Vue.js 提供了另外一个内置的组件 和 is 特性，可以更好地实现动态组件。 先来看一个 和 is 的基本示例，首先定义三个普通组件： 组件 A export default { } 组件 B export default { } 组件 C export default { } 然后在父组件中导入这 3 个组件，并动态切换： 显示 A 组件 显示 B 组件 显示 C 组件 import componentA from '../components/a.vue'; import componentB from '../components/b.vue'; import componentC from '../components/c.vue'; export default { data () { return { component: componentA } }, methods: { handleChange (component) { if (component === 'A') { this.component = componentA; } else if (component === 'B') { this.component = componentB; } else if (component === 'C') { this.component = componentC; } } } } 这里的 is 动态绑定的是一个组件对象（Object），它直接指向 a / b / c 三个组件中的一个。除了直接绑定一个 Object，还可以是一个 String，比如标签名、组件名。下面的这个组件，将原生的按钮 button 进行了封装，如果传入了 prop: to，那它会渲染为一个 标签，用于打开这个链接地址，如果没有传入 to，就当作普通 button 使用。来看下面的示例： export default { props: { // 链接地址 to: { type: String, default: '' }, // 链接打开方式，如 _blank target: { type: String, default: '_self' } }, computed: { // 动态渲染不同的标签 tagName () { return this.to === '' ? 'button' : 'a'; }, // 如果是链接，把这些属性都绑定在 component 上 tagProps () { let props = {}; if (this.to) { props = { target: this.target, href: this.to } } return props; } } } 使用组件： 普通按钮 链接按钮 新窗口打开链接按钮 import iButton from '../components/a.vue'; export default { components: { iButton } } 最终会渲染出一个原生的 按钮和两个原生的链接 ，且第二个点击会在新窗口中打开链接，如图： i-button 组件中的 is 绑定的就是一个标签名称 button / a，并且通过 v-bind 将一些额外的属性全部绑定到了 上。 再回到第一个 a / b / c 组件切换的示例，如果这类的组件，频繁切换，事实上组件是会重新渲染的，比如我们在组件 A 里加两个生命周期： 组件 A export default { mounted () { console.log('组件创建了'); }, beforeDestroy () { console.log('组件销毁了'); } } 只要切换到 A 组件，mounted 就会触发一次，切换到其它组件，beforeDestroy 也会触发一次，说明组件再重新渲染，这样有可能导致性能问题。为了避免组件的重复渲染，可以在 外层套一个 Vue.js 内置的 组件，这样，组件就会被缓存起来： 这时，只有 mounted 触发了，如果不离开当前页面，切换到其它组件，beforeDestroy 不会被触发，说明组件已经被缓存了。 keep-alive 还有一些额外的 props 可以配置： include：字符串或正则表达式。只有名称匹配的组件会被缓存。 exclude：字符串或正则表达式。任何名称匹配的组件都不会被缓存。 max：数字。最多可以缓存多少组件实例。 结语 还有一类是异步组件，Vue.js 文档已经介绍的很清楚了，可以阅读文末的扩展阅读 1。事实上异步组件我们用的很多，比如 router 的配置列表，一般都是用的异步组件形式： { path: '/form', component: () => import('./views/form.vue') } 这样每个页面才会在路由到时才加载对应的 JS 文件，否则入口文件会非常庞大。 递归组件、动态组件和异步组件是 Vue.js 中相对冷门的 3 种组件模式，不过在封装复杂的独立组件时，前两者会经常使用。 扩展阅读 异步组件 "},"Vue.js组件精讲/15.实战7：树形控件——Tree.html":{"url":"Vue.js组件精讲/15.实战7：树形控件——Tree.html","title":"15.实战7：树形控件——Tree","keywords":"","body":"实战 7：树形控件——Tree 本小节基于 Vue.js 的递归组件知识，来开发一个常见的树形控件—Tree。 Tree 组件是递归类组件的典型代表，它常用于文件夹、组织架构、生物分类、国家地区等等，世间万物的大多数结构都是树形结构。使用树控件可以完整展现其中的层级关系，并具有展开收起选择等交互功能。 本节要实现的 Tree 组件具有以下功能： 节点可以无限延伸（递归）； 可以展开 / 收起子节点； 节点可以选中，选中父节点，它的所有子节点也全部被选中，同样，反选父节点，其所有子节点也取消选择； 同一级所有子节点选中时，它的父级也自动选中，一直递归判断到根节点。 API Tree 是典型的数据驱动型组件，所以节点的配置就是一个 data，里面描述了所有节点的信息，比如图片中的示例数据为： data: [ { title: 'parent 1', expand: true, children: [ { title: 'parent 1-1', expand: true, children: [ { title: 'leaf 1-1-1' }, { title: 'leaf 1-1-2' } ] }, { title: 'parent 1-2', children: [ { title: 'leaf 1-2-1' }, { title: 'leaf 1-2-1' } ] } ] } ] 每个节点的配置（props：data）描述如下： title：节点标题（本例为纯文本输出，可参考 Table 的 Render 或 slot-scope 将其扩展）； expand：是否展开直子节点。开启后，其直属子节点将展开； checked：是否选中该节点。开启后，该节点的 Checkbox 将选中； children：子节点属性数组。 如果一个节点没有 children 字段，那它就是最后一个节点，这也是递归组件终结的判断依据。 同时再提供一个是否显示多选框的 props：showCheckbox，以及两个 events： on-toggle-expand：展开和收起子列表时触发； on-check-change：点击复选框时触发。 因为是数据驱动，组件的 API 都比较简单，这一点跟 Table 组件是一样的，它们复杂的逻辑都在组件本身。 入口 tree.vue 在 src/components 中新建目录 tree，并在 tree 下创建两个组件 tree.vue 和 node.vue。tree.vue 是组件的入口，用于接收和处理数据，并将数据传递给 node.vue；node.vue 就是一个递归组件，它构成了每一个节点，即一个可展开 / 关闭的按钮（+或-）、一个多选框（使用第 7 节的 Checkbox 组件）、节点标题以及递归的下一级节点。可能现在听起来比较困惑，不要慌，下面逐一分解。 tree.vue 主要负责两件事： 定义了组件的入口，即组件的 API； 对接收的数据 props：data 初步处理，为了在 tree.vue 中不破坏使用者传递的源数据 data，所以会克隆一份数据（cloneData）。 因为传递的数据 data 是一个复杂的数组结构，克隆它要使用深拷贝，因为浅拷贝数据仍然是引用关系，会破坏源数据。所以在工具集 src/utils/assist.js 中新加一个深拷贝的工具函数 deepCopy： // assist.js，部分代码省略 function typeOf(obj) { const toString = Object.prototype.toString; const map = { '[object Boolean]' : 'boolean', '[object Number]' : 'number', '[object String]' : 'string', '[object Function]' : 'function', '[object Array]' : 'array', '[object Date]' : 'date', '[object RegExp]' : 'regExp', '[object Undefined]': 'undefined', '[object Null]' : 'null', '[object Object]' : 'object' }; return map[toString.call(obj)]; } // deepCopy function deepCopy(data) { const t = typeOf(data); let o; if (t === 'array') { o = []; } else if ( t === 'object') { o = {}; } else { return data; } if (t === 'array') { for (let i = 0; i deepCopy 函数会递归地对数组或对象进行逐一判断，如果某项是数组或对象，再拆分继续判断，而其它类型就直接赋值了，所以深拷贝的数据不会破坏原有的数据（更多深拷贝与浅拷贝的内容，可阅读扩展阅读 1）。 先来看 tree.vue 的代码： import TreeNode from './node.vue'; import { deepCopy } from '../../utils/assist.js'; export default { name: 'Tree', components: { TreeNode }, props: { data: { type: Array, default () { return []; } }, showCheckbox: { type: Boolean, default: false } }, data () { return { cloneData: [] } }, created () { this.rebuildData(); }, watch: { data () { this.rebuildData(); } }, methods: { rebuildData () { this.cloneData = deepCopy(this.data); } } } 在组件 created 时（以及 watch 监听 data 改变时），调用了 rebuildData 方法克隆源数据，并赋值给了 cloneData。 在 template 中，先是渲染了一个 node.vue 组件（），这一级是 Tree 的根节点，因为 cloneDate 是一个数组，所以这个根节点不一定只有一项，有可能是并列的多项。不过这里使用的 node.vue 还没有用到 Vue.js 的递归组件，它只处理第一级根节点。 组件（node.vue）接收两个 props： showCheckbox：与 tree.vue 的 showCheckbox 相同，只是进行传递； data：node.vue 接收的 data 是一个 Object 而非 Array，因为它只负责渲染当前的一个节点，并递归渲染下一个子节点（即 children），所以这里对 cloneData 进行循环，将每一项节点数据赋给了 tree-node。 递归组件 node.vue node.vue 是树组件 Tree 的核心，而一个 tree-node 节点包含 4 个部分： 展开与关闭的按钮（+或-）； 多选框； 节点标题； 递归子节点。 先来看 node.vue 的基本结构： + - {{ data.title }} import iCheckbox from '../checkbox/checkbox.vue'; export default { name: 'TreeNode', components: { iCheckbox }, props: { data: { type: Object, default () { return {}; } }, showCheckbox: { type: Boolean, default: false } } } .tree-ul, .tree-li{ list-style: none; padding-left: 10px; } .tree-expand{ cursor: pointer; } props：data 包含了当前节点的所有信息，比如是否展开子节点（expand）、是否选中（checked）、子节点数据（children）等。 第一部分 expand，如果当前节点不含有子节点，也就是没有 children 字段或 children 的长度是 0，那就说明当前节点已经是最后一级节点，所以不含有展开 / 收起的按钮。 多选框直接使用了第 7 节的 Checkbox 组件（单用模式），这里将 prop: value 和事件 @input 分开绑定，没有使用 v-model 语法糖。value 绑定的数据 data.checked 表示当前节点是否选中，在点击多选框时，handleCheck 方法会修改 data.checked 数据，下文会分析。这里之所以不使用 v-model 而是分开绑定，是因为 @input 里要额外做一些处理，不是单纯的修改数据。 上一节我们说到，一个 Vue.js 递归组件有两个必要条件：name 特性和终结条件。name 已经指定为 TreeNode，而这个终结递归的条件，就是 v-for=\"(item, index) in data.children\"，当 data.children 不存在或为空数组时，自然就不会继续渲染子节点，递归也就停止了。 注意，这里的 v-if=\"data.expand\" 并不是递归组件的终结条件，虽然它看起来像是一个可以为 false 的判断语句，但它的用处是判断当前节点的子节点是否展开（渲染），如果当前节点不展开，那它所有的子节点也就不会展开（渲染）。 上面的代码保留了两个方法 handleExpand 与 handleCheck，先来看前者。 点击 + 号时，会展开直属子节点，点击 - 号关闭，这一步只需在 handleExpand 中修改 data 的 expand 数据即可，同时，我们通过 Tree 的根组件（tree.vue）触发一个自定义事件 @on-toggle-expand（上文已介绍）： // node.vue，部分代码省略 import { findComponentUpward } from '../../utils/assist.js'; export default { data () { return { tree: findComponentUpward(this, 'Tree') } }, methods: { handleExpand () { this.$set(this.data, 'expand', !this.data.expand); if (this.tree) { this.tree.emitEvent('on-toggle-expand', this.data); } }, } } // tree.vue，部分代码省略 export default { methods: { emitEvent (eventName, data) { this.$emit(eventName, data, this.cloneData); } } } 在 node.vue 中，通过 findComponentUpward 向上找到了 Tree 的实例，并调用它的 emitEvent 方法来触发自定义事件 @on-toggle-expand。之所以使用 findComponentUpward 寻找组件，而不是用 $parent，是因为当前的 node.vue，它的父级不一定就是 tree.vue，因为它是递归组件，父级有可能还是自己。 这里有一点需要注意，修改 data.expand，我们是通过 Vue 的 $set 方法来修改，并没有像下面这样修改： this.data.expand = !this.data.expand; 这样有什么区别呢？如果直接用上面这行代码修改，发现数据虽然被修改了，但是视图并没有更新（原来是 + 号，点击后还是 + 号）。要理解这里，我们先看下，到底修改了什么。这里的 this.data，是一个 props，它是通过上一级传递的，这个上一级有两种可能，一种是递归的 node.vue，一种是根组件 tree.vue，但是递归的 node.vue，最终也是由 tree.vue 传递的，追根溯源，要修改的 this.data 事实上是 tree.vue 的 cloneData。cloneData 里的节点数据，是不一定含有 expand 或 checked 字段的，如果不含有，直接通过 this.data.expand 修改，这个 expand 就不是可响应的数据，Vue.js 是无法追踪到它的变化，视图自然不会更新，而 $set 的用法就是对可响应对象中添加一个属性，并确保这个新属性同样是响应式的，且触发视图更新。总结来说，如果 expand 字段一开始是存在的（不管 true 或 false），不管用哪种方式修改都是可以的，否则必须用 $set 修改，结合起来，干脆直接用 $set 了。同理，后文的 checked 也是一样。 接下来是整个 Tree 组件最复杂的一部分，就是处理节点的响应状态。你可能会问，不就是选中或取消选中吗，跟 expand 一样，修改数据就行了？如果只是考虑一个节点，的确这样就可以了，但树组件是有上下级关系的，它们分为两种逻辑，当选中（或取消选中）一个节点时： 它下面的所有子节点都会被选中； 如果同一级所有子节点选中时，它的父级也自动选中，一直递归判断到根节点。 第 1 个逻辑相对简单，当选中一个节点时，只要递归地遍历它下面所属的所有子节点数据，修改所有的 checked 字段即可： // node.vue，部分代码省略 export default { methods: { handleCheck (checked) { this.updateTreeDown(this.data, checked); if (this.tree) { this.tree.emitEvent('on-check-change', this.data); } }, updateTreeDown (data, checked) { this.$set(data, 'checked', checked); if (data.children && data.children.length) { data.children.forEach(item => { this.updateTreeDown(item, checked); }); } } } } updateTreeDown 只是向下修改了所有的数据，因为当前节点的数据里，是包含其所有子节点数据的，通过递归遍历可以轻松修改，这也是第 1 种逻辑简单的原因。 再来看第 2 个逻辑，它的难点在于，无法通过当前节点数据，修改到它的父节点，因为拿不到。写到这里，正常的思路应该是在 this.updateTreeDown(this.data, checked); 的下面再写一个 updateTreeUp 的方法，向上遍历，问题就是，怎样向上遍历，一种常规的思路是，把 updateTreeUp 方法写在 tree.vue 里，并且在 node.vue 的 handleCheck 方法里，通过 this.tree 调用根组件的 updateTreeUp，并且传递当前节点的数据，在 tree.vue 里，要找到当前节点的位置，那还需要一开始在 cloneData 里预先给每个节点设置一个唯一的 key，后面的逻辑读者应该能想到了，就是通过 key 找到节点位置，并向上递归判断……但是，这个方法想着就麻烦。 正常的思路不太好解决，我们就换个思路。一个节点，除了手动选中（或反选），还有就是第 2 种逻辑的被动选中（或反选），也就是说，如果这个节点的所有直属子节点（就是它的第一级子节点）都选中（或反选）时，这个节点就自动被选中（或反选），递归地，可以一级一级响应上去。有了这个思路，我们就可以通过 watch 来监听当前节点的子节点是否都选中，进而修改当前的 checked 字段： // node.vue，部分代码省略 export default { watch: { 'data.children': { handler (data) { if (data) { const checkedAll = !data.some(item => !item.checked); this.$set(this.data, 'checked', checkedAll); } }, deep: true } } } 在 watch 中，监听了 data.children 的改变，并且是深度监听的。这段代码的意思是，当 data.children 中的数据的某个字段发生变化时（这里当然是指 checked 字段）,也就是说它的某个子节点被选中（或反选）了，这时执行绑定的句柄 handler 中的逻辑。const checkedAll = !data.some(item => !item.checked); 也是一个巧妙的缩写，checkedAll 最终返回结果就是当前子节点是否都被选中了。 这里非常巧妙地利用了递归的特性，因为 node.vue 是一个递归组件，那每一个组件里都会有 watch 监听 data.children，要知道，当前的节点有两个”身份“，它既是下属节点的父节点，同时也是上级节点的子节点，它作为下属节点的父节点被修改的同时，也会触发上级节点中的 watch 监听函数。这就是递归。 以上就是 Tree 组件的所有内容，完整的代码见： https://github.com/icarusion/vue-component-book/tree/master/src/components/tree 用例：https://github.com/icarusion/vue-component-book/blob/master/src/views/tree.vue 结语 递归就像人类繁衍一样，蕴藏了无限可能，充满着神奇与智慧。 扩展阅读 浅拷贝与深拷贝 注：本节部分代码参考 iView。 "},"Vue.js组件精讲/16.拓展：Vue.js容易忽略的API详解.html":{"url":"Vue.js组件精讲/16.拓展：Vue.js容易忽略的API详解.html","title":"16.拓展：Vue.js容易忽略的API详解","keywords":"","body":"拓展：Vue.js 容易忽略的 API 详解 前面的 15 小节已经覆盖了 Vue.js 组件的绝大部分内容，但还是有一些 API 容易忽略。本节则对 Vue.js 的一些重要且易忽略的 API 进行详细介绍。 nextTick nextTick 是 Vue.js 提供的一个函数，并非浏览器内置。nextTick 函数接收一个回调函数 cb，在下一个 DOM 更新循环之后执行。比如下面的示例： 内容 显示 export default { data () { return { show: false } }, methods: { handleShow () { this.show = true; console.log(this.$refs.node); // undefined this.$nextTick(() => { console.log(this.$refs.node); // 内容 }); } } } 当 show 被置为 true 时，这时 p 节点还未被渲染，因此打印出的是 undefined，而在 nextTick 的回调里，p 已经渲染好了，这时能正确打印出节点。 nextTick 的源码在 https://github.com/vuejs/vue/blob/dev/src/core/util/next-tick.js，可以看到，Vue.js 使用了 Promise、setTimeout 和 setImmediate 三种方法来实现 nextTick，在不同环境会使用不同的方法。 v-model 语法糖 v-model 常用于表单元素上进行数据的双向绑定，比如 。除了原生的元素，它还能在自定义组件中使用。 v-model 是一个语法糖，可以拆解为 props: value 和 events: input。就是说组件必须提供一个名为 value 的 prop，以及名为 input 的自定义事件，满足这两个条件，使用者就能在自定义组件上使用 v-model。比如下面的示例，实现了一个数字选择器： 减 1 {{ currentValue }} 加 1 export default { name: 'InputNumber', props: { value: { type: Number } }, data () { return { currentValue: this.value } }, watch: { value (val) { this.currentValue = val; } }, methods: { increase (val) { this.currentValue += val; this.$emit('input', this.currentValue); } } } props 一般不能在组件内修改，它是通过父级修改的，因此实现 v-model 一般都会有一个 currentValue 的内部 data，初始时从 value 获取一次值，当 value 修改时，也通过 watch 监听到及时更新；组件不会修改 value 的值，而是修改 currentValue，同时将修改的值通过自定义事件 input 派发给父组件，父组件接收到后，由父组件修改 value。所以，上面的数字选择器组件可以有下面两种使用方式： import InputNumber from '../components/input-number/input-number.vue'; export default { components: { InputNumber }, data () { return { value: 1 } } } 或： import InputNumber from '../components/input-number/input-number.vue'; export default { components: { InputNumber }, data () { return { value: 1 } }, methods: { handleChange (val) { this.value = val; } } } 如果你不想用 value 和 input 这两个名字，从 Vue.js 2.2.0 版本开始，提供了一个 model 的选项，可以指定它们的名字，所以数字选择器组件也可以这样写： 减 1 {{ currentValue }} 加 1 export default { name: 'InputNumber', props: { number: { type: Number } }, model: { prop: 'number', event: 'change' }, data () { return { currentValue: this.number } }, watch: { value (val) { this.currentValue = val; } }, methods: { increase (val) { this.currentValue += val; this.$emit('number', this.currentValue); } } } 在 model 选项里，就可以指定 prop 和 event 的名字了，而不一定非要用 value 和 input，因为这两个名字在一些原生表单元素里，有其它用处。 .sync 修饰符 如果你使用过 Vue.js 1.x，一定对 .sync 不陌生。在 1.x 里，可以使用 .sync 双向绑定数据，也就是父组件或子组件都能修改这个数据，是双向响应的。在 Vue.js 2.x 里废弃了这种用法，目的是尽可能将父子组件解耦，避免子组件无意中修改了父组件的状态。 不过在 Vue.js 2.3.0 版本，又增加了 .sync 修饰符，但它的用法与 1.x 的不完全相同。2.x 的 .sync 不是真正的双向绑定，而是一个语法糖，修改数据还是在父组件完成的，并非在子组件。 仍然是数字选择器的示例，这次不用 v-model，而是用 .sync，可以这样改写： 减 1 {{ value }} 加 1 export default { name: 'InputNumber', props: { value: { type: Number } }, methods: { increase (val) { this.$emit('update:value', this.value + val); } } } 用例： import InputNumber from '../components/input-number/input-number.vue'; export default { components: { InputNumber }, data () { return { value: 1 } } } 看起来要比 v-model 的实现简单多，实现的效果是一样的。v-model 在一个组件中只能有一个，但 .sync 可以设置很多个。.sync 虽好，但也有限制，比如： 不能和表达式一起使用（如 v-bind:title.sync=\"doc.title + '!'\" 是无效的）； 不能用在字面量对象上（如 v-bind.sync=\"{ title: doc.title }\" 是无法正常工作的）。 $set 在上一节已经介绍过 $set，有两种情况会用到它： 由于 JavaScript 的限制，Vue 不能检测以下变动的数组： 当利用索引直接设置一个项时，例如：this.items[index] = value; 当修改数组的长度时，例如：vm.items.length = newLength。 由于 JavaScript 的限制，Vue 不能检测对象属性的添加或删除。 举例来看，就是： // 数组 export default { data () { return { items: ['a', 'b', 'c'] } }, methods: { handler () { this.items[1] = 'x'; // 不是响应性的 } } } 使用 $set： // 数组 export default { data () { return { items: ['a', 'b', 'c'] } }, methods: { handler () { this.$set(this.items, 1, 'x'); // 是响应性的 } } } 以对象为例： // 对象 export default { data () { return { item: { a: 1 } } }, methods: { handler () { this.item.b = 2; // 不是响应性的 } } } 使用 $set： // 对象 export default { data () { return { item: { a: 1 } } }, methods: { handler () { this.$set(this.item, 'b', 2); // 是响应性的 } } } 另外，数组的以下方法，都是可以触发视图更新的，也就是响应性的： push()、pop()、shift()、unshift()、splice()、sort()、reverse()。 还有一种小技巧，就是先 copy 一个数组，然后通过 index 修改后，再把原数组整个替换，比如： handler () { const data = [...this.items]; data[1] = 'x'; this.items = data; } 计算属性的 set 计算属性（computed）很简单，而且也会大量使用，但大多数时候，我们只是用它默认的 get 方法，也就是平时的常规写法，通过 computed 获取一个依赖其它状态的数据。比如： computed: { fullName () { return `${this.firstName} ${this.lastName}`; } } 这里的 fullName 事实上可以写为一个 Object，而非 Function，只是 Function 形式是我们默认使用它的 get 方法，当写为 Object 时，还能使用它的 set 方法： computed: { fullName: { get () { return `${this.firstName} ${this.lastName}`; }, set (val) { const names = val.split(' '); this.firstName = names[0]; this.lastName = names[names.length - 1]; } } } 计算属性大多时候只是读取用，使用了 set 后，就可以写入了，比如上面的示例，如果执行 this.fullName = 'Aresn Liang'，computed 的 set 就会调用，firstName 和 lastName 会被赋值为 Aresn 和 Liang。 剩余值得注意的 API 还有一些 API，可能不常用，也比较简单，只需知道就好，本册不详细展开介绍，可以通过指引到 Vue.js 文档查看。 delimiters 改变纯文本插入分隔符，Vue.js 默认的是 {{ }}，如果你使用其它一些后端模板，比如 Python 的 Tornado 框架，那 Vue.js 和 Tornado 的 {{ }} 就冲突了，这时用它可以修改为指定的分隔符。 v-once 只渲染元素和组件一次。随后的重新渲染，元素/组件及其所有的子节点将被视为静态内容并跳过。这可以用于优化更新性能。 vm.$isServer 当前 Vue 实例是否运行于服务器，如果你的组件要兼容 SSR，它会很有用。 inheritAttrs 一些原生的 html 特性，比如 id，即使没有定义 props，也会被集成到组件根节点上，设置 inheritAttrs 为 false 可以关闭此特性。 errorHandler 使用 errorHandler 可以进行异常信息的获取。 watch 监听状态的变化，用的也很多了，但它和 computed 一样，也有 Object 的写法，这样能配置更多的选项，比如： handler 执行的函数 deep 是否深度 immediate 是否立即执行 完整的配置可以阅读文档。 comments 开启会保留 html 注释。 transition 内置的组件，可做过渡效果，比如 CSS 的高度从 0 到 auto（使用纯 CSS 是无法实现动画的）。 结语 彻底掌握一门语言（框架），不需要阅读它所有的源码，但至少要阅读它所有的 API。 "},"Vue.js组件精讲/17.拓展：Vue.js面试、常见问题答疑.html":{"url":"Vue.js组件精讲/17.拓展：Vue.js面试、常见问题答疑.html","title":"17.拓展：Vue.js面试、常见问题答疑","keywords":"","body":"拓展：Vue.js 面试、常见问题答疑 在过去的很多面试中，我会经常问候选人一些关于 Vue.js 的问题。这些问题从题面来看很简单，但仔细想又不是那么简单，不同的人，会答出不同的层次，从而更好地了解一个人对 Vue.js 的理解程度。 题目 v-show 与 v-if 区别 第一题应该是最简单的，提这个问题，也是想让候选人不那么紧张，因为但凡用过 Vue.js，多少知道 v-show 和 v-if 的区别，否则就没得聊了。不过这最简单的一道题，有三个层次，我会逐一追问。首先，基本所有人都会说到： v-show 只是 CSS 级别的 display: none; 和 display: block; 之间的切换，而 v-if 决定是否会选择代码块的内容（或组件）。 回答这些，已经可以得到 50 分了，紧接着我会追问，什么时候用 v-show，什么时候用 v-if ？到这里一部分人会比较吞吐，可能是知道，但表达不出来。我比较倾向的回答是： 频繁操作时，使用 v-show，一次性渲染完的，使用 v-if，只要意思对就好。 第二问可以得到 80 分了，最后一问很少有人能答上：**那使用 v-if 在性能优化上有什么经验？**这是一个加分项，要对 Vue.js 的组件编译有一定的理解。说一下期望的答案： 因为当 v-if=\"false\" 时，内部组件是不会渲染的，所以在特定条件才渲染部分组件（或内容）时，可以先将条件设置为 false，需要时（或异步，比如 $nextTick）再设置为 true，这样可以优先渲染重要的其它内容，合理利用，可以进行性能优化。 绑定 class 的数组用法 动态绑定 class 应该不陌生吧，这也是最基本的，但是这个问题却有点绕，什么叫**绑定 class 的数组用法？**我们看一下，最常用的绑定 class 怎么写： 内容 export default { data () { return { isShow: true } } } 绑定 class 的对象用法能满足大部分业务需求，不过，在复杂的场景下，会用到数组，来看示例： export default { computed: { classes () { return [ `${prefixCls}`, `${prefixCls}-${this.type}`, { [`${prefixCls}-long`]: this.long, [`${prefixCls}-${this.shape}`]: !!this.shape, [`${prefixCls}-${this.size}`]: this.size !== 'default', [`${prefixCls}-loading`]: this.loading != null && this.loading, [`${prefixCls}-icon-only`]: !this.showSlot && (!!this.icon || !!this.customIcon || this.loading), [`${prefixCls}-ghost`]: this.ghost } ]; } } } 示例来自 iView 的 Button 组件，可以看到，数组里，可以是固定的值，还有动态值（对象）的混合。 计算属性和 watch 的区别 回答该题前，一般都会思考一下。很多人会偏题，直接去答计算属性和 watch 怎么用，这是不得分的，因为题目是问区别，并不是用法。 计算属性是自动监听依赖值的变化，从而动态返回内容，监听是一个过程，在监听的值变化时，可以触发一个回调，并做一些事情。 所以区别来源于用法，只是需要动态值，那就用计算属性；需要知道值的改变后执行业务逻辑，才用 watch，用反或混用虽然可行，但都是不正确的用法。 这个问题会延伸出几个问题： computed 是一个对象时，它有哪些选项？ computed 和 methods 有什么区别？ computed 是否能依赖其它组件的数据？ watch 是一个对象时，它有哪些选项？ 问题 1，已经在 16 小节介绍过，有 get 和 set 两个选项。 问题 2，methods 是一个方法，它可以接受参数，而 computed 不能；computed 是可以缓存的，methods 不会；一般在 v-for 里，需要根据当前项动态绑定值时，只能用 methods 而不能用 computed，因为 computed 不能传参。 问题 3，computed 可以依赖其它 computed，甚至是其它组件的 data。 问题 4，第 16 小节也有提到，有以下常用的配置： handler 执行的函数 deep 是否深度 immediate 是否立即执行 事件修饰符 这个问题我会先写一段代码： 内容 然后问：怎样给这个自定义组件 custom-component 绑定一个原生的 click 事件？ 我一开始并不会问什么是事件修饰符，但是如果候选人说 ，就已经错了，说明它对这个没有概念。这里的 @click 是自定义事件 click，并不是原生事件 click。绑定原生的 click 是这样的： 内容 该问题会引申很多，比如常见的事件修饰符有哪些？如果你能说上 .exact，说明你是个很爱探索的人，会大大加分哦。 .exact 是 Vue.js 2.5.0 新加的，它允许你控制由精确的系统修饰符组合触发的事件，比如： A A A 你可能还需要了解常用的几个事件修饰符： .stop .prevent .capture .self 而且，事件修饰符在连用时，是有先后顺序的。 组件中 data 为什么是函数 为什么组件中的 data 必须是一个函数，然后 return 一个对象，而 new Vue 实例里，data 可以直接是一个对象？ 因为组件是用来复用的，JS 里对象是引用关系，这样作用域没有隔离，而 new Vue 的实例，是不会被复用的，因此不存在引用对象的问题。 keep-alive 的理解 这是个概念题，主要考察候选人是否知道这个用法。简单说，就是把一个组件的编译缓存起来。在第 14 节有过详细介绍，也可以看看 Vue.js 的文档。 递归组件的要求 回答这道题，首先你得知道什么是递归组件。而不到 10% 的人知道递归组件。其实在实际业务中用的确实不多，在独立组件中会经常使用，第 14 节和 15 节专门讲过递归组件。那回到问题，递归组件的要求是什么？主要有两个： 要给组件设置 name； 要有一个明确的结束条件。 自定义组件的语法糖 v-model 是怎样实现的 在第 16 节已经详细介绍过，这里的 v-model，并不是给普通输入框 用的那种 v-model，而是在自定义组件上使用。既然是语法糖，就能够还原，我们先还原一下： {{ currentValue }} Click export default { props: { value: { type: Number, default: 0 } }, data () { return { currentValue: this.value } }, methods: { handleClick () { this.currentValue += 1; this.$emit('input', this.currentValue); } }, watch: { value (val) { this.currentValue = val; } } } 这个组件中，只有一个 props，但是名字叫 value，内部还有一个 currentValue，当改变 currentValue 时，会触发一个自定义事件 @input，并把 currentValue 的值返回。这就是一个 v-model 的语法糖，它要求 props 有一个叫 value 的项，同时触发的自定义事件必须叫 input。这样就可以在自定义组件上用 v-model 了： 如果你能说到 model 选项，绝对是加分的。 Vuex 中 mutations 和 actions 的区别 主要的区别是，actions 可以执行异步。actions 是调用 mutations，而 mutations 来修改 store。 Render 函数 这是比较难的一题了，因为很少有人会去了解 Vue.js 的 Render 函数，因为基本用不到。Render 函数的内容本小册已经很深入的讲解过了，遇到这个问题，一般可以从这几个方面来回答： 什么是 Render 函数，它的使用场景是什么。 createElement 是什么？ Render 函数有哪些常用的参数？ 说到 Render 函数，就要说到虚拟 DOM（Virtual DOM）,Virtual DOM 并不是真正意义上的 DOM，而是一个轻量级的 JavaScript 对象，在状态发生变化时，Virtual DOM 会进行 Diff 运算，来更新只需要被替换的 DOM，而不是全部重绘。 它的使用场景，就是完全发挥 JavaScript 的编程能力，有时需要结合 JSX 来使用。 createElement 是 Render 函数的核心，它构成了 Vue Virtual DOM 的模板，它有 3 个参数： createElement () { // {String | Object | Function} // 一个 HTML 标签，组件选项，或一个函数 // 必须 return 上述其中一个 'div', // {Object} // 一个对应属性的数据对象，可选 // 您可以在 template 中使用 { // 详细的属性 }, // {String | Array} // 子节点（VNodes），可选 [ createElement('h1', 'hello world'), createElement(MyComponent, { props: { someProps: 'foo' } }), 'bar' ] } 常用的参数，主要是指上面第二个参数里的值了，这个比较多，得去看 Vue.js 的文档。 怎样理解单向数据流 这个概念出现在组件通信。父组件是通过 prop 把数据传递到子组件的，但是这个 prop 只能由父组件修改，子组件不能修改，否则会报错。子组件想修改时，只能通过 $emit 派发一个自定义事件，父组件接收到后，由父组件修改。 一般来说，对于子组件想要更改父组件状态的场景，可以有两种方案： 在子组件的 data 中拷贝一份 prop，data 是可以修改的，但 prop 不能： export default { props: { value: String }, data () { return { currentValue: this.value } } } 如果是对 prop 值的转换，可以使用计算属性： export default { props: ['size'], computed: { normalizedSize: function () { return this.size.trim().toLowerCase(); } } } 如果你能提到 v-model 实现数据的双向绑定、.sync 用法，会大大加分的，这些在第 16 节已经详细介绍过。 生命周期 Vue.js 生命周期 主要有 8 个阶段： 创建前 / 后（beforeCreate / created）：在 beforeCreate 阶段，Vue 实例的挂载元素 el 和数据对象 data 都为 undefined，还未初始化。在 created 阶段，Vue 实例的数据对象 data 有了，el 还没有。 载入前 / 后（beforeMount / mounted）：在 beforeMount 阶段，Vue 实例的 $el 和 data 都初始化了，但还是挂载之前为虚拟的 DOM 节点，data 尚未替换。在 mounted 阶段，Vue 实例挂载完成，data 成功渲染。 更新前 / 后（beforeUpdate / updated）：当 data 变化时，会触发 beforeUpdate 和 updated 方法。这两个不常用，且不推荐使用。 销毁前 / 后（beforeDestroy / destroyed）：beforeDestroy 是在 Vue 实例销毁前触发，一般在这里要通过 removeEventListener 解除手动绑定的事件。实例销毁后，触发 destroyed。 组件间通信 本小册一半的篇幅都在讲组件的通信，如果能把这些都吃透，基本上 Vue.js 的面试就稳了。 这个问题看似简单，却比较大，回答时，可以拆分为几种场景： 父子通信： 父向子传递数据是通过 props，子向父是通过 events（$emit）；通过父链 / 子链也可以通信（$parent / $children）；ref 也可以访问组件实例；provide / inject API。 兄弟通信： Bus；Vuex； 跨级通信： Bus；Vuex；provide / inject API。 除了常规的通信方法，本册介绍的 dispatch / broadcast 和 findComponents 系列方法也可以说的，如果能说到这些，说明你对 Vue.js 组件已经有较深入的研究。 路由的跳转方式 一般有两种： 通过 ，router-link 标签会渲染为 标签，在 template 中的跳转都是用这种； 另一种是编程式导航，也就是通过 JS 跳转，比如 router.push('/home')。 Vue.js 2.x 双向绑定原理 这个问题几乎是面试必问的，回答也是有深有浅。基本上要知道核心的 API 是通过 Object.defineProperty() 来劫持各个属性的 setter / getter，在数据变动时发布消息给订阅者，触发相应的监听回调，这也是为什么 Vue.js 2.x 不支持 IE8 的原因（IE 8 不支持此 API，且无法通过 polyfill 实现）。 Vue.js 文档已经对 深入响应式原理 解释的很透彻了。 什么是 MVVM，与 MVC 有什么区别 MVVM 模式是由经典的软件架构 MVC 衍生来的。当 View（视图层）变化时，会自动更新到 ViewModel（视图模型），反之亦然。View 和 ViewModel 之间通过双向绑定（data-binding）建立联系。与 MVC 不同的是，它没有 Controller 层，而是演变为 ViewModel。 ViewModel 通过双向数据绑定把 View 层和 Model 层连接了起来，而 View 和 Model 之间的同步工作是由 Vue.js 完成的，我们不需要手动操作 DOM，只需要维护好数据状态。 结语 一个人的简历，是由简单到复杂再到简单，技术是无止尽的，接触的越多，越能感到自己的渺小。 "},"Vue.js组件精讲/18.拓展：如何做好一个开源项目（上篇）.html":{"url":"Vue.js组件精讲/18.拓展：如何做好一个开源项目（上篇）.html","title":"18.拓展：如何做好一个开源项目（上篇）","keywords":"","body":"拓展：如何做好一个开源项目（上篇） iView 的故事 毕业四年以来，我一直觉得自己是一个很幸运的人，幸运参与过创业，幸运一路有大牛带，幸运开源了 iView 项目。 2016 年初，我还是一名普通的前端工程师，那时候还是 Vue.js 1.x 的时代，知名度也远不如现在，在大部分人眼中，Vue.js 就是一个轻量级的 Angular。 我所在的公司是做 to B 业务的，与大部分公司一样，那时主导 jQuery，把 Vue.js 引入团队乃至整个公司，是一件很不易的事，因为不是你自己在用，你要说服所有人用，现在看来，当初的决定是很正确的。如果你有兴趣，欢迎阅读扩展阅读 1，那篇文章详细介绍了我的 Vue.js “推广史”。 到了 16 年 7 月，我们团队已经完全认可了 Vue.js + Webpack 的技术栈，一直践行至今。一个偶然的机会，公司举办了一个创新大赛，作为可视化团队，我提议做一套自己的组件库。当初也只是一个想法，抱着试试看的态度就报名了。比赛的目的只是呼吁大家创新，后续就没有动作了，但是我没有就此放下，从那时起，几乎全职开发 iView，两年半来，我每天的工作基本就是维护 iView。不得不说，一个成功的开源项目，必须有 leader 的认可和公司的支持，缺一不可。 那时不比现在，优秀的 Vue.js 组件库非常少，文献更是少得可怜。一开始做 iView 没什么头绪，只是规划了一张 MindNode 脑图，罗列了一期要做的所有组件。这里有一个插曲，因为这张 todo 的脑图有贴在 GitHub 的 Readme，以至于一开始大部分 issues 都是问这个脑图是用什么软件做的，因为做的很好看，索性写了个提问须知，注明了脑图是用 MindNode 制作的。 起初对开源工作不是很了解，连一个编译工程都搭不起来，想了数日也搞不定。与大部分人一样，一开始也是要参考其它人的开源项目（就像现在很多人参考 iView 是一样的），那是我参考 Vux（移动端的 Vue.js 组件库，当时有 6k star），向作者捐了杯咖啡钱，顺便加了好友（因为是支付宝捐赠，能加好友），请教了工程的问题，这才一步步搭起来，现在想想真是幸运。 万事开头难，把地基搭好，剩下的都是添砖加瓦的事。差不多 16 年底，iView 一期完成了（43 个组件），也发布了第一个正式版，有了第一批用户（当然，主要还是自己公司），然而在那个时候，又做了一个在今天看来稍晚但正确的决定——支持 Vue.js 2。 虽然是开源项目，但主要还是先满足自己团队和公司的需求，那个时候所有的项目都是 Vue.js 1.x 的，还没有用 Vue.js 2，但 2.x 已经发布有一段时间了，以至于在 2017 年初，GitHub 有很多 issues 问什么时候支持 2.x。很长一段时间没有升级到 2.x，主要因为要支持公司的项目，而我当时也觉得升级到 2.x 是一个很耗时的工作，就没有支持。后来，有一个人提交了一个非常大的 PR，将所有组件都支持了 2.x，而且只用了一个周末的时间。这件事让我意识到支持 Vue.js 2.x 的重要性了，于是花了 2 周时间研究，并升级到了 2.x（那个 pr 没有直接合并，而是参考，因为很多地方有 bug）。接下来的几个月，都在不断维护新的 iView，使用者也不断增多，社区又重新活跃起来。 如果当初没有及时转型（现在看来仍然是晚了），还在一味地维护 Vue.js 1.x 版本，那 iView 也许早就完了。有了好的开头，就要不放弃，不抛弃，坚持做下去，认真处理每一个 PR，因为质量是一个开源组件库最重要的，但并不是每一个 PR 都适合 merge，即使作者付出了很多时间提交这个 PR，也会有质量问题。 有了不错的口碑，在 2018 年继续完善，目前已经是同类产品里功能最丰富的组件库，而且在 18 年的 7 月 28 日（iView 两周年）成功举行了 3.0 发布会，一切都在朝着更好的一面发展着...... 这就是我的 iView 开源的故事，一个成功的开源项目，或许带有一点小幸运，因为如今的同类开源产品已经数不胜数了，不过确实有很多值得分享的地方，如果你打算做一个开源项目，希望下面的些许经验能够帮助到你。 不要盲目造轮子 每一个做开源项目的开发者，都是有目的的，如果你做一个开源项目没有任何目的，那你的目的多半是要造个轮子来提升下技术。 中国当前的开源环境和氛围虽不是很好，“拿来主义”者居多，但相比几年前，已是不错了，更多的人喜欢把自己杰出的代码开源出来。目前多数“正经”的开源项目，都是 KPI 导向的，不能说项目不好，只是一定时间后，可能就不维护了，而开源项目不仅仅要解决问题，持续维护也是观望着最在意的。 相比 React，Vue.js 的组件库开源项目要多的多，每隔一段时间就能看到几个新的，可能是因为 Vue.js 更容易上手，开发者很活跃。既然已经有这么的同类项目了，那为什么还要持续造轮子呢？因为中国的开发者就是喜欢自己折腾一个，而不是去维护一个现成的。 就以 Vue.js 组件库的开源现象来说，源源不断的轮子，主要还是市面上已有的组件库不能完全满足自己的业务，主要还是 UI 层面的，单论功能，市面上成熟的组件库足够完善，甚至超出你的业务需求。不好说这种现象是好是坏，好的是从头开发一个组件库，对技术的提升还是有的，它会督促你学习别人的代码，来改良自己的代码，否则造一个还不如别人的轮子也就没意义了。对于公司来说，也有了自己的 UI 组件库和规范（虽然很多只是 fork 后改的），感觉用自己的东西，对内对外都是一件很自豪的事。不好的就是，这是一种程序员向产品或 UI 或 leader 的妥协，因为没办法说服他们使用市面上成熟的组件库，否则，完全可以把造轮子的精力用于维护一个成熟的项目。 造轮子这个词，似乎成了前端圈的代名词，的确，前端的造轮子能力是极强的，但不能盲目造轮子。如果你只是仿照其它开源项目练习，那就不说了，如果是想认真做一个开源项目，而不是造个轮子玩玩，那一定要构思好你要做的东西。 一般来说，在决定做一个开源项目前，都是要做市场调研的，你要很清楚的知道，自己做的项目弥补了同类产品的哪些不足，或者有哪些新的特性，因为它们是用户选择你的开源项目的主要依据，否则内容都一样，为什么不选一个成熟的呢。 如果某个开源项目已经很不错，但你希望基于它进行改造，但不是以 PR 的形式，那你可以在开源协议允许的前提下，fork 后，基于某个 release 独立维护。 每个开源项目都有一个核心的功能，或是解决用户的核心痛点，比如 iView 就是解决用户建站的问题，相比同类产品，它的特点就是组件丰富程度最高，功能也是最全面的，生态完善，有技术支持渠道。如果你的开源项目解决的问题是其它任何开源项目没有的，那用户很有可能会使用。但对于相同功能的，用户更倾向于选择还在维护的、star 数多的（star 多，说明这个项目的关注度高，更活跃）。所以，在做开源时，你不仅要知道自己产品的核心技术和特性，还要了解市面同类产品，去其糟粕，取其精华，不断更新和修复 bug，逐渐就会获得第一批用户。 做了东西要用 虽然我这两年的工作基本全是在维护 iView 开源项目，但偶尔也会穿插做几个项目，因为使用了，才能更好地了解自己的开源项目。 你可能会问，我每天都在维护 iView，还有我不了解的吗？还真是，维护和使用完全不一样，在开发组件库时，往往只聚焦在某个组件上，我们定义了 API，然后通过文档告诉使用者怎么用，有些功能是实现了，然而维护者只知道提供了这个功能，却不知在实际项目中好不好用，能用和好用是两个概念。 很多 feature，是自己用了才提炼出来的。比如 iView 的 单元格组件 Cell 和 相对时间组件 Time，都是我在做项目时发现并增加的，没有项目的支持，可能觉得这个组件没什么意义，完全应该由使用者在业务里自己写，作为基础组件后，使用体验确实好很多。 如果你足够重视你的开源项目，应该亲自使用并且安利别人使用来收集反馈，对于组件库来说，细节是很重要的，而很多细节与我们的用户习惯有关，比如 iView 在 3.0 版本开始，对按钮 Button 组件提供了一个新的 props： to，用于指定跳转路径，之前版本如果点击按钮跳转，必须监听它的 @click 事件，然后通过 vue-router 的编程式导航（也就是通过 JS）跳转，如果不亲自使用，绝对不知道这种原先的跳转模式写起来有多麻烦。如果你足够注重细节，这个 Button 组件在跳转时，还应该支持键盘的 Command 键（Windows 为 Ctrl，要做兼容）在新窗口打开链接。这些细节都与使用习惯息息相关，所以，一定要多用用自己的开源项目，在一个个小细节都处理好后，你会的开源项目自然会蒸蒸日上。 第一批用户 开源项目做好后，要获得第一批使用者。现在的环境，大多是公司或团队主导做开源，个人的很少，所以你的公司或团队自然就是第一批用户，做开源的主要目的，也是服务他们。 第一批用户也可以算是开源项目的小白鼠，一开始说服全公司使用，还是比较困难的，可以先小范围推广使用。公司都希望自己的产品稳定，而新的开源项目前期必定会有不少 bug，在经历几个小项目试水后，再尝试向更多的团队推广。因为有了成功案例，又是“自家”的开源项目，给自己人推广还是比较容易的。 在第一批用户的推广中，你的 leader 可能会起到决定性作用。你的开源项目，八成市场上已经有同类的了，不得不承认，即使让“自己人”做技术选型，也更期望选市面上成熟的，这种情况，就需要你的 leader 出来“拍板”了，否则，你的开源项目也许永远不会有第一批用户来试错。记得当时我在团队推广 Vue.js 时，起初也是很多质疑，有一部分人坚持使用 jQuery + 前端模板，得到 leader 的认可后，试水了几个项目，大家都能感受到 Vue.js 和 webpack 带来的高效开发体验，从此就没人再用 jQuery 了。不过呢，你最好确保你的开源项目质量还不错，否则这锅就得 leader 替你背了。 与市面上同类成熟的开源项目相比，你的开源项目最大的优势就是你能为第一批用户提供优质的“售后”服务。如果是同事的问题，你可以很快直接解答；如果是通过 GitHub 提交的 issues（前期不会很多了），尽量在半小时内回复，这样使用者会觉得你确实在用心维护这个开源项目。通过前期的口碑积累，你的第一批用户也成为了最忠实的用户，这时可以组建微信或 QQ 群，更直接地提供“售后”，而这第一批忠实用户，会成为后期推广的重要人脉。 生态 生态（ecosystem）不是与生俱来的，当你的开源项目有了一定的规模后，可以考虑发展生态体系。比如 iView，起初只是一个组件库，后续逐渐提供了 iview-project 工程、具有 GUI 的 iView CLI（这个概念可比 Vue CLI 3 早了一年）、后台模板 iview-admin、支持 Vue CLI 3 的 vue-cli-plugin-iview，以及业务组件 iview-area 和 markdown 编辑器 iview-editor，再到后来支持 SSR、TS。 完善的生态体系对于新用户来说，可以最快速搭建产品，减少学习和开发成本；对于观望者（正在决定是否使用的人）来说，更愿意选择生态完善的开源项目。所以，你的开源项目生态越完善，使用者也会越多。 生态的另一个好处，就是让用户产生依赖。最典型的例子就是 Vue 全家桶，一般刚接触的人，只会用个 Vue.js，再后来 vue-router、vuex 都是必须的了，再后来搭配一个三方的组件库，比如 iView，各种业务都能轻松应对。一旦用户对你的生态足够依赖，就很难更换技术栈了，因为生态的深入，更换成本很大，这也是很多企业的老项目所谓的“历史原因”。 生态的建设，不一定都是官方的行为，但是最核心的还是要自己维护，用户既然选择你的开源项目，也就意味着信任你的技术实力，放心用你的生态。项目到了一定规模，自然有不少第三方的开发者一起建设生态，这些 contributors 都是最有价值的开发者，尽量联系他们，一起来贡献更多的代码。 对于 Vue.js 组件库来说，生态一般分为脚手架、后台模板和业务组件。最新的 Vue CLI 3 提供了插件机制，现在的主流做法都是提供一个类似 vue-cli-plugin-iview 的插件，很少有单独提供自己的工程了，在文档里，要推荐使用者用 Vue CLI 3 来管理项目，享受 Vue 的生态。后台模板是开箱即用的，默认配置好了路由、权限管理、多语言、登录等常规的后台系统功能，使用者 down 下来后，稍作修改就能很快开发自己的后台管理系统，主流的 UI 组件库，都会提供自家的后台模板，当然也有第三方专注在做后台模板的。最后一类业务组件，比如城市级联选择器 iview-area，它基于 iView 的基础组件开发，但又不是基础组件，所以不能归到 iView 里，只能作为独立组件单独维护，业务组件理论上使用者可以自己封装，但是重复性的工作，还是交给社区做吧，这就是开源。 下一篇，将介绍： 持续运营 国际化 让更多的人参与 让 Robot 来做“坏人” 赞助与商业化 扩展阅读 2016我的心路历程：从 Vue 到 Webpack 到 iView "},"Vue.js组件精讲/19.拓展：如何做好一个开源项目（下篇）.html":{"url":"Vue.js组件精讲/19.拓展：如何做好一个开源项目（下篇）.html","title":"19.拓展：如何做好一个开源项目（下篇）","keywords":"","body":"拓展：如何做好一个开源项目（下篇） 持续运营 项目有了一定的规模和进展后，需要持续运营，让更多的人知道和使用。运营并不是个技术活，对于程序员来说，还是或缺的技能。最简单的运营手段，就是在一些技术社区分享“软文”，iView 在早期就是这样做的，还总结出了一个 “500 star 定律”，也就是说，每一次分享文章，差不多能在 GitHub 带来 500 个 star。star 对于一个开源项目来说，还是蛮重要的，它直接决定了用户是否会选择你的项目，但用户都是程序员，又不傻，如果项目质量低，star 就变的一文不值了，还会坏了口碑。切记，不要刷 star，前端圈堪比娱乐圈，会被针对的很惨。 当然，不是什么内容都能发，比如更新日志，最好就不要发了，除非像 2.0、3.0 这种大版本。即使是发大版本的更新内容，也不是说把更新日志一贴就完事，如果你足够重视你的开源项目，就应该重视每一篇文章，把更新的核心思路说清楚。典型的案例可以参考 iView： iView 发布 3.0 版本，以及开发者社区等 5 款新产品 iView 近期的更新，以及那些“不为人知”的故事 iView 发布后台管理系统 iview-admin，没错，它就是你想要的 标题的重要性就不必说了，在信息爆炸的时代，你的标题不够吸引人，根本没人看。 目前，有几个社区是值得关注和积累粉丝的： 掘金：比较活跃的程序员社区，前端属性较浓，社区运营做的很好，对开源项目有扶持，相关的文章首次亮相，官方都会给予一定的资源支持。 知乎：流量最大的社区，大 V 属性，如果你是初入知乎，可以把文章投稿到热门的专栏，比如前端评论外刊、前端之巅等。因为自己起初是没有粉丝订阅的，发表了也不会有人看到，投稿就不一样了。而且，被某个大 V 赞一下，那效果就像中奖。 v2ex：不用解释，就是很火的社区。 开源项目，一般都会在 GitHub 托管，不过也可以在开源中国（Gitee）同步一份，每个版本的更新日志，可以以新闻的形式，向开源中国投稿。开源中国在国内还是有一定的影响力的。 除了发表文章，一些技术分享大会也可以关注，可以以公司的名义申请成为嘉宾做分享。如果有机会，还可以到其它公司做技术分享，尤其是大厂商，这些都是难得推广开源项目的好机会。你的开源项目，如果有几个 BAT 这类的大厂使用，那会成为维护者、社区用户和观望者的信心来源。 还有发布会。在国内，开源项目搞发布会的，据我所知只有 iView。没错，18 年 7 月，iView 搞了一场新品发布会，线下进行，线上同步直播，当时有超过 2 万的在线用户观看，推广效果还是不错的。一场“合格”的活动，要分活动前、活动中、活动后。活动开始前一个月，就要散布消息，让用户有个初步印象，之间还可以爆料一些活动热点；活动进行中，要有专人负责现场，还要与观众互动；活动结束后，要加个班，把核心内容整理为文字，在第一时间通过官方渠道发表出来。这种大规模的活动，没有公司支持，个人很难完成的，因为这不是一两个人的事，需要很多工作人员一起完成，幕前幕后、直播的网络、现场 wifi，还要应对各种突破状况，不过，最重要的还是活动内容的策划准备了，否则一切都是纸上谈兵。 讲到这，你可能会说，老老实实做技术不好吗，非要弄这些花里胡哨的东西。的确，推广这件事，并不是做开源必须的，老实做技术没有错，推广只是让你的开源项目更快传达给目标用户。做这些事的目的就一个，让更多的人使用你的开源项目，让更多的开发者参与贡献代码。 最后一点，如果你的公司或团队有经费，适当投放一点广告也是不错的。 国际化 是时候与世界接轨了。一般来说，国际化（Internationalization，简称 i18n）分 3 个部分，首先是你的开源项目支持多国语言，对于 UI 组件库来说，这个还是很好支持的，只需要提供一个多语言的配置文件就行，每种语言一个文件，然后由社区贡献更多的语言。以 Vue.js 为例，社区也提供了 vue-i18n 插件，那你的组件库还要兼容 vue-i18n，可能还要考虑兼容多个主流的版本。 另一部分是文档的国际化，除了中文，至少应该提供一个英文版本，毕竟英文算是通用的语言。如果文档内容不多，可以让社区来提供更多的翻译版本。维护多语言的文档是一件很辛苦的事，这意味着每一个版本更新都是中英双语的，并不是说文档翻译一遍就不管了。好在翻译文档是个一次性的技术活，前期多找一些英文好的热心用户一起翻译，后面只要确保每次更新都保持中英双语就好了。 做国际化，意味着要服务国际友人，那就不能强求他们用微信或 QQ。在开源界，比较通用的是 Gitter，只需要关联一次 GitHub 的 repo 就行。除此之外，官方可以在 Twitter 开通一个账户，来更新一些动态，与其它 Twitter 互动。Discord 也是技术圈比较热门的一个 App，以 Vue.js 来说，你可以加入一个名为 Vue Land 的服务器，在里面找到 #ui-libraries 的频道，就可以和全世界的开发者讨论组件库的话题了。 支持国际化，短期来看，是一件付出回报比很低的事，但从长远利益出发，对国际化的支持，有助于更多的国外开发者成为核心 maintainers，让全世界能够参与进来，才是开源的意义所在。 让更多的人参与 开源项目从来就不是一个人的事，一个健壮的开源项目，需要不断有人贡献代码。在项目有了一定知名度和使用人群后，自然会有不少 PR 进来，知名的开源项目 contributors 都有几百人，哪怕修改一行代码，只要被 merge，就算一个 contributors。最核心的维护者一般不会超过 5 人，而且除了作者本人，很多都是阶段性的，毕竟是开源，大多数人还是兼职做的，能贡献一点是一点，业务忙了就没顾不上了。 为开源项目贡献代码，主要以 PR 的形式进行，作为一个开源项目的 owner，即使 organization 的其他成员有直接 commit 的权限，也应该建议他们提交 PR，而不是直接 commit，owner 需要认真 review 每一个 PR 以确保代码质量。修复一个问题最怕的，是引起新的问题，或导致以前已修复的问题又复现，有时候，contributor 可能只为了 fix 某一个 issue，但它对整个项目是不了解的，而且对以前“发生的事情”都不了解，会导致一些他看不到的问题，这种情况作为 owner 就要认真审查了。 参与一个开源项目的方式有很多，除了最直接的 PR，还可以 review issues。项目活跃时，每天都会有不少 issues 进来，owner 可能没时间及时处理，但可以打标签（labels）。一个 issue 被标记了 label，说明已经审核过此 issue，常见的 label 有以下几种： bug：已确定为 bug； feature request：已确定为请求新功能； invalid：无效的 issue，一般可以直接关闭； contribution welcome：owner 可能暂时没有精力处理，期望社区来贡献代码； provide example：issue 需要提供复现示例； discussion：暂时无法断定，需要进一步讨论； may be supported in the future：先标记一下，也许未来会支持。 管理 issues 的另一个方式是用好里程碑（milestones）功能。milestones 可以按照版本号创建，把期望在这个版本解决的 issues 添加进去，发版前对当前 milestone 的所有 issues 集中查看，是否都处理完成了。 有一些有价值的 issues 可能会耗费不少精力处理，而且社区很多用户都希望能够解决，owner 当然也希望处理，只是没有时间。这种情况不妨有偿悬赏，推荐一个新起的国外社区 IssueHunt，用户可以为某一个 repo 的 issue 众筹，谁处理了，就可以得到全部赏金。 每一个版本发布后，记得创建一条 release，这样做一是有一个版本更新日志记录的地方，二是 watch 你项目的人都可以及时收到邮件通知提醒升级，三是 release 会打一个 tag，其它贡献者可以切换到此 tag。release 最好不要在发版前再创建，不然整理起来很费劲，建议每个 release 发布后，就新建下一个版本的 release 作为草稿（draft），处理一个 issue，就记录一条，避免遗漏。 版本号也是有讲究的，比如 3.2.1，这里的最后一位，代表只有 bug fixed，中间一位代表有 new features，第一位代表有 break changes。一般来说，除了第一位，剩下的版本都是兼容式的，就是说用户升级后不会影响当前项目，如果有 API 的变更，应该发布第一位版本号。 代码贡献越活跃，贡献者越多，开源项目也越健壮，作为 owner，应该及时联络有价值的贡献者，一个人的能力毕竟是有限的。当你与世界各地讲着不同语言的的人，一起完成一个开源项目，会觉得开源真是一件了不起的事情。 让 Robot 来做“坏人” 开源项目有一定的规模后，社区就会很活跃，每天都会有大量的 issues，这些 issues 越积越多，不及时处理掉，对 owner 来说就是精神压力。在项目初期，由于使用者不多，是鼓励提 issues 的，建议、新功能请求、bug 反馈、问题咨询等各种内容都可以提交，而且作者有足够的时间和精力来认真回答。到了一定规模后，可能什么 issues 都会出现，不乏一些带有恶意的、言语攻击的，如果直接关闭 issue，可能还会继续“纠缠”，说 owner 态度不好之类的，这些都是笔者亲身经历过的。 除了恶意的 issues，还有很多 issues 不符合格式要求，连代码格式化都没有，甚至连问题都说不清楚，也没有描述，就一个标题，这些无效的 issues 一个个回复都会占据大量的精力，直接 close 还会被说没处理怎么就关闭了，实属无奈。 这时你需要一个 GitHub 机器人来充当“坏人”的角色，也就是注册另一个 GitHub 账户，用它来处理一些不符合要求的 issues，这是一个很聪明的做法，关闭 issues 这些活都让 robot 来操作。比如 iView 的“坏人”就是 iview-bot，不过它是一个智能的 robot，不需要 owner 控制，会自动关闭不合格的 issues 并回复提问者。GitHub 提供了 API 来接收每一个 issues 并通过 API 来操作 issues，包括关闭、打标签、回复等，只要给 robot 设置足够的权限就行。比如 iView 的 issues 机器人代码是 https://github.com/iview/iview-bot。用户如果直接通过 GitHub 提交 issues，会被 robot 立即关闭，并回复： Hello, this issue has been closed because it does not conform to our issue requirements. Please use the Issue Helper to create an issue - thank you! 就是说，用户必须通过 Issue Helper 这个页面提交 issues 才可以，不是通过它提交的，会被检测出来立即关闭。在这个页面中，用户需要提供详细的描述才能通过表单验证。issues 只接受 bug 报告或是新功能请求 (feature requests)，对于使用咨询等其它问题，都不能提交，而是鼓励到 Stackoverflow 之类的社区讨论。如果是 Bug，还必须提供能够最小化复现问题的在线链接，以及详细的复现步骤。 robot 还有一个作用：翻译。它会把中文的 issues 自动翻译为英文并把翻译内容自动创建一条回复，同时标题也会修改为英文。开源项目到这个规模，使用者和贡献者不仅仅是中国人了，世界各地的开发者都有，使用英文会让所有人都看懂 issues。 虽然 robot 能自动过滤 80% 不合格的 issues，但仍有浑水摸鱼的用户跳过这些验证，这时可以给 robot 设置一些快捷回复，人为来 comment & close： Hello, this issue has been closed because similar problems exist or have been explained in the documentation, please check carefully. 已有相同 issues，或文档有说明 Hello, this issue has been closed because it is not required to submit or describe is not clear. 描述不清楚 Hello, this issue has been closed because it has nothing to do with the bug report or feature request. Maybe you can ask normal question through SegmentFault or stackoverflow. 不是 bug 反馈或 新功能请求，请到社区讨论 Hello, this issue has been closed because it is not a bug, but a usage problem, please consult other communities. 用法不对 Please provide online code. You can quickly create an example using the following online link：https://run.iviewui.com/. 没有提供在线示例 其实呢，这个“坏人”也没那么坏，还是挺可爱的。 赞助与商业化 开源项目的发展离不开资金的支持，向社区寻求赞助并不是一件“羞耻”的事情，而是理所当然的。 最简单的赞助方式就是通过二维码打赏，不过这种方式在国内几乎没有什么用，中国的开发者大多比较“囊中羞涩”，而且由于打赏的匿名性（微信），时不时收到个 1 分钱，也就呵呵了。 这里推荐几种比较好的“募资”方式：patreon 和 opencollective 是开源项目最常用的，可以一次性支持，或周期性，以美元结算，可转至 PayPal。不过这两种都是美元，而且转到 owner 这里，扣除手续费可能少很多，不过对赞助者（往往是企业）来说，好处就是有发票。另一种方式是通过开源中国来赞助，开源中国的用户还是比较慷慨的。 另一种是投放广告，这里推荐 Carbon，不同于 Google Ads 的是，它的广告都是与互联网相关的，而且样式可以完全自定义，很美观，不会让用户产生反感，广告根据展示和点击转化付费。Carbon 的中国市场负责人中文很溜哦，作为中国开发者，不用担心谈不来。 不过呢，最值得推荐的还是接入品牌广告，但前提是你的文档要有一定的流量。开源项目的文档有着最大的特点：访问者几乎都是程序员，所以你要是挂个某多多的广告，几乎会被喷死。在线教育、云主机服务商都是不错的选择。一般不会有人主动联系 owner 投放的，除非像 Vue.js 这种级别的，但你可以尝试发一封友好的邮件来询问。不知道发给谁？告诉你个好办法，去其它社区（比如 v2ex）看看都有哪些金主投放就知道了，既然已经投放，说明有投放广告的需求，都是潜在的目标“客户”。 再来说说商业化。 开源并不是意味着免费，根据开源协议的不同，有的开源软件在用于商业时，可能要购买授权，源码是开放的，但不一定可以免费使用。不过能够收取授权费，也说明你的软件确实无可替代。企业为了避免不必要的纠纷，肯定是愿意购买你的软件的。但是对于大多数 MIT 的开源项目，可以商业化吗？答案是肯定的。 首先要知道，能够付费的，都是企业，而非个人，个人也没有付费的必要。一种比较常见的模式就是软件免费，然后可以向企业提供额外的付费咨询服务或顾问。最懂开源项目的人，绝对是这个项目的 owner，如果企业是深度用户，还是很愿意支付一些费用来咨询问题的。我是做 to B 业务的，我们公司也是做 to B 的，公司高管大多也来自 Oracle（算是比较大的 to B 企业了），所以我对企业服务也有一定的理解，一款好的产品，绝对是技术加咨询服务。 商业化还是有很多方式的，具体要看开源项目的类型。以组件库为例，它本身是免费的，也可以无限制免费使用，但可能提供付费的高级组件或模板系统，以及其它生态产品，比如基于组件库的 IM 系统。 当然了，并不是所有的开源项目都要商业化，大部分还是完全免费的，商业化也有利弊，如果没有一定的实力，很有可能搞砸哦！ 以上，就是我从事开源工作两年多的一些浅薄经验，希望能给聪明的你带来帮助。 结语 每个开发者，都应该尝试维护一个开源项目。 每个开发者，都应该抱着一颗敬畏之心使用他人的开源项目，而不是“用你的是看得起你”。 每个开发者，都应该适当地赞助一个帮助过你的开源项目。 "},"Vue.js组件精讲/20.写在最后.html":{"url":"Vue.js组件精讲/20.写在最后.html","title":"20.写在最后","keywords":"","body":"写在最后 亲爱的读者，到这里本小册就要结束了，你是否从中学习到了属于你的知识呢？我们来回顾一下小册的内容吧。 Vue.js 在开发独立组件时，由于它的特殊性，无法使用 Vuex、Bus 这样的第三方插件来做组件通信，因此小册提到了 3 种组件间的通信方法，都是支持跨多级的： provide / inject：由父组件通过 provide 向下提供一个数据，子组件在需要时，通过 inject 注入这个依赖，就可以直接访问父级的数据了。 dispatch / broadcast：组件向上派发或向下广播一个自定义事件，组件通过 $on 来监听。 findComponents 系列：共包含 5 个方法，通过组件的 name 选项，遍历找到对应的实例，这是组件通信的终极方案，适用于所有场景。 本册总共讲解了 7 个组件的实例： 具有数据校验功能的 Form 组件，它用到了第 1 种组件通信； 组合多选框 Checkbox 组件，它用到了第 2 种和第 3 种组件通信； Display 组件，它利用 Vue.js 的构造器 extend 和手动挂载 $mount API； 全局通知 $Alert 组件，也是利用了 $mount API，与传统组件不同的是，它基于 Vue.js 组件开发，但却是以 JavaScript 的形式调用的，并且组件会在 body 节点下渲染； 表格组件 Table，典型的数据驱动型组件，使用了函数式组件（Functional Render）来自定义列模板； 表格组件 Table，与上例不同的是，它的自定义列模板使用了 slot-scope； 树形控件 Tree，典型的数据驱动型组件，也是典型的递归组件，其中利用 computed 做父子节点联动是精髓。 最后的拓展部分，对 Vue.js 组件的常见 API 做了详细介绍，以及常见的 Vue.js 面试题分析和对开源的一些见解。 Vue.js 组件开发，归根到底拼的是 JavaScript 的功底，Vue.js 在其中只是决定了开发模式，所以，打好 JavaScript 基础才是最重要的。 最后，祝愿亲爱的读者能在编程的道路上越走越远。 另外，如果您有关于 Vue.js 或其它前端相关的问题，可以通过 iView 社区 付费向笔者提问，希望能对一部分人有所帮助。 "},"Vue项目构建与开发入门/01.开篇：Vue_CLI_3项目构建基础.html":{"url":"Vue项目构建与开发入门/01.开篇：Vue_CLI_3项目构建基础.html","title":"01.开篇：Vue_CLI_3项目构建基础","keywords":"","body":"开篇：Vue CLI 3 项目构建基础 大家好，当你点进这个标题，开始阅读本章的时候，说明你对 Vue.js 是充满好奇心和求知欲的。我之前写过一篇文章，这样评价 Vue.js，称它是“简单却不失优雅，小巧而不乏大匠”的作品，正如其官网介绍的“易用，灵活和高效”那样。其实框架是 Vue.js 的本质，而真正了解它的人则会把它当成一件作品来欣赏。 Vue.js 作为一门轻量级、易上手的前端框架，从入门难度和学习曲线上相对其他框架来说算是占据优势的，越来越多的人开始投入 Vue.js 的怀抱，走进 Vue.js 的世界。那么接下来屏幕前的你不妨一起来和我从零开始构建一个 Vue 项目，体会一下 Vue.js 的精彩绝伦。 依赖工具 在构建一个 Vue 项目前，我们先要确保你本地安装了 Node 环境以及包管理工具 npm，打开终端运行： # 查看 node 版本 node -v # 查看 npm 版本 npm -v 如果成功打印出版本号，说明你本地具备了 node 的运行环境，我们可以使用 npm 来安装管理项目的依赖，而如果没有或报错，则你需要去 node 官网进行 node 的下载及安装，如图： 左边的版本是推荐安装的稳定版本，也就是目前已经被正式列入标准的版本，而右边的版本是当前最新的版本，该版本包含了一些新的特性，还未被完全列入标准，可能以后会有所变动。这里建议大家安装最新的 node 稳定版进行开发。 脚手架 当我们安装完 node 后便可以开始进行后续的构建工作了，那么这里我主要给大家介绍下最便捷的脚手架构建。 1. 什么是脚手架 很多人可能经常会听到“脚手架”三个字，无论是前端还是后台，其实它在生活中的含义是为了保证各施工过程顺利进行而搭设的工作平台。因此作为一个工作平台，前端的脚手架可以理解为能够帮助我们快速构建前端项目的一个工具或平台。 2. vue-cli 其实说到脚手架，目前很多主流的前端框架都提供了各自官方的脚手架工具，以帮助开发者快速构建起自己的项目，比如 Vue、React 等，这里我们就来介绍下 Vue 的脚手架工具 vue-cli。 vue-cli 经历了几个版本的迭代，目前最新的版本是 3.x，也是本小册构建项目所使用的版本，我们一起来看下其人性化的构建流程： a. 安装 我们可以在终端通过以下命令全局安装 vue-cli： # 安装 Vue CLI 3.x npm i -g @vue/cli 如果你习惯使用 yarn，你也可以： # 没有全局安装yarn需执行此命令 npm i -g yarn yarn global add @vue/cli 注意因为是全局安装，所以 vue-cli 是全局的包，它和我们所处的项目没有关系。同时我们这里介绍的 CLI 版本是最新的 3.x，它和 2.x 版本存在着很大的区别，具体的讲解会在后续章节中进行介绍。 b. 构建 安装完 vue-cli 后，我们在你想要创建的项目目录地址下执行构建命令： # my-project 是你的项目名称 vue create my-project 执行完上述命令后，会出现一系列的选择项，我们可以根据自己的需要进行选择，流程图如下： 如果你只想构建一个基础的 Vue 项目，那么使用 Babel、Router、Vuex、CSS Pre-processors 就足够了，最后选择你喜欢的包管理工具 npm or yarn。 c. 启动 等待构建完成后你便可以运行命令来启动你的 Vue 项目： # 打开项目目录 cd vue-project # 启动项目 yarn serve # or npm run serve 需要注意的是如果启动的时候出现报错或者包丢失等情况，最好将 node 或者 yarn （如果使用）的版本更新到最新重新构建。 成功后打开浏览器地址：http://localhost:8080/ 可以看到如下界面： d. 目录结构 最后脚手架生成的目录结构如下： ├── node_modules # 项目依赖包目录 ├── public │ ├── favicon.ico # ico图标 │ └── index.html # 首页模板 ├── src │ ├── assets # 样式图片目录 │ ├── components # 组件目录 │ ├── views # 页面目录 │ ├── App.vue # 父组件 │ ├── main.js # 入口文件 │ ├── router.js # 路由配置文件 │ └── store.js # vuex状态管理文件 ├── .gitignore # git忽略文件 ├── .postcssrc.js # postcss配置文件 ├── babel.config.js # babel配置文件 ├── package.json # 包管理文件 └── yarn.lock # yarn依赖信息文件 根据你安装时选择的依赖不同，最后生成的目录结构也会有所差异。 3. 可视化界面 当然，除了使用上述命令行构建外，vue-cli 3.x 还提供了可视化的操作界面，在项目目录下我们运行如下命令开启图形化界面： vue ui 之后浏览器会自动打开本地 8000 端口，页面如下： 如果你还没有任何项目，那么可以点击创建或者直接导入现有的项目。创建项目和我们使用命令行的步骤基本相同，完全可视化操作，一定程度上降低了构建和使用的难度。项目创建或导入成功后你便可以进入项目进行可视化管理了。 在整个管理界面中，我们可以为自己的项目安装 CLI 提供的插件，比如安装 @vue/cli-plugin-babel 插件，同时我们也可以配置相应插件的配置项，进行代码的编译、热更新、检查等。详细的操作大家可以自己进行手动尝试，相信你会发现意想不到的惊喜。 你还需要了解什么 上方我们用 vue-cli 成功生成了一个最基础的 Vue 项目，麻雀虽小，五脏俱全，但是想要让麻雀飞起来，我们还要不断的给它进行拓展训练，那么我们还需要了解什么呢？ 以上这些内容（包含但不限于）将会在本小册的接下来几章进行详细的讲解，你准备好了吗？ 结语 本文主要讲述了使用 vue-cli 脚手架进行 Vue 项目构建的基本知识，从构建的流程中我们不难发现 Vue 提供给了我们一套非常灵活可配置的工具，其小巧而不乏大匠的魅力不言而喻。希望大家能够从构建开始，逐渐领略 Vue.js 的匠心，激发自己的对 Vue 的兴趣。 "},"Vue项目构建与开发入门/02.构建基础篇1：你需要了解的包管理工具与配置项.html":{"url":"Vue项目构建与开发入门/02.构建基础篇1：你需要了解的包管理工具与配置项.html","title":"02.构建基础篇1：你需要了解的包管理工具与配置项","keywords":"","body":"构建基础篇 1：你需要了解的包管理工具与配置项 任何一个项目的构建离不开工具和统一的管理标准，在项目开发和维护过程中，我们需要了解安装包的相应工具和配置文件，以此来有效的进行项目的迭代和版本的更新，为项目提供基本的运行环境。本文将详细介绍构建 Vue.js 项目相关的依赖包安装工具和相应的配置文件，为大家提供参考。 介绍 相信大家对于包管理工具的使用一定不会陌生，毕竟它已经成为前端项目中必不可少的一部分，为了照顾部分零基础用户，这里我们做一个简单的介绍。 1. npm 与 package.json npm 是 Node Package Manager 的简称，顾名思义，它是 node 的包管理工具，也是目前世界上最大的开源库生态系统。官方地址为：https://www.npmjs.com/，你可以在里面找到数以万计的开源包。 使用 npm 包下载量统计工具，比如 npm-start，我们可以查看相应包在一定时间范围内的下载量数据，下面是 vue-cli 和 @vue/cli 的下载量趋势： 在上篇文章中我们介绍了使用 vue-cli 来构建自己的项目，并生成了相应的目录结构，而在最外层目录中，我们可以看到有 package.json 这一文件，该文件便是我们需要了解的包管理文件。 我们先来看一下该文件里面的内容： { \"name\": \"my-project\", \"version\": \"0.1.0\", \"private\": true, \"scripts\": { \"serve\": \"vue-cli-service serve\", \"build\": \"vue-cli-service build\", \"lint\": \"vue-cli-service lint\" }, \"dependencies\": { \"vue\": \"^2.5.16\", \"vue-router\": \"^3.0.1\", \"vuex\": \"^3.0.1\" }, \"devDependencies\": { \"@vue/cli-plugin-babel\": \"^3.0.0-beta.15\", \"@vue/cli-service\": \"^3.0.0-beta.15\", \"less\": \"^3.0.4\", \"less-loader\": \"^4.1.0\", \"vue-template-compiler\": \"^2.5.16\" }, \"browserslist\": [ \"> 1%\", \"last 2 versions\", \"not ie 可以看到该文件是由一系列键值对构成的 JSON 对象，每一个键值对都有其相应的作用，比如 scripts 脚本命令的配置，我们在终端启动项目运行的 npm run serve 命令其实便是执行了 scripts 配置下的 serve 项命令 vue-cli-service serve ，我们可以在 scripts 下自己修改或添加相应的项目命令。 而 dependencies 和 devDependencies 分别为项目生产环境和开发环境的依赖包配置，也就是说像 @vue/cli-service 这样只用于项目开发时的包我们可以放在 devDependencies 下，但像 vue-router 这样结合在项目上线代码中的包应该放在 dependencies 下。 详细的package.json文件配置项介绍可以参考：package.json 2. 常用命令 在简单的了解了 package.json 文件后，我们再来看下包管理工具的常用命令。一般在项目的构建和开发阶段，我们常用的 npm 命令有： # 生成 package.json 文件（需要手动选择配置） npm init # 生成 package.json 文件（使用默认配置） npm init -y # 一键安装 package.json 下的依赖包 npm i # 在项目中安装包名为 xxx 的依赖包（配置在 dependencies 下） npm i xxx # 在项目中安装包名为 xxx 的依赖包（配置在 dependencies 下） npm i xxx --save # 在项目中安装包名为 xxx 的依赖包（配置在 devDependencies 下） npm i xxx --save-dev # 全局安装包名为 xxx 的依赖包 npm i -g xxx # 运行 package.json 中 scripts 下的命令 npm run xxx 比较陌生但实用的有： # 打开 xxx 包的主页 npm home xxx # 打开 xxx 包的代码仓库 npm repo xxx # 将当前模块发布到 npmjs.com，需要先登录 npm publish 相比 npm，yarn 相信大家也不会陌生，它是由 facebook 推出并开源的包管理工具，具有速度快，安全性高，可靠性强等主要优势，它的常用命令如下： # 生成 package.json 文件（需要手动选择配置） yarn init # 生成 package.json 文件（使用默认配置） yarn init -y # 一键安装 package.json 下的依赖包 yarn # 在项目中安装包名为 xxx 的依赖包（配置在 dependencies 下）,同时 yarn.lock 也会被更新 yarn add xxx # 在项目中安装包名为 xxx 的依赖包（配置在配置在 devDependencies 下）,同时 yarn.lock 也会被更新 yarn add xxx --dev # 全局安装包名为 xxx 的依 yarn global add xxx # 运行 package.json 中 scripts 下的命令 yarn xxx 比较陌生但实用的有： # 列出 xxx 包的版本信息 yarn outdated xxx # 验证当前项目 package.json 里的依赖版本和 yarn 的 lock 文件是否匹配 yarn check # 将当前模块发布到 npmjs.com，需要先登录 yarn publish 以上便是 npm 与 yarn 包管理工具的常用及实用命令，需要注意的是，本小册的讲解将会优先使用 yarn 命令进行包的管理和安装。 3. 第三方插件配置 在上方的 package.json 文件中我们可以看到有 browserslist 这一配置项，那么该配置项便是这里所说的第三方插件配置，该配置的主要作用是用于在不同的前端工具之间共享目标浏览器和 Node.js 的版本： \"browserslist\": [ \"> 1%\", // 表示包含所有使用率 > 1% 的浏览器 \"last 2 versions\", // 表示包含浏览器最新的两个版本 \"not ie 比如像 autoprefixer 这样的插件需要把你写的 css 样式适配不同的浏览器，那么这里要针对哪些浏览器呢，就是上面配置中所包含的。 而如果写在 autoprefixer 的配置中，那么会存在一个问题，万一其他第三方插件也需要浏览器的包含范围用于实现其特定的功能，那么就又得在其配置中设置一遍，这样就无法得以共用。所以在 package.json 中配置 browserslist 的属性使得所有工具都会自动找到目标浏览器。 当然，你也可以单独写在 .browserslistrc 的文件中： # Browsers that we support > 1% last 2 versions not ie 至于它是如何去衡量浏览器的使用率和版本的，数据都是来源于 Can I Use。你也可以访问 http://browserl.ist/ 去搜索配置项所包含的浏览器列表，比如搜索 last 2 versions 会得到你想要的结果，或者在项目终端运行如下命令查看： npx browserslist 除了上述插件的配置，项目中常用的插件还有：babel、postcss 等，有兴趣的同学可以访问其官网进行了解。 4. vue-cli 包安装 在上述的教程中，我们使用 npm 或 yarn 进行了包的安装和配置，除了以上两种方法，vue-cli 3.x 还提供了其专属的 vue add 命令，但是需要注意的是该命令安装的包是以 @vue/cli-plugin 或者 vue-cli-plugin 开头，即只能安装 Vue 集成的包。 比如运行： vue add jquery 其会安装 vue-cli-plugin-jquery，很显然这个插件不存在便会安装失败。又或者你运行： vue add @vue/eslint 其会解析为完整的包名 @vue/cli-plugin-eslint，因为该包存在所以会安装成功。 同时，不同于 npm 或 yarn 的安装， vue add 不仅会将包安装到你的项目中，其还会改变项目的代码或文件结构，所以安装前最好提交你的代码至仓库。 另外 vue add 中还有两个特例，如下： # 安装 vue-router vue add router # 安装 vuex vue add vuex 这两个命令会直接安装 vue-router 和 vuex 并改变你的代码结构，使你的项目集成这两个配置，并不会去安装添加 vue-cli-plugin 或 @vue/cli-plugin 前缀的包。 结语 不积跬步无以至千里，不积小流无以成江海。本文主要介绍了在 Vue 项目构建前期需要了解的包管理工具与配置的知识点，只有了解了基本的工具使用才能熟练的对项目进行按需配置，希望大家在接下来的学习中能够学以致用，付诸实践。 思考 & 作业 文章中使用的一些 npm 包名为什么要用 @ 开头？ 除了文章中介绍的 browserslist 这样的配置项可以写在单独的文件中外，还有哪些常用的配置项可以这样操作？又是如何配置的？ Vue CLI 3 还集成了哪些包，可以通过 vue add 命令安装？ "},"Vue项目构建与开发入门/03.构建基础篇2：webpack在CLI3中的应用.html":{"url":"Vue项目构建与开发入门/03.构建基础篇2：webpack在CLI3中的应用.html","title":"03.构建基础篇2：webpack在CLI3中的应用","keywords":"","body":"构建基础篇 2：webpack 在 CLI 3 中的应用 webpack 作为目前最流行的项目打包工具，被广泛使用于项目的构建和开发过程中，其实说它是打包工具有点大材小用了，我个人认为它是一个集前端自动化、模块化、组件化于一体的可拓展系统，你可以根据自己的需要来进行一系列的配置和安装，最终实现你需要的功能并进行打包输出。 而在 Vue 的项目中，webpack 同样充当着举足轻重的作用，比如打包压缩、异步加载、模块化管理等等。如果你了解 webpack 那么相信本文会让你更了解其在 Vue 中的使用，如果你是一个 webpack 小白，那么也没事，相信你会很容易的了解它在项目中的配置和功能。 webpack 的使用 1. 与 vue-cli 2.x 的差异 如果你使用过 vue-cli 2.x，那么你应该了解其构建出的目录会包含相应的 webpack 配置文件，但是在 vue-cli 3.x 中你却见不到一份关于 webpack 的配置文件，难道 3.x 抛弃了 webpack？其实不然，3.x 提供了一种开箱即用的模式，即你无需配置 webpack 就可以运行项目，并且它提供了一个 vue.config.js 文件来满足开发者对其封装的 webpack 默认配置的修改。如图： 2. vue.config.js 的配置 通过上方新老版本的对比，我们可以清晰的看出 vue.config.js 的配置项结构，如果你构建的项目中没有该文件，那么你需要在根目录手动创建它。下面我们就来介绍一下其常用配置项的功能和用途： a. baseurl 在第一节《Vue CLI 3 项目构建基础》中我们通过 vue-cli 3.x 成功构建并在浏览器中打开 http://localhost:8080/ 展示了项目首页。如果现在你想要将项目地址加一个二级目录，比如：http://localhost:8080/vue/，那么我们需要在 vue.config.js 里配置 baseurl 这一项： // vue.config.js module.exports = { ... baseUrl: 'vue', ... } 其改变的其实是 webpack 配置文件中 output 的 publicPath 项，这时候你重启终端再次打开页面的时候我们首页的 url 就会变成带二级目录的形式。 b. outputDir 如果你想将构建好的文件打包输出到 output 文件夹下（默认是 dist 文件夹），你可以配置： // vue.config.js module.exports = { ... outputDir: 'output', ... } 然后运行命令 yarn build 进行打包输出，你会发现项目跟目录会创建 output 文件夹， 这其实改变了 webpack 配置中 output 下的 path 项，修改了文件的输出路径。 c. productionSourceMap 该配置项用于设置是否为生产环境构建生成 source map，一般在生产环境下为了快速定位错误信息，我们都会开启 source map： // vue.config.js module.exports = { ... productionSourceMap: true, ... } 该配置会修改 webpack 中 devtool 项的值为 source-map。 开启 source map 后，我们打包输出的文件中会包含 js 对应的 .map 文件，其用途可以参考：JavaScript Source Map 详解 d. chainWebpack chainWebpack 配置项允许我们更细粒度的控制 webpack 的内部配置，其集成的是 webpack-chain 这一插件，该插件可以让我们能够使用链式操作来修改配置，比如： // 用于做相应的合并处理 const merge = require('webpack-merge'); module.exports = { ... // config 参数为已经解析好的 webpack 配置 chainWebpack: config => { config.module .rule('images') .use('url-loader') .tap(options => merge(options, { limit: 5120, }) ) } ... } 以上操作我们可以成功修改 webpack 中 module 项里配置 rules 规则为图片下的 url-loader 值，将其 limit 限制改为 5M，修改后的 webpack 配置代码如下： { ... module: { rules: [ { /* config.module.rule('images') */ test: /\\.(png|jpe?g|gif|webp)(\\?.*)?$/, use: [ /* config.module.rule('images').use('url-loader') */ { loader: 'url-loader', options: { limit: 5120, name: 'img/[name].[hash:8].[ext]' } } ] } ] } ... } 这里需要注意的是我们使用了 webpack-merge 这一插件，该插件用于做 webpack 配置的合并处理，这样 options 下面的其他值就不会被覆盖或改变。 关于 webpack-chain 的使用可以参考其 github 官方地址：https://github.com/mozilla-neutrino/webpack-chain，它提供了操作类似 JavaScript Set 和 Map 的方式，以及一系列速记方法。 e. configureWebpack 除了上述使用 chainWebpack 来改变 webpack 内部配置外，我们还可以使用 configureWebpack 来进行修改，两者的不同点在于 chainWebpack 是链式修改，而 configureWebpack 更倾向于整体替换和修改。示例代码如下： // vue.config.js module.exports = { ... // config 参数为已经解析好的 webpack 配置 configureWebpack: config => { // config.plugins = []; // 这样会直接将 plugins 置空 // 使用 return 一个对象会通过 webpack-merge 进行合并，plugins 不会置空 return { plugins: [] } } ... } configureWebpack 可以直接是一个对象，也可以是一个函数，如果是对象它会直接使用 webpack-merge 对其进行合并处理，如果是函数，你可以直接使用其 config 参数来修改 webpack 中的配置，或者返回一个对象来进行 merge 处理。 你可以在项目目录下运行 vue inspect 来查看你修改后的 webpack 完整配置，当然你也可以缩小审查范围，比如： # 只查看 plugins 的内容 vue inspect plugins f. devServer vue.config.js 还提供了 devServer 项用于配置 webpack-dev-server 的行为，使得我们可以对本地服务器进行相应配置，我们在命令行中运行的 yarn serve 对应的命令 vue-cli-service serve 其实便是基于 webpack-dev-server 开启的一个本地服务器，其常用配置参数如下： // vue.config.js module.exports = { ... devServer: { open: true, // 是否自动打开浏览器页面 host: '0.0.0.0', // 指定使用一个 host。默认是 localhost port: 8080, // 端口地址 https: false, // 使用https提供服务 proxy: null, // string | Object 代理设置 // 提供在服务器内部的其他中间件之前执行自定义中间件的能力 before: app => { // `app` 是一个 express 实例 } } ... } 当然除了以上参数，其支持所有的 webpack-dev-server 中的选项，比如 historyApiFallback 用于重写路由（会在后续的多页应用配置中讲解）、progress 将运行进度输出到控制台等，具体可参考：devServer 以上讲解了 vue.config.js 中一些常用的配置项功能，具体的配置实现需要结合实际项目进行，完整的配置项可以查看：vue.config.js 3. 默认插件简介 通过对 vue.config.js 的了解，我们知道了 vue-cli 3.x 为我们默认封装了项目运行的常用 webpack 配置，那么它给我们提供了哪些默认插件，每一个 plugin 又有着怎样的用途呢？除了使用 vue inspect plugins 我们还可以通过运行 vue ui 进入可视化页面查看，步骤如下： 打开可视化页面，点击对应项目进入管理页面（如果没有对应项目，需要导入或新建） 点击侧边栏 Tasks 选项，再点击二级栏 inspect 选项 点击 Run task 按钮执行审查命令 如图所示： 最后我们从输出的内容中找到 plugins 数组，其包含了如下插件（配置项已经省略，增加了定义插件的代码）： // vue-loader是 webpack 的加载器，允许你以单文件组件的格式编写 Vue 组件 const VueLoaderPlugin = require('vue-loader/lib/plugin'); // webpack 内置插件，用于创建在编译时可以配置的全局常量 const { DefinePlugin } = require('webpack'); // 用于强制所有模块的完整路径必需与磁盘上实际路径的确切大小写相匹配 const CaseSensitivePathsPlugin = require('case-sensitive-paths-webpack-plugin'); // 识别某些类型的 webpack 错误并整理，以提供开发人员更好的体验。 const FriendlyErrorsPlugin = require('friendly-errors-webpack-plugin'); // 将 CSS 提取到单独的文件中，为每个包含 CSS 的 JS 文件创建一个 CSS 文件 const MiniCssExtractPlugin = require(\"mini-css-extract-plugin\"); // 用于在 webpack 构建期间优化、最小化 CSS文件 const OptimizeCssnanoPlugin = require('optimize-css-assets-webpack-plugin'); // webpack 内置插件，用于根据模块的相对路径生成 hash 作为模块 id, 一般用于生产环境 const { HashedModuleIdsPlugin } = require('webpack'); // 用于根据模板或使用加载器生成 HTML 文件 const HtmlWebpackPlugin = require('html-webpack-plugin'); // 用于在使用 html-webpack-plugin 生成的 html 中添加 或 ，有助于异步加载 const PreloadPlugin = require('preload-webpack-plugin'); // 用于将单个文件或整个目录复制到构建目录 const CopyWebpackPlugin = require('copy-webpack-plugin'); module.exports = { plugins: [ /* config.plugin('vue-loader') */ new VueLoaderPlugin(), /* config.plugin('define') */ new DefinePlugin(), /* config.plugin('case-sensitive-paths') */ new CaseSensitivePathsPlugin(), /* config.plugin('friendly-errors') */ new FriendlyErrorsWebpackPlugin(), /* config.plugin('extract-css') */ new MiniCssExtractPlugin(), /* config.plugin('optimize-css') */ new OptimizeCssnanoPlugin(), /* config.plugin('hash-module-ids') */ new HashedModuleIdsPlugin(), /* config.plugin('html') */ new HtmlWebpackPlugin(), /* config.plugin('preload') */ new PreloadPlugin(), /* config.plugin('copy') */ new CopyWebpackPlugin() ] } 我们可以看到每个插件上方都添加了使用 chainWebpack 访问的方式，同时我也添加了每个插件相应的用途注释，需要注意的是要区分 webpack 内置插件和第三方插件的区别，如果是内置插件则无需安装下载，而外部插件大家可以直接访问：https://www.npmjs.com/ 搜索对应的插件，了解其详细的 api 设置。 结语 本文主要阐述了 vue-cli 3.x 下基于 vue.config.js 配置 webpack 的主要方法，同时也介绍了其默认的 webpack 插件与主要功能，相信大家在了解 webpack 的知识后能够更加轻松的开展后续内容的学习，为接下来项目的构建和开发奠定基础。 思考 & 作业 除了文章中介绍的配置项，vue.config.js 中还有哪些额外的配置？ webpack-merge 的合并原理是怎样的？ 使用 chainWebpack 获取到 webpack 中的某一插件后，如何修改其配置？ "},"Vue项目构建与开发入门/04.构建基础篇3：env文件与环境设置.html":{"url":"Vue项目构建与开发入门/04.构建基础篇3：env文件与环境设置.html","title":"04.构建基础篇3：env文件与环境设置","keywords":"","body":"构建基础篇 3：env 文件与环境设置 在实际项目的开发中，我们一般会经历项目的开发阶段、测试阶段和最终上线阶段，每一个阶段对于项目代码的要求可能都不尽相同，那么我们如何能够游刃有余的在不同阶段下使我们的项目呈现不同的效果，使用不同的功能呢？这里就需要引入环境的概念。 一般一个项目都会有以下 3 种环境： 开发环境（开发阶段，本地开发版本，一般会使用一些调试工具或额外的辅助功能） 测试环境（测试阶段，上线前版本，除了一些 bug 的修复，基本不会和上线版本有很大差别） 生产环境（上线阶段，正式对外发布的版本，一般会进行优化，关掉错误报告） 作为一名开发人员，我们可能需要针对每一种环境编写一些不同的代码并且保证这些代码运行在正确的环境中，那么我们应该如何在代码中判断项目所处的环境同时执行不同的代码呢？这就需要我们进行正确的环境配置和管理。 介绍 1. 配置文件 正确的配置环境首先需要我们认识不同环境配置之间的关系，如图所示： 我们从上图中可以了解到每一个环境其实有其不同的配置，同时它们也存在着交集部分，交集便是它们都共有的配置项，那么在 Vue 中我们应该如何处理呢？ 我们可以在根目录下创建以下形式的文件进行不同环境下变量的配置： .env # 在所有的环境中被载入 .env.local # 在所有的环境中被载入，但会被 git 忽略 .env.[mode] # 只在指定的模式中被载入 .env.[mode].local # 只在指定的模式中被载入，但会被 git 忽略 比如我们创建一个名为 .env.stage 的文件，该文件表明其只在 stage 环境下被加载，在这个文件中，我们可以配置如下键值对的变量： NODE_ENV=stage VUE_APP_TITLE=stage mode 这时候我们怎么在 vue.config.js 中访问这些变量呢？很简单，使用 process.env.[name] 进行访问就可以了，比如： // vue.config.js console.log(process.env.NODE_ENV); // development（在终端输出） 当你运行 yarn serve 命令后会发现输出的是 development，因为 vue-cli-service serve 命令默认设置的环境是 development，你需要修改 package.json 中的 serve 脚本的命令为： \"scripts\": { \"serve\": \"vue-cli-service serve --mode stage\", } --mode stage 其实就是修改了 webpack 4 中的 mode 配置项为 stage，同时其会读取对应 .env.[model] 文件下的配置，如果没找到对应配置文件，其会使用默认环境 development，同样 vue-cli-service build 会使用默认环境 production。 这时候如果你再创建一个 .env 的文件，再次配置重复的变量，但是值不同，如： NODE_ENV=staging VUE_APP_TITLE=staging mode VUE_APP_NAME=project 因为 .env 文件会被所有环境加载，即公共配置，那么最终我们运行 vue-cli-service serve 打印出来的是哪个呢？答案是 stage，但是如果是 .env.stage.local 文件中配置成上方这样，答案便是 staging，所以 .env.[mode].local 会覆盖 .env.[mode] 下的相同配置。同理 .env.local 会覆盖 .env 下的相同配置。 由此可以得出结论，相同配置项的权重： .env.[mode].local > .env.[mode] > .env.local > .env 但是需要注意的是，除了相同配置项权重大的覆盖小的，不同配置项它们会进行合并操作，类似于 Javascript 中的 Object.assign 的用法。 2. 环境注入 通过上述配置文件的创建，我们成功使用命令行的形式对项目环境进行了设置并可以自由切换，但是需要注意的是我们在 Vue 的前端代码中打印出的 process.env 与 vue.config.js 中输出的可能是不一样的，这需要普及一个知识点：webpack 通过 DefinePlugin 内置插件将 process.env 注入到客户端代码中。 // webpack 配置 { ... plugins: [ new webpack.DefinePlugin({ 'process.env': { NODE_ENV: JSON.stringify(process.env.NODE_ENV) } }), ], ... } 由于 vue-cli 3.x 封装的 webpack 配置中已经帮我们完成了这个功能，所以我们可以直接在客户端代码中打印出 process.env 的值，该对象可以包含多个键值对，也就是说可以注入多个值，但是经过 CLI 封装后仅支持注入环境配置文件中以 VUE_APP_ 开头的变量，而 NODE_ENV 和 BASE_URL 这两个特殊变量除外。比如我们在权重最高的 .env.stage.local 文件中写入： NODE_ENV=stage2 VUE_APP_TITLE=stage mode2 NAME=vue 然后我们尝试在 vue.config.js 中打印 process.env，终端输出： { ... npm_config_ignore_scripts: '', npm_config_version_git_sign: '', npm_config_ignore_optional: '', npm_config_init_version: '1.0.0', npm_package_dependencies_vue_router: '^3.0.1', npm_config_version_tag_prefix: 'v', npm_node_execpath: '/usr/local/bin/node', NODE_ENV: 'stage2', VUE_APP_TITLE: 'stage mode2', NAME: 'vue', BABEL_ENV: 'development', ... } 可以看到输出内容除了我们环境配置中的变量外还包含了很多 npm 的信息，但是我们在入口文件 main.js 中打印会发现输出： { \"BASE_URL\": \"/vue/\", \"NODE_ENV\": \"stage2\", \"VUE_APP_TITLE\": \"stage mode2\" } 可见注入时过滤调了非 VUE_APP_ 开头的变量，其中多出的 BASE_URL 为你在 vue.config.js 设置的值，默认为 /，其在环境配置文件中设置无效。 3. 额外配置 以上我们通过新建配置文件的方式为项目不同环境配置不同的变量值，能够实现项目基本的环境管理，但是 .env 这样的配置文件中的参数目前只支持静态值，无法使用动态参数，在某些情况下无法实现特定需求，这时候我们可以在根目录下新建 config 文件夹用于存放一些额外的配置文件。 /* 配置文件 index.js */ // 公共变量 const com = { IP: JSON.stringify('xxx') }; module.exports = { // 开发环境变量 dev: { env: { TYPE: JSON.stringify('dev'), ...com } }, // 生产环境变量 build: { env: { TYPE: JSON.stringify('prod'), ...com } } } 上方代码我们把环境变量分为了公共变量、开发环境变量和生产环境变量，当然这些变量可能是动态的，比如用户的 ip 等。现在我们要在 vue.config.js 里注入这些变量，我们可以使用 chainWebpack 修改 DefinePlugin 中的值： /* vue.config.js */ const configs = require('./config'); // 用于做相应的 merge 处理 const merge = require('webpack-merge'); // 根据环境判断使用哪份配置 const cfg = process.env.NODE_ENV === 'production' ? configs.build.env : configs.dev.env; module.exports = { ... chainWebpack: config => { config.plugin('define') .tap(args => { let name = 'process.env'; // 使用 merge 保证原始值不变 args[0][name] = merge(args[0][name], cfg); return args }) }, ... } 最后我们可以在客户端成功打印出包含动态配置的对象： { \"NODE_ENV\": \"stage2\", \"VUE_APP_TITLE\": \"stage mode2\", \"BASE_URL\": \"/vue/\", \"TYPE\": \"dev\", \"IP\": \"xxx\" } 4. 实际场景 结合以上环境变量的配置，我们项目中一般会遇到一些实际场景： 比如在非线上环境我们可以给自己的移动端项目开启 vConsole 调试，但是在线上环境肯定不需要开启这一功能，我们可以在入口文件中进行设置，代码如下： /* main.js */ import Vue from 'vue' import App from './App.vue' import router from './router' import store from './store' Vue.config.productionTip = false // 如果是非正式环境，加载 VConsole if (process.env.NODE_ENV !== 'production') { var VConsole = require('vconsole/dist/vconsole.min.js'); var vConsole = new VConsole(); } new Vue({ router, store, render: h => h(App) }).$mount('#app') vConsole 是一款用于移动网页的轻量级，可扩展的前端开发工具，可以看作是移动端浏览器的控制台，如图： 另外我们还可以使用配置中的 BASE_URL 来设置路由的 base 参数： /* router.js */ import Vue from 'vue' import Router from 'vue-router' import Home from './views/Home.vue' import About from './views/About.vue' Vue.use(Router) let base = `${process.env.BASE_URL}`; // 获取二级目录 export default new Router({ mode: 'history', base: base, // 设置 base 值 routes: [ { path: '/', name: 'home', component: Home }, { path: '/about', name: 'about', component: About } ] }) 每一个环境变量你都可以用于项目的一些地方，它提供给了我们一种全局的可访问形式，也是基于 Node 开发的特性所在。 结语 环境的配置和管理对于项目的构建起到了至关重要的作用，通过给项目配置不同的环境不仅可以增加开发的灵活性、提高程序的拓展性，同时也有助于帮助我们去了解并分析项目在不同环境下的运行机制，建立全局观念。 思考 & 作业 webpack 通过 DefinePlugin 内置插件将 process.env 注入到客户端代码中时，process.env.NODE_ENV 为什么要进行 JSON.stringify 处理？ process.env 中如何获取 package.json 中 name 的值？ 如何在 package.json 中的 scripts 字段中定义一些自定义脚本来切换不同的环境？ "},"Vue项目构建与开发入门/05.构建实战篇1：单页应用的基本配置.html":{"url":"Vue项目构建与开发入门/05.构建实战篇1：单页应用的基本配置.html","title":"05.构建实战篇1：单页应用的基本配置","keywords":"","body":"构建实战篇 1：单页应用的基本配置 前几篇文章我们介绍了 Vue 项目构建及运行的前期工作，包括 webpack 的配置、环境变量的使用等，在了解并掌握了这些前期准备工作后，那么接下来我们可以走进 Vue 项目的内部，一探其内部配置的基本构成。 配置 1. 路由配置 由于 Vue 这类型的框架都是以一个或多个单页构成，在单页内部跳转并不会重新渲染 HTML 文件，其路由可以由前端进行控制，因此我们需要在项目内部编写相应的路由文件，Vue 会解析这些文件中的配置并进行对应的跳转渲染。 我们来看一下 CLI 给我们生成的 router.js 文件的配置： /* router.js */ import Vue from 'vue' import Router from 'vue-router' import Home from './views/Home.vue' // 引入 Home 组件 import About from './views/About.vue' // 引入 About 组件 Vue.use(Router) // 注册路由 export default new Router({ routes: [{ path: '/', name: 'home', component: Home }, { path: '/about', name: 'about', component: About }] }) 这份配置可以算是最基础的路由配置，有以下几点需要进行优化： 如果路由存在二级目录，需要添加 base 属性，否则默认为 \"/\" 默认路由模式是 hash 模式，会携带 # 标记，与真实 url 不符，可以改为 history 模式 页面组件没有进行按需加载，可以使用 require.ensure() 来进行优化 下面是我们优化结束的代码： /* router.js */ import Vue from 'vue' import Router from 'vue-router' // 引入 Home 组件 const Home = resolve => { require.ensure(['./views/Home.vue'], () => { resolve(require('./views/Home.vue')) }) } // 引入 About 组件 const About = resolve => { require.ensure(['./views/About.vue'], () => { resolve(require('./views/About.vue')) }) } Vue.use(Router) let base = `${process.env.BASE_URL}` // 动态获取二级目录 export default new Router({ mode: 'history', base: base, routes: [{ path: '/', name: 'home', component: Home }, { path: '/about', name: 'about', component: About }] }) 改为 history 后我们 url 的路径就变成了 http://127.0.0.1:8080/vue/about，而不是原来的 http://127.0.0.1:8080/vue/#/about，但是需要注意页面渲染 404 的问题，具体可查阅：HTML5 History 模式。 而在异步加载的优化上，我们使用了 webpack 提供的 require.ensure() 进行了代码拆分，主要区别在于没有优化前，访问 Home 页面会一起加载 About 组件的资源，因为它们打包进了一个 app.js 中： 但是优化过后，它们分别被拆分成了 2.js 和 3.js： 如此，只有当用户点击了某页面，才会加载对应页面的 js 文件，实现了按需加载的功能。 webpack 在编译时，会静态地解析代码中的 require.ensure()，同时将模块添加到一个分开的 chunk 当中。这个新的 chunk 会被 webpack 通过 jsonp 来按需加载。 关于 require.ensure() 的知识点可以参考官方文档：require.ensure。 当然，除了使用 require.ensure 来拆分代码，Vue Router 官方文档还推荐使用动态 import 语法来进行代码分块，比如上述 require.ensure 代码可以修改为： // 引入 Home 组件 const Home = () => import('./views/Home.vue'); // 引入 About 组件 const About = () => import('./views/About.vue'); 其余代码可以保持不变，仍然可以实现同样的功能。如果你想给拆分出的文件命名，可以尝试一下 webpack 提供的 Magic Comments（魔法注释）： const Home = () => import(/* webpackChunkName:'home'*/ './views/Home.vue'); 2. Vuex 配置 除了 vue-router，如果你的项目需要用到 Vuex ，那么你应该对它有一定的了解，Vuex 是一个专为 Vue.js 应用程序开发的状态管理模式。这里我们先来看一下使用 CLI 生成的配置文件 store.js 中的内容： import Vue from 'vue' import Vuex from 'vuex' Vue.use(Vuex) export default new Vuex.Store({ state: { }, mutations: { }, actions: { } }) 该配置文件便是 Vuex 的配置文件，主要有 4 个核心点：state、mutations、actions 及 getter，详细的介绍大家可以参考官方文档：核心概念，这里我用一句话介绍它们之间的关系就是：我们可以通过 actions 异步提交 mutations 去 修改 state 的值并通过 getter 获取。 需要注意的是不是每一个项目都适合使用 Vuex，如果你的项目是中大型项目，那么使用 Vuex 来管理错综复杂的状态数据是很有帮助的，而为了后期的拓展性和可维护性，这里不建议使用 CLI 生成的一份配置文件来管理所有的状态操作，我们可以把它拆分为以下目录： └── store ├── index.js # 我们组装模块并导出 store 的地方 ├── actions.js # 根级别的 action ├── mutations.js # 根级别的 mutation └── modules ├── moduleA.js # A模块 └── moduleB.js # B模块 与单个 store.js 文件不同的是，我们按模块进行了划分，每个模块中都可以包含自己 4 个核心功能。比如模块 A 中： /* moduleA.js */ const moduleA = { state: { text: 'hello' }, mutations: { addText (state, txt) { // 这里的 `state` 对象是模块的局部状态 state.text += txt } }, actions: { setText ({ commit }) { commit('addText', ' world') } }, getters: { getText (state) { return state.text + '!' } } } export default moduleA 上方我们导出 A 模块，并在 index.js 中引入： /* index.js */ import Vue from 'vue' import Vuex from 'vuex' import moduleA from './modules/moduleA' import moduleB from './modules/moduleB' import { mutations } from './mutations' import actions from './actions' Vue.use(Vuex) export default new Vuex.Store({ state: { groups: [1] }, modules: { moduleA, // 引入 A 模块 moduleB, // 引入 B 模块 }, actions, // 根级别的 action mutations, // 根级别的 mutations // 根级别的 getters getters: { getGroups (state) { return state.groups } } }) 这样项目中状态的模块划分就更加清晰，对应模块的状态我们只需要修改相应模块文件即可。详细的案例代码可参考文末 github 地址。 3. 接口配置 在项目的开发过程中，我们也少不了与后台服务器进行数据的获取和交互，这一般都是通过接口完成的，那么我们如何进行合理的接口配置呢？我们可以在 src 目录下新建 services 文件夹用于存放接口文件： └── src └── services ├── http.js # 接口封装 ├── moduleA.js # A模块接口 └── moduleB.js # B模块接口 为了让接口便于管理，我们同样使用不同的文件来配置不同模块的接口，同时由于接口的调用 ajax 请求代码重复部分较多，我们可以对其进行简单的封装，比如在 http.js 中（fetch为例）： /* http.js */ import 'whatwg-fetch' // HTTP 工具类 export default class Http { static async request(method, url, data) { const param = { method: method, headers: { 'Content-Type': 'application/json' } }; if (method === 'GET') { url += this.formatQuery(data) } else { param['body'] = JSON.stringify(data) } // Tips.loading(); // 可调用 loading 组件 return fetch(url, param).then(response => this.isSuccess(response)) .then(response => { return response.json() }) } // 判断请求是否成功 static isSuccess(res) { if (res.status >= 200 && res.status 封装完毕后我们在 moduleA.js 中配置一个 github 的开放接口：https://api.github.com/repos/octokit/octokit.rb /* moduleA.js */ import Http from './http' // 获取测试数据 export const getTestData = () => { return Http.get('https://api.github.com/repos/octokit/octokit.rb') } 然后在项目页面中进行调用，会成功获取 github 返回的数据，但是一般我们在项目中配置接口的时候会直接省略项目 url 部分，比如： /* moduleA.js */ import Http from './http' // 获取测试数据 export const getTestData = () => { return Http.get('/repos/octokit/octokit.rb') } 这时候我们再次调用接口的时候会发现其调用地址为本地地址：http://127.0.0.1:8080/repos/octokit/octokit.rb，那么为了让其指向 https://api.github.com，我们需要在 vue.config.js 中进行 devServer 的配置： /* vue.config.js */ module.exports = { ... devServer: { // string | Object 代理设置 proxy: { // 接口是 '/repos' 开头的才用代理 '/repos': { target: 'https://api.github.com', // 目标地址 changeOrigin: true, // 是否改变源地址 // pathRewrite: {'^/api': ''} } }, } ... } 在 devServer 中 我们配置 proxy 进行接口的代理，将我们本地地址转换为真实的服务器地址，此时我们同样能顺利的获取到数据，不同点在于接口状态变成了 304（重定向）： 4. 公共设施配置 最后我们项目开发中肯定需要对一些公共的方法进行封装使用，这里我把它称之为公共设施，那么我们可以在 src 目录下建一个 common 文件夹来存放其配置文件： └── src └── common ├── index.js # 公共配置入口 ├── validate.js # 表单验证配置 └── other.js # 其他配置 在入口文件中我们可以向外暴露其他功能配置的模块，比如： /* index.js */ import Validate from './validate' import Other from './other' export { Validate, Other, } 这样我们在页面中只需要引入一个 index.js 即可。 结语 本文介绍了 Vue 单页应用的一些基本配置，从项目构建层面阐述了各文件的主要配置方式和注意点，由于本文并不是一篇文档类的配置说明，并不会详细介绍各配置文件的 API 功能，大家可以访问文中列出的官方文档进行查阅。 本案例代码地址：single-page-project 思考 & 作业 devServer 中 proxy 的 key 值代表什么？如果再添加一个 /reposed 的配置会产生什么隐患？ 如何配置 webpack 使得 require.ensure() 拆分出的 js 文件具有自定义文件名？ "},"Vue项目构建与开发入门/06.构建实战篇2：使用pages构建多页应用.html":{"url":"Vue项目构建与开发入门/06.构建实战篇2：使用pages构建多页应用.html","title":"06.构建实战篇2：使用pages构建多页应用","keywords":"","body":"构建实战篇 2：使用 pages 构建多页应用 经过对单页应用配置的了解，相信大家应该对如何构建一个 Vue 单页应用项目已经有所收获和体会，在大部分实际场景中，我们都可以构建单页应用来进行项目的开发和迭代，然而对于项目复杂度过高或者页面模块之间差异化较大的项目，我们可以选择构建多页应用来实现。那么什么是多页应用，如何构建一个多页应用便是本文所要阐述的内容。 概念 首先我们可以把多页应用理解为由多个单页构成的应用，而何谓多个单页呢？其实你可以把一个单页看成是一个 html 文件，那么多个单页便是多个 html 文件，多页应用便是由多个 html 组成的应用，如下图所示： 既然多页应用拥有多个 html，那么同样其应该拥有多个独立的入口文件、组件、路由、vuex 等。没错，说简单一点就是多页应用的每个单页都可以拥有单页应用 src 目录下的文件及功能，我们来看一下一个基础多页应用的目录结构： ├── node_modules # 项目依赖包目录 ├── build # 项目 webpack 功能目录 ├── config # 项目配置项文件夹 ├── src # 前端资源目录 │ ├── images # 图片目录 │ ├── components # 公共组件目录 │ ├── pages # 页面目录 │ │ ├── page1 # page1 目录 │ │ │ ├── components # page1 组件目录 │ │ │ ├── router # page1 路由目录 │ │ │ ├── views # page1 页面目录 │ │ │ ├── page1.html # page1 html 模板 │ │ │ ├── page1.vue # page1 vue 配置文件 │ │ │ └── page1.js # page1 入口文件 │ │ ├── page2 # page2 目录 │ │ └── index # index 目录 │ ├── common # 公共方法目录 │ └── store # 状态管理 store 目录 ├── .gitignore # git 忽略文件 ├── .env # 全局环境配置文件 ├── .env.dev # 开发环境配置文件 ├── .postcssrc.js # postcss 配置文件 ├── babel.config.js # babel 配置文件 ├── package.json # 包管理文件 ├── vue.config.js # CLI 配置文件 └── yarn.lock # yarn 依赖信息文件 根据上方目录结构我们可以看出其实 pages 下的一个目录就是一个单页包含的功能，这里我们包含了 3 个目录就构成了多页应用。 除了目录结构的不同外，其实区别单页应用，多页应用在很多配置上都需要进行修改，比如单入口变为多入口、单模板变为多模板等，那么下面我们就来了解一下多页应用的具体实现。 多入口 在单页应用中，我们的入口文件只有一个，CLI 默认配置的是 main.js，但是到了多页应用，我们的入口文件便包含了 page1.js、page2.js、index.js等，数量取决于 pages 文件夹下目录的个数，这时候为了项目的可拓展性，我们需要自动计算入口文件的数量并解析路径配置到 webpack 中的 entry 属性上，如： module.exports = { ... entry: { page1: '/xxx/pages/page1/page1.js', page2: '/xxx/pages/page2/page2.js', index: '/xxx/pages/index/index.js', }, ... } 那么我们如何读取并解析这样的路径呢，这里就需要使用工具和函数来解决了。我们可以在根目录新建 build 文件夹存放 utils.js 这样共用的 webpack 功能性文件，并加入多入口读取解析方法： /* utils.js */ const path = require('path'); // glob 是 webpack 安装时依赖的一个第三方模块，该模块允许你使用 * 等符号, // 例如 lib/*.js 就是获取 lib 文件夹下的所有 js 后缀名的文件 const glob = require('glob'); // 取得相应的页面路径，因为之前的配置，所以是 src 文件夹下的 pages 文件夹 const PAGE_PATH = path.resolve(__dirname, '../src/pages'); /* * 多入口配置 * 通过 glob 模块读取 pages 文件夹下的所有对应文件夹下的 js * 后缀文件，如果该文件存在 * 那么就作为入口处理 */ exports.getEntries = () => { let entryFiles = glob.sync(PAGE_PATH + '/*/*.js') // 同步读取所有入口文件 let map = {} // 遍历所有入口文件 entryFiles.forEach(filePath => { // 获取文件名 let filename = filePath.substring(filePath.lastIndexOf('\\/') + 1, filePath.lastIndexOf('.')) // 以键值对的形式存储 map[filename] = filePath }) return map } 上方我们使用了 glob 这一第三方模块读取所有 pages 文件夹下的入口文件，其需要进行安装：yarn add glob --dev 读取并存储完毕后，我们得到了一个入口文件的对象集合，这个对象我们便可以将其设置到 webpack 的 entry 属性上，这里我们需要修改 vue.config.js 的配置来间接修改 webpack 的值： /* vue.config.js */ const utils = require('./build/utils') module.exports = { ... configureWebpack: config => { config.entry = utils.getEntries() }, ... } 这样我们多入口的设置便完成了，当然这并不是 CLI 所希望的操作，后面我们会进行改进。 多模板 相对于多入口来说，多模板的配置也是大同小异，这里所说的模板便是每个 page 下的 html 模板文件，而模板文件的作用主要用于 webpack 中 html-webpack-plugin 插件的配置，其会根据模板文件生产一个编译后的 html 文件并自动加入携带 hash 的脚本和样式，基本配置如下： /* webpack 配置文件 */ const HtmlWebpackPlugin = require('html-webpack-plugin') // 安装并引用插件 module.exports = { ... plugins: [ new HtmlWebpackPlugin({ title: 'My Page', // 生成 html 中的 title filename: 'demo.html', // 生成 html 的文件名 template: 'xxx/xxx/demo.html', // 模板路径 chunks: ['manifest', 'vendor', 'demo'], // 所要包含的模块 inject: true, // 是否注入资源 }) ] ... } 以上是单模板的配置，那么如果是多模板只要继续往 plugins 数组中添加 HtmlWebpackPlugin 即可，但是为了和多入口一样能够灵活的获取 pages 目录下所有模板文件并进行配置，我们可以在 utils.js 中添加多模板的读取解析方法： /* utils.js */ // 多页面输出配置 // 与上面的多页面入口配置相同，读取 page 文件夹下的对应的 html 后缀文件，然后放入数组中 exports.htmlPlugin = configs => { let entryHtml = glob.sync(PAGE_PATH + '/*/*.html') let arr = [] entryHtml.forEach(filePath => { let filename = filePath.substring(filePath.lastIndexOf('\\/') + 1, filePath.lastIndexOf('.')) let conf = { template: filePath, // 模板路径 filename: filename + '.html', // 生成 html 的文件名 chunks: ['manifest', 'vendor', filename], inject: true, } // 如果有自定义配置可以进行 merge if (configs) { conf = merge(conf, configs) } // 针对生产环境配置 if (process.env.NODE_ENV === 'production') { conf = merge(conf, { minify: { removeComments: true, // 删除 html 中的注释代码 collapseWhitespace: true, // 删除 html 中的空白符 // removeAttributeQuotes: true // 删除 html 元素中属性的引号 }, chunksSortMode: 'manual' // 按 manual 的顺序引入 }) } arr.push(new HtmlWebpackPlugin(conf)) }) return arr } 以上我们仍然是使用 glob 读取所有模板文件，然后将其遍历并设置每个模板的 config，同时针对一些自定义配置和生产环境的配置进行了 merge 处理，其中自定义配置的功能我会在下节进行介绍，这里介绍一下生产环境下 minify 配置的作用：将 html-minifier 的选项作为对象来缩小输出。 html-minifier 是一款用于缩小 html 文件大小的工具，其有很多配置项功能，包括上述所列举的常用的删除注释、空白、引号等。 当我们编写完了多模板的方法后，我们同样可以在 vue.config.js 中进行配置，与多入口不同的是我们在 configureWebpack 中不能直接替换 plugins 的值，因为它还包含了其他插件，这时候大家还记得第 3 节中讲到的使用 return 返回一个对象来进行 merge 操作吗？ /* vue.config.js */ const utils = require('./build/utils') module.exports = { ... configureWebpack: config => { config.entry = utils.getEntries() // 直接覆盖 entry 配置 // 使用 return 一个对象会通过 webpack-merge 进行合并，plugins 不会置空 return { plugins: [...utils.htmlPlugin()] } }, ... } 如此我们多页应用的多入口和多模板的配置就完成了，这时候我们运行命令 yarn build 后你会发现 dist 目录下生成了 3 个 html 文件，分别是 index.html、page1.html 和 page2.html。 使用 pages 配置 其实，在 vue.config.js 中，我们还有一个配置没有使用，便是 pages。pages 对象允许我们为应用配置多个入口及模板，这就为我们的多页应用提供了开放的配置入口。官方示例代码如下： /* vue.config.js */ module.exports = { pages: { index: { // page 的入口 entry: 'src/index/main.js', // 模板来源 template: 'public/index.html', // 在 dist/index.html 的输出 filename: 'index.html', // 当使用 title 选项时， // template 中的 title 标签需要是 title: 'Index Page', // 在这个页面中包含的块，默认情况下会包含 // 提取出来的通用 chunk 和 vendor chunk。 chunks: ['chunk-vendors', 'chunk-common', 'index'] }, // 当使用只有入口的字符串格式时， // 模板会被推导为 `public/subpage.html` // 并且如果找不到的话，就回退到 `public/index.html`。 // 输出文件名会被推导为 `subpage.html`。 subpage: 'src/subpage/main.js' } } 我们不难发现，pages 对象中的 key 就是入口的别名，而其 value 对象其实是入口 entry 和模板属性的合并，这样我们上述介绍的获取多入口和多模板的方法就可以合并成一个函数来进行多页的处理，合并后的 setPages 方法如下： // pages 多入口配置 exports.setPages = configs => { let entryFiles = glob.sync(PAGE_PATH + '/*/*.js') let map = {} entryFiles.forEach(filePath => { let filename = filePath.substring(filePath.lastIndexOf('\\/') + 1, filePath.lastIndexOf('.')) let tmp = filePath.substring(0, filePath.lastIndexOf('\\/')) let conf = { // page 的入口 entry: filePath, // 模板来源 template: tmp + '.html', // 在 dist/index.html 的输出 filename: filename + '.html', // 页面模板需要加对应的js脚本，如果不加这行则每个页面都会引入所有的js脚本 chunks: ['manifest', 'vendor', filename], inject: true, }; if (configs) { conf = merge(conf, configs) } if (process.env.NODE_ENV === 'production') { conf = merge(conf, { minify: { removeComments: true, // 删除 html 中的注释代码 collapseWhitespace: true, // 删除 html 中的空白符 // removeAttributeQuotes: true // 删除 html 元素中属性的引号 }, chunksSortMode: 'manual'// 按 manual 的顺序引入 }) } map[filename] = conf }) return map } 上述代码我们 return 出的 map 对象就是 pages 所需要的配置项结构，我们只需在 vue.config.js 中引用即可： /* vue.config.js */ const utils = require('./build/utils') module.exports = { ... pages: utils.setPages(), ... } 这样我们多页应用基于 pages 配置的改进就大功告成了，当你运行打包命令来查看输出结果的时候，你会发现和之前的方式相比并没有什么变化，这就说明这两种方式都适用于多页的构建，但是这里还是推荐大家使用更便捷的 pages 配置。 结语 本文主要讲解了多页应用开发中多入口和多模板的实现方式，通过针对 webpack 配置的修改我们基本了解了多页模式与单页模式的差异性，下篇文章我们将以本文内容为基础进一步完善我们的多页应用配置，使其能够正常适应实际的开发与生产。 本案例代码地址：multi-page-project 思考 & 作业 多页应用相比单页应用有哪些优点和缺点？ chunksSortMode 除了文中介绍的 manual 手动排序外，还有哪些排序方式？ glob 中 * 和 ** 的区别是什么？ "},"Vue项目构建与开发入门/07.构建实战篇3：多页路由与模板解析.html":{"url":"Vue项目构建与开发入门/07.构建实战篇3：多页路由与模板解析.html","title":"07.构建实战篇3：多页路由与模板解析","keywords":"","body":"构建实战篇 3：多页路由与模板解析 上篇文章中我们成功打包并输出了多页文件，而构建一个多页应用能够让我们进一步了解项目配置的可拓展性，可以对学习 Vue 和 webpack 起到强化训练的效果，本文将在此基础上主要针对多页路由及模板的配置进行系列的介绍。 路由配置 1. 跳转 在配置路由前，首先我们要明确一点就是，多页应用中的每个单页都是相互隔离的，即如果你想从 page1 下的路由跳到 page2 下的路由，你无法使用 vue-router 中的方法进行跳转，需要使用原生方法：location.href 或 location.replace。 此外为了能够清晰的分辨路由属于哪个单页，我们应该给每个单页路由添加前缀，比如： index 单页：/vue/ page1 单页：/vue/page1/ page2 单页：/vue/page2/ 其中 /vue/ 为项目的二级目录，其后的目录代表路由属于哪个单页。因此我们每个单页的路由配置可以像这样： /* page1 单页路由配置 */ import Vue from 'vue' import Router from 'vue-router' // 首页 const Home = (resolve => { require.ensure(['../views/home.vue'], () => { resolve(require('../views/home.vue')) }) }) Vue.use(Router) let base = `${process.env.BASE_URL}` + 'page1'; // 添加单页前缀 export default new Router({ mode: 'history', base: base, routes: [ { path: '/', name: 'home', component: Home }, ] }) 我们通过设置路由的 base 值来为每个单页添加路由前缀，如果是 index 单页我们无需拼接路由前缀，直接跳转至二级目录即可。 那么在单页间跳转的地方，我们可以这样写： Index | Page1 | Page2 | export default { methods: { goFn(name) { location.href = `${process.env.BASE_URL}` + name } } } 但是为了保持和 Vue 路由跳转同样的风格，我可以对单页之间的跳转做一下封装，实现一个 Navigator 类，类的代码可以查看本文最后的示例，封装完成后我们可以将跳转方法修改为： this.$openRouter({ name: name, // 跳转地址 query: { text: 'hello' // 可以进行参数传递 }, }) 使用上述 $openRouter 方法我们还需要一个前提条件，便是将其绑定到 Vue 的原型链上，我们在所有单页的入口文件中添加： import { Navigator } from '../../common' // 引入 Navigator Vue.prototype.$openRouter = Navigator.openRouter; // 添加至 Vue 原型链 至此我们已经能够成功模仿 vue-router 进行单页间的跳转，但是需要注意的是因为其本质使用的是 location 跳转，所以必然会产生浏览器的刷新与重载。 2. 重定向 当我们完成上述路由跳转的功能后，可以在本地服务器上来进行一下测试，你会发现 Index 首页可以正常打开，但是跳转 Page1、Page2 却仍然处于 Index 父组件下，这是因为浏览器认为你所要跳转的页面还是在 Index 根路由下，同时又没有匹配到 Index 单页中对应的路由。这时候我们服务器需要做一次重定向，将下方路由指向对应的 html 文件即可： /vue/page1 -> /vue/page1.html /vue/page2 -> /vue/page2.html 在 vue.config.js 中，我们需要对 devServer 进行配置，添加 historyApiFallback 配置项，该配置项主要用于解决 HTML5 History API 产生的问题，比如其 rewrites 选项用于重写路由： /* vue.config.js */ let baseUrl = '/vue/'; module.exports = { ... devServer: { historyApiFallback: { rewrites: [ { from: new RegExp(baseUrl + 'page1'), to: baseUrl + 'page1.html' }, { from: new RegExp(baseUrl + 'page2'), to: baseUrl + 'page2.html' }, ] } } ... } 上方我们通过 rewrites 匹配正则表达式的方式将 /vue/page1 这样的路由替换为访问服务器下正确 html 文件的形式，如此不同单页间便可以进行正确跳转和访问了。最后需要注意的是如果你的应用发布到正式服务器上，你同样需要让服务器或者中间层作出合理解析，参考：HTML5 History 模式 # 后端配置例子 而更多关于 historyApiFallback 的信息可以访问：connect-history-api-fallback 模板配置 上篇文章我们已经介绍了关于多模板的读取和配置，在配置 html-webpack-plugin 的时候我们提到了自定义配置，这里我将结合模板渲染的功能来进行统一介绍。 1. 模板渲染 这里所说的模板渲染是在我们的 html 模板文件中使用 html-webpack-plugin 提供的 default template 语法进行模板编写，比如： 模板 \" rel=\"stylesheet\" /> \"> 以上我们使用模板语法手动获取并遍历 htmlWebpackPlugin 打包后的文件并生成到模板中，其中的 htmlWebpackPlugin 变量是模板提供的可访问变量，其有以下特定数据： \"htmlWebpackPlugin\": { \"files\": { \"css\": [ \"main.css\" ], \"js\": [ \"assets/head_bundle.js\", \"assets/main_bundle.js\"], \"chunks\": { \"head\": { \"entry\": \"assets/head_bundle.js\", \"css\": [ \"main.css\" ] }, \"main\": { \"entry\": \"assets/main_bundle.js\", \"css\": [] }, } } } 我们通过 htmlWebpackPlugin.files 可以获取打包输出的 js 及 css 文件路径，包括入口文件路径等。 需要注意的是如果你在模板中编写了插入对应 js 及 css 的语法，你需要设置 inject 的值为 false 来关闭资源的自动注入： /* utils.js */ ... let conf = { entry: filePath, // page 的入口 template: filePath, // 模板路径 filename: filename + '.html', // 生成 html 的文件名 chunks: ['manifest', 'vendor', filename], inject: false, // 关闭资源自动注入 } ... 否则在页面会引入两次资源，如下图所示： 2. 自定义配置 在模板渲染中，我们只能够使用 htmlWebpackPlugin 内部的一些属性和方法来进行模板的定制化开发，那么如果遇到需要根据不同环境来引入不同资源，同时不同模板间的配置还可能不一样的需求情况的话，我们使用自定义配置会比较方便。比如我们需要在生产环境模板中引入第三方统计脚本： /* vue.config.js */ module.exports = { ... pages: utils.setPages({ addScript() { if (process.env.NODE_ENV === 'production') { return ` ` } return '' } }), ... } 然后在页面模板中通过 htmlWebpackPlugin.options 获取自定义配置对象并进行输出： 同时你也可以针对个别模板进行配置，比如我想只在 Index 单页中添加统计脚本，在 Page1 单页中添加其他脚本，那么你可以给 addScript 传入标识符来进行判断输出，比如： 同时为 addScript 方法添加参数 from： addScript(from) { if (process.env.NODE_ENV === 'production') { let url = \"https://xxx\"; if (from === 'index') { url = \"https://s95.cnzz.com/z_stat.php?id=xxx&web_id=xxx\"; } return ` ` } return '' } 这样我们就完成了自定义配置中的模板渲染功能。当然根据实际项目需求你的自定义配置项可能会更加复杂和灵活。 结语 通过 2 小节的学习，相信大家对 Vue 多页应用的构建已经有所了解。本文在第 1 节的基础上重点介绍了多页路由及模板的配置，阐述了其与单页应用的不同之处，同时针对模板自定义配置的使用场景给出了简单的实例，希望大家在了解的基础上将下方的实例代码作为参考，进行相应的实战。 本案例代码地址：multi-page-project 思考 & 作业 多页应用中各自的 Vuex Store 信息能实现共享吗？ html-webpack-plugin 如何解析非 .html 的模板，比如 .hbs，应该如何配置？ "},"Vue项目构建与开发入门/08.构建实战篇4：项目整合与优化.html":{"url":"Vue项目构建与开发入门/08.构建实战篇4：项目整合与优化.html","title":"08.构建实战篇4：项目整合与优化","keywords":"","body":"构建实战篇 4：项目整合与优化 前几小节，我们讲述了 Vue 项目构建的整体流程，从无到有的实现了单页和多页应用的功能配置，但在实现的过程中不乏一些可以整合的功能点及可行性的优化方案，就像大楼造完需要进行最后的项目验收改进一样，有待我们进一步的去完善。 使用 alias 简化路径 使用 webpack 构建过 Vue 项目的同学应该知道 alias 的作用，我们可以使用它将复杂的文件路径定义成一个变量来访问。在不使用 alias 的项目中，我们引入文件的时候通常会去计算被引入文件对于引入它的文件的相对路径，比如像这样： import HelloWorld from '../../../../HelloWorld.vue' 一旦相对层次结构较深，我们就很难去定位所引入文件的具体位置，其实这并不是我们应该操心的地方，完全可以交给 webpack 来进行处理。在原生的 webpack 配置中我们可以定义 alias 来解决这一问题： const path = require('path') const resolve = dir => { return path.join(__dirname, dir) } module.exports = { ... resolve: { alias: { '@': resolve('src'), // 定义 src 目录变量 _lib: resolve('src/common'), // 定义 common 目录变量, _com: resolve('src/components'), // 定义 components 目录变量, _img: resolve('src/images'), // 定义 images 目录变量, _ser: resolve('src/services'), // 定义 services 目录变量, } }, ... } 上方我们在 webpack resolve（解析）对象下配置 alias 的值，将常用的一些路径赋值给了我们自定义的变量，这样我们便可以将第一个例子简化为： import HelloWorld from '_com/HelloWorld.vue' 而在 CLI 3.x 中我们无法直接操作 webpack 的配置文件，我们需要通过 chainWebpack 来进行间接修改，代码如下： /* vue.config.js */ module.exports = { ... chainWebpack: config => { config.resolve.alias .set('@', resolve('src')) .set('_lib', resolve('src/common')) .set('_com', resolve('src/components')) .set('_img', resolve('src/images')) .set('_ser', resolve('src/services')) }, ... } 这样我们修改 webpack alias 来简化路径的优化就实现了。但是需要注意的是对于在样式及 html 模板中引用路径的简写时，前面需要加上 ～ 符，否则路径解析会失败，如： .img { background: (~_img/home.png); } 整合功能模块 在多页应用的构建中，由于存在多个入口文件，因此会出现重复书写相同入口配置的情况，这样对于后期的修改和维护都不是特别友好，需要修改所有入口文件的相同配置，比如在 index 单页的入口中我们引用了 VConsole 及 performance 的配置，同时在 Vue 实例上还添加了 $openRouter 方法： import Vue from 'vue' import App from './index.vue' import router from './router' import store from '@/store/' import { Navigator } from '../../common' // 如果是非线上环境，不加载 VConsole if (process.env.NODE_ENV !== 'production') { var VConsole = require('vconsole/dist/vconsole.min.js'); var vConsole = new VConsole(); Vue.config.performance = true; } Vue.$openRouter = Vue.prototype.$openRouter = Navigator.openRouter; new Vue({ router, store, render: h => h(App) }).$mount('#app') 而在 page1 和 page2 的入口文件中也同样进行了上述配置，那我们该如何整合这些重复代码，使其能够实现一次修改多处生效的功能呢？最简单的方法便是封装成一个共用方法来进行调用，这里我们可以在 common 文件夹下新建 entryConfig 文件夹用于放置入口文件中公共配置的封装，封装代码如下： import { Navigator } from '../index' export default (Vue) => { // 如果是非线上环境，不加载 VConsole if (process.env.NODE_ENV !== 'production') { var VConsole = require('vconsole/dist/vconsole.min.js'); var vConsole = new VConsole(); Vue.config.performance = true; } Vue.$openRouter = Vue.prototype.$openRouter = Navigator.openRouter; } 上述代码我们向外暴露了一个函数，在调用它的入口文件中传入 Vue 实例作为参数即可实现内部功能的共用，我们可以将原本的入口文件简化为: import Vue from 'vue' import App from './index.vue' import router from './router' import store from '@/store/' import entryConfig from '_lib/entryConfig/' // 调用公共方法加载配置 entryConfig(Vue) new Vue({ router, store, render: h => h(App) }).$mount('#app') 这样我们便完成了入口文件配置的整合，当然你还可以给该函数传入 router 实例及自定义参数用于其他共用配置的封装。 开启 Gzip 压缩 在《webpack 在 CLI 3 中的应用》章节，我们介绍了 CLI 为我们内置的 webpack plugins，使用这些内置插件基本已经能够满足我们大多数项目的构建和优化，当然你仍然可以为项目添加自己想要的插件来实现一些差异化的功能，比如使用 compression-webpack-plugin 来开启 Gzip 压缩。在 vue.config.js 配置文件中，我们通过 configureWebpack 中返回一个对象来实现 plugins 的合并： /* vue.config.js */ const isPro = process.env.NODE_ENV === 'production' module.exports = { ... configureWebpack: config => { if (isPro) { return { plugins: [ new CompressionWebpackPlugin({ // 目标文件名称。[path] 被替换为原始文件的路径和 [query] 查询 asset: '[path].gz[query]', // 使用 gzip 压缩 algorithm: 'gzip', // 处理与此正则相匹配的所有文件 test: new RegExp( '\\\\.(js|css)$' ), // 只处理大于此大小的文件 threshold: 10240, // 最小压缩比达到 0.8 时才会被压缩 minRatio: 0.8， }) ] } } } ... } 上方我们通过在生产环境中增加 Gzip 压缩配置实现了打包后输出增加对应的 .gz 为后缀的文件，而由于我们配置项中配置的是只压缩大小超过 10240B（10kB）的 JS 及 CSS，因此不满足条件的文件不会进行 Gzip 压缩。 Gzip 压缩能在普通压缩的基础上再进行 50% 以上 的压缩，我们可以直接来看下控制台的输出对比图： 很明显，Gzip 压缩后的文件体积得到了很大程度的减小，这对于浏览器资源加载速度的提升起到了非常有效的帮助。但是需要注意的是访问 Gzip 压缩的文件需要服务端进行相应配置，以下是 Nginx Gzip 压缩的流程： Nginx 开启 Gzip 压缩配置后，其会根据配置情况对指定的类型文件进行压缩，主要针对 JS 与 CSS 。如果文件路径中存在与原文件同名（加了个 .gz），Nginx 会获取 gz 文件，如果找不到，会主动进行 Gzip 压缩。 结语 至此，一路走来，我们成功完成了本小册 Vue 项目构建部分的教程，从 CLI 3.x 的使用到项目内外部环境的配置，再到最后多页应用的拓展，我们循序渐进、由浅入深的讲解了 Vue 项目构建的主要知识点及详细流程，希望大家能够在此基础上举一反三，结合实际代码，将理论知识转化为实际运用，配合自己的理解，一步步实现自己的项目构建，并为构建出的项目添砖加瓦，实现质的飞跃。 思考 & 作业 除了本文中介绍的项目优化方法，还有哪些常见的优化手段？如何通过 Vue CLI 3 配置实现？ 总结并对比 Vue CLI 2.x，Vue CLI 3.x 在项目构建方面有哪些优势和不足？ "},"Vue项目构建与开发入门/09.开发指南篇1：从编码技巧与规范开始.html":{"url":"Vue项目构建与开发入门/09.开发指南篇1：从编码技巧与规范开始.html","title":"09.开发指南篇1：从编码技巧与规范开始","keywords":"","body":"开发指南篇 1：从编码技巧与规范开始 当我们完成项目的构建，进入开发阶段的时候，除了你需要了解框架本身的知识点外，我们还需要提前掌握一些项目的编码技巧与规范，在根源上解决之后因编码缺陷而导致的项目维护困难、性能下降等常见问题，为项目多人开发提供编码的一致性。 本文将罗列项目中常用的一些编码技巧与规范来帮助大家提升代码质量，并会结合代码片段加强大家的理解与认知。当然不是所有实例都是针对 Vue.js 开发的，有些同样也适用于其他前端项目。 实例 1. 使用对象代替 if 及 switch 在很多情况下，我们经常会遇到循环判断执行赋值操作的场景，一般我们都会使用 if 及 switch 的条件判断，如果符合则执行赋值，不符合则进入下个判断，比如： let name = 'lisi'; let age = 18; if (name === 'zhangsan') { age = 21; } else if (name === 'lisi') { age = 18; } else if (name === 'wangwu') { age = 12; } // 或者 switch(name) { case 'zhangsan': age = 21; break case 'lisi': age = 18; break case 'wangwu': age = 12; break } 这样的写法不仅冗余，而且代码执行效率不高，我们可以使用对象的形式简写： let name = 'lisi'; let obj = { zhangsan: 21, lisi: 18, wangwu: 12 }; let age = obj[name] || 18; 以上这种技巧适用于循环判断一次赋值的情况，如果判断过后有较多处理逻辑的还需要使用 if 或 switch 等方法。 2. 使用 Array.from 快速生成数组 一般我们生成一个有规律的数组会使用循环插入的方法，比如使用时间选择插件时，我们可能需要将小时数存放在数组中： let hours = []; for (let i = 0; i 如果使用 Array.from 我们可以简写为： let hours = Array.from({ length: 24 }, (value, index) => index + '时'); 3. 使用 router.beforeEach 来处理跳转前逻辑 在某些情况下，我们需要在路由跳转前处理一些特定的业务逻辑，比如修改路由跳转、设置 title 等，代码如下： import Vue from 'vue' import Router from 'vue-router' Vue.use(Router) // 首页 const Home = (resolve => { require.ensure(['../views/home.vue'], () => { resolve(require('../views/home.vue')) }) }) let base = `${process.env.BASE_URL}`; let router = new Router({ mode: 'history', base: base, routes: [ { path: '/', name: 'home', component: Home, meta: { title: '首页' } }, ] }) router.beforeEach((to, from, next) => { let title = to.meta && to.meta.title; if (title) { document.title = title; // 设置页面 title } if (to.name === 'home') { // 拦截并跳转至 page2 单页，$openRouter 方法在第 5 节中封装 Vue.$openRouter({ name: 'page2' }); } next(); }) export default router 注意最后需要调用 next() 方法执行路由跳转。 4. 使用 v-if 来优化页面加载 在 Vue 页面中，一些模块可能需要用户主动触发才会显示，比如弹框组件等这样的子组件，那么我们可以使用 v-if 来进行按需渲染，没必要一进页面就渲染所有模块。比如： import moduleB from 'components/moduleB' export default { data() { return { isShowModuleB: false } }, components: { moduleB } } 这样当 isShowModuleB 为 false 的时候便不会加载该模块下的代码，包括一些耗时的接口调用。当然 v-if 主要适用于代码量较多、用户点击不是很频繁的模块的显示隐藏，同时如果涉及到权限问题的代码都需要使用 v-if，而不是 v-show。 5. 路由跳转尽量使用 name 而不是 path 我们前期配置的路由路径后期难免会进行修改，如果我们页面跳转的地方全是使用的 path，那么我们需要修改所有涉及该 path 的页面，这样不利于项目的维护。而相对于 path，name 使用起来就方便多了，因为其具有唯一性，即使我们修改了 path，还可以使用原来的 name 值进行跳转。 this.$router.push({ name: 'page1' }); // 而不是 this.$router.push({ path: 'page1' }); 6. 使用 key 来优化 v-for 循环 v-for 是 Vue 提供的基于源数据多次渲染元素或模板块的指令。正因为是数据驱动，所以在修改列表数据的时候，Vue 内部会根据 key 值去判断某个值是否被修改，其会重新渲染修改后的值，否则复用之前的元素。 这里如果数据中存在唯一表示 id，则推荐使用 id 作为 key，如果没有则可以使用数组的下标 index 作为 key。因为如果在数组中间插入值，其之后的 index 会发生改变，即使数据没变 Vue 也会进行重新渲染，所以最好的办法是使用数组中不会变化且唯一的那一项作为 key 值。例如： {{ item.data }} export default { data() { return { arr: [ { id: 1, data: 'a' }, { id: 2, data: 'b' }, { id: 3, data: 'c' } ] } } } 7. 使用 computed 代替 watch 很多时候页面会出现 watch 的滥用而导致一系列问题的产生，而通常更好的办法是使用 computed 属性，首先需要区别它们有什么区别： watch：当监测的属性变化时会自动执行对应的回调函数 computed：计算的属性只有在它的相关依赖发生改变时才会重新求值 其实它们在功能上还是有所区别的，但是有时候可以实现同样的效果，而 computed 会更胜一筹，比如： {{ fullName }} {{ fullName2 }} export default { data() { reurn { firstName: '', lastName: '', fullName2: '' } }, // 使用 computed computed: { fullName() { return this.firstName + ' ' + this.lastName } }, // 使用 watch watch: { firstName: function(newVal, oldVal) { this.fullName2 = newVal + ' ' + this.lastName; }, lastName: function(newVal, oldVal) { this.fullName2 = this.firstName + ' ' + newVal; }, } } 上方我们通过对比可以看到，在处理多数据联动的情况下，使用 computed 会更加合理一点。 computed 监测的是依赖值，依赖值不变的情况下其会直接读取缓存进行复用，变化的情况下才会重新计算；而 watch 监测的是属性值， 只要属性值发生变化，其都会触发执行回调函数来执行一系列操作。 8. 统一管理缓存变量 在项目中或多或少会使用浏览器缓存，比如 sessionStorage 和 localStorage，当一个项目中存在很多这样的缓存存取情况的时候就会变得难以维护和管理，因为其就像全局变量一样散落在项目的各个地方，这时候我们应该将这些变量统一管理起来，放到一个或多个文件中去，比如： /* types.js */ export const USER_NAME = 'userName'; export const TOKEN = 'token'; 在需要存取的时候，直接引用： import { USER_NAME, TOKEN } from '../types.js' sessionStorage[USER_NAME] = '张三'; localStorage[TOKEN] = 'xxx'; 使用这种方法的好处在于一旦我们需要修改变量名，直接修改管理文件中的值即可，无需修改使用它的页面，同时这也可以避免命名冲突等问题的出现，这类似于 vuex 中 mutations 变量的管理。 9. 使用 setTimeout 代替 setInterval 一般情况下我们在项目里不建议使用 setInterval，因为其会存在代码的执行间隔比预期小以及 “丢帧” 的现象，原因在于其本身的实现逻辑。很多人会认为 setInterval 中第二个时间参数的作用是经过该毫秒数执行回调方法，其实不然，其真正的作用是经过该毫秒数将回调方法放置到队列中去，但是如果队列中存在正在执行的方法，其会等待之前的方法完毕再执行，如果存在还未执行的代码实例，其不会插入到队列中去，也就产生了 “丢帧”。 而 setTimeout 并不会出现这样的现象，因为每一次调用都会产生了一个新定时器，同时在前一个定时器代码执行完之前，不会向队列插入新的定时器代码。 // 该定时器实际会在 3s 后立即触发下一次回调 setInterval(() => { // 执行完这里的代码需要 2s }, 1000); // 使用 setTimeout 改写，4秒后触发下一次回调 let doSometing = () => { // 执行完这里的代码需要 2s setTimeout(doSometing, 1000); } doSometing(); 延伸阅读：对于“不用setInterval，用setTimeout”的理解 10. 不要使用 for in 循环来遍历数组 大家应该都知道 for in 循环是用于遍历对象的，但它可以用来遍历数组吗？答案是可以的，因为数组在某种意义上也是对象，但是如果用其遍历数组会存在一些隐患：其会遍历数组原型链上的属性。 let arr = [1, 2]; for (let key in arr) { console.log(arr[key]); // 会正常打印 1, 2 } // 但是如果在 Array 原型链上添加一个方法 Array.prototype.test = function() {}; for (let key in arr) { console.log(arr[key]); // 此时会打印 1, 2, ƒ () {} } 因为我们不能保证项目代码中不会对数组原型链进行操作，也不能保证引入的第三方库不对其进行操作，所以不要使用 for in 循环来遍历数组。 结语 本文罗列了 10 个项目开发中常见的编码技巧与规范，其实技巧和规范之间本身就是相辅相成的，所以没有分别进行罗列。当然实际的项目开发中存在着很多这样的例子需要大家自己去归纳和整理，比如使用 name 来命名你的组件等。如果你有不错的点子，也可以分享在下方的评论区域中供大家学习。 拓展阅读：前端各类规范集合 思考 & 作业 可以使用哪些技巧来实现数组的循环遍历、去重等？ 在 Vue 项目中如何使用 ESLint 来规范 JS 代码的编写？ .vue 单文件组件中如何进行代码的格式化？ "},"Vue项目构建与开发入门/10.开发指南篇2：学会编写可复用性模块.html":{"url":"Vue项目构建与开发入门/10.开发指南篇2：学会编写可复用性模块.html","title":"10.开发指南篇2：学会编写可复用性模块","keywords":"","body":"开发指南篇 2：学会编写可复用性模块 在生活中，重复的机械劳动会消耗我们的时间和精力，提高生产成本，降低工作效率。同样，在代码世界中，编写重复的代码会导致代码的冗余，页面性能的下降以及后期维护成本的增加。由此可见将重复的事情复用起来是提高生产效率、降低维护成本的不二之选。 在 Vue 项目中，每一个页面都可以看作是由大大小小的模块构成的，即便是一行代码、一个函数、一个组件都可以看作是一个个自由的模块。那么提高代码的复用性的关键便在于编写可复用的模块，也就是编写可复用的代码、函数和组件等。 一个简单的例子 let person = []; for (let i = 0; i 不知道上方代码给你的第一印象是什么？总之给我的印象是糟糕的，因为出现了重复性的代码片段 data.obj.items，可能这样的代码在我们团队开发中随处可见，这也说明了重复编码现象其实无处不在。 面对自己编写的代码，我们应该保持一颗去重的心，发现重复的地方就相当于找到了可以复用的模块。在不复用的情况下，上述代码一旦需要修改变量 items 为 lists，那么我们就得修改 3 处地方，不知不觉就增加了维护成本。而到时候往往修改你代码的人并不是你自己，所以对自己好点，对他人也会好点。复用后的代码如下： let person = []; let values = data.obj.items; for (let i = 0; i 我们通过将 data.obj.items 的值赋值给变量 values 来实现了复用，此时修改 items 为 lists 的话我们只需修改一处地方即可，不管是维护成本还是代码可读性上，复用的优势都显而易见。 封装成一个函数 除了使用变量的赋值缓存使用来解决数据的重复读取外，我们在开发过程中重复性更多的也许是功能点的重复，比如： {{ str1.slice(1).toUpperCase() }} {{ str2.slice(1).toUpperCase() }} 上述代码的重复功能点在于截取输入框中第二个字符开始到最后的值并把它们转化成大写字母，像这样很简单的操作虽然重复使用也不会出现太大的问题，但是如果是代码量较多的操作呢？重复书写相同功能的代码是一种不经过大脑思考的行为，我们需要对其进行优化，这里我们可以把功能点封装成一个函数： export default { methods: { sliceUpperCase(val) { return val.slice(1).toUpperCase() } } } 如此我们只要在用到该方法的地方调用即可，将值传入其中并返回新值。当然像在双花括号插值和 v-bind 表达式中重复的功能点我们可以封装成过滤器比较合适： // 单文件组件注册过滤器 filters: { sliceUpperCase(val) { return val.slice(1).toUpperCase() } } // 全局注册过滤器 Vue.filter('sliceUpperCase', function (val) { return val.slice(1).toUpperCase() }) 然后在 html 中使用“管道”符进行过滤： {{ str1 | sliceUpperCase }} {{ str2 | sliceUpperCase }} 这样我们就把重复的功能性代码封装成了函数，而不管是过滤器还是正常的方法封装，其本质都是函数的封装。 封装成一个组件 相比较于函数的封装，规模更大一点的便是组件的封装，组件包含了模板、脚本以及样式的代码，在实际开发中组件的使用频率也是非常大的，我们项目中的每一个页面其实都可以看作是一个父组件，其可以包含很多子组件，子组件通过接收父组件的值来渲染页面，父组件通过响应子组件的回调来触发事件。 封装一个组件主要包含两种方式，一种是最常见的整体封装，用户通过改变数据源来呈现不同的页面状态，代码结构不可定制化。例如： 另一种便是自定义封装，也就是插槽(slot)，我们可以开放一部分槽位给父组件，使其能够进行一定程度的定制化，例如： 这是定制化的数据 在 myComponent 组件中我们便可以接收对应的 slot： {{ data }} 这里我们通过定义 slot 标签的 name 值为 customize 来接收父组件在使用该组件时在 template 标签上定义的 slot=\"customize\" 中的代码，不同父组件可以定制不同的 slot 代码来实现差异化的插槽。最终渲染出来的代码如下： 我是父组件传入子组件的数据 这是定制化的数据 这样我们就完成了一个小型组件的封装，将共用代码封装到组件中去，页面需要引入的时候直接使用 import 并进行相应注册即可，当然你也可以进行全局的引入： import myComponent from '../myComponent.vue' // 全局 Vue.component('my-component', myComponent) 封装成一个插件 在某些情况下，我们封装的内容可能不需要使用者对其内部代码结构进行了解，其只需要熟悉我们提供出来的相应方法和 api 即可，这需要我们更系统性的将公用部分逻辑封装成插件，来为项目添加全局功能，比如常见的 loading 功能、弹框功能等。 Vue 提供给了我们一个 install 方法来编写插件，使用该方法中的第一个 Vue 构造器参数可以为项目添加全局方法、资源、选项等。比如我们可以给组件添加一个简单的全局调用方法来实现插件的编写： /* toast.js */ import ToastComponent from './toast.vue' // 引入组件 let $vm export default { install(Vue, options) { // 判断实例是否存在 if (!$vm) { const ToastPlugin = Vue.extend(ToastComponent); // 创建一个“扩展实例构造器” // 创建 $vm 实例 $vm = new ToastPlugin({ el: document.createElement('div') // 声明挂载元素 }); document.body.appendChild($vm.$el); // 把 toast 组件的 DOM 添加到 body 里 } // 给 toast 设置自定义文案和时间 let toast = (text, duration) => { $vm.text = text; $vm.duration = duration; // 在指定 duration 之后让 toast 消失 setTimeout(() => { $vm.isShow = false; }, $vm.duration); } // 判断 Vue.$toast 是否存在 if (!Vue.$toast) { Vue.$toast = toast; } Vue.prototype.$toast = Vue.$toast; // 全局添加 $toast 事件 } } 成功编写完插件的 JS 脚本后，我们在入口文件中需要通过 Vue.use() 来注册一下该插件： import Toast from '@/widgets/toast/toast.js' Vue.use(Toast); // 注册 Toast 最后我们在需要调用它的地方直接传入配置项使用即可，比如： this.$toast('Hello World', 2000); 当然你也可以不使用 install 方法来编写插件，直接采用导出一个封装好的实例方法并将其挂载到 Vue 的原型链上来实现相同的功能。 更详细的编写插件和实例的方法可以参考我之前写的一篇文章：Vue 插件编写与实战 结语 本文讲解了编写可复用性模块的常见方法，通过出现了重复代码 -> 封装成一个变量 -> 封装成一个函数 -> 封装成一个组件 -> 封装成一个插件，一步步将重复代码进行分析和复用。而与重复代码做斗争是一个持久性的过程，我们需要时刻保持一种“强迫症”的心态去整理复用项目中的重复代码，做好编码的严谨和自律。 思考 & 作业 在 Vue 中如何添加全局自定义指令？ 在 vue 路由切换时如何全局隐藏某个插件？比如文中的 toast 如何实现一个表单验证插件？需要运用到哪些知识？ "},"Vue项目构建与开发入门/11.开发指南篇3：合理划分容器组件与展示组件.html":{"url":"Vue项目构建与开发入门/11.开发指南篇3：合理划分容器组件与展示组件.html","title":"11.开发指南篇3：合理划分容器组件与展示组件","keywords":"","body":"开发指南篇 3：合理划分容器组件与展示组件 上篇文章我们提到了组件的概念，组件是目前模块化、组件化开发模式中必不可少的单元形式，那么除了其概念和可复用性外，我们对它的职能划分了解多少呢？ 本文将立足 Vue 组件的职能来谈谈我个人对于其划分的理解，唯有了解不同类型组件的职能才能编写出可维护、低耦合的前端代码。 组件的职能划分 如果要将 Vue 组件按照职能划分，我们可以将其分为两种类型：容器组件和展示组件。 容器组件和展示组件的概念来自于 Redux 文档，那么首先什么是容器组件呢？顾名思义，它是一个容器性质的组件，我们可以把它理解为最外层的父组件，也就是最顶层的组件，一般我们把它放置在 views 文件夹下，其功能主要用于做数据提取与实现公共逻辑，然后渲染对应的子组件。 另一类组件叫做展示组件，字面意思就是主要用于做展示的组件，其主要功能是负责接收从容器组件传输过来的数据并在页面上渲染，实现其内部独有的功能逻辑。 一个页面中容器组件与展示组件的关系如下图所示： 上图我们以博客首页为例，容器组件就是整个首页最外层的父组件，而展示组件就包含了导航栏、文章列表、底部等子组件，代码层面如下： import { mapActions, mapGetters } from 'vuex'; export default { mounted() { this.SET_BLOG_DATA(); // 调用接口获取数据 }, computed: { ...mapGetters(['articleList']), // 监听 state } methods: { ...mapActions(['SET_BLOG_DATA', 'SET_NAV_COUNT']), countFn(item) { // 调用接口存储导航点击次数并跳转，通过派发 action 的形式来发起 state 变化 this.SET_NAV_COUNT({ type: item.type }); this.$router.push({name: item.route}); } } } 以上是首页容器组件中的主要代码，其主要做了两件事情：数据的传递和回调的处理，当然还可以包括处理一些该页面中不属于任何一个展示组件的方法，比如校验登录状态。在一个容器组件中可以包含多个展示组件，下面我们来看一下展示组件 Navigation 中的代码： export default { data() { return { nav: [{ name: '首页', route: 'index', type: 'index' }, { name: '文章', route: 'article', type: 'article' }, { name: '关于', route: 'about', type: 'about' }] } }, methods: { goNav(item) { this.$emit('count', item); // 触发回调 } } } Navigation 导航组件只负责自己内部的数据渲染和回调逻辑，对于存储每个导航的点击量及跳转逻辑来说，作为展示组件这并不是其所关心的，所以我们需要通过触发容器组件回调的方式来实现。再来看一下展示组件 Article 的代码： export default { props: { // 接收容器组件数据 list: { default: [], type: Array } } } 展示组件 Article 中动态的数据通过 props 从父组件中获取，其内部只处理文章列表的渲染工作，这样很好的将 UI 层面和应用层面进行了分离，便于今后该组件的复用。 此外 Foot 组件为纯静态组件，其只负责内部数据的渲染，不接收外部的数据和回调方法，这里就不做介绍了。 从以上代码示例中我们不难发现容器组件和展示组件的主要区别和注意点： 展示组件 容器组件 作用 描述如何展现（骨架、样式） 描述如何运行（数据获取、状态更新） 是否使用 Vuex 否 是 数据来源 props 监听 Vuex state 数据修改 从 props 调用回调函数 向 Vuex 派发 actions 相比较如果上述的博客首页不做组件的划分，全部逻辑都放在一个组件中，那么必然会导致代码的臃肿和难以维护，而一旦划分了容器组件和展示组件，后期如果哪个页面同样需要展示文章列表，我们只需要传递不同的数据直接复用即可。 组件的层次结构 了解了组件职能的划分后，我们再来看一下组件的层次结构。关于组件的层次，一般页面中不宜嵌套超过 3 层的组件，因为超过 3 层后父子组件的通信就会变得相对困难，不利于项目的开发和维护。3 层结构的容器组件与展示组件的数据传递如下： 可见组件的层次越深数据传递的过程就会变得越复杂，当然这取决于你如何划分容器组件和展示组件，比如我们可以将上述博客首页换一种划分方式： 上图我们页面中存在 3 个容器组件，每个容器组件又可以包含各自的展示组件，这样一定程度上可以减少组件的层次嵌套深度。当然展示组件中也可以包含对应的容器组件来解决数据传输的问题： 这样展示组件 B 下面的容器组件 C 便可以不依赖于容器组件 A 的数据，其可以单独的进行数据获取和状态更新。 而对于那些你不知道应该划分为容器组件和展示组件的组件，比如一些耦合度较高的组件，那么你可以暂时归类到其他组件中，混用容器和展示，随着日后功能的逐渐清晰，我们再将其进行划分。 结语 本文主要介绍了容器组件和展示组件的概念和层次划分，在编码上，容器组件和展示组件各司其职，它们将容器和展示更好的分离，提高了组件的重用度，降低了功能上的耦合度，为高效、高质量的代码开发奠定了基础。 思考 & 作业 如果你了解 React，那么试想一下在 React 中展示组件与容器组件有哪些异同点？ 如果需要你对掘金首页进行组件的划分，你会如何划分其结构和层次？ 在子组件的 props 中，如何动态的设置默认值？ "},"Vue项目构建与开发入门/12.开发指南篇4：数据驱动与拼图游戏.html":{"url":"Vue项目构建与开发入门/12.开发指南篇4：数据驱动与拼图游戏.html","title":"12.开发指南篇4：数据驱动与拼图游戏","keywords":"","body":"开发指南篇 4：数据驱动与拼图游戏 数据驱动是 Vue 框架的核心特性之一，也是 Vue 响应式原理的具体体现，相信大家对其应该深有体会，尤其是在操作数据来触发页面更新的时候。 为了让大家更加了解数据驱动的理念，并解决使用过程中可能出现的一系列问题，本文将结合比较常见和简单的 “拼图游戏” 来展示 Vue 数据驱动的魅力所在。 效果展示 首先我们先来看一下实现的 “拼图游戏” 的动态效果： 在不操作 DOM 的情况下实现以上功能其实需要我们对 Vue 数据驱动及数据可视化有一个非常清楚的认知，在操作数据的同时驱动可视化界面的还原。 关键代码 接下来我们来看一下实现该拼图游戏的功能点及关键代码： 游戏面板的构建 // 数据部分 export default { data() { return { puzzles: Array.from({ length: 15 }, (value, index) => index + 1) } }, } 上方我们使用 v-for 循环构建了从 1 ～ 15 按顺序排列的方块格子，也就是拼图完成时候的顺序，但是拼图游戏一开始数字的顺序应该是无序的，也是随机打乱的，那么我们怎么实现呢？可以使用下方的随机排列函数： function shuffle(arr) { let len = arr.length for (let i = 0; i 该函数中我们使用 Math.random() 来返回 0 和 1 之间的伪随机数，可能为 0，但总是小于1，[0, 1)，而通过这一特性我们可以实现生成 n-m，包含 n 但不包含 m 的整数，具体步骤如下： 第一步算出 m-n 的值，假设等于 w 第二步 Math.random() * w 第三步 Math.random() * w + n 第四步 Math.floor(Math.random() * w + n) 在 shuffle 函数中 n 值永远是 0，而 w（即 len - i） 值随着循环 i 值的变大而不断减小。 在上面的算法里，我们每一次循环从前 len - i 个元素里随机一个位置，将这个元素和第 len - i 个元素进行交换，迭代直到 i = len - 1 为止。 这一便实现了数组的随机打乱。最后我们需要在数组末尾追加一个空值来显示唯一一个空白格子： this.puzzles.push(''); 交换方块位置 实现随机数字后，当我们点击方块，如果其上下左右存在为空的格子就需要将其进行交换，而由于是数据驱动界面，这里我们便需要交换两者在数组中的位置来实现： export default { methods: { // 点击方块 moveFn(index) { let puzzles = this.puzzles // 获取点击位置上下左右的值 let leftNum = this.puzzles[index - 1], rightNum = this.puzzles[index + 1], topNum = this.puzzles[index - 4], bottomNum = this.puzzles[index + 4] // 和为空的位置交换数值 if (leftNum === '' && index % 4) { this.setPuzzle(index, -1) } else if (rightNum === '' && 3 !== index % 4) { this.setPuzzle(index, 1) } else if (topNum === '') { this.setPuzzle(index, -4) } else if (bottomNum === '') { this.setPuzzle(index, 4) } }, // 设置数组值 setPuzzle(index, num) { let curNum = this.puzzles[index] this.$set(this.puzzles, index + num, curNum) this.$set(this.puzzles, index, '') }, } } 由于是 16 宫格的拼图，所以我们在点击获取位置的时候需要考虑边界情况，比如第 4 个格子为空，我们点击第 5 个格子不应该交换它们，因为在界面上第 4 个格子不在第 5 个格子的左侧，所以我们使用 index % 4 的方法来进行边界的判断，同时使用 Vue 提供的 $set 方法来将响应属性添加到数组上。 校验是否过关 最后我们需要校验游戏是否过关，我们只需要在最后一个格子为空时去进行校验即可： if (this.puzzles[15] === '') { const newPuzzles = this.puzzles.slice(0, 15) const isPass = newPuzzles.every((e, i) => e === i + 1) if (isPass) { alert ('恭喜，闯关成功！') } } 我们使用数组的 every 方法来简化代码的复杂度，当所有数字大小和对应的数组下标 + 1 相吻合时即会返回 true。 如此我们便完成了一个简单拼图游戏的功能。 盲点及误区 在实现拼图游戏后，有些同学可能会存在一些疑惑，比如：数组赋值为什么要用 $set 方法？数组随机打乱为什么不用 sort 排序呢？下面便来进行讲解： 为什么要用 $set 方法 大家应该都知道如果不用 $set 方法我们可以直接通过操作数组索引的形式对数组进行赋值，从而交换拼图的中两者的数据： // 设置数组值 setPuzzle(index, num) { let curNum = this.puzzles[index] this.puzzles[index + num] = curNum this.puzzles[index] = '' // this.$set(this.puzzles, index + num, curNum) // this.$set(this.puzzles, index, '') } 但是你会发现这样做数据是改变了，但是页面并没有因此重新渲染，这是为什么呢？其实 Vue 官方已经给出了明确的答案： 由于 JavaScript 的限制，Vue 不能检测以下变动的数组： 当你利用索引直接设置一个项时，例如：vm.items[indexOfItem] = newValue 当你修改数组的长度时，例如：vm.items.length = newLength 我们这里使用的便是第一种利用索引的方式，由于 Vue 检测不到数组变动，因此页面便无法重绘。同样 Vue 也不能检测对象属性的添加或删除，需要使用 Vue.set(object, key, value) 方法来实现。 其实还有一种比较取巧的方式便是强制重新渲染 Vue 实例来解决这一问题： // 设置数组值 setPuzzle(index, num) { let curNum = this.puzzles[index] this.puzzles[index + num] = curNum this.puzzles[index] = '' this.$forceUpdate() // 迫使 Vue 实例重新渲染 // this.$set(this.puzzles, index + num, curNum) // this.$set(this.puzzles, index, '') } 上方我们使用了 Vue 提供的 $forceUpdate 方法迫使 Vue 实例重新渲染，这样改变的数据就会被更新的页面中去。但是最好不要这样操作，因为这会导致 Vue 重新遍历此对象所有的属性，一定程度上会影响页面的性能。 为什么不用 sort 排序 其实 sort 方法也能够实现数组的随机排序，代码如下： let puzzleArr = Array.from({ length: 15 }, (value, index) => index + 1); // 随机打乱数组 puzzleArr = puzzleArr.sort(() => { return Math.random() - 0.5 }); 我们通过使用 Math.random() 的随机数减去 0.5 来返回一个大于、等于或小于 0 的数，sort 方法会根据接收到的值来对相互比较的数据进行升序或是降序排列。 但是由于 JavaScript 内置排序算法的缺陷性，使用 sort 排序的结果并不随机分布，经过大量的测试你会发现越大的数字出现在越后面的概率越大。 由于本文并非是一篇介绍 sort 排序的文章，关于论证其缺陷性的话题这里就不进行详细展开了，感兴趣的同学可以进一步进行探究。 结语 本文实例是基于我之前写的一篇关于利用 Vue.js 实现拼图游戏的文章上进行了改进和优化，希望通过这样一个小游戏来强化大家对于 Vue 数据驱动的理解。相比操作 DOM 元素，操作数据其实更加的便捷和快速，可以使用较少的代码来实现一些较为复杂的逻辑。 具体实例代码可以参考：puzzle 思考 & 作业 Vue 中监听数据变化的原理是什么？是通过何种方式实现的？ 如何论证原生 JS 中 sort 排序后越大的数字出现在越后面的概率越大？ 如何使用 Math.random() 生成 n-m，不包含 n 但包含 m 的整数？ "},"Vue项目构建与开发入门/13.开发指南篇5：Vue_API盲点解析.html":{"url":"Vue项目构建与开发入门/13.开发指南篇5：Vue_API盲点解析.html","title":"13.开发指南篇5：Vue_API盲点解析","keywords":"","body":"开发指南篇 5：Vue API 盲点解析 在了解了一些实用的开发技巧和编码理念后，我们在项目的开发过程中难免也会遇到因为不熟悉 Vue API 而导致的技术问题，而往往就是这样的一些问题消耗了我们大量的开发时间，造成代码可读性下降、功能紊乱甚至 bug 量的增加，其根本原因还是自己对 Vue API 的 “无知”。 本文将介绍 Vue 项目开发中比较难以理解并可能被你忽视的 API，唯有知己知彼，才能百战不殆。 API 解析 使用 performance 开启性能追踪 performance API 是 Vue 全局配置 API 中的一个，我们可以使用它来进行网页性能的追踪，我们可以在入口文件中添加： if (process.env.NODE_ENV !== 'production') { Vue.config.performance = true; } 来开启这一功能，该 API（2.2.0 新增）功能只适用于开发模式和支持 performance.mark API 的浏览器上，开启后我们可以下载 Vue Performance Devtool 这一 chrome 插件来看查看各个组件的加载情况，如图： 从中我们可以清晰的看到页面组件在每个阶段的耗时情况，而针对耗时比较久的组件，我们便可以对其进行相应优化。 而其在 Vue 源码中主要使用了 window.performance 来获取网页性能数据，其中包含了 performance.mark 和 performance.measure。 performance.mark 主要用于创建标记 performance.measure 主要用于记录两个标记的时间间隔 例如： performance.mark('start'); // 创建 start 标记 performance.mark('end'); // 创建 end 标记 performance.measure('output', 'start', 'end'); // 计算两者时间间隔 performance.getEntriesByName('output'); // 获取标记，返回值是一个数组，包含了间隔时间数据 熟练的使用 performance 我们可以查看并分析网页的很多数据，为我们项目优化提供保障。除了上述介绍的两个方法，我们还可以使用 performance.timing 来计算页面各个阶段的加载情况，关于 performance.timing 的介绍可以查看我之前写的一篇文章：利用 Navigation Timing 测量页面加载时间 使用 errorHandler 来捕获异常 在浏览器异常捕获的方法上，我们熟知的一般有：try ... catch 和 window.onerror，这也是原生 JavaScript 提供给我们处理异常的方式。但是在 Vue 2.x 中如果你一如既往的想使用 window.onerror 来捕获异常，那么其实你是捕获不到的，因为异常信息被框架自身的异常机制捕获了，你可以使用 errorHandler 来进行异常信息的获取： Vue.config.errorHandler = function (err, vm, info) { let { message, // 异常信息 name, // 异常名称 stack // 异常堆栈信息 } = err; // vm 为抛出异常的 Vue 实例 // info 为 Vue 特定的错误信息，比如错误所在的生命周期钩子 } 在入口文件中加入上述代码后，我们便可以捕获到 Vue 项目中的一些异常信息了，但是需要注意的是 Vue 2.4.0 起的版本才支持捕获 Vue 自定义事件处理函数内部的错误，比如: export default { methods: { doSomething() { console.log(a); // a is not defined } } } 使用 Vue 中的异常捕获机制，我们可以针对捕获到的数据进行分析和上报，为实现前端异常监控奠定基础。关于对异常捕获的详细介绍，感兴趣的同学可以查看我的这篇文章：谈谈前端异常捕获与上报 使用 nextTick 将回调延迟到下次 DOM 更新循环之后执行 在某些情况下，我们改变页面中绑定的数据后需要对新视图进行一些操作，而这时候新视图其实还未生成，需要等待 DOM 的更新后才能获取的到，在这种场景下我们便可以使用 nextTick 来延迟回调的执行。比如未使用 nextTick 时的代码： export default { data() { return { arr: [] } }, mounted() { this.getData(); }, methods: { getData() { this.arr = [1, 2, 3]; this.$refs.box.getElementsByTagName('li')[0].innerHTML = 'hello'; } } } 上方代码我们在实际运行的时候肯定会报错，因为我们获取 DOM 元素 li 的时候其还未被渲染，我们将方法放入 nextTick 回调中即可解决该问题： this.$nextTick(() => { this.$refs.box.getElementsByTagName('li')[0].innerHTML = 'hello'; }) 当然你也可以使用 ES6 的 async/await 语法来改写上述方法： methods: { async getData() { this.arr = [1, 2, 3]; await this.$nextTick(); this.$refs.box.getElementsByTagName('li')[0].innerHTML = 'hello'; } } 那么接下来我们来分析下 Vue 是如何做到的，其源码中使用了 3 种方式： promise.then 延迟调用 setTimeout(func, 0) 延迟功能 MutationObserver 监听变化 前两种方式相信大家都比较熟悉，其都具备延迟执行的功能，我们也可以直接替换 nextTick 为这两种方式中的一种，同样可以解决问题。这里主要介绍下 MutationObserver 这一 HTML5 新特性，那么什么是 MutationObserver 呢？用一句话介绍就是：我们可以使用它创建一个观察者对象，其会监听某个 DOM 元素，并在它的 DOM 树发生变化时执行我们提供的回调函数。实例化代码及配置如下： // 传入回调函数进行实例化 var observer = new MutationObserver(mutations => { mutations.forEach(mutation => { console.log(mutation.type); }) }); // 选择目标节点 var target = document.querySelector('#box'); // 配置观察选项 var config = { attributes: true, // 是否观察属性的变动 childList: true, // 是否观察子节点的变动（指新增，删除或者更改） characterData: true // 是否观察节点内容或节点文本的变动 }; // 传入目标节点和观察选项 observer.observe(target, config); // 停止观察 observer.disconnect(); 这样我们便可以观察 id 为 box 下的 DOM 树变化，一旦发生变化就会触发相应的回调方法，实现延迟调用的功能。 使用 watch 的深度遍历和立即调用功能 相信很多同学使用 watch 来监听数据变化的时候通常只使用过其中的 handler 回调，其实其还有两个参数，便是： deep 设置为 true 用于监听对象内部值的变化 immediate 设置为 true 将立即以表达式的当前值触发回调 我们来看下代码中的配置： 修改 export default { data() { return { obj: { a: 1, } } }, watch: { obj: { handler: function(newVal, oldVal) { console.log(newVal); }, deep: true, immediate: true } } } 以上代码我们修改了 obj 对象中 a 属性的值，我们可以触发其 watch 中的 handler 回调输出新的对象，而如果不加 deep: true，我们只能监听 obj 的改变，并不会触发回调。同时我们也添加了 immediate: true 配置，其会立即以 obj 的当前值触发回调。 在 Vue 源码中，主要使用了 Object.defineProperty (obj, key, option) 方法来实现数据的监听，同时其也是 Vue 数据双向绑定的关键方法之一。示例代码如下： function Observer() { var result = null; Object.defineProperty(this, 'result', { get: function() { console.log('你访问了 result'); return result; }, set: function(value) { result = value; console.log('你设置了 result = ' + value); } }); } var app = new Observer(); // 实例化 app.result; // 你访问了 result app.result = 11; // 你设置了 result = 11 我们通过实例化了 Observer 方法来实现了一个简单的监听数据访问与变化的功能。Object.defineProperty 是 ES5 的语法，这也就是为什么 Vue 不支持 IE8 以及更低版本浏览器的主要原因。 对低开销的静态组件使用 v-once Vue 提供了 v-once 指令用于只渲染元素和组件一次，一般可以用于存在大量静态数据组件的更新性能优化，注意是大量静态数据，因为少数情况下我们的页面渲染会因为一些静态数据而变慢。如果你需要对一个组件使用 v-once，可以直接在组件上绑定： 这时候因为组件绑定了 v-once，所以无论 msg 的值如何变化，组件内渲染的永远是其第一次获取到的初始值。因此我们在使用 v-once 的时候需要考虑该组件今后的更新情况，避免不必要的问题产生。 使用 $isServer 判断当前实例是否运行于服务器 当我们的 Vue 项目中存在服务端渲染（SSR）的时候，有些项目文件可能会同时在客户端和服务端加载，这时候代码中的一些客户端浏览器才支持的属性或变量在服务端便会加载出错，比如 window、 document 等，这时候我们需要进行环境的判断来区分客户端和服务端，如果你不知道 $isServer，那么你可能会使用 try ... catch 或者 process.env.VUE_ENV 来判断： try { document.title = 'test'; } catch(e) {} // process.env.VUE_ENV 需要在 webpack 中进行配置 if (process.env.VUE_ENV === 'client') { document.title = 'test'; } 而使用 $isServer 则无需进行配置，在组件中直接使用该 API 即可： if (this.$isServer) { document.title = 'test'; } 其源码中使用了 Object.defineProperty 来进行数据监测： Object.defineProperty(Vue.prototype, '$isServer', { get: isServerRendering }); var _isServer; var isServerRendering = function () { if (_isServer === undefined) { if (!inBrowser && !inWeex && typeof global !== 'undefined') { _isServer = global['process'].env.VUE_ENV === 'server'; } else { _isServer = false; } } return _isServer }; 当我们访问 $isServer 属性时，其会调用 isServerRendering 方法，该方法会首先判断当前环境，如果在浏览器或者 Weex 下则返回 false，否则继续判断当前全局环境下的 process.env.VUE_ENV 是否为 server 来返回最终结果。 结语 每一门语言、一个框架都有其 API 文档，在 Vue 的项目开发过程中，很多时候当你一筹莫展之际，你可以尝试浏览一下 Vue 的 API 列表，或许你就会柳暗花明。 思考 & 作业 使用 watch 监听某一值时，同时修改该值两次会触发几次 watch 回调？ 使用 errorHandler 捕获异常堆栈后如何解析 source-map 信息？ 除了本文介绍的 Vue 盲点外，还有哪些需要注意并容易忽略的 API？ "},"Vue项目构建与开发入门/14.开发拓展篇1：扩充你的开发工具.html":{"url":"Vue项目构建与开发入门/14.开发拓展篇1：扩充你的开发工具.html","title":"14.开发拓展篇1：扩充你的开发工具","keywords":"","body":"开发拓展篇 1：扩充你的开发工具 在项目开发中，工具的使用起到了至关重要的作用，正所谓工欲善其事，必先利其器，掌握一些实用的开发工具能够使我们的开发效率事半功倍。 那么我们应该掌握哪些开发工具的使用方法呢？其实一路走来，我们已经介绍的开发工具包括了 npm、yarn、webpack 以及一些集成在项目中的工具包，这些工具一定程度上都大大简化了我们的开发流程，起到了项目助推剂的作用。因此在开发工具的学习上我们应该抱着宜多不宜少的心态，积极主动的扩充自己的工具库。 巧用 Chrome 插件 首先，既然说到工具，那我们不得不介绍下占据浏览器市场份额霸主地位的 Chrome 了。相信每一个从事前端开发的同学都对其寄存着一种亲切感，因为只要是参与 web 项目的开发就基本上离不开它的关照，比如它提供的调试控制台以及数以万计的插件等。 而作为一名前端开发人员，我想你的 Chrome 浏览器地址栏右侧肯定排列着几款你钟爱的插件，使用的插件数量越多说明了你掌握的 Chrome 技能越多，同时一定程度上也凸显了你的开发能力。 那么接下来我们不妨来认识一下几款实用的 Chrome 插件： Vue.js devtools 首先介绍的肯定是 Vue.js devtools，它是 Vue 官方发布的一款调试 Vue 项目的插件，支持数据模拟与调试。相信从事过 Vue 项目开发的同学都已经把它收入在自己的工具库中了，它的界面如下： 成功安装它之后，在 Vue 项目的页面中我们可以打开 Chrome 控制台选择 Vue 的 tab 进行页面调试。 Vue Performance Devtool 在《Vue API 盲点解析》章节我们已经介绍了 Vue Performance Devtool 这款插件，它可以分析我们页面中各个组件的性能情况，从而在其基础上我们可以有针对性的对组件的代码进行优化，如下图所示： 同样安装完毕后，我们可以打开 Chrome 控制台选择 Vue Performance 的 tab 进行组件的性能观察。 Postman Postman 相信大家都比较熟悉，它是一款非常好用的接口调试工具。在 Vue 项目开发中，我们或多或少需要对后台提供的接口进行测试，比如传递数据并查看返回结果等，这时候使用 Postman 便可以完成这些任务。 Postman 会当作 Chrome 应用程序安装到你的电脑上，打开后我们可以选择请求方式（GET／POST），输入请求 URL 以及设置传递参数来进行接口的调用。 Web Developer Web Developer 是一款强大的用于操作网页中各项资源与浏览器的插件，比如一键禁用 JS、编辑 CSS、清除 Cookie 等。 虽然说一些功能我们也可以在 Chrome 控制台实现，但其提供的快捷键能够十分方便的让我们在页面中操作某些资源。 Google PageSpeed Insights API Extension PageSpeed Insights (PSI) 是 Google 在全球范围内应用最广的开发者工具之一，其中文网页版 developers.google.cn/speed/pagespeed/insights/ 也已经发布。作为一款专注于改进网页性能的开发者工具，它主要具有以下两个优势：真实的网页运行速度 及 优化建议。 为了便于使用，我们可以直接下载 Chrome 插件 Google PageSpeed Insights API Extension 来对当前访问网址进行测试和分析。 FeHelper FeHelper 是百度 FE 团队开发的一款前端工具集插件，包含代码压缩／性能检测／字符串编解码等功能，能够帮助我们完成一些琐碎的开发任务。 FeHelper 为我们提供了十多种快捷功能，在需要的时候我们直接点击插件图标选择对应功能即可，操作起来十分便捷。 Can I Use Can I Use 是 https://caniuse.com/ 网页版的插件。我们可以使用其来查看某一特性的浏览器支持程度，确保主流浏览器的支持。 使用 Chrome 插件形式的 Can I Use 我们可以快捷的查看项目中用到的某一特性的浏览器支持范围，同时还可以查看支持程度和兼容方式。 其他实用插件 JSONView ：一款可以将后台返回的 JSON 字符串数据自动格式化成规范 JSON 格式的插件 WhatFont：一款可以显示浏览器中选择文字的字体类型／字号／颜色的插件 The QR Code Extension：一款允许当前页面生成二维码，并使用网络摄像头扫描二维码的插件 Test IE：一款可以模拟 IE 及其他主流浏览器的插件，但大部分模拟场景需要付费才能使用 Wappalyzer：一款查看当前网站使用的前后端技术的插件，帮助你学习和认识优秀网站的技术选型 Mobile/Responsive Web Design Tester：一款用于测试页面在不同机型下呈现的插件 Resolution Test：一款用于测试页面在不同分辨率下呈现的插件 以上我们介绍了一些非常实用的 chrome 拓展插件来助力我们的前端开发，为项目开发提供了工具解决方案，同时也有助于帮助大家开启以工具为向导的开发模式。 分析你的包文件 每当我们使用 webpack 打包项目代码的时候，你可能需要关注一下打包生成的每个 js 文件的大小以及其包含的内容，这对于优化项目打包速度和提升页面加载性能都有十分大的帮助。 这里我们推荐使用 webpack-bundle-analyzer 这一款 webpack 插件来进行包文件的分析，下面我们就来介绍下其配置和使用方法。 首先作为一款需要内置在代码中的开发分析工具，我们需要安装并在 webpack 的 plugins 中添加该插件： # 安装命令 yarn add webpack-bundle-analyzer --dev /* vue.config.js */ const BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin const isPro = process.env.NODE_ENV === 'production' module.exports = { ... configureWebpack: config => { if (isPro) { return { plugins: [ // 使用包分析工具 new BundleAnalyzerPlugin() ] } } }, ... } 这样我们在生产环境下打包便可以在浏览器 8888 端口（默认）下打开页面进行包文件的分析，如下图所示： 图中区域内包含了我们打包出的所有 js 文件，我们可以以不同的颜色进行区分，同时我们也可以点击某一区块进行放大观察，以此来分析是否存在较大或重复的模块。而在页面左侧存在一个筛选面板，在该面板中我们能勾选需要查看的文件来进行显示，同时也可以切换查看原始、普通及 GZIP 压缩模式下的文件大小。 使用好 webpack-bundle-analyzer 工具我们可以快速的找到需要合并的模块，解决文件冗余，为资源优化提供可行性方案。 调试移动端页面 除了 Chrome 插件及打包分析工具的介绍外，我们再来了解下移动端页面的调试工具。相比 PC 端调试，移动端调试可能稍微复杂一点，但是只要熟练的使用好 “工具” 这一东西，我们同样可以在移动端的世界中游刃有余。 作为一名 Mac 及 iOS 用户，这里我主要介绍在 iPhone 手机中调试页面的方法，当然最后也会简单介绍一下 Android 手机页面的调试方法。 首先我们得具备这些工具：iPhone 手机一部、数据线一条、Mac 电脑一台。在满足以上要求后我们需要把手机通过数据线连接上 Mac 电脑，连接完毕后便可以进行如下步骤的设置： 1. 打开苹果手机的 Web 检查器 （设置 > Safari浏览器 > 高级 > Web检查器），一般情况下默认是开启的 2. 打开 Mac 上的 Safari 的 “开发”菜单，一般情况下默认是开启的 3. 在手机 Safari 浏览器中打开你需要调试的页面 4. 在 Mac Safari 浏览器中选择你需要调试的页面（开发 > 你的 iPhone > 你的页面地址） 5. 点击地址后弹出如图所示的控制台，你便可以在该控制台中进行调试了 最后你可以针对你的移动端页面进行断点调试、操作缓存、查看网络及资源等，帮助你快速的定位和解决问题。 而在 Android 手机中，我们同样可以对移动端页面进行调试，主要不同点在于 IOS 使用的工具是 iPhone 和 Mac，Android 使用的工具主要是 Android 手机和 Windows 系统罢了（Mac 也可以使用模拟器），当然还需要借助 Chrome 的帮助。 这里主要介绍一下 Chrome 中的 inspect，我们可以在 Chrome 地址栏输入：chrome://inspect/ 来捕获手机访问的页面地址，前提是你的 Android 手机通过数据线连接上了电脑并开启了相应权限，最后获取到的地址会在 Remote Target 中显示： 点击相应的地址会弹出一个控制台，你可以在该控制台中进行页面的调试。 结语 本文介绍了 Vue 项目开发时常用的 Chrome 插件、包分析工具以及移动端调试工具，这些开发工具的使用能够帮助我们快速的定位项目中出现的一些疑难杂症，而唯有 “用正确的工具，做正确的事情” 才能有效的彰显工具对于项目开发和维护的重要性，使我们的工具库能够发挥它真正的价值。 思考 & 作业 webpack-bundle-analyzer 有哪些配置项？分别有什么作用？ 除了本文介绍的开发工具外，还有哪些比较实用的开发工具？ "},"Vue项目构建与开发入门/15.开发拓展篇2：将UI界面交给第三方库.html":{"url":"Vue项目构建与开发入门/15.开发拓展篇2：将UI界面交给第三方库.html","title":"15.开发拓展篇2：将UI界面交给第三方库","keywords":"","body":"开发拓展篇 2：将 UI 界面交给第三方库 当你了解了 Vue 项目构建和开发的基本知识后，我认为接下来你一定想亲自在构建出的项目中填充自己的业务和功能逻辑，因为目前其还是空白的。 但是这里我不会教你如何实现一个具体的业务和功能模块，因为每个人想要实现的东西都可能不尽相同。如果你想快速开发一款应用，并且不想过多的操心页面 UI 层次的内容，比如你不想去实现一个下拉 UI 组件或设计一个 icon 图标，那么我想你有必要了解下 UI 库及图标库的应用。 UI 库 UI 库是脱离 JS 框架外的一种 “工具”，相比 JS 框架可以帮助你实现各种业务逻辑，其更关注于页面 UI 层面的实现，比如提供和业务无关的弹窗、导航、表单组件等，为项目 UI 层面的功能提供解决方案，比如 jQuery UI。 而由于本小册介绍的 JS 框架是 Vue，所以在 Vue 项目中我们需要使用基于 Vue 开发的 UI 库。本文将以比较流行的 Vux 为例，其目前 github star 数已在 14 k 左右。 Vux 是一款是基于 WeUI 和 Vue(2.x) 开发的移动端 UI 组件库，主要服务于微信页面。 Vux 的安装和配置 那么我们如何在项目中使用 Vux 呢？首先我们先要进行安装： yarn add vux # 或者 npm install vux --save 同时我们还需要安装 vux-loader： yarn add vux-loader --dev # 或者 npm install vux-loader --save-dev 安装完成后，我们需要在项目中进行配置，而由于目前 Vux 官网的配置教程未对 Vue CLI 3.x 作出说明，我们先来看下其目前的介绍： /* build/webpack.base.conf.js */ const vuxLoader = require('vux-loader') const webpackConfig = originalConfig // 原来的 module.exports 代码赋值给变量 webpackConfig module.exports = vuxLoader.merge(webpackConfig, { plugins: ['vux-ui'] }) 官方目前的配置是在 Vue CLI 2.x 的 build/webpack.base.conf.js 文件中进行修改，merge vux-loader 的配置项。那么在 Vue CLI 3.x 中其实原理是一样的，不一样的地方在于我们无法直接修改 webpack 配置文件，而需要通过 vue.config.js 中的 configureWebpack 配置项来进行修改罢了。代码如下： /* vue.config.js */ const vuxLoader = require('vux-loader') module.exports = { ... configureWebpack: config => { vuxLoader.merge(config, { plugins: ['vux-ui'] }) }, ... } configureWebpack 配置中提供的 config 参数便是 webpack 的配置内容，也可以看作是官方文档中提到的原来在 webpack.base.conf.js 中的 module.exports 代码。 Vux 的使用 当我们配置好 Vux 后，我们便可以在项目中使用了。Vux 为我们提供了很多项目中常用的组件和工具函数等，比如我们在全局父组件 App.vue 中添加一个底部导航： Demo 实验室 关于 import { Tabbar, TabbarItem } from 'vux' export default { components: { Tabbar, TabbarItem, } } @import '~vux/src/styles/reset.less'; 我们通过引入组件的方式将导航组 Tabbar、TabbarItem 件引入并注册到页面中，这样通过 Vux 文档中的介绍我们便可以对相应组件进行配置。呈现效果如下： 需要注意的是我们需要在 App.vue 中引入 Vux 的 reset 样式 less 文件以解决样式呈现不统一的问题。关于其他 Vux 组件的配置可以参考官方文档：组件 其他 UI 库（框架） 除了上方介绍的 Vux 外，类似的 Vue 的第三方 UI 库还有很多，这里我列举几个比较常用的： iview：一套基于 Vue.js 的高质量 UI 组件库（PC端） iView Admin：搭配使用iView UI组件库形成的一套后台集成解决方案（PC端） Element：一套为开发者、设计师和产品经理准备的基于 Vue 2.0 的桌面端组件库（PC端） Vue Antd：Ant Design 的 Vue 实现，开发和服务于企业级后台产品（PC端） VueStrap：一款 Bootstrap 风格的 Vue UI 库（PC端） Mint UI：由饿了么前端开发的基于 Vue.js 的移动端组件库（移动端） Vonic：一个基于 vue.js 和 ionic 样式的 UI 框架，用于快速构建移动端单页应用（移动端） Vant：轻量、可靠的移动端 Vue 组件库（移动端） Cube UI：基于 Vue.js 实现的精致移动端组件库（移动端） 图标库 了解完 UI 库，我们再来了解下图标库。图标库，顾名思义就是汇聚了大量图标的仓库，在这样的仓库中我们可以查找并下载我们想要的图标，甚至还可以制定颜色和大小。 在项目中使用图标库可以为我们的项目制定统一的图标管理标准，同时一定程度上也可以减少项目图片的数量。下面我们便来介绍下目前最流行的一款图标库 Iconfont。 使用 Iconfont 下载管理图标 Iconfont 是阿里妈妈 MUX 倾力打造的矢量图标管理、交流平台。 设计师将图标上传到 Iconfont 平台，用户可以自定义下载多种格式的 icon，平台也可将图标转换为字体，便于前端工程师自由调整与调用。 在 Iconfont 首页，我们可以点击图标库来进行图标的搜索。这里我们可以点击官方图标库后选择 Ant Design 官方图标库进入。 进入对应的图标库后，我们可以选择对应的图标加入购物车，同时购物车会更新添加后的图标数量。 选择完成后，为了使图标便于今后管理，我们可以新建一个项目并将图标移入项目中。在项目中，我们便可以进行图标的添加、删除和下载等操作（需要登录）。 这里我们采用将图标下载到本地的方式进行使用，当然你也可以使用在线链接，但这会受到网络的影响。 Iconfont 的使用 下载到本地后，我们需要将文件夹中的 iconfont.css、iconfont.eot、iconfont.svg、iconfont.ttf 和 iconfont.woff 文件统一放到项目中去，比如我们可以放入新建的 assets 文件夹的 iconfont 中去。而 iconfont.css 便是管理这样图标字体的样式文件，我们可以将其引入到入口文件中： /* main.js */ import './assets/iconfont/iconfont.css' 引入后我们便可以在项目中通过给 html 标签添加样式名称的方式来进行图标的使用，比如我们在上方 Vux 的导航上添加图标： Demo 实验室 关于 按照 Vux 导航文档添加名称为 icon 的 solt 插槽后，我们还需要在标签上添加对应图标的 class 名称，比如 iconfont icon-bulb，最终我们的展示效果如图所示： 其他图标库 除了 Iconfont，常用的图标库还有： Font Awesome：世界上最受欢迎且最易于使用的图标集 Ionicons ：精美的开源图标库，可以用于Web，iOS，Android和桌面应用程序 Themify：一套用于网页设计和应用程序的完整图标 相信以上这些图标库就足以使你应付所有项目了。 结语 本文介绍了 Vue 项目开发中可能会使用到的 UI 库与图标库的应用，以 Vux 和 Iconfont 为例讲解了它们在项目中的使用方法和注意事项，相信大家能够在项目构建和开发的基础上使用 UI 库与图标库快速实现自己的项目 UI 层面的功能和展示，为自己的项目添砖加瓦。 具体实例代码可以参考：ui-framework-project 思考 & 作业 查看 Vux 源码，尝试自己编写一个 UI 插件 Iconfont 是矢量图标库，其相比位图的主要区别是什么？ "},"Vue项目构建与开发入门/16.开发拓展篇3：尝试使用外部数据.html":{"url":"Vue项目构建与开发入门/16.开发拓展篇3：尝试使用外部数据.html","title":"16.开发拓展篇3：尝试使用外部数据","keywords":"","body":"开发拓展篇 3：尝试使用外部数据 当你应用的 UI 层面已经趋于完善的时候，接下来你就需要去获取动态的数据来实现真实的应用场景。那么动态数据从哪里来呢？前端主要还是通过接口的形式获取。 如果有专业的接口开发人员和你一起完成一个应用，那么你只需要和他定义好接口的入参和出参，然后进行调用就好了，这也是公司中前端与后台的常见合作方式。 而在以下场景下，你可能并不需要或者并没有后台工程师提供接口给你： 你个人开发的项目 你的应用数据来源于外部 这时候你就需要通过调用第三方接口来实现应用的数据交互与展现。那么接下来我们就来介绍下第三方接口的使用。 介绍 大多数情况下，我们调用的第三方接口都是完全或者部分开源及免费的，因此只要在合理的范围内使用我们便可以实现一些简单的数据交互。本文将以聚合数据提供的第三方接口 API 为例进行讲解。 聚合数据 聚合数据是国内领先的基础数据服务商， 以自有数据为基础，各种便捷服务整合以及第三方数据接入，为互联网开发全行业提供标准化 API 技术支撑服务的 DaaS 平台。 在官网 API 首页（https://www.juhe.cn/docs）我们可以选择你想要的接口类型进行调用，如下图所示： 其中包含了免费及付费的接口类型，如果只是用于单个的调用或测试，建议大家使用免费接口就可以了（非会员只能申请一个免费接口，比较坑），但如果你的应用准备上架或发布，你最好付费以获得更多的调用和使用接口的次数。 点击你想使用的接口后你便可以查看该接口的 API 文档，包括接口地址、请求方式、请求示例及返回示例等，比如这里我点击“笑话大全”： 调用接口需要平台提供的 AppKey，在你注册登录个人中心的我的数据中可以查看对应接口的 AppKey： 获取到 AppKey 后我们便可以对接口进行测试了，这里我们可以直接通过对应接口的测试按钮进行测试，当然你也可以通过 postman 工具进行调试： 测试完毕后，我们便可以在 Vue 项目中接入我们的第三方接口，实现动态数据和功能。 其他第三方接口 除了整合型的第三方接口聚合数据外，其他比较实用的第三方接口还有： 高德地图：访问高德地图的 Web API GitHub：世界上领先的软件开发平台 百度翻译：支持多种语言之间的相互翻译 和风天气：中国天气信息 阿凡达数据 ：提供中国可用的 API 实例 接下来，我们便可以在 Vue 项目中接入第三方接口来实现数据的交互。这里我们以接入聚合数据的历史上的今天接口为例。 首先我们来看一下该接口的请求详情： 请求地址：http://api.juheapi.com/japi/toh 请求参数：v=1.0&month=10&day=31&key=你的AppKey 请求方式：GET 上方详情中我们可以看到请求参数主要有 4 个，分别为： v：string 类型。版本，当前：1.0 month：int 类型。月份，如：10 day：int 类型。日，如：1 key：string 类型。你的 AppKey 通过接口入参的说明我们可以知道唯一可以变的数据便是月份和日期，所以我们页面中得有选择月日的功能。 另外我们再来看一下该接口的出参示例： { \"error_code\": 0, \"reason\": \"请求成功！\", \"result\": [ { \"day\": 1, \"des\": \"1907年11月1日 电影导演吴永刚诞生 &emsp;&emsp;吴永刚，1907年11月1日生于江苏吴县。1932年后参加影片《三个摩登女性》、《母性之光》的拍摄工作。1934年在联华影片公司编导处女作《神女》，一举成名，...\", \"id\": 9000, \"lunar\": \"丁未年九月廿六\", \"month\": 11, \"pic\": \"\", \"title\": \"电影导演吴永刚诞生\", \"year\": 1907 }, } } 通过上方示例，我们可以获取历史上的今天的标题、详情、图片等，这些数据可以用于页面展示。 这样经过接口入参和出参的分析，我们可以使用 Vux 构建一个简单的页面，如下图所示： 通过点击上图中“查看历史上的今天”按钮，便可以调用接口获取数据列表并渲染。主要代码如下： 选中值: {{ value }} 查看历史上的今天 import { DatetimeView, XButton, Panel } from 'vux' import { getHistory } from '_ser/moduleB' export default { data() { return { value: '10-31', format: 'MM-DD', list: [] } }, methods: { watchHistory() { let data = this.value.split('-') this.list = []; getHistory({ v: '1.0', month: data[0], day: data[1], key: 'd6ceaf9be9f116ae45e7699845d87056' }).then(response => { if (!response.error_code) { response.result.map(e => { this.list.push({ title: e.title, desc: e.des, src: e.pic, }) }) } }) } }, components: { DatetimeView, XButton, Panel }, } 上方我们通过调用封装的 getHistory 接口名称进行数据的获取，在本地调用的过程中需要注意跨域的问题，可以配置 devServer 的 proxy 代理来解决： /* vue.config.js */ module.exports = { devServer: { proxy: { '/juheapi': { target: 'http://api.juheapi.com/', changeOrigin: true, pathRewrite: {'^/juheapi': ''} } } } } 具体实例代码可以参考：ui-framework-project 这样我们便完成了使用第三方接口获取数据实现页面渲染的功能，为自己的应用填充了数据和功能。 结语 第三方接口的使用能够帮助我们快速的获取数据并实现应用的动态交互，同时也有助于解决接口开发的人力及服务器资源消耗，为部分 Vue 项目开发提供数据保障。 至此，本小册的开发部分章节也将告一段落。在这部分的内容中我们一起学习了 Vue 项目开发的实用技巧、方法和工具，并在构建出的项目基础上了解并实践了 Vue 开发的相关技术要点。希望这部分内容的介绍能够巩固大家对于 Vue 开发的基础知识，弥补 Vue 开发的技能空白。 思考 & 作业 自己通过调用外部数据完成一个页面动态的数据渲染 devServer 的 proxy 代理是如何实现接口转换和重定向的？各配置项的作用是什么？ "},"Vue项目构建与开发入门/17.总结篇：写在最后.html":{"url":"Vue项目构建与开发入门/17.总结篇：写在最后.html","title":"17.总结篇：写在最后","keywords":"","body":"总结篇：写在最后 看到这里，也就是要和大家说再见的时候了，其实还有很多想和大家分享的内容没能来得及一一阐述，但是没有关系，我相信在今后学习 Vue 的道路上我们永远会保持关注，彼此照应，一起学习，一起进步。 而正所谓温故而知新，可以为师矣，接下来我们不妨一起回顾下本小册的主要内容。 回顾与总结 浏览小册目录，我们可以清楚的将小册的内容归类为构建与开发两部分，这也是本小册所要分享的知识点所在。 在小册构建部分我们由浅入深的进行了项目构建的学习，在 Vue CLI 3.x 的基础上，从基础构建开始，经历了 npm 与 yarn 的使用、webpack 的配置以及项目环境的注入，最后通过单页应用和多页应用的构建实战来进一步强化大家的认知，并对构建出的项目进行了整合和优化。 而在小册开发部分，我们主要针对 Vue 项目开发过程中可能遇到的技术点、难点及优化点进行了指南性的介绍，包括了编码技巧与规范、可复用性模块的编写、组件的职能划分、数据驱动的介绍以及 Vue API 的解析等，通过理论结合实战的形式一步步地帮助大家构筑 Vue 开发知识体系。 相对于偏具体实战性质的书籍，本小册主要偏向理论及应用层面。因为小册没有针对实现某一系统性的功能或项目进行详细的讲解，而是介绍了从无到有开发一个 Vue 基础项目的方法和经验，本着“授人以渔”的宗旨给大家进行应用性质的指南，而至于具体的业务及功能场景，则需要大家自己去填充。 进阶与提升 由于本小册定位是一本入门提升级的书籍，很多底层和原理性的知识都没能够在此详细介绍，如果你看完本小册并已经充分掌握了小册中的知识体系，或许接下来你可能有点迷茫，不知道下一步该如何完善自己的项目。不用担心，你可以按照下图的知识路线进一步提升自己，将一个纯前端的项目发展为由前端 —— 中间层组成的真正前后端分离的项目，如下图所示： 本小册讲解的是上图中纯前端部分的内容，而所谓的 Node 中间层其实就是处于前端数据请求与后台响应渲染中间位置的架构，它是运行在服务端的，可以帮助我们启动脱离于后台项目的前端服务并实现数据的中转处理与页面渲染等功能。 这里我们需要了解 Node.js 的 Web 开发框架 Koa（或者 Express）, 你可以尝试使用 Koa 项目脚手架 koa-generator 来实现一个简单的中间层项目。 在我们的 Vue 项目中，我们通过 webpack 打包在 dist 目录下输出了用于生产环境的静态文件，那么这些静态文件最后哪里会使用它们？其实我们可以通过启动 Node 服务来进行加载并渲染入口 html，也就是最终我们将这些文件放在服务器上运行的效果。 当然中间层的作用远不止渲染我们打包后的页面这么简单，通过添加一些 middleware（中间件）我们可以将客户端的一些功能转移到服务端处理，比如登录验证、用户信息获取、路由重定向以及各页面业务逻辑的封装等。感兴趣的同学可以以此为进阶和提升的下一个目标。 作者寄语 文森特·梵高曾经说过：“不要吹灭你的灵感和你的想象力; 不要成为你的模型的奴隶。” 看完本小册，你可能并没有学到什么，但是我希望你能发现什么，发现自己的灵感，发挥自己的想象力去继续深挖填充小册中介绍的内容，永远不要止步于当下，你还有很多东西需要去学习。 我们应该抱着玩的心态的去尝试各种新鲜的技术，然后回归运用到应用中去，毕竟世界那么大，每一个 Hello Wrold 实战都是你打开未知大门的钥匙。 有些时候你花了时间去学习，但是最后总会茫然的感觉自己并没有收获任何实际性的东西，其实你忽略了自己的思想，忽略了思想上的提升。就好比有些人上了四年大学，当他回望大学生涯的时候会发现大学并没有教会他什么，但却给了他一种思想，而这种思想正塑造了自己的人生。 Vue 的学习并非一朝一夕就能完成的，不要吝啬自己的学习时间，也不要局限于 Vue 本身，因为所有知识都是融会贯通的，当你学会了 React 的时候再来看看 Vue 的文档，或许也会有一种似曾相识的亲切感。 最后，愿自己码梦为生，笔耕不辍；愿你码到成功，初心不改。 关于作者 如果你喜欢我的文章并想继续关注“劳卜”我的话，可以扫一扫下方的二维码关注我的微信公众号「前端呼啦圈」，第一时间获取我的原创推送。 同时也可以关注我的博客：http://www.cnblogs.com/luozhihao/ "},"Web前端面试指南与高频考题解析/00.准备：简历编写和面试前准备.html":{"url":"Web前端面试指南与高频考题解析/00.准备：简历编写和面试前准备.html","title":"00.准备：简历编写和面试前准备","keywords":"","body":"准备：简历编写和面试前准备 一般来说，跳槽找工作要经历投递简历、准备面试、面试和谈 offer 四个阶段。其中面试题目会因你的等级和职位而异，从入门级到专家级，广度和深度都会有所增加。不过，不管什么级别和职位，面试题目一般都可以分类为理论知识、算法、项目细节、技术视野、开放性题、工作案例等内容。接下来重点来说下简历和知识点梳理的方法。 准备一份合适的简历 首先，什么样子的简历更加容易拿到面试邀请？笔者作为一名在 BAT 中待过两家的面试官，见过各种各样的简历，先说一下一些比较不受欢迎的简历： 招聘网站上的简历：有些简历是 HR 直接从某招聘网站直接下载下来的，格式统一，而且对于自己的技能还有自己打分，这类简历有可能是候选人根本就没自己精心准备简历，而是网站根据他填写的内容自动生成的，遇到这样的简历笔者一定会让 HR 或者候选人更新一份简历给我。 太花俏的简历：有人觉得简历花俏一点会让人眼前一亮，但是公司招聘的是前端不是视觉设计，所以如果找的不是视觉设计工作，还是工工整整的简历会比较受欢迎，而且太花俏的简历有可能让人第一感觉是华而不实，并不是关注候选人的技能。 造假或者描述太出格的简历：看到你简历的人可能是不懂技术的 HR，也可能是专业领域的大牛，如果数据造假或者夸大其实，这样很容易就让人给卡掉。 那么，怎样的简历才是好的简历呢？ 技术型简历的重要组成部分 一份合适的技术型简历最重要的三部分是： 个人掌握的技能，是否有岗位需要用到的技能，及其技能掌握的熟练程度：熟悉、了解还是精通 项目经历，项目经历是否对现在岗位有用或者有重叠，是否能够驾驭大型项目 实习经历，对于没有经验的应届生来说，实习经历是很重要的部分，是否有大公司或者具体项目的实习经历是筛选简历的重要参考 技术型简历一般不要太花俏，关键要语言表达通顺清楚，让语言准确和容易理解，在 HR 筛选简历的时候，可以瞬间抓住他的眼球。另外如果有一些特殊奖项，也可以在简历中突出出来，比如：季度之星、最佳个人之类的奖项，应届生会有优秀毕业生、全额奖学金等。 推荐使用 PDF 版本的简历 一般来说简历会有 Word、Markdown 等版本，这里笔者推荐使用 PDF 版本的简历，主要原因如下： 内容丰富，布局调整方便 字体等格式有保障，你不知道收到你简历的人用的是什么环境，PDF 版本不会因为不同操作系统等原因而受限 便于携带和传播，始终存一份简历在手机或者邮箱内，随时发送 不容易被涂改 一般 Windows 系统的 Word、Mac 系统的 Pages 都支持导出 PDF 格式的文件，原稿可以保存到云端或者 iCloud，方便以后修改。 虽然我们是 Web 前端工程师，笔者还是不推荐使用 HTML 格式的简历，HTML 版本的简历容易受浏览器等环境因素影响，而且接收方不一定是技术人员，你做的炫酷的效果也不一定会被看到。 简历最好要有针对性地来写 简历是「敲门砖」，笔者建议根据你想要找的公司、岗位和职位描述来有针对性地写简历。尤其是个人技能和项目（实习）经验部分，要根据岗位要求来写，这样才能增加受邀面试的机会。 举个例子：好友给你推荐了百度地图部门的一个高级 Web 前端工程师工作，并且把职位描述（JD）发给你了，里面有要求哪些技能，用到哪些技术，还有加分项。那么你写简历就应该思考自己有没有这些技能。如果没有 JD，那么至少你应该知道：地图部门肯定做一些跟地图相关的工作，如果恰巧你之前研究过地图定位，了解 HTML5 Geolocation 定位接口，那么你可以在简历里提一下。 很多时候我们并不知道简历会被谁看到，也不知道简历会被朋友/猎头投递到什么公司或者职位，那么这样的简历应该是一种「通用简历」。所谓通用简历，应该是与你找的职位和期望的级别相匹配的简历，比如想找大概 T4 水平的 Web 前端工作，那么你就应该在简历体现出来自己的技能能够达到 T4 的水平。不要拿着一两年前的简历去找工作，前端这两年发展速度很快，只靠一两年前简历上面「精通、熟悉」的库和框架，可能已经找不到工作了。 所以，写简历也是个技术活，而且是一个辛苦活！不要用千篇一律的模板！ 简历是面试时「点菜」用的菜单 简历除了是「敲门砖」之外，还是供面试官提问用的「菜单」。面试官会从你简历上面写的技能、项目进行提问。所以简历是候选人「反客为主」的重要工具，这也是笔者一直提到的：不要造假或者描述太出格，而应该实事求是地写简历。简历中的技能和项目都要做好知识点梳理，尽量多地梳理出面试官可能问到的问题，并且想出怎么回答应对，千万不要在简历上自己给自己挖坑。 案例：记得有一个候选人，写的工作时间段有问题，简历上写在 2015 年 3 月到 2017 年 4 月在 A 公司工作，但是面试自我介绍的时候说自己在 A 公司工作了一年，这就有可能让面试官认为个人工作经历存在造假可能。不要小看细节！ 另外简历中不要出现错误的单词拼写，注意单词的大小写，比如jQuery之类。 拿到面试邀请之后做的准备工作 当有公司邀请你去面试的时候，应该针对性地做一些功课。 了解部门和团队 了解部门做的事情，团队用的技术栈，前文提到这部分信息一般从 JD 当中就可以看到，如果 JD 并没有这些信息，那么可以根据面试的部门搜索下，总会找到一些零星的信息，如果实在没有任何信息，就准备岗位需要的通用技术。 了解面试官 通过邀请电话或者面试邀请邮件，可以找到面试官信息。通过这些信息查找面试官技术博客、GitHub 等，了解面试官最近关注的技术和擅长的技术，因为面试官往往会在面试的过程中问自己擅长的技术。 面试中出现的常规问题 对于面试中出现的常规问题要做好准备，比如：介绍下自己，为什么跳槽，面试最后一般会问有什么要问的。 介绍自己 介绍自己时，切忌从自己大学实习一直到最新公司全部毫无侧重地介绍，这些在简历当中都有，最好的方式是在介绍中铺垫自己的技术特长、做的项目，引导面试官问自己准备好的问题。 为什么跳槽 这个问题一定要慎重和认真思考，诚实回答。一般这个问题是想评估你入职能够待多长时间，是否能够融入团队。 每个人跳槽前肯定想了很多原因，最终才走出这一步，不管现在工作怎样，切忌抱怨，不要吐槽，更不要说和现在领导不和睦之类的话。 多从自身发展找原因，可以表达寻找自己心目中的好的技术团队氛围和平台机会，比如：个人遇见了天花板，希望找个更好的发展机会。 利用脑图来梳理知识点 对于统一校招类的面试，要重点梳理前端的所有知识点，校招面试一般是为了做人才储备，所以看的是候选人的可塑性和学习能力；对于社招类面试，则看重的是业务能力和 JD 匹配程度，所以要针对性地整理前端知识点，针对性的内容包括：项目用到的技术细节、个人技能部分需要加强或提升的常考知识点。 所以，不仅仅简历要针对性地来写，知识点也要根据自己的经历、准备的简历、公司和职位描述来针对性地梳理。每个读者的技术能力和工作经历不同，因而知识点梳理大纲也不同，本小册重点介绍如何梳理自己的面试知识点，并且对一些常考的题目进行解答，起到知识点巩固和讲解的作用。 基础知识来自于自己平时的储备，一般对着一本系统的书籍或者自己平时的笔记过一遍即可，但是提到自己做到的项目是没有固定的复习套路的，而且围绕项目可以衍生出来各种问题，都需要了解，项目讲清楚对于候选人也特别重要。基础是固定的，任何人经过一段时间都可以学完的，但是项目经历是实打实的经验。 对于项目的复习和准备，笔者建议是列思维导图（脑图），针对自己重点需要讲的项目，列出用到的技术点（知识点），介绍背景、项目上线后的收益以及后续优化点。这是第一层，第二层就是针对技术点（知识点）做各种发散的问题。 小结 本小节希望你得到下面的知识： 找工作之前应该准备一份合适的工作简历 工作简历可以针对性地来写 收到面试邀请之后应该去了解下 JD 和涉及公司部门的基本情况 利用思维导图来梳理知识点 "},"Web前端面试指南与高频考题解析/01.一面1：ES基础知识点与高频考题解析.html":{"url":"Web前端面试指南与高频考题解析/01.一面1：ES基础知识点与高频考题解析.html","title":"01.一面1：ES基础知识点与高频考题解析","keywords":"","body":"一面 1：ES 基础知识点与高频考题解析 JavaScript 是 ECMAScript 规范的一种实现，本小节重点梳理下 ECMAScript 中的常考知识点，然后就一些容易出现的题目进行解析。 知识点梳理 变量类型 JS 的数据类型分类和判断 值类型和引用类型 原型与原型链（继承） 原型和原型链定义 继承写法 作用域和闭包 执行上下文 this 闭包是什么 异步 同步 vs 异步 异步和单线程 前端异步的场景 ES6/7 新标准的考查 箭头函数 Module Class Set 和 Map Promise 变量类型 JavaScript 是一种弱类型脚本语言，所谓弱类型指的是定义变量时，不需要什么类型，在程序运行过程中会自动判断类型。 ECMAScript 中定义了 6 种原始类型： Boolean String Number Null Undefined Symbol（ES6 新定义） 注意：原始类型不包含 Object。 题目：类型判断用到哪些方法？ typeof typeof xxx得到的值有以下几种类型：undefined boolean number string object function、symbol ，比较简单，不再一一演示了。这里需要注意的有三点： typeof null结果是object ，实际这是typeof的一个bug，null是原始值，非引用类型 typeof [1, 2]结果是object，结果中没有array这一项，引用类型除了function其他的全部都是object typeof Symbol() 用typeof获取symbol类型的值得到的是symbol，这是 ES6 新增的知识点 instanceof 用于实例和构造函数的对应。例如判断一个变量是否是数组，使用typeof无法判断，但可以使用[1, 2] instanceof Array来判断。因为，[1, 2]是数组，它的构造函数就是Array。同理： function Foo(name) { this.name = name } var foo = new Foo('bar') console.log(foo instanceof Foo) // true 题目：值类型和引用类型的区别 值类型 vs 引用类型 除了原始类型，ES 还有引用类型，上文提到的typeof识别出来的类型中，只有object和function是引用类型，其他都是值类型。 根据 JavaScript 中的变量类型传递方式，又分为值类型和引用类型，值类型变量包括 Boolean、String、Number、Undefined、Null，引用类型包括了 Object 类的所有，如 Date、Array、Function 等。在参数传递方式上，值类型是按值传递，引用类型是按共享传递。 下面通过一个小题目，来看下两者的主要区别，以及实际开发中需要注意的地方。 // 值类型 var a = 10 var b = a b = 20 console.log(a) // 10 console.log(b) // 20 上述代码中，a b都是值类型，两者分别修改赋值，相互之间没有任何影响。再看引用类型的例子： // 引用类型 var a = {x: 10, y: 20} var b = a b.x = 100 b.y = 200 console.log(a) // {x: 100, y: 200} console.log(b) // {x: 100, y: 200} 上述代码中，a b都是引用类型。在执行了b = a之后，修改b的属性值，a的也跟着变化。因为a和b都是引用类型，指向了同一个内存地址，即两者引用的是同一个值，因此b修改属性时，a的值随之改动。 再借助题目进一步讲解一下。 说出下面代码的执行结果，并分析其原因。 function foo(a){ a = a * 10; } function bar(b){ b.value = 'new'; } var a = 1; var b = {value: 'old'}; foo(a); bar(b); console.log(a); // 1 console.log(b); // value: new 通过代码执行，会发现： a的值没有发生改变 而b的值发生了改变 这就是因为Number类型的a是按值传递的，而Object类型的b是按共享传递的。 JS 中这种设计的原因是：按值传递的类型，复制一份存入栈内存，这类类型一般不占用太多内存，而且按值传递保证了其访问速度。按共享传递的类型，是复制其引用，而不是整个复制其值（C 语言中的指针），保证过大的对象等不会因为不停复制内容而造成内存的浪费。 引用类型经常会在代码中按照下面的写法使用，或者说容易不知不觉中造成错误！ var obj = { a: 1, b: [1,2,3] } var a = obj.a var b = obj.b a = 2 b.push(4) console.log(obj, a, b) 虽然obj本身是个引用类型的变量（对象），但是内部的a和b一个是值类型一个是引用类型，a的赋值不会改变obj.a，但是b的操作却会反映到obj对象上。 原型和原型链 JavaScript 是基于原型的语言，原型理解起来非常简单，但却特别重要，下面还是通过题目来理解下JavaScript 的原型概念。 题目：如何理解 JavaScript 的原型 对于这个问题，可以从下面这几个要点来理解和回答，下面几条必须记住并且理解 所有的引用类型（数组、对象、函数），都具有对象特性，即可自由扩展属性（null除外） 所有的引用类型（数组、对象、函数），都有一个__proto__属性，属性值是一个普通的对象 所有的函数，都有一个prototype属性，属性值也是一个普通的对象 所有的引用类型（数组、对象、函数），__proto__属性值指向它的构造函数的prototype属性值 通过代码解释一下，大家可自行运行以下代码，看结果。 // 要点一：自由扩展属性 var obj = {}; obj.a = 100; var arr = []; arr.a = 100; function fn () {} fn.a = 100; // 要点二：__proto__ console.log(obj.__proto__); console.log(arr.__proto__); console.log(fn.__proto__); // 要点三：函数有 prototype console.log(fn.prototype) // 要点四：引用类型的 __proto__ 属性值指向它的构造函数的 prototype 属性值 console.log(obj.__proto__ === Object.prototype) 原型 先写一个简单的代码示例。 // 构造函数 function Foo(name, age) { this.name = name } Foo.prototype.alertName = function () { alert(this.name) } // 创建示例 var f = new Foo('zhangsan') f.printName = function () { console.log(this.name) } // 测试 f.printName() f.alertName() 执行printName时很好理解，但是执行alertName时发生了什么？这里再记住一个重点 当试图得到一个对象的某个属性时，如果这个对象本身没有这个属性，那么会去它的__proto__（即它的构造函数的prototype）中寻找，因此f.alertName就会找到Foo.prototype.alertName。 那么如何判断这个属性是不是对象本身的属性呢？使用hasOwnProperty，常用的地方是遍历一个对象的时候。 var item for (item in f) { // 高级浏览器已经在 for in 中屏蔽了来自原型的属性，但是这里建议大家还是加上这个判断，保证程序的健壮性 if (f.hasOwnProperty(item)) { console.log(item) } } 题目：如何理解 JS 的原型链 原型链 还是接着上面的示例，如果执行f.toString()时，又发生了什么？ // 省略 N 行 // 测试 f.printName() f.alertName() f.toString() 因为f本身没有toString()，并且f.__proto__（即Foo.prototype）中也没有toString。这个问题还是得拿出刚才那句话——当试图得到一个对象的某个属性时，如果这个对象本身没有这个属性，那么会去它的__proto__（即它的构造函数的prototype）中寻找。 如果在f.__proto__中没有找到toString，那么就继续去f.__proto__.__proto__中寻找，因为f.__proto__就是一个普通的对象而已嘛！ f.__proto__即Foo.prototype，没有找到toString，继续往上找 f.__proto__.__proto__即Foo.prototype.__proto__。Foo.prototype就是一个普通的对象，因此Foo.prototype.__proto__就是Object.prototype，在这里可以找到toString 因此f.toString最终对应到了Object.prototype.toString 这样一直往上找，你会发现是一个链式的结构，所以叫做“原型链”。如果一直找到最上层都没有找到，那么就宣告失败，返回undefined。最上层是什么 —— Object.prototype.__proto__ === null 原型链中的this 所有从原型或更高级原型中得到、执行的方法，其中的this在执行时，就指向了当前这个触发事件执行的对象。因此printName和alertName中的this都是f。 作用域和闭包 作用域和闭包是前端面试中，最可能考查的知识点。例如下面的题目： 题目：现在有个 HTML 片段，要求编写代码，点击编号为几的链接就alert弹出其编号 编号1，点击我请弹出1 2 3 4 5 一般不知道这个题目用闭包的话，会写出下面的代码： var list = document.getElementsByTagName('li'); for (var i = 0; i 实际上执行才会发现始终弹出的是6，这时候就应该通过闭包来解决： var list = document.getElementsByTagName('li'); for (var i = 0; i 要理解闭包，就需要我们从「执行上下文」开始讲起。 执行上下文 先讲一个关于 变量提升 的知识点，面试中可能会遇见下面的问题，很多候选人都回答错误： 题目：说出下面执行的结果（这里笔者直接注释输出了） console.log(a) // undefined var a = 100 fn('zhangsan') // 'zhangsan' 20 function fn(name) { age = 20 console.log(name, age) var age } console.log(b); // 这里报错 // Uncaught ReferenceError: b is not defined b = 100; 在一段 JS 脚本（即一个标签中）执行之前，要先解析代码（所以说 JS 是解释执行的脚本语言），解析的时候会先创建一个 全局执行上下文 环境，先把代码中即将执行的（内部函数的不算，因为你不知道函数何时执行）变量、函数声明都拿出来。变量先暂时赋值为undefined，函数则先声明好可使用。这一步做完了，然后再开始正式执行程序。再次强调，这是在代码执行之前才开始的工作。 我们来看下上面的面试小题目，为什么a是undefined，而b却报错了，实际 JS 在代码执行之前，要「全文解析」，发现var a，知道有个a的变量，存入了执行上下文，而b没有找到var关键字，这时候没有在执行上下文提前「占位」，所以代码执行的时候，提前报到的a是有记录的，只不过值暂时还没有赋值，即为undefined，而b在执行上下文没有找到，自然会报错（没有找到b的引用）。 另外，一个函数在执行之前，也会创建一个 函数执行上下文 环境，跟 全局上下文 差不多，不过 函数执行上下文 中会多出this arguments和函数的参数。参数和arguments好理解，这里的this咱们需要专门讲解。 总结一下： 范围：一段、js 文件或者一个函数 全局上下文：变量定义，函数声明 函数上下文：变量定义，函数声明，this，arguments this 先搞明白一个很重要的概念 —— this的值是在执行的时候才能确认，定义的时候不能确认！ 为什么呢 —— 因为this是执行上下文环境的一部分，而执行上下文需要在代码执行之前确定，而不是定义的时候。看如下例子 var a = { name: 'A', fn: function () { console.log(this.name) } } a.fn() // this === a a.fn.call({name: 'B'}) // this === {name: 'B'} var fn1 = a.fn fn1() // this === window this执行会有不同，主要集中在这几个场景中 作为构造函数执行，构造函数中 作为对象属性执行，上述代码中a.fn() 作为普通函数执行，上述代码中fn1() 用于call apply bind，上述代码中a.fn.call({name: 'B'}) 下面再来讲解下什么是作用域和作用域链，作用域链和作用域也是常考的题目。 题目：如何理解 JS 的作用域和作用域链 作用域 ES6 之前 JS 没有块级作用域。例如 if (true) { var name = 'zhangsan' } console.log(name) 从上面的例子可以体会到作用域的概念，作用域就是一个独立的地盘，让变量不会外泄、暴露出去。上面的name就被暴露出去了，因此，JS 没有块级作用域，只有全局作用域和函数作用域。 var a = 100 function fn() { var a = 200 console.log('fn', a) } console.log('global', a) fn() 全局作用域就是最外层的作用域，如果我们写了很多行 JS 代码，变量定义都没有用函数包括，那么它们就全部都在全局作用域中。这样的坏处就是很容易撞车、冲突。 // 张三写的代码中 var data = {a: 100} // 李四写的代码中 var data = {x: true} 这就是为何 jQuery、Zepto 等库的源码，所有的代码都会放在(function(){....})()中。因为放在里面的所有变量，都不会被外泄和暴露，不会污染到外面，不会对其他的库或者 JS 脚本造成影响。这是函数作用域的一个体现。 附：ES6 中开始加入了块级作用域，使用let定义变量即可，如下： if (true) { let name = 'zhangsan' } console.log(name) // 报错，因为let定义的name是在if这个块级作用域 作用域链 首先认识一下什么叫做 自由变量 。如下代码中，console.log(a)要得到a变量，但是在当前的作用域中没有定义a（可对比一下b）。当前作用域没有定义的变量，这成为 自由变量 。自由变量如何得到 —— 向父级作用域寻找。 var a = 100 function fn() { var b = 200 console.log(a) console.log(b) } fn() 如果父级也没呢？再一层一层向上寻找，直到找到全局作用域还是没找到，就宣布放弃。这种一层一层的关系，就是 作用域链 。 var a = 100 function F1() { var b = 200 function F2() { var c = 300 console.log(a) // 自由变量，顺作用域链向父作用域找 console.log(b) // 自由变量，顺作用域链向父作用域找 console.log(c) // 本作用域的变量 } F2() } F1() 闭包 讲完这些内容，我们再来看一个例子，通过例子来理解闭包。 function F1() { var a = 100 return function () { console.log(a) } } var f1 = F1() var a = 200 f1() 自由变量将从作用域链中去寻找，但是 依据的是函数定义时的作用域链，而不是函数执行时，以上这个例子就是闭包。闭包主要有两个应用场景： 函数作为返回值，上面的例子就是 函数作为参数传递，看以下例子 function F1() { var a = 100 return function () { console.log(a) } } function F2(f1) { var a = 200 console.log(f1()) } var f1 = F1() F2(f1) 至此，对应着「作用域和闭包」这部分一开始的点击弹出alert的代码再看闭包，就很好理解了。 异步 异步和同步也是面试中常考的内容，下面笔者来讲解下同步和异步的区别。 同步 vs 异步 先看下面的 demo，根据程序阅读起来表达的意思，应该是先打印100，1秒钟之后打印200，最后打印300。但是实际运行根本不是那么回事。 console.log(100) setTimeout(function () { console.log(200) }, 1000) console.log(300) 再对比以下程序。先打印100，再弹出200（等待用户确认），最后打印300。这个运行效果就符合预期要求。 console.log(100) alert(200) // 1秒钟之后点击确认 console.log(300) 这俩到底有何区别？—— 第一个示例中间的步骤根本没有阻塞接下来程序的运行，而第二个示例却阻塞了后面程序的运行。前面这种表现就叫做 异步（后面这个叫做 同步 ），即不会阻塞后面程序的运行。 异步和单线程 JS 需要异步的根本原因是 JS 是单线程运行的，即在同一时间只能做一件事，不能“一心二用”。 一个 Ajax 请求由于网络比较慢，请求需要 5 秒钟。如果是同步，这 5 秒钟页面就卡死在这里啥也干不了了。异步的话，就好很多了，5 秒等待就等待了，其他事情不耽误做，至于那 5 秒钟等待是网速太慢，不是因为 JS 的原因。 讲到单线程，我们再来看个真题： 题目：讲解下面代码的执行过程和结果 var a = true; setTimeout(function(){ a = false; }, 100) while(a){ console.log('while执行了') } 这是一个很有迷惑性的题目，不少候选人认为100ms之后，由于a变成了false，所以while就中止了，实际不是这样，因为JS是单线程的，所以进入while循环之后，没有「时间」（线程）去跑定时器了，所以这个代码跑起来是个死循环！ 前端异步的场景 定时 setTimeout setInterval 网络请求，如 Ajax 加载 Ajax 代码示例 console.log('start') $.get('./data1.json', function (data1) { console.log(data1) }) console.log('end') img 代码示例（常用于打点统计） console.log('start') var img = document.createElement('img') // 或者 img = new Image() img.onload = function () { console.log('loaded') img.onload = null } img.src = '/xxx.png' console.log('end') ES6/7 新标准的考查 题目：ES6 箭头函数中的this和普通函数中的有什么不同 箭头函数 箭头函数是 ES6 中新的函数定义形式，function name(arg1, arg2) {...}可以使用(arg1, arg2) => {...}来定义。示例如下： // JS 普通函数 var arr = [1, 2, 3] arr.map(function (item) { console.log(index) return item + 1 }) // ES6 箭头函数 const arr = [1, 2, 3] arr.map((item, index) => { console.log(index) return item + 1 }) 箭头函数存在的意义，第一写起来更加简洁，第二可以解决 ES6 之前函数执行中this是全局变量的问题，看如下代码 function fn() { console.log('real', this) // {a: 100} ，该作用域下的 this 的真实的值 var arr = [1, 2, 3] // 普通 JS arr.map(function (item) { console.log('js', this) // window 。普通函数，这里打印出来的是全局变量，令人费解 return item + 1 }) // 箭头函数 arr.map(item => { console.log('es6', this) // {a: 100} 。箭头函数，这里打印的就是父作用域的 this return item + 1 }) } fn.call({a: 100}) 题目：ES6 模块化如何使用？ Module ES6 中模块化语法更加简洁，直接看示例。 如果只是输出一个唯一的对象，使用export default即可，代码如下 // 创建 util1.js 文件，内容如 export default { a: 100 } // 创建 index.js 文件，内容如 import obj from './util1.js' console.log(obj) 如果想要输出许多个对象，就不能用default了，且import时候要加{...}，代码如下 // 创建 util2.js 文件，内容如 export function fn1() { alert('fn1') } export function fn2() { alert('fn2') } // 创建 index.js 文件，内容如 import { fn1, fn2 } from './util2.js' fn1() fn2() 题目：ES6 class 和普通构造函数的区别 class class 其实一直是 JS 的关键字（保留字），但是一直没有正式使用，直到 ES6 。 ES6 的 class 就是取代之前构造函数初始化对象的形式，从语法上更加符合面向对象的写法。例如： JS 构造函数的写法 function MathHandle(x, y) { this.x = x; this.y = y; } MathHandle.prototype.add = function () { return this.x + this.y; }; var m = new MathHandle(1, 2); console.log(m.add()) 用 ES6 class 的写法 class MathHandle { constructor(x, y) { this.x = x; this.y = y; } add() { return this.x + this.y; } } const m = new MathHandle(1, 2); console.log(m.add()) 注意以下几点，全都是关于 class 语法的： class 是一种新的语法形式，是class Name {...}这种形式，和函数的写法完全不一样 两者对比，构造函数函数体的内容要放在 class 中的constructor函数中，constructor即构造器，初始化实例时默认执行 class 中函数的写法是add() {...}这种形式，并没有function关键字 使用 class 来实现继承就更加简单了，至少比构造函数实现继承简单很多。看下面例子 JS 构造函数实现继承 // 动物 function Animal() { this.eat = function () { console.log('animal eat') } } // 狗 function Dog() { this.bark = function () { console.log('dog bark') } } Dog.prototype = new Animal() // 哈士奇 var hashiqi = new Dog() ES6 class 实现继承 class Animal { constructor(name) { this.name = name } eat() { console.log(`${this.name} eat`) } } class Dog extends Animal { constructor(name) { super(name) this.name = name } say() { console.log(`${this.name} say`) } } const dog = new Dog('哈士奇') dog.say() dog.eat() 注意以下两点： 使用extends即可实现继承，更加符合经典面向对象语言的写法，如 Java 子类的constructor一定要执行super()，以调用父类的constructor 题目：ES6 中新增的数据类型有哪些？ Set 和 Map Set 和 Map 都是 ES6 中新增的数据结构，是对当前 JS 数组和对象这两种重要数据结构的扩展。由于是新增的数据结构，目前尚未被大规模使用，但是作为前端程序员，提前了解是必须做到的。先总结一下两者最关键的地方： Set 类似于数组，但数组可以允许元素重复，Set 不允许元素重复 Map 类似于对象，但普通对象的 key 必须是字符串或者数字，而 Map 的 key 可以是任何数据类型 Set Set 实例不允许元素有重复，可以通过以下示例证明。可以通过一个数组初始化一个 Set 实例，或者通过add添加元素，元素不能重复，重复的会被忽略。 // 例1 const set = new Set([1, 2, 3, 4, 4]); console.log(set) // Set(4) {1, 2, 3, 4} // 例2 const set = new Set(); [2, 3, 5, 4, 5, 8, 8].forEach(item => set.add(item)); for (let item of set) { console.log(item); } // 2 3 5 4 8 Set 实例的属性和方法有 size：获取元素数量。 add(value)：添加元素，返回 Set 实例本身。 delete(value)：删除元素，返回一个布尔值，表示删除是否成功。 has(value)：返回一个布尔值，表示该值是否是 Set 实例的元素。 clear()：清除所有元素，没有返回值。 const s = new Set(); s.add(1).add(2).add(2); // 添加元素 s.size // 2 s.has(1) // true s.has(2) // true s.has(3) // false s.delete(2); s.has(2) // false s.clear(); console.log(s); // Set(0) {} Set 实例的遍历，可使用如下方法 keys()：返回键名的遍历器。 values()：返回键值的遍历器。不过由于 Set 结构没有键名，只有键值（或者说键名和键值是同一个值），所以keys()和values()返回结果一致。 entries()：返回键值对的遍历器。 forEach()：使用回调函数遍历每个成员。 let set = new Set(['aaa', 'bbb', 'ccc']); for (let item of set.keys()) { console.log(item); } // aaa // bbb // ccc for (let item of set.values()) { console.log(item); } // aaa // bbb // ccc for (let item of set.entries()) { console.log(item); } // [\"aaa\", \"aaa\"] // [\"bbb\", \"bbb\"] // [\"ccc\", \"ccc\"] set.forEach((value, key) => console.log(key + ' : ' + value)) // aaa : aaa // bbb : bbb // ccc : ccc Map Map 的用法和普通对象基本一致，先看一下它能用非字符串或者数字作为 key 的特性。 const map = new Map(); const obj = {p: 'Hello World'}; map.set(obj, 'OK') map.get(obj) // \"OK\" map.has(obj) // true map.delete(obj) // true map.has(obj) // false 需要使用new Map()初始化一个实例，下面代码中set get has delete顾名即可思义（下文也会演示）。其中，map.set(obj, 'OK')就是用对象作为的 key （不光可以是对象，任何数据类型都可以），并且后面通过map.get(obj)正确获取了。 Map 实例的属性和方法如下： size：获取成员的数量 set：设置成员 key 和 value get：获取成员属性值 has：判断成员是否存在 delete：删除成员 clear：清空所有 const map = new Map(); map.set('aaa', 100); map.set('bbb', 200); map.size // 2 map.get('aaa') // 100 map.has('aaa') // true map.delete('aaa') map.has('aaa') // false map.clear() Map 实例的遍历方法有： keys()：返回键名的遍历器。 values()：返回键值的遍历器。 entries()：返回所有成员的遍历器。 forEach()：遍历 Map 的所有成员。 const map = new Map(); map.set('aaa', 100); map.set('bbb', 200); for (let key of map.keys()) { console.log(key); } // \"aaa\" // \"bbb\" for (let value of map.values()) { console.log(value); } // 100 // 200 for (let item of map.entries()) { console.log(item[0], item[1]); } // aaa 100 // bbb 200 // 或者 for (let [key, value] of map.entries()) { console.log(key, value); } // aaa 100 // bbb 200 Promise Promise是 CommonJS 提出来的这一种规范，有多个版本，在 ES6 当中已经纳入规范，原生支持 Promise 对象，非 ES6 环境可以用类似 Bluebird、Q 这类库来支持。 Promise 可以将回调变成链式调用写法，流程更加清晰，代码更加优雅。 简单归纳下 Promise：三个状态、两个过程、一个方法，快速记忆方法：3-2-1 三个状态：pending、fulfilled、rejected 两个过程： pending→fulfilled（resolve） pending→rejected（reject） 一个方法：then 当然还有其他概念，如catch、 Promise.all/race，这里就不展开了。 关于 ES6/7 的考查内容还有很多，本小节就不逐一介绍了，如果想继续深入学习，可以在线看《ES6入门》。 小结 本小节主要总结了 ES 基础语法中面试经常考查的知识点，包括之前就考查较多的原型、异步、作用域，以及 ES6 的一些新内容，这些知识点希望大家都要掌握。 "},"Web前端面试指南与高频考题解析/02.一面2：JS-Web-API知识点与高频考题解析.html":{"url":"Web前端面试指南与高频考题解析/02.一面2：JS-Web-API知识点与高频考题解析.html","title":"02.一面2：JS-Web-API知识点与高频考题解析","keywords":"","body":"一面 2：JS-Web-API 知识点与高频考题解析 除 ES 基础之外，Web 前端经常会用到一些跟浏览器相关的 API，接下来我们一起梳理一下。 知识点梳理 BOM 操作 DOM 操作 事件绑定 Ajax 存储 BOM BOM（浏览器对象模型）是浏览器本身的一些信息的设置和获取，例如获取浏览器的宽度、高度，设置让浏览器跳转到哪个地址。 navigator screen location history 这些对象就是一堆非常简单粗暴的 API，没任何技术含量，讲起来一点意思都没有，大家去 MDN 或者 w3school 这种网站一查就都明白了。面试的时候，面试官基本不会出太多这方面的题目，因为只要基础知识过关了，这些 API 即便你记不住，上网一查也都知道了。下面列举一下常用功能的代码示例 获取浏览器特性（即俗称的UA）然后识别客户端，例如判断是不是 Chrome 浏览器 var ua = navigator.userAgent var isChrome = ua.indexOf('Chrome') console.log(isChrome) 获取屏幕的宽度和高度 console.log(screen.width) console.log(screen.height) 获取网址、协议、path、参数、hash 等 // 例如当前网址是 https://juejin.im/timeline/frontend?a=10&b=10#some console.log(location.href) // https://juejin.im/timeline/frontend?a=10&b=10#some console.log(location.protocol) // https: console.log(location.pathname) // /timeline/frontend console.log(location.search) // ?a=10&b=10 console.log(location.hash) // #some 另外，还有调用浏览器的前进、后退功能等 history.back() history.forward() DOM 题目：DOM 和 HTML 区别和联系 什么是 DOM 讲 DOM 先从 HTML 讲起，讲 HTML 先从 XML 讲起。XML 是一种可扩展的标记语言，所谓可扩展就是它可以描述任何结构化的数据，它是一棵树！ Tove Jani Reminder Don't forget me this weekend! HTML 是一个有既定标签标准的 XML 格式，标签的名字、层级关系和属性，都被标准化（否则浏览器无法解析）。同样，它也是一棵树。 Document this is p 我们开发完的 HTML 代码会保存到一个文档中（一般以.html或者.htm结尾），文档放在服务器上，浏览器请求服务器，这个文档被返回。因此，最终浏览器拿到的是一个文档而已，文档的内容就是 HTML 格式的代码。 但是浏览器要把这个文档中的 HTML 按照标准渲染成一个页面，此时浏览器就需要将这堆代码处理成自己能理解的东西，也得处理成 JS 能理解的东西，因为还得允许 JS 修改页面内容呢。 基于以上需求，浏览器就需要把 HTML 转变成 DOM，HTML 是一棵树，DOM 也是一棵树。对 DOM 的理解，可以暂时先抛开浏览器的内部因素，先从 JS 着手，即可以认为 DOM 就是 JS 能识别的 HTML 结构，一个普通的 JS 对象或者数组。 获取 DOM 节点 最常用的 DOM API 就是获取节点，其中常用的获取方法如下面代码示例： // 通过 id 获取 var div1 = document.getElementById('div1') // 元素 // 通过 tagname 获取 var divList = document.getElementsByTagName('div') // 集合 console.log(divList.length) console.log(divList[0]) // 通过 class 获取 var containerList = document.getElementsByClassName('container') // 集合 // 通过 CSS 选择器获取 var pList = document.querySelectorAll('p') // 集合 题目：property 和 attribute 的区别是什么？ property DOM 节点就是一个 JS 对象，它符合之前讲述的对象的特征 —— 可扩展属性，因为 DOM 节点本质上也是一个 JS 对象。因此，如下代码所示，p可以有style属性，有className nodeName nodeType属性。注意，这些都是 JS 范畴的属性，符合 JS 语法标准的。 var pList = document.querySelectorAll('p') var p = pList[0] console.log(p.style.width) // 获取样式 p.style.width = '100px' // 修改样式 console.log(p.className) // 获取 class p.className = 'p1' // 修改 class // 获取 nodeName 和 nodeType console.log(p.nodeName) console.log(p.nodeType) attribute property 的获取和修改，是直接改变 JS 对象，而 attribute 是直接改变 HTML 的属性，两种有很大的区别。attribute 就是对 HTML 属性的 get 和 set，和 DOM 节点的 JS 范畴的 property 没有关系。 var pList = document.querySelectorAll('p') var p = pList[0] p.getAttribute('data-name') p.setAttribute('data-name', 'juejin') p.getAttribute('style') p.setAttribute('style', 'font-size:30px;') 而且，get 和 set attribute 时，还会触发 DOM 的查询或者重绘、重排，频繁操作会影响页面性能。 题目：DOM 操作的基本 API 有哪些？ DOM 树操作 新增节点 var div1 = document.getElementById('div1') // 添加新节点 var p1 = document.createElement('p') p1.innerHTML = 'this is p1' div1.appendChild(p1) // 添加新创建的元素 // 移动已有节点。注意，这里是“移动”，并不是拷贝 var p2 = document.getElementById('p2') div1.appendChild(p2) 获取父元素 var div1 = document.getElementById('div1') var parent = div1.parentElement 获取子元素 var div1 = document.getElementById('div1') var child = div1.childNodes 删除节点 var div1 = document.getElementById('div1') var child = div1.childNodes div1.removeChild(child[0]) 还有其他操作的API，例如获取前一个节点、获取后一个节点等，但是面试过程中经常考到的就是上面几个。 事件 事件绑定 普通的事件绑定写法如下： var btn = document.getElementById('btn1') btn.addEventListener('click', function (event) { // event.preventDefault() // 阻止默认行为 // event.stopPropagation() // 阻止冒泡 console.log('clicked') }) 为了编写简单的事件绑定，可以编写通用的事件绑定函数。这里虽然比较简单，但是会随着后文的讲解，来继续完善和丰富这个函数。 // 通用的事件绑定函数 function bindEvent(elem, type, fn) { elem.addEventListener(type, fn) } var a = document.getElementById('link1') // 写起来更加简单了 bindEvent(a, 'click', function(e) { e.preventDefault() // 阻止默认行为 alert('clicked') }) 最后，如果面试被问到 IE 低版本兼容性问题，我劝你果断放弃这份工作机会。现在互联网流量都在 App 上， IE 占比越来越少，再去为 IE 浪费青春不值得，要尽量去做 App 相关的工作。 题目：什么是事件冒泡？ 事件冒泡 激活 取消 取消 取消 取消 取消 对于以上 HTML 代码结构，要求点击p1时候进入激活状态，点击其他任何都取消激活状态，如何实现？代码如下，注意看注释： var body = document.body bindEvent(body, 'click', function (e) { // 所有 p 的点击都会冒泡到 body 上，因为 DOM 结构中 body 是 p 的上级节点，事件会沿着 DOM 树向上冒泡 alert('取消') }) var p1 = document.getElementById('p1') bindEvent(p1, 'click', function (e) { e.stopPropagation() // 阻止冒泡 alert('激活') }) 如果我们在p1 div1 body中都绑定了事件，它是会根据 DOM 的结构来冒泡，从下到上挨个执行的。但是我们使用e.stopPropagation()就可以阻止冒泡 题目：如何使用事件代理？有何好处？ 事件代理 我们设定一种场景，如下代码，一个中包含了若干个，而且还能继续增加。那如何快捷方便地为所有绑定事件呢？ a1 a2 a3 a4 点击增加一个 a 标签 这里就会用到事件代理。我们要监听的事件，但要把具体的事件绑定到上，然后看事件的触发点是不是。 var div1 = document.getElementById('div1') div1.addEventListener('click', function (e) { // e.target 可以监听到触发点击事件的元素是哪一个 var target = e.target if (e.nodeName === 'A') { // 点击的是 元素 alert(target.innerHTML) } }) 我们现在完善一下之前写的通用事件绑定函数，加上事件代理。 function bindEvent(elem, type, selector, fn) { // 这样处理，可接收两种调用方式 bindEvent(div1, 'click', 'a', function () {...}) 和 bindEvent(div1, 'click', function () {...}) 这两种 if (fn == null) { fn = selector selector = null } // 绑定事件 elem.addEventListener(type, function (e) { var target if (selector) { // 有 selector 说明需要做事件代理 // 获取触发时间的元素，即 e.target target = e.target // 看是否符合 selector 这个条件 if (target.matches(selector)) { fn.call(target, e) } } else { // 无 selector ，说明不需要事件代理 fn(e) } }) } 然后这样使用，简单很多。 // 使用代理，bindEvent 多一个 'a' 参数 var div1 = document.getElementById('div1') bindEvent(div1, 'click', 'a', function (e) { console.log(this.innerHTML) }) // 不使用代理 var a = document.getElementById('a1') bindEvent(div1, 'click', function (e) { console.log(a.innerHTML) }) 最后，使用代理的优点如下： 使代码简洁 减少浏览器的内存占用 Ajax XMLHttpRequest 题目：手写 XMLHttpRequest 不借助任何库 这是很多奇葩的、个性的面试官经常用的手段。这种考查方式存在很多争议，但是你不能完全说它是错误的，毕竟也是考查对最基础知识的掌握情况。 var xhr = new XMLHttpRequest() xhr.onreadystatechange = function () { // 这里的函数异步执行，可参考之前 JS 基础中的异步模块 if (xhr.readyState == 4) { if (xhr.status == 200) { alert(xhr.responseText) } } } xhr.open(\"GET\", \"/api\", false) xhr.send(null) 当然，使用 jQuery、Zepto 或 Fetch 等库来写就更加简单了，这里不再赘述。 状态码说明 上述代码中，有两处状态码需要说明。xhr.readyState是浏览器判断请求过程中各个阶段的，xhr.status是 HTTP 协议中规定的不同结果的返回状态说明。 xhr.readyState的状态码说明： 0 -代理被创建，但尚未调用 open() 方法。 1 -open() 方法已经被调用。 2 -send() 方法已经被调用，并且头部和状态已经可获得。 3 -下载中， responseText 属性已经包含部分数据。 4 -下载操作已完成 题目：HTTP 协议中，response 的状态码，常见的有哪些？ xhr.status即 HTTP 状态码，有 2xx 3xx 4xx 5xx 这几种，比较常用的有以下几种： 200 正常 3xx 301 永久重定向。如http://xxx.com这个 GET 请求（最后没有/），就会被301到http://xxx.com/（最后是/） 302 临时重定向。临时的，不是永久的 304 资源找到但是不符合请求条件，不会返回任何主体。如发送 GET 请求时，head 中有If-Modified-Since: xxx（要求返回更新时间是xxx时间之后的资源），如果此时服务器 端资源未更新，则会返回304，即不符合要求 404 找不到资源 5xx 服务器端出错了 看完要明白，为何上述代码中要同时满足xhr.readyState == 4和xhr.status == 200。 Fetch API 目前已经有一个获取 HTTP 请求更加方便的 API：Fetch，通过Fetch提供的fetch()这个全局函数方法可以很简单地发起异步请求，并且支持Promise的回调。但是 Fetch API 是比较新的 API，具体使用的时候还需要查查 caniuse，看下其浏览器兼容情况。 看一个简单的例子： fetch('some/api/data.json', { method:'POST', //请求类型 GET、POST headers:{}, // 请求的头信息，形式为 Headers 对象或 ByteString body:{}, //请求发送的数据 blob、BufferSource、FormData、URLSearchParams（get 或head 方法中不能包含 body） mode:'', //请求的模式，是否跨域等，如 cors、 no-cors 或 same-origin credentials:'', //cookie 的跨域策略，如 omit、same-origin 或 include cache:'', //请求的 cache 模式: default、no-store、reload、no-cache、 force-cache 或 only-if-cached }).then(function(response) { ... }); Fetch 支持headers定义，通过headers自定义可以方便地实现多种请求方法（ PUT、GET、POST 等）、请求头（包括跨域）和cache策略等；除此之外还支持 response（返回数据）多种类型，比如支持二进制文件、字符串和formData等。 跨域 题目：如何实现跨域？ 浏览器中有 同源策略 ，即一个域下的页面中，无法通过 Ajax 获取到其他域的接口。例如有一个接口http://m.juejin.com/course/ajaxcourserecom?cid=459，你自己的一个页面http://www.yourname.com/page1.html中的 Ajax 无法获取这个接口。这正是命中了“同源策略”。如果浏览器哪些地方忽略了同源策略，那就是浏览器的安全漏洞，需要紧急修复。 url 哪些地方不同算作跨域？ 协议 域名 端口 但是 HTML 中几个标签能逃避过同源策略——、、，这三个标签的src/href可以加载其他域的资源，不受同源策略限制。 因此，这使得这三个标签可以做一些特殊的事情。 可以做打点统计，因为统计方并不一定是同域的，在讲解 JS 基础知识异步的时候有过代码示例。除了能跨域之外，几乎没有浏览器兼容问题，它是一个非常古老的标签。 和可以使用 CDN，CDN 基本都是其他域的链接。 另外还可以实现 JSONP，能获取其他域接口的信息，接下来马上讲解。 但是请注意，所有的跨域请求方式，最终都需要信息提供方来做出相应的支持和改动，也就是要经过信息提供方的同意才行，否则接收方是无法得到它们的信息的，浏览器是不允许的。 解决跨域 - JSONP 首先，有一个概念你要明白，例如访问http://coding.m.juejin.com/classindex.html的时候，服务器端就一定有一个classindex.html文件吗？—— 不一定，服务器可以拿到这个请求，动态生成一个文件，然后返回。 同理，也不一定加载一个服务器端的静态文件，服务器也可以动态生成文件并返回。OK，接下来正式开始。 例如我们的网站和掘金网，肯定不是一个域。我们需要掘金网提供一个接口，供我们来获取。首先，我们在自己的页面这样定义 window.callback = function (data) { // 这是我们跨域得到信息 console.log(data) } 然后掘金网给我提供了一个http://coding.m.juejin.com/api.js，内容如下（之前说过，服务器可动态生成内容） callback({x:100, y:200}) 最后我们在页面中加入，那么这个js加载之后，就会执行内容，我们就得到内容了。 解决跨域 - 服务器端设置 http header 这是需要在服务器端设置的，作为前端工程师我们不用详细掌握，但是要知道有这么个解决方案。而且，现在推崇的跨域解决方案是这一种，比 JSONP 简单许多。 response.setHeader(\"Access-Control-Allow-Origin\", \"http://m.juejin.com/\"); // 第二个参数填写允许跨域的域名称，不建议直接写 \"*\" response.setHeader(\"Access-Control-Allow-Headers\", \"X-Requested-With\"); response.setHeader(\"Access-Control-Allow-Methods\", \"PUT,POST,GET,DELETE,OPTIONS\"); // 接收跨域的cookie response.setHeader(\"Access-Control-Allow-Credentials\", \"true\"); 存储 题目：cookie 和 localStorage 有何区别？ cookie cookie 本身不是用来做服务器端存储的（计算机领域有很多这种“狗拿耗子”的例子，例如 CSS 中的 float），它是设计用来在服务器和客户端进行信息传递的，因此我们的每个 HTTP 请求都带着 cookie。但是 cookie 也具备浏览器端存储的能力（例如记住用户名和密码），因此就被开发者用上了。 使用起来也非常简单，document.cookie = ....即可。 但是 cookie 有它致命的缺点： 存储量太小，只有 4KB 所有 HTTP 请求都带着，会影响获取资源的效率 API 简单，需要封装才能用 localStorage 和 sessionStorage 后来，HTML5 标准就带来了sessionStorage和localStorage，先拿localStorage来说，它是专门为了浏览器端缓存而设计的。其优点有： 存储量增大到 5MB 不会带到 HTTP 请求中 API 适用于数据存储 localStorage.setItem(key, value) localStorage.getItem(key) sessionStorage的区别就在于它是根据 session 过去时间而实现，而localStorage会永久有效，应用场景不同。例如，一些需要及时失效的重要信息放在sessionStorage中，一些不重要但是不经常设置的信息，放在localStorage中。 另外告诉大家一个小技巧，针对localStorage.setItem，使用时尽量加入到try-catch中，某些浏览器是禁用这个 API 的，要注意。 小结 本小节总结了 W3C 标准中 Web-API 部分，面试中常考的知识点，这些也是日常开发中最常用的 API 和知识。 "},"Web前端面试指南与高频考题解析/03.一面3：CSS-HTML知识点与高频考题解析.html":{"url":"Web前端面试指南与高频考题解析/03.一面3：CSS-HTML知识点与高频考题解析.html","title":"03.一面3：CSS-HTML知识点与高频考题解析","keywords":"","body":"一面 3：CSS-HTML 知识点与高频考题解析 CSS 和 HTML 是网页开发中布局相关的组成部分，涉及的内容比较多和杂乱，本小节重点介绍下常考的知识点。 知识点梳理 选择器的权重和优先级 盒模型 盒子大小计算 margin 的重叠计算 浮动float 浮动布局概念 清理浮动 定位position 文档流概念 定位分类 fixed 定位特点 绝对定位计算方式 flex布局 如何实现居中对齐？ 理解语义化 CSS3 动画 重绘和回流 选择器的权重和优先级 CSS 选择器有很多，不同的选择器的权重和优先级不一样，对于一个元素，如果存在多个选择器，那么就需要根据权重来计算其优先级。 权重分为四级，分别是： 代表内联样式，如style=\"xxx\"，权值为 1000； 代表 ID 选择器，如#content，权值为 100； 代表类、伪类和属性选择器，如.content、:hover、[attribute]，权值为 10； 代表元素选择器和伪元素选择器，如div、p，权值为 1。 需要注意的是：通用选择器（*）、子选择器（>）和相邻同胞选择器（+）并不在这四个等级中，所以他们的权值都为 0。 权重值大的选择器其优先级也高，相同权重的优先级又遵循后定义覆盖前面定义的情况。 盒模型 什么是“盒子” 初学 CSS 的朋友，一开始学 CSS 基础知识的时候一定学过padding border和margin，即内边距、边框和外边距。它们三者就构成了一个“盒子”。就像我们收到的快递，本来买了一部小小的手机，收到的却是那么大一个盒子。因为手机白色的包装盒和手机机器之间有间隔层（内边距），手机白色盒子有厚度，虽然很薄（边框），盒子和快递箱子之间还有一层泡沫板（外边距）。这就是一个典型的盒子。 如上图，真正的内容就是这些文字，文字外围有 10px 的内边距，5px 的边框，10px 的外边距。看到盒子了吧？ 题目：盒子模型的宽度如何计算 固定宽度的盒子 之前看过一篇文章，叫做《浏览器工作原理：新式网络浏览器幕后揭秘》， 文章言简意赅的介绍的浏览器的工作过程，web前端 如上图，得到网页效果之后，我们可以用截图工具来量一下文字内容的宽度。发现，文字内容的宽度刚好是 300px，也就是我们设置的宽度。 因此，在盒子模型中，我们设置的宽度都是内容宽度，不是整个盒子的宽度。而整个盒子的宽度是：（内容宽度 + border宽度 + padding宽度 + margin宽度）之和。这样我们改四个中的其中一个，都会导致盒子宽度的改变。这对我们来说不友好。 没关系，这个东西不友好早就有人发现了，而且已经解决，下文再说。 充满父容器的盒子 默认情况下，div是display:block，宽度会充满整个父容器。如下图： 之前看过一篇文章，叫做《浏览器工作原理：新式网络浏览器幕后揭秘》， 文章言简意赅的介绍的浏览器的工作过程，web前端 之前看过一篇文章，叫做《浏览器工作原理：新式网络浏览器幕后揭秘》， 文章言简意赅的介绍的浏览器的工作过程，web前端 但是别忘记，这个 div 是个盒子模型，它的整个宽度包括（内容宽度 + border宽度 + padding宽度 + margin宽度），整个的宽度充满父容器。 问题就在这里。如果父容器宽度不变，我们手动增大margin、border或padding其中一项的宽度值，都会导致内容宽度的减少。极端情况下，如果内容的宽度压缩到不能再压缩了（例如一个字的宽度），那么浏览器会强迫增加父容器的宽度。这可不是我们想要看到的。 包裹内容的盒子 这种情况下比较简单，内容的宽度按照内容计算，盒子的宽度将在内容宽度的基础上再增加（padding宽度 + border宽度 + margin宽度）之和。 之前看过一篇文章，叫做《浏览器工作原理：新式网络浏览器幕后揭秘》 box-sizing:border-box 前面提到，为盒子模型设置宽度，结果只是设置了内容的宽度，这个不合理。如何解决这一问题？答案就是为盒子指定样式：box-sizing:border-box。 之前看过一篇文章，叫做《浏览器工作原理：新式网络浏览器幕后揭秘》 上图中，为div设置了box-sizing:border-box之后，300px 的宽度是内容 + padding + 边框的宽度（不包括margin），这样就比较符合我们的实际要求了。建议大家在为系统写 CSS 时候，第一个样式是： * { box-sizing:border-box; } 大名鼎鼎的 Bootstrap 也把box-sizing:border-box加入到它的*选择器中，我们为什么不这样做呢？ 纵向 margin 重叠 这里提到 margin，就不得不提一下 margin 的这一特性——纵向重叠。如的纵向 margin 是 16px，那么两个之间纵向的距离是多少？—— 按常理来说应该是 16 + 16 = 32px，但是答案仍然是 16px。因为纵向的 margin 是会重叠的，如果两者不一样大的话，大的会把小的“吃掉”。 浮动float float 用于网页布局比较多，使用起来也比较简单，这里总结了一些比较重要、需要注意的知识点，供大家参考。 误解和误用 float 被设计出来的初衷是用于文字环绕效果，即一个图片一段文字，图片float:left之后，文字会环绕图片。 一段文字一段文字一段文字一段文字一段文字一段文字一段文字一段文字一段文字 但是，后来大家发现结合float + div可以实现之前通过table实现的网页布局，因此就被“误用”于网页布局了。 题目：为何 float 会导致父元素塌陷？ 破坏性 float 的破坏性 —— float 破坏了父标签的原本结构，使得父标签出现了坍塌现象。导致这一现象的最根本原因在于：被设置了 float 的元素会脱离文档流。其根本原因在于 float 的设计初衷是解决文字环绕图片的问题。大家要记住 float 的这个影响。 包裹性 包裹性也是 float 的一个非常重要的特性，大家用 float 时一定要熟知这一特性。咱们还是先从一个小例子看起： 如上图，普通的 div 如果没有设置宽度，它会撑满整个屏幕，在之前的盒子模型那一节也讲到过。而如果给 div 增加float:left之后，它突然变得紧凑了，宽度发生了变化，把内容中的三个字包裹了——这就是包裹性。为 div 设置了 float 之后，其宽度会自动调整为包裹住内容宽度，而不是撑满整个父容器。 注意，此时 div 虽然体现了包裹性，但是它的 display 样式是没有变化的，还是display: block。 float 为什么要具有包裹性？其实答案还是得从 float 的设计初衷来寻找，float 是被设计用于实现文字环绕效果的。文字环绕图片比较好理解，但是如果想要让文字环绕一个 div 呢？此时 div 不被“包裹”起来的话，就无法实现环绕效果了。 清空格 float 还有一个大家可能不是很熟悉的特性——清空格。按照惯例，咱还是先举例子说明。 加上float:left之后： 上面第一张图中，正常的 img 中间是会有空格的，因为多个 img 标签会有换行，而浏览器识别换行为空格，这也是很正常的。第二张图中，为 img 增加了float:left的样式，这就使得 img 之间没有了空格，4 个 img 紧紧挨着。 如果大家之前没注意，现在想想之前写过的程序，是不是有这个特性。为什么 float 适合用于网页排版（俗称“砌砖头”）？就是因为 float 排版出来的网页严丝合缝，中间连个苍蝇都飞不进去。 “清空格”这一特性的根本原因是 float 会导致节点脱离文档流结构。它都不属于文档流结构了，那么它身边的什么换行、空格就都和它没了关系，它就尽量往一边靠拢，能靠多近就靠多近，这就是清空格的本质。 题目：手写 clearfix clearfix 清除浮动的影响，一般使用的样式如下，统称clearfix代码。所有 float 元素的父容器，一般情况下都应该加clearfix这个 class。 .clearfix:after { content: ''; display: table; clear: both; } .clearfix { *zoom: 1; /* 兼容 IE 低版本 */ } 小结 float 的设计初衷是解决文字环绕图片的问题，后来误打误撞用于做布局，因此有许多不合适或者需要注意的地方，上文基本都讲到了需要的知识点。如果是刚开始接触 float 的同学，学完上面的基础知识之后，还应该做一些练习实战一下 —— 经典的“圣杯布局”和“双飞翼布局”。这里就不再展开讲了，网上资料非常多，例如浅谈面试中常考的两种经典布局——圣杯与双飞翼（此文的最后两张图清晰地展示了这两种布局）。 定位position position 用于网页元素的定位，可设置 static/relative/absolute/fixed 这些值，其中 static 是默认值，不用介绍。 题目：relative 和 absolute 有何区别？ relative 相对定位 relative 可以用一个例子很轻松地演示出来。例如我们写 4 个，出来的样子大家不用看也能知道。 第一段文字 第二段文字 第三段文字 第四段文字 然后我们在第三个上面，加上position:relative并且设置left和top值，看这个有什么变化。 第一段文字 第二段文字 第三段文字 第四段文字 上图中，大家应该要识别出两个信息（相信大部分人会忽略第二个信息） 第三个发生了位置变化，分别向右向下移动了10px； 其他的三个位置没有发生变化，这一点也很重要。 可见，relative 会导致自身位置的相对变化，而不会影响其他元素的位置、大小。这是 relative 的要点之一。还有第二个要点，就是 relative 产生一个新的定位上下文。下文有关于定位上下文的详细介绍，这里可以先通过一个例子来展示一下区别： 注意看这两图的区别，下文将有解释。 absolute 还是先写一个基本的 demo。 第一段文字 第二段文字 第三段文字 第四段文字 然后，我们把第三个改为position:absolute;，看看会发生什么变化。 从上面的结果中，我们能看出几点信息： absolute 元素脱离了文档结构。和 relative 不同，其他三个元素的位置重新排列了。只要元素会脱离文档结构，它就会产生破坏性，导致父元素坍塌。（此时你应该能立刻想起来，float 元素也会脱离文档结构。） absolute 元素具有“包裹性”。之前的宽度是撑满整个屏幕的，而此时的宽度刚好是内容的宽度。 absolute 元素具有“跟随性”。虽然 absolute 元素脱离了文档结构，但是它的位置并没有发生变化，还是老老实实地呆在它原本的位置，因为我们此时没有设置 top、left 的值。 absolute 元素会悬浮在页面上方，会遮挡住下方的页面内容。 最后，通过给 absolute元素设置 top、left 值，可自定义其内容，这个都是平时比较常用的了。这里需要注意的是，设置了 top、left 值时，元素是相对于最近的定位上下文来定位的，而不是相对于浏览器定位。 fixed 其实 fixed 和 absolute 是一样的，唯一的区别在于：absolute 元素是根据最近的定位上下文确定位置，而 fixed 根据 window （或者 iframe）确定位置。 题目：relative、absolute 和 fixed 分别依据谁来定位？ 定位上下文 relative 元素的定位永远是相对于元素自身位置的，和其他元素没关系，也不会影响其他元素。 fixed 元素的定位是相对于 window （或者 iframe）边界的，和其他元素没有关系。但是它具有破坏性，会导致其他元素位置的变化。 absolute 的定位相对于前两者要复杂许多。如果为 absolute 设置了 top、left，浏览器会根据什么去确定它的纵向和横向的偏移量呢？答案是浏览器会递归查找该元素的所有父元素，如果找到一个设置了position:relative/absolute/fixed的元素，就以该元素为基准定位，如果没找到，就以浏览器边界定位。如下两个图所示： flex布局 布局的传统解决方案基于盒子模型，依赖 display 属性 + position 属性 + float 属性。它对于那些特殊布局非常不方便，比如，垂直居中（下文会专门讲解）就不容易实现。在目前主流的移动端页面中，使用 flex 布局能更好地完成需求，因此 flex 布局的知识是必须要掌握的。 基本使用 任何一个容器都可以使用 flex 布局，代码也很简单。 .container { display: flex; } .item { border: 1px solid #000; flex: 1; } aaa bbb ccc ddd 注意，第三个的flex: 2，其他的的flex: 1，这样第二个的宽度就是其他的的两倍。 设计原理 设置了display: flex的元素，我们称为“容器”（flex container），其所有的子节点我们称为“成员”（flex item）。容器默认存在两根轴：水平的主轴（main axis）和垂直的交叉轴（cross axis）。主轴的开始位置（与边框的交叉点）叫做 main start，结束位置叫做 main end；交叉轴的开始位置叫做 cross start，结束位置叫做cross end。项目默认沿主轴排列。单个项目占据的主轴空间叫做 main size，占据的交叉轴空间叫做 cross size。 将以上文字和图片结合起来，再详细看一遍，这样就能理解 flex 的设计原理，才能更好地实际使用。 设置主轴的方向 flex-direction可决定主轴的方向，有四个可选值： row（默认值）：主轴为水平方向，起点在左端。 row-reverse：主轴为水平方向，起点在右端。 column：主轴为垂直方向，起点在上沿。 column-reverse：主轴为垂直方向，起点在下沿。 .box { flex-direction: column-reverse| column | row | row-reverse; } 以上代码设置的主轴方向，将依次对应下图： 设置主轴的对齐方式 justify-content属性定义了项目在主轴上的对齐方式，值如下： flex-start（默认值）：向主轴开始方向对齐。 flex-end：向主轴结束方向对齐。 center： 居中。 space-between：两端对齐，项目之间的间隔都相等。 space-around：每个项目两侧的间隔相等。所以，项目之间的间隔比项目与边框的间隔大一倍。 .box { justify-content: flex-start | flex-end | center | space-between | space-around; } 交叉轴的对齐方式 align-items属性定义项目在交叉轴上如何对齐，值如下： flex-start：交叉轴的起点对齐。 flex-end：交叉轴的终点对齐。 center：交叉轴的中点对齐。 baseline: 项目的第一行文字的基线对齐。 stretch（默认值）：如果项目未设置高度或设为 auto，将占满整个容器的高度。 .box { align-items: flex-start | flex-end | center | baseline | stretch; } 如何实现居中对齐？ 题目：如何实现水平居中？ 水平居中 inline 元素用text-align: center;即可，如下： .container { text-align: center; } block 元素可使用margin: auto;，PC 时代的很多网站都这么搞。 .container { text-align: center; } .item { width: 1000px; margin: auto; } 绝对定位元素可结合left和margin实现，但是必须知道宽度。 .container { position: relative; width: 500px; } .item { width: 300px; height: 100px; position: absolute; left: 50%; margin: -150px; } 题目：如何实现垂直居中？ 垂直居中 inline 元素可设置line-height的值等于height值，如单行文字垂直居中： .container { height: 50px; line-height: 50px; } 绝对定位元素，可结合left和margin实现，但是必须知道尺寸。 优点：兼容性好 缺点：需要提前知道尺寸 .container { position: relative; height: 200px; } .item { width: 80px; height: 40px; position: absolute; left: 50%; top: 50%; margin-top: -20px; margin-left: -40px; } 绝对定位可结合transform实现居中。 优点：不需要提前知道尺寸 缺点：兼容性不好 .container { position: relative; height: 200px; } .item { width: 80px; height: 40px; position: absolute; left: 50%; top: 50%; transform: translate(-50%, -50%); background: blue; } 绝对定位结合margin: auto，不需要提前知道尺寸，兼容性好。 .container { position: relative; height: 300px; } .item { width: 100px; height: 50px; position: absolute; left: 0; top: 0; right: 0; bottom: 0; margin: auto; } 其他的解决方案还有，不过没必要掌握太多，能说出上文的这几个解决方案即可。 理解语义化 题目：如何理解 HTML 语义化？ 所谓“语义”就是为了更易读懂，这要分两部分： 让人（写程序、读程序）更易读懂 让机器（浏览器、搜索引擎）更易读懂 让人更易读懂 对于人来说，代码可读性、语义化就是一个非常广泛的概念了，例如定义 JS 变量的时候使用更易读懂的名称，定义 CSS class 的时候也一样，例如length list等，而不是使用a b这种谁都看不懂的名称。 不过我们平常考查的“语义化”并不会考查这么广义、这么泛的问题，而是考查 HTML 的语义化，是为了更好地让机器读懂 HTML。 让机器更易读懂 HTML 符合 XML 标准，但又和 XML 不一样 —— HTML 不允许像 XML 那样自定义标签名称，HTML 有自己规定的标签名称。问题就在这里 —— HTML 为何要自己规定那么多标签名称呢，例如p div h1 ul等 —— 就是为了语义化。其实，如果你精通 CSS 的话，你完全可以全部用标签来实现所有的网页效果，其他的p h1 ul等标签可以一个都不用。但是我们不推荐这么做，这样做就失去了 HTML 语义化的意义。 拿搜索引擎来说，爬虫下载到我们网页的 HTML 代码，它如何更好地去理解网页的内容呢？—— 就是根据 HTML 既定的标签。h1标签就代表是标题；p里面的就是段落详细内容，权重肯定没有标题高；ul里面就是列表；strong就是加粗的强调的内容 …… 如果我们不按照 HTML 语义化来写，全部都用标签，那搜索引擎将很难理解我们网页的内容。 为了加强 HTML 语义化，HTML5 标准中又增加了header section article等标签。因此，书写 HTML 时，语义化是非常重要的，否则 W3C 也没必要辛辛苦苦制定出这些标准来。 CSS3 动画 CSS3 可以实现动画，代替原来的 Flash 和 JavaScript 方案。 首先，使用@keyframes定义一个动画，名称为testAnimation，如下代码，通过百分比来设置不同的 CSS 样式，规定动画的变化。所有的动画变化都可以这么定义出来。 @keyframes testAnimation { 0% {background: red; left:0; top:0;} 25% {background: yellow; left:200px; top:0;} 50% {background: blue; left:200px; top:200px;} 75% {background: green; left:0; top:200px;} 100% {background: red; left:0; top:0;} } 然后，针对一个 CSS 选择器来设置动画，例如针对div元素设置动画，如下： div { width: 100px; height: 50px; position: absolute; animation-name: myfirst; animation-duration: 5s; } animation-name对应到动画名称，animation-duration是动画时长，还有其他属性： animation-timing-function：规定动画的速度曲线。默认是ease animation-delay：规定动画何时开始。默认是 0 animation-iteration-count：规定动画被播放的次数。默认是 1 animation-direction：规定动画是否在下一周期逆向地播放。默认是normal animation-play-state ：规定动画是否正在运行或暂停。默认是running animation-fill-mode：规定动画执行之前和之后如何给动画的目标应用，默认是none，保留在最后一帧可以用forwards 题目：CSS 的transition和animation有何区别？ 首先transition和animation都可以做动效，从语义上来理解，transition是过渡，由一个状态过渡到另一个状态，比如高度100px过渡到200px；而animation是动画，即更专业做动效的，animation有帧的概念，可以设置关键帧keyframe，一个动画可以由多个关键帧多个状态过渡组成，另外animation也包含上面提到的多个属性。 重绘和回流 重绘和回流是面试题经常考的题目，也是性能优化当中应该注意的点，下面笔者简单介绍下。 重绘：指的是当页面中的元素不脱离文档流，而简单地进行样式的变化，比如修改颜色、背景等，浏览器重新绘制样式 回流：指的是处于文档流中 DOM 的尺寸大小、位置或者某些属性发生变化时，导致浏览器重新渲染部分或全部文档的情况 相比之下，回流要比重绘消耗性能开支更大。另外，一些属性的读取也会引起回流，比如读取某个 DOM 的高度和宽度，或者使用getComputedStyle方法。在写代码的时候要避免回流和重绘。比如在笔试中可能会遇见下面的题目： 题目：找出下面代码的优化点，并且优化它 var data = ['string1', 'string2', 'string3']; for(var i = 0; i ' + data[i] + ''; } 上面的代码在循环中每次都获取dom，然后对其内部的 HTML 进行累加li，每次都会操作 DOM 结构，可以改成使用documentFragment或者先遍历组成 HTML 的字符串，最后操作一次innerHTML。 小结 本小节总结了 CSS 和 HTML 常考的知识点，包括 CSS 中比较重要的定位、布局的知识，也介绍了一些 CSS3 的知识点概念和题目，以及 HTML 的语义化。 "},"Web前端面试指南与高频考题解析/04.一面4：从容应对算法题目.html":{"url":"Web前端面试指南与高频考题解析/04.一面4：从容应对算法题目.html","title":"04.一面4：从容应对算法题目","keywords":"","body":"一面 4：从容应对算法题目 由冯·诺依曼机组成我们知道：数据存储和运算是计算机工作的主要内容。程序=数据结构+算法，所以计算机类工程师必须掌握一定的数据结构和算法知识。 知识点梳理 常见的数据结构 栈、队列、链表 集合、字典、散列集 常见算法 递归 排序 枚举 算法复杂度分析 算法思维 分治 贪心 动态规划 高级数据结构 树、图 深度优先和广度优先搜索 本小节会带领大家快速过一遍数据结构和算法，重点讲解一些常考、前端会用到的算法和数据结构。 数据结构 数据结构决定了数据存储的空间和时间效率问题，数据的写入和提取速度要求也决定了应该选择怎样的数据结构。 根据对场景需求的不同，我们设计不同的数据结构，比如： 读得多的数据结构，应该想办法提高数据的读取效率，比如 IP 数据库，只需要写一次，剩下的都是读取； 读写都多的数据结构，要兼顾两者的需求平衡，比如 LRU Cache 算法。 算法是数据加工处理的方式，一定的算法会提升数据的处理效率。比如有序数组的二分查找，要比普通的顺序查找快很多，尤其是在处理大量数据的时候。 数据结构和算法是程序开发的通用技能，所以在任何面试中都可能会遇见。随着近几年 AI、大数据、小游戏越来越火，Web 前端职位难免会跟数据结构和算法打交道，面试中也会出现越来越多的算法题目。学习数据结构和算法也能够帮助我们打开思路，突破技能瓶颈。 前端常遇见的数据结构问题 现在我来梳理下前端常遇见的数据结构： 简单数据结构（必须理解掌握） 有序数据结构：栈、队列、链表，有序数据结构省空间（存储空间小） 无序数据结构：集合、字典、散列表，无序数据结构省时间（读取时间快） 复杂数据结构 树、堆 图 对于简单数据结构，在 ES 中对应的是数组（Array）和对象（Object）。可以想一下，数组的存储是有序的，对象的存储是无序的，但是我要在对象中根据key找到一个值是立即返回的，数组则需要查找的过程。 这里我通过一个真实面试题目来说明介绍下数据结构设计。 题目：使用 ECMAScript（JS）代码实现一个事件类Event，包含下面功能：绑定事件、解绑事件和派发事件。 在稍微复杂点的页面中，比如组件化开发的页面，同一个页面由两三个人来开发，为了保证组件的独立性和降低组件间耦合度，我们往往使用「订阅发布模式」，即组件间通信使用事件监听和派发的方式，而不是直接相互调用组件方法，这就是题目要求写的Event类。 这个题目的核心是一个事件类型对应回调函数的数据设计。为了实现绑定事件，我们需要一个_cache对象来记录绑定了哪些事件。而事件发生的时候，我们需要从_cache中读取出来事件回调，依次执行它们。一般页面中事件派发（读）要比事件绑定（写）多。所以我们设计的数据结构应该尽量地能够在事件发生时，更加快速地找到对应事件的回调函数们，然后执行。 经过这样一番考虑，我简单写了下代码实现： class Event { constructor() { // 存储事件的数据结构 // 为了查找迅速，使用了对象（字典） this._cache = {}; } // 绑定 on(type, callback) { // 为了按类查找方便和节省空间， // 将同一类型事件放到一个数组中 // 这里的数组是队列，遵循先进先出 // 即先绑定的事件先触发 let fns = (this._cache[type] = this._cache[type] || []); if (fns.indexOf(callback) === -1) { fns.push(callback); } return this; } // 触发 trigger(type, data) { let fns = this._cache[type]; if (Array.isArray(fns)) { fns.forEach((fn) => { fn(data); }); } return this; } // 解绑 off(type, callback) { let fns = this._cache[type]; if (Array.isArray(fns)) { if (callback) { let index = fns.indexOf(callback); if (index !== -1) { fns.splice(index, 1); } } else { //全部清空 fns.length = 0; } } return this; } } // 测试用例 const event = new Event(); event.on('test', (a) => { console.log(a); }); event.trigger('test', 'hello world'); event.off('test'); event.trigger('test', 'hello world'); 类似于树、堆、图这些高级数据结构，前端一般也不会考查太多，但是它们的查找方法却常考，后面介绍。高级数据应该平时多积累，好好理解，比如理解了堆是什么样的数据结构，在面试中遇见的「查找最大的 K 个数」这类算法问题，就会迎刃而解。 算法的效率是通过算法复杂度来衡量的 算法的好坏可以通过算法复杂度来衡量，算法复杂度包括时间复杂度和空间复杂度两个。时间复杂度由于好估算、好评估等特点，是面试中考查的重点。空间复杂度在面试中考查得不多。 常见的时间复杂度有： 常数阶 O(1) 对数阶 O(logN) 线性阶 O(n) 线性对数阶 O(nlogN) 平方阶 O(n^2) 立方阶 O(n^3) !k次方阶 O(n^k) 指数阶O(2^n) 随着问题规模 n 的不断增大，上述时间复杂度不断增大，算法的执行效率越低。 一般做算法复杂度分析的时候，遵循下面的技巧： 看看有几重循环，一般来说一重就是O(n)，两重就是 O(n^2)，以此类推 如果有二分，则为O(logN) 保留最高项，去除常数项 题目：分析下面代码的算法复杂度（为了方便，我已经在注释中加了代码分析） let i =0; // 语句执行一次 while (i 根据注释可以得到，算法复杂度为1 + n + n + n = 1 + 3n，去除常数项，为O(n)。 let number = 1; // 语句执行一次 while (number 上面代码while的跳出判断条件是number，而循环体内number增长速度是(2^n)，所以循环代码实际执行logN次，复杂度为：1 + 2 * logN = O(logN) for (let i = 0; i 上面代码是两个for循环嵌套，很容易得出复杂度为：O(n^2) 人人都要掌握的基础算法 枚举和递归是最最简单的算法，也是复杂算法的基础，人人都应该掌握！枚举相对比较简单，我们重点说下递归。 递归由下面两部分组成： 递归主体，就是要循环解决问题的代码 递归的跳出条件，递归不能一直递归下去，需要完成一定条件后跳出 关于递归有个经典的面试题目是： 实现 JS 对象的深拷贝 什么是深拷贝？ 「深拷贝」就是在拷贝数据的时候，将数据的所有引用结构都拷贝一份。简单的说就是，在内存中存在两个数据结构完全相同又相互独立的数据，将引用型类型进行复制，而不是只复制其引用关系。 分析下怎么做「深拷贝」： 首先假设深拷贝这个方法已经完成，为 deepClone 要拷贝一个数据，我们肯定要去遍历它的属性，如果这个对象的属性仍是对象，继续使用这个方法，如此往复 function deepClone(o1, o2) { for (let k in o2) { if (typeof o2[k] === 'object') { o1[k] = {}; deepClone(o1[k], o2[k]); } else { o1[k] = o2[k]; } } } // 测试用例 let obj = { a: 1, b: [1, 2, 3], c: {} }; let emptyObj = Object.create(null); deepClone(emptyObj, obj); console.log(emptyObj.a == obj.a); console.log(emptyObj.b == obj.b); 递归容易造成爆栈，尾部调用可以解决递归的这个问题，Chrome 的 V8 引擎做了尾部调用优化，我们在写代码的时候也要注意尾部调用写法。递归的爆栈问题可以通过将递归改写成枚举的方式来解决，就是通过for或者while来代替递归。 我们在使用递归的时候，要注意做优化，比如下面的题目。 题目：求斐波那契数列（兔子数列） 1,1,2,3,5,8,13,21,34,55,89...中的第 n 项 下面的代码中count记录递归的次数，我们看下两种差异性的代码中的count的值： let count = 0; function fn(n) { let cache = {}; function _fn(n) { if (cache[n]) { return cache[n]; } count++; if (n == 1 || n == 2) { return 1; } let prev = _fn(n - 1); cache[n - 1] = prev; let next = _fn(n - 2); cache[n - 2] = next; return prev + next; } return _fn(n); } let count2 = 0; function fn2(n) { count2++; if (n == 1 || n == 2) { return 1; } return fn2(n - 1) + fn2(n - 2); } console.log(fn(20), count); // 6765 20 console.log(fn2(20), count2); // 6765 13529 快排和二分查找 前端中面试排序和查找的可能性比较小，因为 JS 引擎已经把这些常用操作优化得很好了，可能项目中你费劲写的一个排序方法，都不如Array.sort速度快且代码少。因此，掌握快排和二分查找就可以了。 快排和二分查找都基于一种叫做「分治」的算法思想，通过对数据进行分类处理，不断降低数量级，实现O(logN)（对数级别，比O(n)这种线性复杂度更低的一种，快排核心是二分法的O(logN)，实际复杂度为O(N*logN)）的复杂度。 快速排序 快排大概的流程是： 随机选择数组中的一个数 A，以这个数为基准 其他数字跟这个数进行比较，比这个数小的放在其左边，大的放到其右边 经过一次循环之后，A 左边为小于 A 的，右边为大于 A 的 这时候将左边和右边的数再递归上面的过程 具体代码如下： // 划分操作函数 function partition(array, left, right) { // 用index取中间值而非splice const pivot = array[Math.floor((right + left) / 2)] let i = left let j = right while (i 1) { index = partition(array, left, right) if (left 二分查找 二分查找法主要是解决「在一堆有序的数中找出指定的数」这类问题，不管这些数是一维数组还是多维数组，只要有序，就可以用二分查找来优化。 二分查找是一种「分治」思想的算法，大概流程如下： 数组中排在中间的数字 A，与要找的数字比较大小 因为数组是有序的，所以： a) A 较大则说明要查找的数字应该从前半部分查找 b) A 较小则说明应该从查找数字的后半部分查找 这样不断查找缩小数量级（扔掉一半数据），直到找完数组为止 题目：在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 function Find(target, array) { let i = 0; let j = array[i].length - 1; while (i = 0) { if (array[i][j] target) { j--; } else { return true; } } return false; } //测试用例 console.log(Find(10, [ [1, 2, 3, 4], [5, 9, 10, 11], [13, 20, 21, 23] ]) ); 另外笔者在面试中遇见过下面的问题： 题目：现在我有一个 1~1000 区间中的正整数，需要你猜下这个数字是几，你只能问一个问题：大了还是小了？问需要猜几次才能猜对？ 拿到这个题目，笔者想到的就是电视上面有个「猜价格」的购物节目，在规定时间内猜对价格就可以把实物抱回家。所以问题就是让面试官不停地回答我猜的数字比这个数字大了还是小了。这就是二分查找！ 猜几次呢？其实这个问题就是个二分查找的算法时间复杂度问题，二分查找的时间复杂度是O(logN)，所以求log1000的解就是猜的次数。我们知道2^10=1024，所以可以快速估算出：log1000约等于 10，最多问 10 次就能得到这个数！ 面试遇见不会的算法问题怎么办 面试的时候，在遇见算法题目的时候，应该揣摩面试官的意图，听好关键词，比如：有序的数列做查找、要求算法复杂度是O(logN)这类一般就是用二分的思想。 一般来说算法题目的解题思路分以下四步： 先降低数量级，拿可以计算出来的情况（数据）来构思解题步骤 根据解题步骤编写程序，优先将特殊情况做好判断处理，比如一个大数组的问题，如果数组为两个数长度的情况 检验程序正确性 是否可以优化（由浅到深），有能力的话可以故意预留优化点，这样可以体现个人技术能力 正则匹配解题 很多算法题目利用 ES 语法的特性来回答更加简单，比如正则匹配就是常用的一种方式。笔者简单通过几个真题来汇总下正则的知识点。 题目：字符串中第一个出现一次的字符 请实现一个函数用来找出字符流中第一个只出现一次的字符。例如，当从字符流中只读出前两个字符「go」时，第一个只出现一次的字符是「g」。当从该字符流中读出前六个字符「google」时，第一个只出现一次的字符是「l」。 这个如果用纯算法来解答需要遍历字符串，统计每个字符出现的次数，然后按照字符串的顺序来找出第一次出现一次的字符，整个过程比较繁琐，如果用正则就简单多了。 function find(str){ for (var i = 0; i 当然，使用indexOf/lastIndexOf也是一个取巧的方式。再来看一个千分位问题。 题目：将1234567 变成 1,234,567，即千分位标注 这个题目可以用算法直接来解，如果候选人使用正则来回答，这样主动展现了自己其他方面的优势，即使不是算法解答出来的，面试官一般也不会太难为他。这道题目可以利用正则的「零宽断言」(?=exp)，意思是它断言自身出现的位置的后面能匹配表达式 exp。数字千分位的特点是，第一个逗号后面数字的个数是3的倍数，正则：/(\\d{3})+$/；第一个逗号前最多可以有 1~3 个数字，正则：/\\d{1,3}/。加起来就是/\\d{1,3}(\\d{3})+$/，分隔符要从前往后加。 对于零宽断言的详细介绍可以阅读「零宽断言」这篇文章。 function exchange(num) { num += ''; //转成字符串 if (num.length { console.log(v) return v + ','; }); return num; } console.log(exchange(1234567)); 当然上面讲到的多数是算法题目取巧的方式，下面这个题目是纯正则考查，笔者在面试的过程中碰见过，这里顺便提一下。 题目，请写出下面的代码执行结果 var str = 'google'; var reg = /o/g; console.log(reg.test(str)) console.log(reg.test(str)) console.log(reg.test(str)) 代码执行后，会发现，最后一个不是为true，而是false，这是因为reg这个正则有个g，即global全局的属性，这种情况下lastIndex就发挥作用了，可以看下面的代码执行结果就明白了。 console.log(reg.test(str), reg.lastIndex) console.log(reg.test(str), reg.lastIndex) console.log(reg.test(str), reg.lastIndex) 实际开发中也会犯这样的错误，比如为了减少变量每次都重新定义，会把用到的变量提前定义好，这样在使用的时候容易掉进坑里，比如下面代码： (function(){ const reg = /o/g; function isHasO(str){ // reg.lastIndex = 0; 这样就可以避免这种情况 return reg.test(str) } var str = 'google'; console.log(isHasO(str)) console.log(isHasO(str)) console.log(isHasO(str)) }()) 小结 本小节介绍了数据结构和算法的关系，作为普通的前端也应该学习数据结构和算法知识，并且顺带介绍了下正则匹配。具体来说，本小节梳理了以下几部分数据结构和算法知识点： 经常用到的数据结构有哪些，它们的特点有哪些 递归和枚举是最基础的算法，必须牢牢掌握 排序里面理解并掌握快速排序算法，其他排序算法可以根据个人实际情况大概了解 有序查找用二分查找 遇见不会的算法问题，先缩小数量级，然后分析推导 当然算法部分还有很多知识，比如动态规划这些算法思想，还有图和树常用到的广度优先搜索和深度优先搜索。这些知识在前端面试和项目中遇见得不多，感兴趣的读者可以在梳理知识点的时候根据个人情况自行决定是否复习。 "},"Web前端面试指南与高频考题解析/05.一面5：浏览器相关知识点与高频考题解析.html":{"url":"Web前端面试指南与高频考题解析/05.一面5：浏览器相关知识点与高频考题解析.html","title":"05.一面5：浏览器相关知识点与高频考题解析","keywords":"","body":"一面 5：浏览器相关知识点与高频考题解析 Web 前端工程师写的页面要跑在浏览器里面，所以面试中也会出现很多跟浏览器相关的面试题目。 知识点梳理 浏览器加载页面和渲染过程 性能优化 Web 安全 本小节会从浏览器的加载过程开始讲解，然后介绍如何进行性能优化，最后介绍下 Web 开发中常见的安全问题和预防。 加载页面和渲染过程 可将加载过程和渲染过程分开说。回答问题的时候，关键要抓住核心的要点，把要点说全面，稍加解析即可，简明扼要不拖沓。 题目：浏览器从加载页面到渲染页面的过程 加载过程 要点如下： 浏览器根据 DNS 服务器得到域名的 IP 地址 向这个 IP 的机器发送 HTTP 请求 服务器收到、处理并返回 HTTP 请求 浏览器得到返回内容 例如在浏览器输入https://juejin.im/timeline，然后经过 DNS 解析，juejin.im对应的 IP 是36.248.217.149（不同时间、地点对应的 IP 可能会不同）。然后浏览器向该 IP 发送 HTTP 请求。 server 端接收到 HTTP 请求，然后经过计算（向不同的用户推送不同的内容），返回 HTTP 请求，返回的内容如下： 其实就是一堆 HMTL 格式的字符串，因为只有 HTML 格式浏览器才能正确解析，这是 W3C 标准的要求。接下来就是浏览器的渲染过程。 渲染过程 要点如下： 根据 HTML 结构生成 DOM 树 根据 CSS 生成 CSSOM 将 DOM 和 CSSOM 整合形成 RenderTree 根据 RenderTree 开始渲染和展示 遇到时，会执行并阻塞渲染 上文中，浏览器已经拿到了 server 端返回的 HTML 内容，开始解析并渲染。最初拿到的内容就是一堆字符串，必须先结构化成计算机擅长处理的基本数据结构，因此要把 HTML 字符串转化成 DOM 树 —— 树是最基本的数据结构之一。 解析过程中，如果遇到和这种外链加载 CSS 和 JS 的标签，浏览器会异步下载，下载过程和上文中下载 HTML 的流程一样。只不过，这里下载下来的字符串是 CSS 或者 JS 格式的。 浏览器将 CSS 生成 CSSOM，再将 DOM 和 CSSOM 整合成 RenderTree ，然后针对 RenderTree 即可进行渲染了。大家可以想一下，有 DOM 结构、有样式，此时就能满足渲染的条件了。另外，这里也可以解释一个问题 —— 为何要将 CSS 放在 HTML 头部？—— 这样会让浏览器尽早拿到 CSS 尽早生成 CSSOM，然后在解析 HTML 之后可一次性生成最终的 RenderTree，渲染一次即可。如果 CSS 放在 HTML 底部，会出现渲染卡顿的情况，影响性能和体验。 最后，渲染过程中，如果遇到就停止渲染，执行 JS 代码。因为浏览器渲染和 JS 执行共用一个线程，而且这里必须是单线程操作，多线程会产生渲染 DOM 冲突。待内容执行完之后，浏览器继续渲染。最后再思考一个问题 —— 为何要将 JS 放在 HTML 底部？—— JS 放在底部可以保证让浏览器优先渲染完现有的 HTML 内容，让用户先看到内容，体验好。另外，JS 执行如果涉及 DOM 操作，得等待 DOM 解析完成才行，JS 放在底部执行时，HTML 肯定都解析成了 DOM 结构。JS 如果放在 HTML 顶部，JS 执行的时候 HTML 还没来得及转换为 DOM 结构，可能会报错。 关于浏览器整个流程，百度的多益大神有更加详细的文章，推荐阅读下：《从输入 URL 到页面加载完成的过程中都发生了什么事情？ 》。 性能优化 性能优化的题目也是面试常考的，这类题目有很大的扩展性，能够扩展出来很多小细节，而且对个人的技术视野和业务能力有很大的挑战。这部分笔者会重点讲下常用的性能优化方案。 题目：总结前端性能优化的解决方案 优化原则和方向 性能优化的原则是以更好的用户体验为标准，具体就是实现下面的目标： 多使用内存、缓存或者其他方法 减少 CPU 和GPU 计算，更快展现 优化的方向有两个： 减少页面体积，提升网络加载 优化页面渲染 减少页面体积，提升网络加载 静态资源的压缩合并（JS 代码压缩合并、CSS 代码压缩合并、雪碧图） 静态资源缓存（资源名称加 MD5 戳） 使用 CDN 让资源加载更快 优化页面渲染 CSS 放前面，JS 放后面 懒加载（图片懒加载、下拉加载更多） 减少DOM 查询，对 DOM 查询做缓存 减少DOM 操作，多个操作尽量合并在一起执行（DocumentFragment） 事件节流 尽早执行操作（DOMContentLoaded） 使用 SSR 后端渲染，数据直接输出到 HTML 中，减少浏览器使用 JS 模板渲染页面 HTML 的时间 详细解释 静态资源的压缩合并 如果不合并，每个都会走一遍之前介绍的请求过程 如果合并了，就只走一遍请求过程 静态资源缓存 通过链接名称控制缓存 只有内容改变的时候，链接名称才会改变 这个名称不用手动改，可通过前端构建工具根据文件内容，为文件名称添加 MD5 后缀。 使用 CDN 让资源加载更快 CDN 会提供专业的加载优化方案，静态资源要尽量放在 CDN 上。例如： 使用 SSR 后端渲染 可一次性输出 HTML 内容，不用在页面渲染完成之后，再通过 Ajax 加载数据、再渲染。例如使用 smarty、Vue SSR 等。 CSS 放前面，JS 放后面 上文讲述浏览器渲染过程时已经提过，不再赘述。 懒加载 一开始先给为 src 赋值成一个通用的预览图，下拉时候再动态赋值成正式的图片。如下，preview.png是预览图片，比较小，加载很快，而且很多图片都共用这个preview.png，加载一次即可。待页面下拉，图片显示出来时，再去替换src为data-realsrc的值。 另外，这里为何要用data-开头的属性值？—— 所有 HTML 中自定义的属性，都应该用data-开头，因为data-开头的属性浏览器渲染的时候会忽略掉，提高渲染性能。 DOM 查询做缓存 两段代码做一下对比： var pList = document.getElementsByTagName('p') // 只查询一个 DOM ，缓存在 pList 中了 var i for (i = 0; i var i for (i = 0; i 总结：DOM 操作，无论查询还是修改，都是非常耗费性能的，应尽量减少。 合并 DOM 插入 DOM 操作是非常耗费性能的，因此插入多个标签时，先插入 Fragment 然后再统一插入 DOM。 var listNode = document.getElementById('list') // 要插入 10 个 li 标签 var frag = document.createDocumentFragment(); var x, li; for(x = 0; x 事件节流 例如要在文字改变时触发一个 change 事件，通过 keyup 来监听。使用节流。 var textarea = document.getElementById('text') var timeoutId textarea.addEventListener('keyup', function () { if (timeoutId) { clearTimeout(timeoutId) } timeoutId = setTimeout(function () { // 触发 change 事件 }, 100) }) 尽早执行操作 window.addEventListener('load', function () { // 页面的全部资源加载完才会执行，包括图片、视频等 }) document.addEventListener('DOMContentLoaded', function () { // DOM 渲染完即可执行，此时图片、视频还可能没有加载完 }) 性能优化怎么做 上面提到的都是性能优化的单个点，性能优化项目具体实施起来，应该按照下面步骤推进： 建立性能数据收集平台，摸底当前性能数据，通过性能打点，将上述整个页面打开过程消耗时间记录下来 分析耗时较长时间段原因，寻找优化点，确定优化目标 开始优化 通过数据收集平台记录优化效果 不断调整优化点和预期目标，循环2~4步骤 性能优化是个长期的事情，不是一蹴而就的，应该本着先摸底、再分析、后优化的原则逐步来做。 Web 安全 题目：前端常见的安全问题有哪些？ Web 前端的安全问题，能回答出下文的两个问题，这个题目就能基本过关了。开始之前，先说一个最简单的攻击方式 —— SQL 注入。 上学的时候就知道有一个「SQL注入」的攻击方式。例如做一个系统的登录界面，输入用户名和密码，提交之后，后端直接拿到数据就拼接 SQL 语句去查询数据库。如果在输入时进行了恶意的 SQL 拼装，那么最后生成的 SQL 就会有问题。但是现在稍微大型一点的系统，都不会这么做，从提交登录信息到最后拿到授权，要经过层层的验证。因此，SQL 注入都只出现在比较低端小型的系统上。 XSS（Cross Site Scripting，跨站脚本攻击） 这是前端最常见的攻击方式，很多大型网站（如 Facebook）都被 XSS 攻击过。 举一个例子，我在一个博客网站正常发表一篇文章，输入汉字、英文和图片，完全没有问题。但是如果我写的是恶意的 JS 脚本，例如获取到document.cookie然后传输到自己的服务器上，那我这篇博客的每一次浏览都会执行这个脚本，都会把访客 cookie 中的信息偷偷传递到我的服务器上来。 其实原理上就是黑客通过某种方式（发布文章、发布评论等）将一段特定的 JS 代码隐蔽地输入进去。然后别人再看这篇文章或者评论时，之前注入的这段 JS 代码就执行了。JS 代码一旦执行，那可就不受控制了，因为它跟网页原有的 JS 有同样的权限，例如可以获取 server 端数据、可以获取 cookie 等。于是，攻击就这样发生了。 XSS的危害 XSS 的危害相当大，如果页面可以随意执行别人不安全的 JS 代码，轻则会让页面错乱、功能缺失，重则会造成用户的信息泄露。 比如早些年社交网站经常爆出 XSS 蠕虫，通过发布的文章内插入 JS，用户访问了感染不安全 JS 注入的文章，会自动重新发布新的文章，这样的文章会通过推荐系统进入到每个用户的文章列表面前，很快就会造成大规模的感染。 还有利用获取 cookie 的方式，将 cookie 传入入侵者的服务器上，入侵者就可以模拟 cookie 登录网站，对用户的信息进行篡改。 XSS的预防 那么如何预防 XSS 攻击呢？—— 最根本的方式，就是对用户输入的内容进行验证和替换，需要替换的字符有： & 替换为：&amp; 替换为：&gt; ” 替换为：&quot; ‘ 替换为：&#x27; / 替换为：&#x2f; 替换了这些字符之后，黑客输入的攻击代码就会失效，XSS 攻击将不会轻易发生。 除此之外，还可以通过对 cookie 进行较强的控制，比如对敏感的 cookie 增加http-only限制，让 JS 获取不到 cookie 的内容。 CSRF（Cross-site request forgery，跨站请求伪造） CSRF 是借用了当前操作者的权限来偷偷地完成某个操作，而不是拿到用户的信息。 例如，一个支付类网站，给他人转账的接口是http://buy.com/pay?touid=999&money=100，而这个接口在使用时没有任何密码或者 token 的验证，只要打开访问就直接给他人转账。一个用户已经登录了http://buy.com，在选择商品时，突然收到一封邮件，而这封邮件正文有这么一行代码，他访问了邮件之后，其实就已经完成了购买。 CSRF 的发生其实是借助了一个 cookie 的特性。我们知道，登录了http://buy.com之后，cookie 就会有登录过的标记了，此时请求http://buy.com/pay?touid=999&money=100是会带着 cookie 的，因此 server 端就知道已经登录了。而如果在http://buy.com去请求其他域名的 API 例如http://abc.com/api时，是不会带 cookie 的，这是浏览器的同源策略的限制。但是 —— 此时在其他域名的页面中，请求http://buy.com/pay?touid=999&money=100，会带着buy.com的 cookie ，这是发生 CSRF 攻击的理论基础。 预防 CSRF 就是加入各个层级的权限验证，例如现在的购物网站，只要涉及现金交易，肯定要输入密码或者指纹才行。除此之外，敏感的接口使用POST请求而不是GET也是很重要的。 小结 本小节总结了前端运行环境（即浏览器）的一些常考查知识点，包括页面加载过程、如何性能优化以及需要注意的安全问题。 "},"Web前端面试指南与高频考题解析/06.一面6：开发环境相关知识点与高频考题解析.html":{"url":"Web前端面试指南与高频考题解析/06.一面6：开发环境相关知识点与高频考题解析.html","title":"06.一面6：开发环境相关知识点与高频考题解析","keywords":"","body":"一面 6：开发环境相关知识点与高频考题解析 工程师的开发环境决定其开发效率，常用的开发环境配置也是面试考查点之一。 知识点梳理 IDE Git Linux 基础命令 前端构建工具 调试方法 本小节会重点介绍 Git 的基本用法、代码部署和开发中常用的 Linux 命令，然后以 webpack 为例介绍下前端构建工具，最后介绍怎么抓包解决线上问题。这些都是日常开发和面试中常用到的知识。 IDE 题目：你平时都使用什么 IDE 编程？有何提高效率的方法？ 前端最常用的 IDE 有 Webstorm、Sublime、Atom 和 VSCode，我们可以分别去它们的官网看一下。 Webstorm 是最强大的编辑器，因为它拥有各种强大的插件和功能，但是我没有用过，因为它收费。不是我舍不得花钱，而是因为我觉得免费的 Sublime 已经够我用了。跟面试官聊到 Webstorm 的时候，没用过没事儿，但一定要知道它：第一，强大；第二，收费。 Sublime 是我日常用的编辑器，第一它免费，第二它轻量、高效，第三它插件非常多。用 Sublime 一定要安装各种插件配合使用，可以去网上搜一下“sublime”常用插件的安装以及用法，还有它的各种快捷键，并且亲自使用它。这里就不一一演示了，网上的教程也很傻瓜式。 Atom 是 GitHub 出品的编辑器，跟 Sublime 差不多，免费并且插件丰富，而且跟 Sublime 相比风格上还有些小清新。但是我用过几次就不用了，因此它打开的时候会比较慢，卡一下才打开。当然总体来说也是很好用的，只是个人习惯问题。 VSCode 是微软出品的轻量级（相对于 Visual Studio 来说）编辑器，微软做 IDE 那是出了名的好，出了名的大而全，因此 VSCode 也有上述 Sublime 和 Atom 的各种优点，但是我也是因为个人习惯问题（本人不愿意尝试没有新意的新东西），用过几次就不用了。 总结一下： 如果你要走大牛、大咖、逼格的路线，就用 Webstorm 如果你走普通、屌丝、低调路线，就用 Sublime 如果你走小清新、个性路线，就用 VSCode 或者 Atom 如果你面试，最好有一个用的熟悉，其他都会一点 最后注意：千万不要说你使用 Dreamweaver 或者 notepad++ 写前端代码，会被人鄙视的。如果你不做 .NET 也不要用 Visual Studio ，不做 Java 也不要用 Eclipse。 Git 你此前做过的项目一定要用过 Git，而且必须是命令行，如果没用过，你自己也得恶补一下。对 Git 的基本应用比较熟悉的同学，可以跳过这一部分了。macOS 自带 Git，Windows 需要安装 Git 客户端，去 Git 官网 下载即可。 国内比较好的 Git 服务商有 coding.net，国外有大名鼎鼎的 GitHub，但是有时会有网络问题，因此建议大家注册一个 coding.net 账号然后创建项目，来练练手。 题目：常用的 Git 命令有哪些？如何使用 Git 多人协作开发？ 常用的 Git 命令 首先，通过git clone 下载下来最新的代码，例如git clone git@git.coding.net:username/project-name.git，默认会下载master分支。 然后修改代码，修改过程中可以通过git status看到自己的修改情况，通过git diff 可查阅单个文件的差异。 最后，将修改的内容提交到远程服务器，做如下操作 git add . git commit -m \"xxx\" git push origin master 如果别人也提交了代码，你想同步别人提交的内容，执行git pull origin master即可。 如何多人协作开发 多人协作开发，就不能使用master分支了，而是要每个开发者单独拉一个分支，使用git checkout -b ，运行git branch可以看到本地所有的分支名称。 自己的分支，如果想同步master分支的内容，可运行git merge master。切换分支可使用git checkout 。 在自己的分支上修改了内容，可以将自己的分支提交到远程服务器 git add . git commit -m \"xxx\" git push origin 最后，待代码测试没问题，再将自己分支的内容合并到master分支，然后提交到远程服务器。 git checkout master git merge git push origin master 关于 SVN 关于 SVN 笔者的态度和针对 IE 低版本浏览器的态度一样，你只需要查询资料简单了解一下。面试的时候可能会问到，但你只要熟悉了 Git 的操作，面试官不会因为你不熟悉 SVN 而难为你。前提是你要知道一点 SVN 的基本命令，自己上网一查就行。 不过 SVN 和 Git 的区别你得了解。SVN 是每一步操作都离不开服务器，创建分支、提交代码都需要连接服务器。而 Git 就不一样了，你可以在本地创建分支、提交代码，最后再一起 push 到服务器上。因此，Git 拥有 SVN 的所有功能，但是却比 SVN 强大得多。（Git 是 Linux 的创始人 Linus 发明的东西，因此也倍得推崇。） Linux 基础命令 目前互联网公司的线上服务器都使用 Linux 系统，测试环境为了保证和线上一致，肯定也是使用 Linux 系统，而且都是命令行的，没有桌面，不能用鼠标操作。因此，掌握基础的 Linux 命令是非常必要的。下面总结一些最常用的 Linux 命令，建议大家在真实的 Linux 系统下亲自试一下。 关于如何得到 Linux 系统，有两种选择：第一，在自己电脑的虚拟机中安装一个 Linux 系统，例如 Ubuntu/CentOS 等，下载这些都不用花钱；第二，花钱去阿里云等云服务商租一个最便宜的 Linux 虚拟机。推荐第二种。一般正式入职之后，公司都会给你分配开发机或者测试机，给你账号和密码，你自己可以远程登录。 题目：常见 linux 命令有哪些？ 登录 入职之后，一般会有现有的用户名和密码给你，你拿来之后直接登录就行。运行 ssh name@server 然后输入密码即可登录。 目录操作 创建目录 mkdir 删除目录 rm 定位目录 cd 查看目录文件 ls ll 修改目录名 mv 拷贝目录 cp 文件操作 创建文件 touch vi 删除文件 rm 修改文件名 mv 拷贝文件 cp 文件内容操作 查看文件 cat head tail 编辑文件内容 vi 查找文件内容 grep '关键字' 前端构建工具 构建工具是前端工程化中不可缺少的一环，非常重要，而在面试中却有其特殊性 —— 面试官会通过询问构建工具的作用、目的来询问你对构建工具的了解，只要这些你都知道，不会再追问细节。因为，在实际工作中，真正能让你编写构建工具配置文件的机会非常少，一个项目就配置一次，后面就很少改动了。而且，如果是大众使用的框架（如 React、Vue 等），还会直接有现成的脚手架工具，一键创建开发环境，不用手动配置。 题目：前端为何要使用构建工具？它解决了什么问题？ 何为构建工具 “构建”也可理解为“编译”，就是将开发环境的代码转换成运行环境代码的过程。开发环境的代码是为了更好地阅读，而运行环境的代码是为了更快地执行，两者目的不一样，因此代码形式也不一样。例如，开发环境写的 JS 代码，要通过混淆压缩之后才能放在线上运行，因为这样代码体积更小，而且对代码执行不会有任何影响。总结一下需要构建工具处理的几种情况： 处理模块化：CSS 和 JS 的模块化语法，目前都无法被浏览器兼容。因此，开发环境可以使用既定的模块化语法，但是需要构建工具将模块化语法编译为浏览器可识别形式。例如，使用 webpack、Rollup 等处理 JS 模块化。 编译语法：编写 CSS 时使用 Less、Sass，编写 JS 时使用 ES6、TypeScript 等。这些标准目前也都无法被浏览器兼容，因此需要构建工具编译，例如使用 Babel 编译 ES6 语法。 代码压缩：将 CSS、JS 代码混淆压缩，为了让代码体积更小，加载更快。 构建工具介绍 最早普及使用的构建工具是 Grunt ，不久又被 Gulp 给追赶上。Gulp 因其简单的配置以及高效的性能而被大家所接受，也是笔者个人比较推荐的构建工具之一。如果你做一些简单的 JS 开发，可以考虑使用。 如果你的项目比较复杂，而且是多人开发，那么你就需要掌握目前构建工具届的神器 —— webpack 。不过神器也有一个缺点，就是学习成本比较高，需要拿出专门的时间来专心学习，而不是三言两语就能讲完的。我们下面就演示一下 webpack 最简单的使用，全面的学习还得靠大家去认真查阅相关文档，或者参考专门讲解 webpack 的教程。 webpack 演示 接下来我们演示一下 webpack 处理模块化和混淆压缩代码这两个基本功能。 首先，你需要安装 Node.js，没有安装的可以去 Node.js 官网 下载并安装。安装完成后运行如下命令来验证是否安装成功。 node -v npm -v 然后，新建一个目录，进入该目录，运行npm init，按照提示输入名称、版本、描述等信息。完成之后，该目录下出现了一个package.json文件，是一个 JSON 文件。 接下来，安装 wepback，运行npm i --save-dev webpack，网络原因需要耐心等待几分钟。 接下来，编写源代码，在该目录下创建src文件夹，并在其中创建app.js和dt.js两个文件，文件内容分别是： // dt.js 内容 module.exports = { getDateNow: function () { return Date.now() } } // app.js 内容 var dt = require('./dt.js') alert(dt.getDateNow()) 然后，再返回上一层目录，新建index.html文件（该文件和src属于同一层级），内容是 test test 然后，编写 webpack 配置文件，新建webpack.config.js，内容是 const path = require('path'); const webpack = require('webpack'); module.exports = { context: path.resolve(__dirname, './src'), entry: { app: './app.js', }, output: { path: path.resolve(__dirname, './dist'), filename: 'bundle.js', }, plugins: [ new webpack.optimize.UglifyJsPlugin({ compress: { //supresses warnings, usually from module minification warnings: false } }), ] }; 总结一下，目前项目的文件目录是： src +-- app.js +-- dt.js index.html package.json webpack.config.js 接下来，打开package.json，然后修改其中scripts的内容为： \"scripts\": { \"start\": \"webpack\" } 在命令行中运行npm start，即可看到编译的结果，最后在浏览器中打开index.html，即可弹出Date.now()的值。 总结 最后再次强调，深刻理解构建工具存在的价值，比你多会一些配置代码更加有意义，特别是对于应对面试来说。 调试方法 调试方法这块被考查最多的就是如何进行抓包。 题目：如何抓取数据？如何使用工具来配置代理？ PC 端的网页，我们可以通过 Chrome、Firefox 等浏览器自带的开发者工具来查看网页的所有网络请求，以帮助排查 bug。这种监听、查看网络请求的操作称为抓包。 针对移动端的抓包工具，Mac 系统下推荐使用 Charles 这个工具，首先 下载 并安装，打开。Windows 系统推荐使用 Fiddler，下载安装打开。两者使用基本一致，下面以 Charles 为例介绍。 接下来，将安装好 Charles 的电脑和要抓包的手机，连接到同一个网络（一般为公司统一提供的内网，由专业网络工程师搭建），保证 IP 段相同。然后，将手机设置网络代理（每种不同手机如何设置网络代理，网上都有傻瓜式教程），代理的 IP 为电脑的 IP，代理的端口为8888。然后，Charles 可能会有一个弹框提示是否允许连接代理，这里选择“允许”即可。这样，使用手机端访问的网页或者联网的请求，Charles 就能监听到了。 在开发过程中，经常用到抓包工具来做代理，将线上的地址代理到测试环境，Charles 和 Fiddler 都可实现这个功能。以 Charles 为例，点击菜单栏中 Tools 菜单，然后二级菜单中点击 Map Remote，会弹出配置框。首先，选中 Enable Map Remote 复选框，然后点击 Add 按钮，添加一个代理项。例如，如果要将线上的https://www.aaa.com/api/getuser?name=xxx这个地址代理到测试地址http://168.1.1.100:8080/api/getuser?name=xxx，配置如下图 小结 本小节总结了前端开发环境常考查的知识，这些知识也是前端程序员必须掌握的，否则会影响开发效率。 "},"Web前端面试指南与高频考题解析/07.二面1：如何回答常见的软技能问题.html":{"url":"Web前端面试指南与高频考题解析/07.二面1：如何回答常见的软技能问题.html","title":"07.二面1：如何回答常见的软技能问题","keywords":"","body":"二面 1：如何回答常见的软技能问题 面试是个技术活，不仅仅是技术，各种软技能的面试技巧也是非常重要的，尤其是程序员一般对于自己的软技能不是很看重，其实软技能才是决定你职场能够走多远的关键。 程序员应该具备的软技能 程序员除了业务技能外，应该具有下面的软技能： 韧性：抗压能力，在一定项目压力下能够迎难而上，比如勇于主动承担和解决技术难题 责任心：对于自己做过的项目，能够出现 bug 之类主动解决 持续学习能力：IT 行业是个需要不断充电的行业，尤其 Web 前端这些年一直在巨变，所以持续学习能力很重要 团队合作能力：做项目不能个人英雄主义，应该融入团队，跟团队一起打仗 交流沟通能力：经常会遇见沟通需求和交互设计的工作，应该乐于沟通分享 另外在《软技能：代码之外的生存指南》这本书里提到了下面一些软技能： 职业 自我营销 学习能力 提升工作效率 理财 健身 积极的人生观 常见的软技能问题和提升 回答软技能类的问题，应该注意在回答过程中体现自己具备的软技能。下面列举几个常见的软技能类的问题。 回想下你遇见过最难打交道的同事，你是如何跟他沟通的 一般来说，工作中总会遇见一两个自己不喜欢的人，这种情况应该尽量避免冲突，从自己做起慢慢让对方感觉到自己的合作精神。 所以，遇见难打交道的同事，不要急于上报领导，应该自己主动多做一些事情，比如规划好工作安排，让他选择自己做的事情，有了结论记得发邮件确认下来，这样你们的领导和其他成员都会了解到工作的安排，在鞭笞对方的同时，也做到了职责明确。在项目当中，多主动检查项目进展，提前发现逾期的问题。 重点是突出：自己主动沟通解决问题的意识，而不是遇见问题就找领导。 当你被分配一个几乎不可能完成的任务时，你会怎么做 这种情况下，一般通过下面方式来解决： 自己先查找资料，寻找解决方案，评估自己需要怎样的资源来完成，需要多长时间 能不能借助周围同事来解决问题 拿着分析结果跟上级反馈，寻求帮助或者资源 突出的软技能：分析和解决问题，沟通寻求帮助。 业余时间都做什么？除了写码之外还有什么爱好 这类问题也是面试官的高频问题，「一个人的业余时间决定了他的未来」，如果回答周末都在追剧打游戏之类的，未免显得太不上进。 一般来说，推荐下面的回答： 周末一般会有三种状态： 和朋友一起去做做运动，也会聚会聊天，探讨下新技术之类的； 也会看一些书籍充充电，比如我最近看的 xx，有什么的想法； 有时候会闷在家用最近比较火的技术做个小项目或者实现个小功能之类的。 这样的回答，既能表现自己阳光善于社交沟通的一面，又能表现自己的上进心。 小结 本小节介绍了程序员除了业务技术能力之外应该日常修炼的软技能，在面试中，软技能会被以各种形式问起，候选人应该先了解有哪些软技能可以修炼，才能在回答软技能问题的时候，尽量提到自己具备的软技能。 "},"Web前端面试指南与高频考题解析/08.二面2：如何介绍项目及应对项目细节追问.html":{"url":"Web前端面试指南与高频考题解析/08.二面2：如何介绍项目及应对项目细节追问.html","title":"08.二面2：如何介绍项目及应对项目细节追问","keywords":"","body":"二面 2：如何介绍项目及应对项目细节追问 一个标准的面试流程中，肯定会在一面二面中问到你具体做过的项目，然后追问项目的细节。这类问题往往会通过下面形式来提问： 发现你简历的一个项目，直接让你介绍下这个项目 让你回忆下你做过的项目中，最值得分享（最大型/最困难/最能体现技术能力/最难忘）的 如果让你设计 xx 系统/项目，你会怎么着手干 这类跟项目相关的综合性问题，既能体现候选人的技术水平、业务水平和架构能力，也能够辨别候选人是不是真的做过项目，还能够发现候选人的一些软技能。 下面分享下，遇见这类问题应该怎样回答。 怎样介绍自己做过的一个项目 按照第 1 小节说的，简历当中的项目，你要精挑细选，既要体现技术难度，又要想好细节。具体要介绍一个项目（包括梳理一个项目），可以按照下面几个阶段来做。 1. 介绍项目背景 这个项目为什么做，当初大的环境背景是什么？还是为了解决一个什么问题而设立的项目？背景是很重要的，如果不了解背景，一上来就听一个结论性的项目，面试官可能对于项目的技术选型、技术难度会有理解偏差，甚至怀疑是否真的有过这样的项目。 比如一上来就说：我们的项目采用了「backbone」来做框架，然后。。。而「backbone」已经是三四年前比较新鲜的技术，现在会有更好的选择方案，如果不介绍项目的时间背景，面试官肯定一脸懵逼。 2. 承担角色 项目涉及的人员角色有哪些，自己在其中扮演的角色是什么？ 这里候选往往人会自己给自己挖坑，比如把自己在项目中起到的作用夸大等。一般来说，面试官细节追问的时候，如果候选人能够把细节或者技术方案等讲明白、讲清楚，不管他是真的做过还是跟别人做过，或者自己认真思考过，都能体现候选人的技术水平和技术视野。前提还是在你能够兜得住的可控范围之内做适当的「美化」。 3. 最终的结果和收益 项目介绍过程中，应该介绍项目最终的结果和收益，比如项目最后经过多久的开发上线了，上线后的数据是怎样的，是否达到预期，还是带来了新的问题，遇见了问题自己后续又是怎样补救的。 4. 有始有终：项目总结和反思 有总结和反思，才会有进步。 项目做完了往往会有一些心得和体会，这时候应该跟面试官说出来。在梳理项目的总结和反思时，可以按照下面的列表来梳理： 收获有哪些？ 是否有做得不足的地方，怎么改进？ 是否具有可迁移性？ 比如，之前详细介绍了某个项目，这个项目当时看来没有什么问题，但是现在有更好的解决方案了，候选人就应该在这里提出来：现在看来，这个项目还有 xx 的问题，我可以通过 xx 的方式来解决。 再比如：做这个项目的时候，你做得比较出彩的地方，可以迁移到其他项目中直接使用，小到代码片段，大到解决方案，总会有你值得总结和梳理的地方。 介绍完项目总结这部分，也可以引导面试官往自己擅长的领域思考。比如上面提到项目中的问题，可以往你擅长的方面引导，即使面试官没有问到，你也介绍到了。 按照上面的四段体介绍项目，会让面试官感觉候选人有清晰的思路，对整个项目也有理解和想法，还能够总结反思项目的收益和问题，可谓「一箭三雕」。 没有做过大型项目怎么办 对于刚刚找工作的应届生，或者面试官让你进行一个大型项目的设计，候选人可能没有类似的经验。这时候不要用「我不会、没做过」一句话就带过。 如果是实在没有项目可以说，那么可以提自己日常做的练手项目，或者看到一个解决方案的文章/书，提到的某个项目，抒发下自己的想法。 如果是对于面试官提出来需要你设计的项目/系统，可以按照下面几步思考： 有没有遇见过类似的项目 有没有读过类似解决方案的文章 项目能不能拆解，拆解过程中能不能发现自己做过的项目可以用 项目解决的问题是什么，这类问题有没有更好的解决方案 总之，切记不要一句「不知道、没做过」就放弃，每一次提问都是自己表现的机会。 项目细节和技术点的追问 介绍项目的过程中，面试官可能会追问技术细节，所以我们在准备面试的时候，应该尽量把技术细节梳理清楚，技术细节包括： 技术选型方案：当时做技术选型所面临的状况 技术解决方案：最终确定某种技术方案的原因，比如：选择用 Vue 而没有用 React 是为什么？ 项目数据和收益 项目中最难的地方 遇见的坑：如使用某种框架遇见哪些坑 一般来说，做技术选型的时候需要考虑下面几个因素： 时代：现在比较火的技术是什么，为什么火起来，解决了什么问题，能否用到我的项目中？ 团队：个人或者团队对某种技术的熟悉程度是怎样的，学习成本又是怎样的？ 业务需求：需求是怎样的，能否套用现在的成熟解决方案/库来快速解决？ 维护成本：一个解决方案的是否再能够 cover 住的范围之内？ 在项目中遇见的数据和收益应该做好跟踪，保证数据的真实性和可信性。另外，遇见的坑可能是面试官问得比较多的，尤其现在比较火的一些技术（Vue、React、webpack），一般团队都在使用，所以一定要提前准备下。 小结 本小节介绍了面试中关于项目类问题的回答方法，介绍项目要使用四段体的方式，从背景、承担角色、收益效果和总结反思四个部分来介绍项目。 准备这个面试环节的时候，利用笔者一直提倡的「思维导图」法，好好回顾和梳理自己的项目。 "},"Web前端面试指南与高频考题解析/09.HR面：谈钱不伤感情.html":{"url":"Web前端面试指南与高频考题解析/09.HR面：谈钱不伤感情.html","title":"09.HR面：谈钱不伤感情","keywords":"","body":"HR 面：谈钱不伤感情 当你顺利通过面试，最后 HR 面试主要有两大环节： 了解候选人是否在岗位、团队、公司文化等方面能够跟要求匹配，并且能够长期服务 谈薪资 匹配度考查 很多情况下 HR 并不懂技术，但是也会问你项目上的问题，这时候其实是考查候选人对自己所做项目和技术的掌握能力。「检验一个人是否掌握一个专业知识，看他能不能把专业知识通俗易懂地对一个外行讲明白」。在面对 HR 询问项目或者技术点的细节时，你应该尽量通俗易懂地将知识点讲明白。怎样做到通俗易懂？笔者建议多作类比，跟生活中常见的或者大家都明白的知识作对比。举个例子，讲解「减少 Cookie 对页面打开速度优化有效果」的时候，笔者会这样来介绍： 你应该知道平时上传文件（比如头像）要比下载文件慢，这是因为网络上行带宽要比下行带宽窄，HTTP 请求的时候其实是双向的，先上传本地的信息，包括要访问的网址、本地携带的一些 Cookie 之类的数据，这些数据因为是上行（从用户手中发到服务器，给服务器上的代码使用），本来上行带宽小，所以对速度的影响更大。因此在 HTTP 上行请求中，减少 Cookie 的大小等方式可以有效提高打开速度，尤其是在带宽不大的网络环境中，比如手机的 2G 弱网络环境。 如果他还是不太清楚，那么带宽、上行、下行这些概念都可以类比迅雷下载这个场景，一解释应该就明白了。 HR 面试还会通过一些问题，判断你与公司文化是否契合，比如阿里的 HR 有政委体系，会严格考查候选人是否符合公司企业文化。针对这类问题应该在回答过程中体现出自己阳光正能量的一面，不要抱怨前公司，抱怨前领导，多从自身找原因和不足，谦虚谨慎。 谈薪资 谈 offer 的环节并不轻松，包括笔者在内往往在这个阶段「折了兵」。不会谈 offer 往往会遇见这样的情况： 给你多少就要多少，不会议价 谈一次被打击一次，最后越来越没有底气 尤其是很多不专业的 HR 以压低工资待遇为自己的首要目标，把候选人打击得不行不行的。一个不够满意的 offer 往往导致入职后出现抱怨，本小节重点讲下如何谈到自己中意的 offer。 准确定位和自我估值 在准备跳槽时，每个人肯定会对自己有一个预估，做好足够的心理准备。下面谈下怎么对自己的薪酬做个评估。一般来说跳槽的薪水是根据现在薪酬的基础上浮 15~30%，具体看个人面试的情况。对于应届毕业生，大公司基本都有标准薪水，同期的应届生差别不会特别大。 除了上面的方法，还应该按照公司的技术职级进行估值。每个公司都有对应的技术职级，不同的技术职级薪酬范围是固定的，如果是小公司，则可以参考大公司的职级范围来确定薪资范围。 根据职级薪资范围和自己现在薪酬基础上浮后的薪酬，做个比较，取其较高的结果。 当然如果面试结果很好，你可以适当地提高下薪酬预期。除了这种情况，应该针对不同的性质来对 offer先做好不同的估值。这里的预期估值只是心理预期，也就是自己的「底牌」。 所谓不同性质的 offer 指的是： 是否是自己真心喜欢的工作岗位： 如果是自己真心喜欢的工作岗位，比如对于个人成长有利，或者希望进入某个公司部门，从事某个专业方向的工作，而你自己对于薪酬又不是特别在意，这时候可以适当调低薪酬预期，以拿到这个工作机会为主。 是否只是做 backup 的岗位：面试可能不止面试一家，对于不是特别喜欢的公司部门，那么可以把这个 offer 做为 backup，后面遇见喜欢的公司可以以此基础来谈薪水。 这时候分两种情况：如果面试结果不是很好，这种情况应该优先拿到 offer，所以可以适当降低期望薪酬；如果面试结果很好，这种情况应该多要一些薪酬，增加的薪酬可以让你加入这家公司也心里很舒服。 对于自己真正的目标职位，面试之前应该先找 backup 岗位练练手，一是为了找出面试的感觉，二是为了拿到几个 offer 做好 backup。 关于如何客观评估自己的身价，有篇知乎的帖子比较专业，有时间可以读一下：如何在跳槽前客观地评估自己的身价？ 跟 HR 沟通的技巧 跟 HR 沟通的时候，不要夸大现在的薪酬，HR 知道的信息往往会超出你的认知，尤其大公司还会有背景调查，所以不要撒谎，实事求是。 跟 HR 沟通的技巧有以下几点： 不要急于出价 不要急于亮出自己的底牌，一旦你说出一个薪酬范围，自己就不能增加薪酬了，还给了对方砍价的空间。而且一个不合理的价格反而会让对方直接放弃。所以不要着急出价，先让对方出价。 同时，对于公司级别也是，不要一开始就奔着某个目标去面试，这样会加大面试的难度，比如： 目标是拿到阿里 P7 的职位，不要说不给 P7 我就不去面试之类的，这样的要求会让对方一开始就拿 P7 的标准来面试，可能会找 P8+ 的面试官来面试你，这样会大大提升面试难度。 要有底气足够自信 要有底气，自信，自己按照上面的估值盘算好了想要的薪酬，那么应该有底气地说出来，并且给出具体的原因，比如： 我已经对贵公司的薪酬范围和级别有了大概的了解，我现在的水平大概范围是多少 现在公司很快就有调薪机会，自己已经很久没有调薪，年前跳槽会损失年终奖等情况 现在我已经有某个公司多少 K 的 offer 如果 HR 表示你想要的薪酬不能满足，这时候你应该给出自己评估的依据，是根据行业职级标准还是自己现有薪酬范围，这样做到有理有据。 谈好 offer 就要尽快落实 对于已经谈拢的薪酬待遇，一定要 HR 以发邮件 offer 的形式来确认。 小结 本小节详细谈了 HR 轮面试的两大环节，重点介绍了谈 offer 的一些技巧，希望对你有所帮助和启发。 "},"Web前端面试指南与高频考题解析/10.总结与补充说明.html":{"url":"Web前端面试指南与高频考题解析/10.总结与补充说明.html","title":"10.总结与补充说明","keywords":"","body":"总结与补充说明 恭喜你，学完了本小册。下面来总结下本小册的内容，并补充一些遗漏的内容。 总结 本小册主要带领大家从准备简历开始，逐步梳理技术面试知识点和非技术面试常考问题，最后介绍了一些谈 offer 之类的面试技巧。下面带领大家根据准备、技术面试、非技术面试和 HR 面试四部分，回顾一下每部分的要点。 准备阶段 简历准备： 简历要求尽量平实，不要太花俏 格式推荐 PDF 内容包含：个人技能、项目经验和实习经验 简历应该针对性来写 简历提到的项目、技能都要仔细回想细节，挖掘可能出现的面试题 拿到面邀之后准备： 开场问题：自我介绍、离职原因等 了解面试官、了解公司和部门做的事情 知识梳理推荐使用思维导图 技术面部分 集中梳理了 ECMAScript 基础、JS-Web-API、CSS 和 HTML、算法、浏览器和开发环境六大部分内容，并且就一些高频考题进行讲解。 非技术面试部分 主要从软技能和项目介绍两个部分来梳理。在软技能方面，介绍了工程师从业人员应该具有的软技能，并且通过几个面试真题介绍了怎么灵活应对面试官；在项目介绍小节，推荐按照项目背景、承担角色、项目收益和项目总结反思四步来介绍，并且继续推荐使用思维导图方式来梳理项目的细节。 HR 面 在小册最后，介绍了 HR 面试应该注意的问题，重点分享了作为一个 Web 前端工程师怎么对自己进行估值，然后跟 HR 进行沟通，拿到自己可以接受的 offer。 最后还介绍了一些面试注意事项，在面试整个流程中，太多主观因素，细节虽小也可能决定候选人面试的结果。 补充说明 本着通用性和面试门槛考虑的设计，本小册对于一些前端进阶和框架类的问题没有进行梳理，没有涉及的内容主要有： Node.js部分 类库：Zepto、jQuery、React、Vue 和 Angular 等 移动开发 下面简单展开下上面的内容。 Node.js部分 Node.js 涉及的知识点比较多，而且比较偏后端和工具性，如果用 Node.js 来做 Server 服务，需要补充大量的后端知识和运维知识，这里帮助梳理下知识点： Node 开发环境 npm 操作 package.json Node 基础 API 考查 file system Event 网络 child process Node 重点和难点 事件和异步理解 Steam 相关概念 Buffer 相关概念 domain vm cluster 异常调优 Server 相关 库 Koa Express 数据库 MongoDB MySQL Redis 运维部署 Nginx 进程守候 日志 Node 的出现让前端可以做的事情更多，除了做一些 Server 的工作以外，Node 在日常开发中可以做一些工具来提升效率，比如常见的前端构建工具目前都是 Node 来编写的，而我们在研发中，一些类似 Mock、本地 server、代码实时刷新之类的功能，都可以使用 Node 来自己实现。 前端框架（库） jQuery 和 Zepto 分别是应用在 PC 和移动上面的库，大大降低了前端开发人员的门槛，很多前端工程师都是从写 jQuery 代码开始的。jQuery 和 Zepto 这两个库对外的 API 都是相同的。在面试的时候可能会问到一些具体代码的实现，比如下面两个问题： 题目：谈谈 jQuery 的 delegate 和 bind 有什么区别；window.onload 和$().ready有什么区别 这实际上都是 JS-Web-API 部分基础知识的实际应用： delegate 是事件代理（委托），bind是直接绑定事件 onload 是浏览器部分的全部加载完成，包括页面的图片之类资源；ready 则是DOMContentLoaded事件，比 onload 提前一些 下面再说下比较火的 Angular、React 和 Vue。 为什么会出现 Angular、React 和 Vue 这种库？ 理解为什么会出现一种新技术，以及新技术解决了什么问题，才能够更好地选择和运用新技术，不至于落入「喜新厌旧」的怪圈。 首先在互联网用户界面和交互越来越复杂的阶段，这些 MV* 库是极大提升了开发效率，比如在数据流为主的后台系统，每天打交道最多的就是数据的增删改查，这时候如果使用这些库，可以将注意力转移到数据本身来，而不再是页面交互，从而极大地提升开发效率和沟通成本。 React 还有个很好的想法是 React Native，只需要写一套代码就可以实现 Web、安卓、iOS 三端相同的效果，但是在实际使用和开发中会有比较大的坑。而且就像 Node 一样，前端用 Node 写 Server 可能需要用到的后端知识要比前端知识多，想要写好 React Native，客户端的知识也是必不可少的。React Native 和Node 都是拓展了 Web 前端工程师可以走的路，既可以向后又可以向前，所谓「全栈」。 Angular、React 和 Vue 各自的特点 AngularJS有着诸多特性，最为核心的是 MVVM、模块化、自动化双向数据绑定、语义化标签、依赖注入等 React 是一个为数据提供渲染为 HTML 视图的开源 JavaScript 库，最大特点是引入 Virtual DOM，极大提升数据修改后 DOM 树的更新速度，而且也有 React Native 来做客户端开发 Vue.js 作为后起前端框架，借鉴了 Angular 、React 等现代前端框架/库的诸多特点，并取得了相当不错的成绩。 一定要用这些库吗？ 目前这些库的确解决了实际开发中很多问题，但是这种「三足鼎立」的状况不是最终态，会是阶段性产物。从长远来说，好的想法和点子终究会体现在语言本身特性上来，即通过这些库的想法来推动标准的改进，比如 jQuery 的很多选择器 API，最终都被 CSS3 和 HTML5 接纳和实现，也就就有了后来的 Zepto。 另外，以展现交互为主的项目不太推荐使用这类库，本身库的性能和体积就对页面造成极大的负担，比如笔者使用 Vue 做纯展现为主的项目，性能要比页面直出 HTML 慢。纯展现页面指的是那些以展现为主、用户交互少的页面，如文章列表页、文章详情页等。 如果是数据交互较多的页面，例如后台系统这类对性能要求不多而数据交互较多的页面，推荐使用。 另外，不管是什么库和框架，我们最终应该学习的是编程思维，比如分层、性能优化等，考虑视图层、组件化和工程效率问题。相信随着 ES 标准发展、摩尔定律（硬件）和浏览器的演进，目前这些问题和状况都会得到改善。 关于三者的学习资料就不补充了，因为实在是太火了，随便搜索一下就会找到。 移动开发 这里说的移动开发指的是做的项目是面向移动端的，比如 HTML5 页面、小程序等。做移动开发用的也是前面几个小节梳理的基础知识，唯一不同的是工程师面向的浏览器是移动端的浏览器或者固定的 Webview，所以会跟普通的 PC 开发有所不同。除了最基础的 JSBridge 概念之外，这里笔者重点列出以下几点： 移动端更加注重性能和体验，因为移动端设备和网络都比 PC 的差一些 交互跟 PC 不同，比如 touch 事件 浏览器和固定的 Webview 带来了更多兼容性的问题，如微信 webview、安卓浏览器和 iOS 浏览器 调试技巧更多，在 Chrome 内开发完页面，放到真机需要再调试一遍，或者需要真机配合才能实现页面的完整功能 后记 小册梳理了很多知识点，但是限于笔者精力、小册篇幅和新知识的不断涌现，难免会有考虑不到的地方，还请大家按照我在第一节提到的思维导图的方式，自己列脑图进行梳理。 最后，祝每个人都拿到满意的 offer！ "},"Web前端面试指南与高频考题解析/11.其他：面试注意事项.html":{"url":"Web前端面试指南与高频考题解析/11.其他：面试注意事项.html","title":"11.其他：面试注意事项","keywords":"","body":"其他：面试注意事项 除了前面小节中提到的一些面试中应该注意的问题，本小节再整理一些面试中应该注意的事项。 1. 注意社交礼仪 虽然说 IT 行业不怎么注重工作环境，上下级也没有繁文缛节，但是在面试中还是应该注意一些社交礼仪的。像进门敲门、出门关门、站着迎人这类基本礼仪还是要做的。 舒适但不随意的着装 首先着装方面，不要太随意，也不要太正式，太正式的衣服可能会使人紧张，所以建议穿自己平时喜欢的衣服，关键是干净整洁。 约个双方都舒服的面试时间 如果 HR 打电话预约面试时间，记得一定要约个双方都舒服的时间，宁愿请假也要安排好面试时间。 有个case：前几天有个朋友说为了给公司招人，晚上住公司附近酒店，原因是候选人为了不耽误现在公司的工作，想在 10 点之前按时上班，预约的面试时间是早上 8 点。这样对于面试官来说增加了负担，心里肯定不会特别舒服，可能会影响候选人的面试结果。 面试时间很重要，提前十分钟到面试地点，熟悉下环境，做个登记之类的，留下个守时的好印象。如果因为堵车之类的原因不能按时到达，则要在约定时间之前电话通知对方。 2. 面试后的提问环节 面试是一个双向选择的事情，所以面试后一般会有提问环节。在提问环节，候选人最好不要什么都不问，更不要只问薪水待遇、是否加班之类的问题。 其实这个时候可以反问面试官了解团队情况、团队做的业务、本职位具体做的工作、工作的规划，甚至一些数据（可能有些问题不会直面回答）。 还可以问一些关于公司培训机会和晋升机会之类的问题。如果是一些高端职位，则可以问一下：自己的 leader 想把这个职位安排给什么样的人，希望多久的时间内可以达到怎样的水平。 3. 面试禁忌 不要对老东家有太多埋怨和负面评价 不要有太多负面情绪，多表现自己阳光的一面 不要夸大其词，尤其是数据方面 不要贬低任何人，包括自己之前的同事，比如有人喜欢说自己周围同事多么的差劲，来突出自己的优秀 不要过多争辩。你是来展现自己胜任能力的，不是来证明面试官很蠢的 4. 最好自己带电脑 有些面试会让候选人直接笔试，或者直接去小黑板上面画图写代码，这种笔试的时候会非常痛苦，我经常见单词拼写错误的候选人，这种情况最好是自己带着电脑，直接在自己熟悉的 IDE 上面编写。 这里应该注意，自己带电脑可能也有弊端。如果你对自己的开发环境和电脑足够熟悉，操作起来能够得心应手，那么可以带着；如果你本身电脑操作就慢，比如 Linux 命令不熟悉，打开命令行忘记了命令，这种情况下会被减分。带与不带自己根据自己情况权衡。 5. 面试后的总结和思考 面试完了多总结自己哪里做得不好，哪里做得好，都记录下来，后续扬长避短 通过面试肯定亲身体会到了公司团队文化、面试官体现出来的技术能力、专业性以及职位将来所做的事情，跟自己预期是否有差距，多个 offer 的话多做对比 每次面试应该都有所收获，毕竟花费了时间和精力。即使面不上也可以知道自己哪方面做得不好，继续加强。 小结 本小节重点谈了面试中应该注意的一些细节问题，细节虽小，但是大家应该注意。 "},"使用webpack定制前端开发环境/01.webpack的概念和基础使用.html":{"url":"使用webpack定制前端开发环境/01.webpack的概念和基础使用.html","title":"01.webpack的概念和基础使用","keywords":"","body":"webpack 的概念和基础使用 我们在小册介绍中提到，webpack 是一个 JS 代码模块化的打包工具，藉由它强大的扩展能力，随着社区的发展，逐渐成为一个功能完善的构建工具。相信开始学习这个小册的同学们多多少少都能够理解为什么前端开发中会使用到 webpack，我们不再详细介绍 webpack 的使用背景，直奔本小节的主题。 安装和使用 我们使用 npm 或者 yarn 来安装 webpack，可以作为一个全局的命令来使用： npm install webpack webpack-cli -g # 或者 yarn global add webpack webpack-cli # 然后就可以全局执行命令了 webpack --help webpack-cli 是使用 webpack 的命令行工具，在 4.x 版本之后不再作为 webpack 的依赖了，我们使用时需要单独安装这个工具。 在项目中，我们更多地会把 webpack 作为项目的开发依赖来安装使用，这样可以指定项目中使用的 webpack 版本，更加方便多人协同开发： 确保你的项目中有 package.json 文件，如果没有可以使用 npm init 来创建。 npm install webpack -D # 或者 yarn add webpack -D 这样 webpack 会出现在 package.json 中，我们再添加一个 npm scripts： \"scripts\": { \"build\": \"webpack --mode production\" }, \"devDependencies\": { \"webpack\": \"^4.1.1\", \"webpack-cli\": \"^2.0.12\", } 然后我们创建一个 ./src/index.js 文件，可以写任意的 JS 代码。创建好了之后执行 npm run build 或者 yarn build 命令，你就会发现新增了一个 dist 目录，里边存放的是 webpack 构建好的 main.js 文件。 因为是作为项目依赖进行安装，所以不会有全局的命令，npm/yarn 会帮助我们在当前项目依赖中寻找对应的命令执行，如果是全局安装的 webpack，直接执行 webpack --mode production 就可以。 webpack 4.x 的版本可以零配置就开始进行构建，但是笔者觉得这个功能还不全面，缺少很多实际项目需要的功能，所以基本你还是需要一个配置文件，后边会详细讲解。 我们先来了解 webpack 中的一些基本概念。 webpack 的基本概念 webpack 本质上是一个打包工具，它会根据代码的内容解析模块依赖，帮助我们把多个模块的代码打包。借用 webpack 官网的图片： 如上图，webpack 会把我们项目中使用到的多个代码模块（可以是不同文件类型），打包构建成项目运行仅需要的几个静态文件。webpack 有着十分丰富的配置项，提供了十分强大的扩展能力，可以在打包构建的过程中做很多事情。我们先来看一下 webpack 中的几个基本概念。 入口 如上图所示，在多个代码模块中会有一个起始的 .js 文件，这个便是 webpack 构建的入口。webpack 会读取这个文件，并从它开始解析依赖，然后进行打包。如图，一开始我们使用 webpack 构建时，默认的入口文件就是 ./src/index.js。 我们常见的项目中，如果是单页面应用，那么可能入口只有一个；如果是多个页面的项目，那么经常是一个页面会对应一个构建入口。 入口可以使用 entry 字段来进行配置，webpack 支持配置多个入口来进行构建： module.exports = { entry: './src/index.js' } // 上述配置等同于 module.exports = { entry: { main: './src/index.js' } } // 或者配置多个入口 module.exports = { entry: { foo: './src/page-foo.js', bar: './src/page-bar.js', // ... } } // 使用数组来对多个文件进行打包 module.exports = { entry: { main: [ './src/foo.js', './src/bar.js' ] } } 最后的例子，可以理解为多个文件作为一个入口，webpack 会解析两个文件的依赖后进行打包。 loader webpack 中提供一种处理多种文件格式的机制，便是使用 loader。我们可以把 loader 理解为是一个转换器，负责把某种文件格式的内容转换成 webpack 可以支持打包的模块。 举个例子，在没有添加额外插件的情况下，webpack 会默认把所有依赖打包成 js 文件，如果入口文件依赖一个 .hbs 的模板文件以及一个 .css 的样式文件，那么我们需要 handlebars-loader 来处理 .hbs 文件，需要 css-loader 来处理 .css 文件（这里其实还需要 style-loader，后续详解），最终把不同格式的文件都解析成 js 代码，以便打包后在浏览器中运行。 当我们需要使用不同的 loader 来解析处理不同类型的文件时，我们可以在 module.rules 字段下来配置相关的规则，例如使用 Babel 来处理 .js 文件： module: { // ... rules: [ { test: /\\.jsx?/, // 匹配文件路径的正则表达式，通常我们都是匹配文件类型后缀 include: [ path.resolve(__dirname, 'src') // 指定哪些路径下的文件需要经过 loader 处理 ], use: 'babel-loader', // 指定使用的 loader }, ], } loader 是 webpack 中比较复杂的一块内容，它支撑着 webpack 来处理文件的多样性。后续我们还会介绍如何更好地使用 loader 以及如何开发 loader。 plugin 在 webpack 的构建流程中，plugin 用于处理更多其他的一些构建任务。可以这么理解，模块代码转换的工作由 loader 来处理，除此之外的其他任何工作都可以交由 plugin 来完成。通过添加我们需要的 plugin，可以满足更多构建中特殊的需求。例如，要使用压缩 JS 代码的 uglifyjs-webpack-plugin 插件，只需在配置中通过 plugins 字段添加新的 plugin 即可： const UglifyPlugin = require('uglifyjs-webpack-plugin') module.exports = { plugins: [ new UglifyPlugin() ], } 除了压缩 JS 代码的 uglifyjs-webpack-plugin，常用的还有定义环境变量的 DefinePlugin，生成 CSS 文件的 ExtractTextWebpackPlugin 等。在这里提到这些 plugin，只是希望读者们能够对 plugin 的作用有个大概的印象，后续的小节会详细介绍如何使用这些 plugin。 plugin 理论上可以干涉 webpack 整个构建流程，可以在流程的每一个步骤中定制自己的构建需求。第 15 小节我们会介绍如何开发 plugin，让读者们在必要时，也可以在 webpack 的基础上开发 plugin 来应对一些项目的特殊构建需求。 输出 webpack 的输出即指 webpack 最终构建出来的静态文件，可以看看上面 webpack 官方图片右侧的那些文件。当然，构建结果的文件名、路径等都是可以配置的，使用 output 字段： module.exports = { // ... output: { path: path.resolve(__dirname, 'dist'), filename: 'bundle.js', }, } // 或者多个入口生成不同文件 module.exports = { entry: { foo: './src/foo.js', bar: './src/bar.js', }, output: { filename: '[name].js', path: __dirname + '/dist', }, } // 路径中使用 hash，每次构建时会有一个不同 hash 值，避免发布新版本时线上使用浏览器缓存 module.exports = { // ... output: { filename: '[name].js', path: __dirname + '/dist/[hash]', }, } 我们一开始直接使用 webpack 构建时，默认创建的输出内容就是 ./dist/main.js。 一个简单的 webpack 配置 我们把上述涉及的几部分配置内容合到一起，就可以创建一个简单的 webpack 配置了，webpack 运行时默认读取项目下的 webpack.config.js 文件作为配置。 所以我们在项目中创建一个 webpack.config.js 文件： const path = require('path') const UglifyPlugin = require('uglifyjs-webpack-plugin') module.exports = { entry: './src/index.js', output: { path: path.resolve(__dirname, 'dist'), filename: 'bundle.js', }, module: { rules: [ { test: /\\.jsx?/, include: [ path.resolve(__dirname, 'src') ], use: 'babel-loader', }, ], }, // 代码模块路径解析的配置 resolve: { modules: [ \"node_modules\", path.resolve(__dirname, 'src') ], extensions: [\".wasm\", \".mjs\", \".js\", \".json\", \".jsx\"], }, plugins: [ new UglifyPlugin(), // 使用 uglifyjs-webpack-plugin 来压缩 JS 代码 // 如果你留意了我们一开始直接使用 webpack 构建的结果，你会发现默认已经使用了 JS 代码压缩的插件 // 这其实也是我们命令中的 --mode production 的效果，后续的小节会介绍 webpack 的 mode 参数 ], } webpack 的配置其实是一个 Node.js 的脚本，这个脚本对外暴露一个配置对象，webpack 通过这个对象来读取相关的一些配置。因为是 Node.js 脚本，所以可玩性非常高，你可以使用任何的 Node.js 模块，如上述用到的 path 模块，当然第三方的模块也可以。 创建了 webpack.config.js 后再执行 webpack 命令，webpack 就会使用这个配置文件的配置了。 有的时候我们开始一个新的前端项目，并不需要从零开始配置 webpack，而可以使用一些工具来帮助快速生成 webpack 配置。 脚手架中的 webpack 配置 现今，大多数前端框架都提供了简单的工具来协助快速生成项目基础文件，一般都会包含项目使用的 webpack 的配置，如： create-react-app create-react-app 的 webpack 配置在这个项目下：react-scripts。 angular/devkit/build-webpack 通常 angular 的项目开发和生产的构建任务都是使用 angular-cli 来运行的，但 angular-cli 只是命令的使用接口，基础功能是由 angular/devkit 来实现的，webpack 的构建相关只是其中一部分，详细的配置可以参考 webpack-configs 。 vue-cli vue-cli 使用 webpack 模板生成的项目文件中，webpack 相关配置存放在 build 目录下。 这些工具都提供了极其完整的配置来帮助开发者快捷开始一个项目，我们可以学习了解它们所提供的 webpack 配置，有些情况下，还会尝试修改这些配置以满足特殊的需求。 所以你也会发现，这些极其流行的前端类库或者框架都提供了基于 webpack 的工具，webpack 基本成为前端项目构建工具的标配。 这三个工具中，只有 angular-cli 使用了 4.x 版本的 webpack，其他的都还是用的 3.x 版本，学习的时候要留意一下版本区别。 小结 webpack 的安装和使用和大多数使用 Node.js 开发的命令行工具一样，使用 npm 安装后执行命令即可，webpack 4.x 版本的零配置特性也让上手变得更加简单。 前面我们已经介绍了 webpack 的几个重要的概念：入口，loader，plugin，输出，并且展示了一个简单的 webpack 配置例子，最后提供了前端社区三大框架基于 webpack 的脚手架工具的链接，也许这些工具提供的配置会比较难懂，后续的小节会帮助你逐渐去深入，慢慢地，你会对 webpack 配置越来越得心应手。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/02.搭建基本的前端开发环境.html":{"url":"使用webpack定制前端开发环境/02.搭建基本的前端开发环境.html","title":"02.搭建基本的前端开发环境","keywords":"","body":"搭建基本的前端开发环境 我们日常使用的前端开发环境应该是怎样的？我们可以尝试着把基本前端开发环境的需求列一下： 构建我们发布需要的 HTML、CSS、JS 文件 使用 CSS 预处理器来编写样式 处理和压缩图片 使用 Babel 来支持 ES 新特性 本地提供静态服务以方便开发调试 上述几项应该可以满足比较简单的前端项目开发环境需求了，下面会一一介绍如何配置 webpack 来满足这些需求。 关联 HTML webpack 默认从作为入口的 .js 文件进行构建（更多是基于 SPA 去考虑），但通常一个前端项目都是从一个页面（即 HTML）出发的，最简单的方法是，创建一个 HTML 文件，使用 script 标签直接引用构建好的 JS 文件，如： 但是，如果我们的文件名或者路径会变化，例如使用 [hash] 来进行命名，那么最好是将 HTML 引用路径和我们的构建结果关联起来，这个时候我们可以使用 html-webpack-plugin。 html-webpack-plugin 是一个独立的 node package，所以在使用之前我们需要先安装它，把它安装到项目的开发依赖中： npm install html-webpack-plugin -D # 或者 yarn add html-webpack-plugin -D 然后在 webpack 配置中，将 html-webpack-plugin 添加到 plugins 列表中： const HtmlWebpackPlugin = require('html-webpack-plugin') module.exports = { // ... plugins: [ new HtmlWebpackPlugin(), ], } 这样配置好之后，构建时 html-webpack-plugin 会为我们创建一个 HTML 文件，其中会引用构建出来的 JS 文件。实际项目中，默认创建的 HTML 文件并没有什么用，我们需要自己来写 HTML 文件，可以通过 html-webpack-plugin 的配置，传递一个写好的 HTML 模板： module.exports = { // ... plugins: [ new HtmlWebpackPlugin({ filename: 'index.html', // 配置输出文件名和路径 template: 'assets/index.html', // 配置文件模板 }), ], } 这样，通过 html-webpack-plugin 就可以将我们的页面和构建 JS 关联起来，回归日常，从页面开始开发。如果需要添加多个页面关联，那么实例化多个 html-webpack-plugin， 并将它们都放到 plugins 字段数组中就可以了。 更多配置这里就不展开讲解了，参考文档 html-webpack-plugin 以及官方提供的例子 html-webpack-plugin/examples。 构建 CSS 我们编写 CSS，并且希望使用 webpack 来进行构建，为此，需要在配置中引入 loader 来解析和处理 CSS 文件： module.exports = { module: { rules: [ // ... { test: /\\.css/, include: [ path.resolve(__dirname, 'src'), ], use: [ 'style-loader', 'css-loader', ], }, ], } } style-loader 和 css-loader 都是单独的 node package，需要安装。 我们创建一个 index.css 文件，并在 index.js 中引用它，然后进行构建。 import \"./index.css\" 可以发现，构建出来的文件并没有 CSS，先来看一下新增两个 loader 的作用： css-loader 负责解析 CSS 代码，主要是为了处理 CSS 中的依赖，例如 @import 和 url() 等引用外部文件的声明； style-loader 会将 css-loader 解析的结果转变成 JS 代码，运行时动态插入 style 标签来让 CSS 代码生效。 经由上述两个 loader 的处理后，CSS 代码会转变为 JS，和 index.js 一起打包了。如果需要单独把 CSS 文件分离出来，我们需要使用 extract-text-webpack-plugin 插件。 extract-text-webpack-plugin 这个插件在笔者写作时并未发布支持 webpack 4.x 的正式版本，所以安装的时候需要指定使用它的 alpha 版本：npm install extract-text-webpack-plugin@next -D 或者 yarn add extract-text-webpack-plugin@next -D。如果你用的是 webpack 3.x 版本，直接用 extract-text-webpack-plugin 现有的版本即可。 看一个简单的例子： const ExtractTextPlugin = require('extract-text-webpack-plugin') module.exports = { // ... module: { rules: [ { test: /\\.css$/, // 因为这个插件需要干涉模块转换的内容，所以需要使用它对应的 loader use: ExtractTextPlugin.extract({ fallback: 'style-loader', use: 'css-loader', }), }, ], }, plugins: [ // 引入插件，配置文件名，这里同样可以使用 [hash] new ExtractTextPlugin('index.css'), ], } CSS 预处理器 在上述使用 CSS 的基础上，通常我们会使用 Less/Sass 等 CSS 预处理器，webpack 可以通过添加对应的 loader 来支持，以使用 Less 为例，我们可以在官方文档中找到对应的 loader。 我们需要在上面的 webpack 配置中，添加一个配置来支持解析后缀为 .less 的文件： module.exports = { // ... module: { rules: [ { test: /\\.less$/, // 因为这个插件需要干涉模块转换的内容，所以需要使用它对应的 loader use: ExtractTextPlugin.extract({ fallback: 'style-loader', use: [ 'css-loader', 'less-loader', ], }), }, ], }, // ... } 处理图片文件 在前端项目的样式中总会使用到图片，虽然我们已经提到 css-loader 会解析样式中用 url() 引用的文件路径，但是图片对应的 jpg/png/gif 等文件格式，webpack 处理不了。是的，我们只要添加一个处理图片的 loader 配置就可以了，现有的 file-loader 就是个不错的选择。 file-loader 可以用于处理很多类型的文件，它的主要作用是直接输出文件，把构建后的文件路径返回。配置很简单，在 rules中添加一个字段，增加图片类型文件的解析配置： module.exports = { // ... module: { rules: [ { test: /\\.(png|jpg|gif)$/, use: [ { loader: 'file-loader', options: {}, }, ], }, ], }, } 更多关于 file-loader 的配置可以参考官方文档 file-loader。 使用 Babel Babel 是一个让我们能够使用 ES 新特性的 JS 编译工具，我们可以在 webpack 中配置 Babel，以便使用 ES6、ES7 标准来编写 JS 代码。 module.exports = { // ... module: { rules: [ { test: /\\.jsx?/, // 支持 js 和 jsx include: [ path.resolve(__dirname, 'src'), // src 目录下的才需要经过 babel-loader 处理 ], loader: 'babel-loader', }, ], }, } Babel 的相关配置可以在目录下使用 .babelrc 文件来处理，详细参考 Babel 官方文档 .babelrc。 启动静态服务 至此，我们完成了处理多种文件类型的 webpack 配置。我们可以使用 webpack-dev-server 在本地开启一个简单的静态服务来进行开发。 在项目下安装 webpack-dev-server，然后添加启动命令到 package.json 中： \"scripts\": { \"build\": \"webpack --mode production\", \"start\": \"webpack-dev-server --mode development\" } 也可以全局安装 webpack-dev-server，但通常建议以项目开发依赖的方式进行安装，然后在 npm package 中添加启动脚本。 尝试着运行 npm run start 或者 yarn start，然后就可以访问 http://localhost:8080/ 来查看你的页面了。默认是访问 index.html，如果是其他页面要注意访问的 URL 是否正确。 小结 我们现在已经可以使用 webpack 来完成日常中需要的基础前端构建需求：构建 HTML、CSS、JS 文件、使用 CSS 预处理器来编写样式、处理和压缩图片、使用 Babel、方便开发调试的静态服务，接下来的小节会在这个基础上，深入 webpack 配置细节，结合实际工作中的一些需要，更进一步地了解 webpack 的使用。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/03.webpack如何解析代码模块路径.html":{"url":"使用webpack定制前端开发环境/03.webpack如何解析代码模块路径.html","title":"03.webpack如何解析代码模块路径","keywords":"","body":"webpack 如何解析代码模块路径 在 webpack 支持的前端代码模块化中，我们可以使用类似 import * as m from './index.js' 来引用代码模块 index.js。 引用第三方类库则是像这样：import React from 'react'。webpack 构建的时候，会解析依赖后，然后再去加载依赖的模块文件，那么 webpack 如何将上述编写的 ./index.js 或 react 解析成对应的模块文件路径呢？ 在 JavaScript 中尽量使用 ECMAScript 2015 Modules 语法来引用依赖。 webpack 中有一个很关键的模块 enhanced-resolve 就是处理依赖模块路径的解析的，这个模块可以说是 Node.js 那一套模块路径解析的增强版本，有很多可以自定义的解析配置。 不熟悉 Node.js 模块路径解析机制的同学可以参考这篇文章：深入 Node.js 的模块机制。 模块解析规则 我们简单整理一下基本的模块解析规则，以便更好地理解后续 webpack 的一些配置会产生的影响。 解析相对路径 查找相对当前模块的路径下是否有对应文件或文件夹 是文件则直接加载 是文件夹则继续查找文件夹下的 package.json 文件 有 package.json 文件则按照文件中 main 字段的文件名来查找文件 无 package.json 或者无 main 字段则查找 index.js 文件 解析模块名查找当前文件目录下，父级目录及以上目录下的 node_modules 文件夹，看是否有对应名称的模块 解析绝对路径（不建议使用）直接查找对应路径的文件 在 webpack 配置中，和模块路径解析相关的配置都在 resolve 字段下： module.exports = { resolve: { // ... } } 接下来的内容会省略上述代码，直接描述 resolve 字段中的内容。 常用的一些配置 我们先从一些简单的需求来阐述 webpack 可以支持哪些解析路径规则的自定义配置。 resolve.alias 假设我们有个 utils 模块极其常用，经常编写相对路径很麻烦，希望可以直接 import 'utils' 来引用，那么我们可以配置某个模块的别名，如： alias: { utils: path.resolve(__dirname, 'src/utils') // 这里使用 path.resolve 和 __dirname 来获取绝对路径 } 上述的配置是模糊匹配，意味着只要模块路径中携带了 utils 就可以被替换掉，如： import 'utils/query.js' // 等同于 import '[项目绝对路径]/src/utils/query.js' 如果需要进行精确匹配可以使用： alias: { utils$: path.resolve(__dirname, 'src/utils') // 只会匹配 import 'utils' } 更多匹配相关的写法可以参考官方文档 Resolve Alias，这里不一一举例说明。 resolve.extensions 在看第 1 小节中的 webpack 配置时，你可能留意到了这么一行： extensions: ['.wasm', '.mjs', '.js', '.json', '.jsx'], // 这里的顺序代表匹配后缀的优先级，例如对于 index.js 和 index.jsx，会优先选择 index.js 看到数组中配置的字符串大概就可以猜到，这个配置的作用是和文件后缀名有关的。是的，这个配置可以定义在进行模块路径解析时，webpack 会尝试帮你补全那些后缀名来进行查找，例如有了上述的配置，当你在 src/utils/ 目录下有一个 common.js 文件时，就可以这样来引用： import * as common from './src/utils/common' webpack 会尝试给你依赖的路径添加上 extensions 字段所配置的后缀，然后进行依赖路径查找，所以可以命中 src/utils/common.js 文件。 但如果你是引用 src/styles 目录下的 common.css 文件时，如 import './src/styles/common'，webpack 构建时则会报无法解析模块的错误。 你可以在引用时添加后缀，import './src/styles/common.css' 来解决，或者在 extensions 添加一个 .css 的配置： extensions: ['.wasm', '.mjs', '.js', '.json', '.jsx', '.css'], resolve.modules 前面的内容有提到，对于直接声明依赖名的模块（如 react ），webpack 会类似 Node.js 一样进行路径搜索，搜索 node_modules 目录，这个目录就是使用 resolve.modules 字段进行配置的，默认就是： resolve: { modules: ['node_modules'], }, 通常情况下，我们不会调整这个配置，但是如果可以确定项目内所有的第三方依赖模块都是在项目根目录下的 node_modules 中的话，那么可以在 node_modules 之前配置一个确定的绝对路径： resolve: { modules: [ path.resolve(__dirname, 'node_modules'), // 指定当前目录下的 node_modules 优先查找 'node_modules', // 如果有一些类库是放在一些奇怪的地方的，你可以添加自定义的路径或者目录 ], }, 这样配置在某种程度上可以简化模块的查找，提升构建速度。 resolve.mainFields 有 package.json 文件则按照文件中 main 字段的文件名来查找文件 我们之前有提到这么一句话，其实确切的情况并不是这样的，webpack 的 resolve.mainFields 配置可以进行调整。当引用的是一个模块或者一个目录时，会使用 package.json 文件的哪一个字段下指定的文件，默认的配置是这样的： resolve: { // 配置 target === \"web\" 或者 target === \"webworker\" 时 mainFields 默认值是： mainFields: ['browser', 'module', 'main'], // target 的值为其他时，mainFields 默认值为： mainFields: [\"module\", \"main\"], }, 因为通常情况下，模块的 package 都不会声明 browser 或 module 字段，所以便是使用 main 了。 在 NPM packages 中，会有些 package 提供了两个实现，分别给浏览器和 Node.js 两个不同的运行时使用，这个时候就需要区分不同的实现入口在哪里。如果你有留意一些社区开源模块的 package.json 的话，你也许会发现 browser 或者 module 等字段的声明。 resolve.mainFiles 当目录下没有 package.json 文件时，我们说会默认使用目录下的 index.js 这个文件，其实这个也是可以配置的，是的，使用 resolve.mainFiles 字段，默认配置是： resolve: { mainFiles: ['index'], // 你可以添加其他默认使用的文件名 }, 通常情况下我们也无须修改这个配置，index.js 基本就是约定俗成的了。 resolve.resolveLoader 这个字段 resolve.resolveLoader 用于配置解析 loader 时的 resolve 配置，原本 resolve 的配置项在这个字段下基本都有。我们看下默认的配置： resolve: { resolveLoader: { extensions: ['.js', '.json'], mainFields: ['loader', 'main'], }, }, 这里提供的配置相对少用，我们一般遵从标准的使用方式，使用默认配置，然后把 loader 安装在项目根路径下的 node_modules 下就可以了。 小结 webpack 依赖 enhanced-resolve 来解析代码模块的路径，webpack 配置文件中和 resolve 相关的选项都会传递给 enhanced-resolve 使用，我们介绍了这些选项的作用： resolve.alias resolve.extensions resolve.modules resolve.mainFiles resolve.resolveLoader webpack 提供的这些选项可以帮助你更加灵活地去控制项目中代码模块的解析，除了上述的选项外，其他的选项在日常项目中相对比较少用到，如若需要，可以参考官方文档 Resolve。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/04.配置loader.html":{"url":"使用webpack定制前端开发环境/04.配置loader.html","title":"04.配置loader","keywords":"","body":"配置 loader 在第 1 小节，我们提到过，webpack 的 loader 用于处理不同的文件类型，在日常的项目中使用 loader 时，可能会遇到比较复杂的情况，本小节我们来深入探讨 loader 的一些配置细节。 loader 匹配规则 当我们需要配置 loader 时，都是在 module.rules 中添加新的配置项，在该字段中，每一项被视为一条匹配使用 loader 的规则。 先来看一个基础的例子： module.exports = { // ... module: { rules: [ { test: /\\.jsx?/, // 条件 include: [ path.resolve(__dirname, 'src'), ], // 条件 use: 'babel-loader', // 规则应用结果\u000e }, // 一个 object 即一条规则 // ... ], }, } loader 的匹配规则中有两个最关键的因素：一个是匹配条件，一个是匹配规则后的应用。 匹配条件通常都使用请求资源文件的绝对路径来进行匹配，在官方文档中称为 resource，除此之外还有比较少用到的 issuer，则是声明依赖请求的源文件的绝对路径。举个例子：在 /path/to/app.js 中声明引入 import './src/style.scss'，resource 是 /path/to/src/style.scss，issuer 是 /path/to/app.js，规则条件会对这两个值来尝试匹配。 上述代码中的 test 和 include 都用于匹配 resource 路径，是 resource.test 和 resource.include 的简写，你也可以这么配置： module.exports = { // ... rules: [ { resource: { // resource 的匹配条件 test: /\\.jsx?/, include: [ path.resolve(__dirname, 'src'), ], }, // 如果要使用 issuer 匹配，便是 issuer: { test: ... } use: 'babel-loader', }, // ... ], } issuer 规则匹配的场景比较少见，你可以用它来尝试约束某些类型的文件中只能引用某些类型的文件。 当规则的条件匹配时，便会使用对应的 loader 配置，如上述例子中的 babel-loader。关于 loader 配置后面再详细介绍，这里先来看看如何配置更加复杂的规则匹配条件。 规则条件配置 大多数情况下，配置 loader 的匹配条件时，只要使用 test 字段就好了，很多时候都只需要匹配文件后缀名来决定使用什么 loader，但也不排除在某些特殊场景下，我们需要配置比较复杂的匹配条件。webpack 的规则提供了多种配置形式： { test: ... } 匹配特定条件 { include: ... } 匹配特定路径 { exclude: ... } 排除特定路径 { and: [...] }必须匹配数组中所有条件 { or: [...] } 匹配数组中任意一个条件 { not: [...] } 排除匹配数组中所有条件 上述的所谓条件的值可以是： 字符串：必须以提供的字符串开始，所以是字符串的话，这里我们需要提供绝对路径 正则表达式：调用正则的 test 方法来判断匹配 函数：(path) => boolean，返回 true 表示匹配 数组：至少包含一个条件的数组 对象：匹配所有属性值的条件 通过例子来帮助理解： rules: [ { test: /\\.jsx?/, // 正则 include: [ path.resolve(__dirname, 'src'), // 字符串，注意是绝对路径 ], // 数组 // ... }, { test: { js: /\\.js/, jsx: /\\.jsx/, }, // 对象，不建议使用 not: [ (value) => { /* ... */ return true; }, // 函数，通常需要高度自定义时才会使用 ], }, ], 上述多个配置形式结合起来就能够基本满足各种各样的构建场景了，通常我们会结合使用 test/and 和 include&exclude 来配置条件，如上述那个简单的例子。 module type webpack 4.x 版本强化了 module type，即模块类型的概念，不同的模块类型类似于配置了不同的 loader，webpack 会有针对性地进行处理，现阶段实现了以下 5 种模块类型。 javascript/auto：即 webpack 3 默认的类型，支持现有的各种 JS 代码模块类型 —— CommonJS、AMD、ESM javascript/esm：ECMAScript modules，其他模块系统，例如 CommonJS 或者 AMD 等不支持，是 .mjs 文件的默认类型 javascript/dynamic：CommonJS 和 AMD，排除 ESM javascript/json：JSON 格式数据，require 或者 import 都可以引入，是 .json 文件的默认类型 webassembly/experimental：WebAssembly modules，当前还处于试验阶段，是 .wasm 文件的默认类型 如果不希望使用默认的类型的话，在确定好匹配规则条件时，我们可以使用 type 字段来指定模块类型，例如把所有的 JS 代码文件都设置为强制使用 ESM 类型： { test: /\\.js/, include: [ path.resolve(__dirname, 'src'), ], type: 'javascript/esm', // 这里指定模块类型 }, 上述做法是可以帮助你规范整个项目的模块系统，但是如果遗留太多不同类型的模块代码时，建议还是直接使用默认的 javascript/auto。 webpack 后续的开发计划会增加对更多模块类型的支持，例如极其常见的 CSS 和 HTML 模块类型，这个特性值得我们期待一下。 使用 loader 配置 当然，在当前版本的 webpack 中，module.rules 的匹配规则最重要的还是用于配置 loader，我们可以使用 use 字段： rules: [ { test: /\\.less/, use: [ 'style-loader', // 直接使用字符串表示 loader { loader: 'css-loader', options: { importLoaders: 1 }, }, // 用对象表示 loader，可以传递 loader 配置等 { loader: 'less-loader', options: { noIeCompat: true }, // 传递 loader 配置 }, ], }, ], 我们看下上述的例子，先忽略 loader 的使用情况，单纯看看如何配置。use 字段可以是一个数组，也可以是一个字符串或者表示 loader 的对象。如果只需要一个 loader，也可以这样：use: { loader: 'babel-loader', options: { ... } }。 我们还可以使用 options 给对应的 loader 传递一些配置项，这里不再展开。当你使用一些 loader 时，loader 的说明一般都有相关配置的描述。 loader 应用顺序 前面提到，一个匹配规则中可以配置使用多个 loader，即一个模块文件可以经过多个 loader 的转换处理，执行顺序是从最后配置的 loader 开始，一步步往前。例如，对于上面的 less 规则配置，一个 style.less 文件会途径 less-loader、css-loader、style-loader 处理，成为一个可以打包的模块。 loader 的应用顺序在配置多个 loader 一起工作时很重要，通常会使用在 CSS 配置上，除了 style-loader 和 css-loader，你可能还要配置 less-loader 然后再加个 postcss 的 autoprefixer 等。 上述从后到前的顺序是在同一个 rule 中进行的，那如果多个 rule 匹配了同一个模块文件，loader 的应用顺序又是怎样的呢？看一份这样的配置： rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: \"eslint-loader\", }, { test: /\\.js$/, exclude: /node_modules/, loader: \"babel-loader\", }, ], 这样无法法保证 eslint-loader 在 babel-loader 应用前执行。webpack 在 rules 中提供了一个 enforce 的字段来配置当前 rule 的 loader 类型，没配置的话是普通类型，我们可以配置 pre 或 post，分别对应前置类型或后置类型的 loader。 eslint-loader 要检查的是人工编写的代码，如果在 babel-loader 之后使用，那么检查的是 Babel 转换后的代码，所以必须在 babel-loader 处理之前使用。 还有一种行内 loader，即我们在应用代码中引用依赖时直接声明使用的 loader，如 const json = require('json-loader!./file.json') 这种。不建议在应用开发中使用这种 loader，后续我们还会再提到。 顾名思义，所有的 loader 按照前置 -> 行内 -> 普通 -> 后置的顺序执行。所以当我们要确保 eslint-loader 在 babel-loader 之前执行时，可以如下添加 enforce 配置： rules: [ { enforce: 'pre', // 指定为前置类型 test: /\\.js$/, exclude: /node_modules/, loader: \"eslint-loader\", }, ] 当项目文件类型和应用的 loader 不是特别复杂的时候，通常建议把要应用的同一类型 loader 都写在同一个匹配规则中，这样更好维护和控制。 使用 noParse 在 webpack 中，我们需要使用的 loader 是在 module.rules 下配置的，webpack 配置中的 module 用于控制如何处理项目中不同类型的模块。 除了 module.rules 字段用于配置 loader 之外，还有一个 module.noParse 字段，可以用于配置哪些模块文件的内容不需要进行解析。对于一些不需要解析依赖（即无依赖） 的第三方大型类库等，可以通过这个字段来配置，以提高整体的构建速度。 使用 noParse 进行忽略的模块文件中不能使用 import、require、define 等导入机制。 module.exports = { // ... module: { noParse: /jquery|lodash/, // 正则表达式 // 或者使用 function noParse(content) { return /jquery|lodash/.test(content) }, } } noParse 从某种程度上说是个优化配置项，日常也可以不去使用。 小结 webpack 的 loader 相关配置都在 module.rules 字段下，我们需要通过 test、include、exclude 等配置好应用 loader 的条件规则，然后使用 use 来指定需要用到的 loader，配置应用的 loader 时还需要注意一下 loader 的执行顺序。 除此之外，webpack 4.x 版本新增了模块类型的概念，相当于 webpack 内置一个更加底层的文件类型处理，暂时只有 JS 相关的支持，后续会再添加 HTML 和 CSS 等类型。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/05.使用plugin.html":{"url":"使用webpack定制前端开发环境/05.使用plugin.html","title":"05.使用plugin","keywords":"","body":"使用 plugin webpack 中的 plugin 大多都提供额外的能力，它们在 webpack 中的配置都只是把插件实例添加到 plugins 字段的数组中。不过由于需要提供不同的功能，不同的插件本身的配置比较多样化。 社区中有很多 webpack 插件可供使用，而优秀的插件基本上都提供了详细的使用说明文档。更多的插件可以在这里查找：plugins in awesome-webpack。 下面通过介绍几个常用的插件来了解插件的使用方法。 DefinePlugin DefinePlugin 是 webpack 内置的插件，可以使用 webpack.DefinePlugin 直接获取。 这个插件用于创建一些在编译时可以配置的全局常量，这些常量的值我们可以在 webpack 的配置中去指定，例如： module.exports = { // ... plugins: [ new webpack.DefinePlugin({ PRODUCTION: JSON.stringify(true), // const PRODUCTION = true VERSION: JSON.stringify('5fa3b9'), // const VERSION = '5fa3b9' BROWSER_SUPPORTS_HTML5: true, // const BROWSER_SUPPORTS_HTML5 = 'true' TWO: '1+1', // const TWO = 1 + 1, CONSTANTS: { APP_VERSION: JSON.stringify('1.1.2') // const CONSTANTS = { APP_VERSION: '1.1.2' } } }), ], } 有了上面的配置，就可以在应用代码文件中，访问配置好的变量了，如： console.log(\"Running App version \" + VERSION); if(!BROWSER_SUPPORTS_HTML5) require(\"html5shiv\"); 上面配置的注释已经简单说明了这些配置的效果，这里再简述一下整个配置规则。 如果配置的值是字符串，那么整个字符串会被当成代码片段来执行，其结果作为最终变量的值，如上面的 \"1+1\"，最后的结果是 2 如果配置的值不是字符串，也不是一个对象字面量，那么该值会被转为一个字符串，如 true，最后的结果是 'true' 如果配置的是一个对象字面量，那么该对象的所有 key 会以同样的方式去定义 这样我们就可以理解为什么要使用 JSON.stringify() 了，因为 JSON.stringify(true) 的结果是 'true'，JSON.stringify(\"5fa3b9\") 的结果是 \"5fa3b9\"。 社区中关于 DefinePlugin 使用得最多的方式是定义环境变量，例如 PRODUCTION = true 或者 __DEV__ = true 等。部分类库在开发环境时依赖这样的环境变量来给予开发者更多的开发调试反馈，例如 react 等。 建议使用 process.env.NODE_ENV: ... 的方式来定义 process.env.NODE_ENV，而不是使用 process: { env: { NODE_ENV: ... } } 的方式，因为这样会覆盖掉 process 这个对象，可能会对其他代码造成影响。 copy-webpack-plugin 这个插件看名字就知道它有什么作用，没错，就是用来复制文件的。 我们一般会把开发的所有源码和资源文件放在 src/ 目录下，构建的时候产出一个 build/ 目录，通常会直接拿 build 中的所有文件来发布。有些文件没经过 webpack 处理，但是我们希望它们也能出现在 build 目录下，这时就可以使用 CopyWebpackPlugin 来处理了。 我们来看下如何配置这个插件： const CopyWebpackPlugin = require('copy-webpack-plugin') module.exports = { // ... plugins: [ new CopyWebpackPlugin([ { from: 'src/file.txt', to: 'build/file.txt', }, // 顾名思义，from 配置来源，to 配置目标路径 { from: 'src/*.ico', to: 'build/*.ico' }, // 配置项可以使用 glob // 可以配置很多项复制规则 ]), ], } glob 用法可以参考 glob-primer。 上述的配置日常应用已经足够，更多的配置内容可以参考 copy-webpack-plugin。 extract-text-webpack-plugin extract-text-webpack-plugin 之前的章节有简单介绍过，我们用它来把依赖的 CSS 分离出来成为单独的文件。这里再看一下使用 extract-text-webpack-plugin 的配置： const ExtractTextPlugin = require('extract-text-webpack-plugin') module.exports = { // ... module: { rules: [ { test: /\\.css$/, // 因为这个插件需要干涉模块转换的内容，所以需要使用它对应的 loader use: ExtractTextPlugin.extract({ fallback: 'style-loader', use: 'css-loader', }), }, ], }, plugins: [ // 引入插件，配置文件名，这里同样可以使用 [hash] new ExtractTextPlugin('index.css'), ], } 在上述的配置中，我们使用了 index.css 作为单独分离出来的文件名，但有的时候构建入口不止一个，extract-text-webpack-plugin 会为每一个入口创建单独分离的文件，因此最好这样配置： plugins: [ new ExtractTextPlugin('[name].css'), ], 这样确保在使用多个构建入口时，生成不同名称的文件。 这里再次提及 extract-text-webpack-plugin，一个原因是它是一个蛮常用的插件，另一个原因是它的使用方式比较特别，除了在 plugins 字段添加插件实例之外，还需要调整 loader 对应的配置。 在这里要强调的是，在 webpack 中，loader 和 plugin 的区分是很清楚的，针对文件模块转换要做的使用 loader，而其他干涉构建内容的可以使用 plugin。 ExtractTextWebpackPlugin 既提供了 plugin，也提供了 extract 方法来获取对应需要的 loader。 ProvidePlugin ProvidePlugin 也是一个 webpack 内置的插件，我们可以直接使用 webpack.ProvidePlugin 来获取。 该组件用于引用某些模块作为应用运行时的变量，从而不必每次都用 require 或者 import，其用法相对简单： new webpack.ProvidePlugin({ identifier: 'module', // ... }) // 或者 new webpack.ProvidePlugin({ identifier: ['module', 'property'], // 即引用 module 下的 property，类似 import { property } from 'module' // ... }) 在你的代码中，当 identifier 被当作未赋值的变量时，module 就会被自动加载了，而 identifier 这个变量即 module 对外暴露的内容。 注意，如果是 ES 的 default export，那么你需要指定模块的 default 属性：identifier: ['module', 'default'],。 更多使用例子可以查看官方文档 ProvidePlugin。 IgnorePlugin IgnorePlugin 和 ProvidePlugin 一样，也是一个 webpack 内置的插件，可以直接使用 webpack.IgnorePlugin 来获取。 这个插件用于忽略某些特定的模块，让 webpack 不把这些指定的模块打包进去。例如我们使用 moment.js，直接引用后，里边有大量的 i18n 的代码，导致最后打包出来的文件比较大，而实际场景并不需要这些 i18n 的代码，这时我们可以使用 IgnorePlugin 来忽略掉这些代码文件，配置如下： module.exports = { // ... plugins: [ new webpack.IgnorePlugin(/^\\.\\/locale$/, /moment$/) ] } IgnorePlugin 配置的参数有两个，第一个是匹配引入模块路径的正则表达式，第二个是匹配模块的对应上下文，即所在目录名。 小结 本小节介绍了几个相对常见的 webpack plugin 的使用： DefinePlugin copy-webpack-plugin extract-text-webpack-plugin ProvidePlugin IgnorePlugin 更多其他组件的使用就请有兴趣的同学自行摸索了：plugins in awesome-webpack。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/06.更好地使用webpack-dev-server.html":{"url":"使用webpack定制前端开发环境/06.更好地使用webpack-dev-server.html","title":"06.更好地使用webpack-dev-server","keywords":"","body":"更好地使用 webpack-dev-server 在构建代码并部署到生产环境之前，我们需要一个本地环境，用于运行我们开发的代码。这个环境相当于提供了一个简单的服务器，用于访问 webpack 构建好的静态文件，我们日常开发时可以使用它来调试前端代码。 之前在第 2 小节的启动静态服务部分，我们已经简单介绍过 webpack-dev-server 的使用了。webpack-dev-server 是 webpack 官方提供的一个工具，可以基于当前的 webpack 构建配置快速启动一个静态服务。当 mode 为 development 时，会具备 hot reload 的功能，即当源码文件变化时，会即时更新当前页面，以便你看到最新的效果。 webpack-dev-server 的基础使用 webpack-dev-server 是一个 npm package，安装后在已经有 webpack 配置文件的项目目录下直接启动就可以： npm install webpack-dev-server -g webpack-dev-server --mode development webpack-dev-server 本质上也是调用 webpack，4.x 版本的也要指定 mode，其实 webpack-dev-server 应该直接把 development 作为默认值，有兴趣的同学可以查看这个 issue：Default mode to development?。 建议把 webpack-dev-server 作为开发依赖安装，然后使用 npm scripts 来启动，如： npm install webpack-dev-server --save-dev package 中的 scripts 配置： { // ... \"scripts\": { \"start\": \"webpack-dev-server --mode development\" } } npm run start webpack-dev-server 默认使用 8080 端口，如果你使用了 html-webpack-plugin 来构建 HTML 文件，并且有一个 index.html 的构建结果，那么直接访问 http://localhost:8080/ 就可以看到 index.html 页面了。如果没有 HTML 文件的话，那么 webpack-dev-server 会生成一个展示静态资源列表的页面。 webpack-dev-server 的配置 在 webpack 的配置中，可以通过 devServer 字段来配置 webpack-dev-server，如端口设置、启动 gzip 压缩等，这里简单讲解几个常用的配置。 public 字段用于指定静态服务的域名，默认是 http://localhost:8080/ ，当你使用 Nginx 来做反向代理时，应该就需要使用该配置来指定 Nginx 配置使用的服务域名。 port 字段用于指定静态服务的端口，如上，默认是 8080，通常情况下都不需要改动。 publicPath 字段用于指定构建好的静态文件在浏览器中用什么路径去访问，默认是 /，例如，对于一个构建好的文件 bundle.js，完整的访问路径是 http://localhost:8080/bundle.js，如果你配置了 publicPath: 'assets/'，那么上述 bundle.js 的完整访问路径就是 http://localhost:8080/assets/bundle.js。可以使用整个 URL 来作为 publicPath 的值，如 publicPath: 'http://localhost:8080/assets/'。如果你使用了 HMR，那么要设置 publicPath 就必须使用完整的 URL。 建议将 devServer.publicPath 和 output.publicPath 的值保持一致。 proxy 用于配置 webpack-dev-server 将特定 URL 的请求代理到另外一台服务器上。当你有单独的后端开发服务器用于请求 API 时，这个配置相当有用。例如： proxy: { '/api': { target: \"http://localhost:3000\", // 将 URL 中带有 /api 的请求代理到本地的 3000 端口的服务上 pathRewrite: { '^/api': '' }, // 把 URL 中 path 部分的 `api` 移除掉 }, } webpack-dev-server 的 proxy 功能是使用 http-proxy-middleware 来实现的，如果需要更详细的 proxy 配置，可以参考官方文档 http-proxy-middleware。 contentBase 用于配置提供额外静态文件内容的目录，之前提到的 publicPath 是配置构建好的结果以什么样的路径去访问，而 contentBase 是配置额外的静态文件内容的访问路径，即那些不经过 webpack 构建，但是需要在 webpack-dev-server 中提供访问的静态资源（如部分图片等）。推荐使用绝对路径： // 使用当前目录下的 public contentBase: path.join(__dirname, \"public\") // 也可以使用数组提供多个路径 contentBase: [path.join(__dirname, \"public\"), path.join(__dirname, \"assets\")] publicPath 的优先级高于 contentBase。 before 和 after 配置用于在 webpack-dev-server 定义额外的中间件，如 before(app){ app.get('/some/path', function(req, res) { // 当访问 /some/path 路径时，返回自定义的 json 数据 res.json({ custom: 'response' }) }) } before 在 webpack-dev-server 静态资源中间件处理之前，可以用于拦截部分请求返回特定内容，或者实现简单的数据 mock。 after 在 webpack-dev-server 静态资源中间件处理之后，比较少用到，可以用于打印日志或者做一些额外处理。 webpack-dev-server 的配置项比较多，这里只列举了一些日常比较有用的，更多的请参考官方文档 webpack-dev-server。 webpack-dev-middleware 如果你熟悉使用 Node.js 来开发 Web 服务，使用过 Express 或者 Koa，那么对中间件的概念应该会有所了解。 简而言之，中间件就是在 Express 之类的 Web 框架中实现各种各样功能（如静态文件访问）的这一部分函数。多个中间件可以一起协同构建起一个完整的 Web 服务器。 不熟悉 Express 中间件概念的同学可以参考 Express 的官方文档 使用中间件。 webpack-dev-middleware 就是在 Express 中提供 webpack-dev-server 静态服务能力的一个中间件，我们可以很轻松地将其集成到现有的 Express 代码中去，就像添加一个 Express 中间件那么简单。 首先安装 webpack-dev-middleware 依赖： npm install webpack-dev-middleware --save-dev 接着创建一个 Node.js 服务的脚本文件，如 app.js： const webpack = require('webpack') const middleware = require('webpack-dev-middleware') const webpackOptions = require('./webpack.config.js') // webpack 配置文件的路径 // 本地的开发环境默认就是使用 development mode webpackOptions.mode = 'development' const compiler = webpack(webpackOptions) const express = require('express') const app = express() app.use(middleware(compiler, { // webpack-dev-middleware 的配置选项 })) // 其他 Web 服务中间件 // app.use(...) app.listen(3000, () => console.log('Example app listening on port 3000!')) 然后用 Node.js 运行该文件即可： node app.js # 使用刚才创建的 app.js 文件 使用 webpack-dev-server 的好处是相对简单，直接安装依赖后执行命令即可，而使用 webpack-dev-middleware 的好处是可以在既有的 Express 代码基础上快速添加 webpack-dev-server 的功能，同时利用 Express 来根据需要添加更多的功能，如 mock 服务、代理 API 请求等。 其实 webpack-dev-server 也是基于 Express 开发的，前面提及的 webpack-dev-server 中 before 或 after 的配置字段，也可以用于编写特定的中间件来根据需要添加额外的功能。 实现一个简单的 mock 服务 在前端的日常开发工作中，我们本地需要的不仅仅是提供静态内容访问的服务，还需要模拟后端 API 数据来做一些应用测试工作，这个时候我们需要一个 mock 数据的服务，而 webpack-dev-server 的 before 或 proxy 配置，又或者是 webpack-dev-middleware 结合 Express，都可以帮助我们来实现简单的 mock 服务。 这一部分内容涉及比较多的 Node.js 代码实现，这里不做过于详细的例子解释，只提供一些实现的思路。 我们最主要的需求是当浏览器请求某一个特定的路径时（如 /some/path ），可以访问我们想要的数据内容。 我们先基于 Express app 实现一个简单 mock 功能的方法： module.export = function mock(app) { app.get('/some/path', (req, res) => { res.json({ data: '' }) }) // ... 其他的请求 mock // 如果 mock 代码过多，可以将其拆分成多个代码文件，然后 require 进来 } 然后应用到配置中的 before 字段： const mock = require('./mock') // ... before(app) { mock(app) // 调用 mock 函数 } 这样的 mock 函数照样可以应用到 Express 中去，提供与 webpack-dev-middleware 同样的功能。 由于 app.get('', (req, res) => { ... }) 的 callback 可以拿到 req 请求对象，其实可以根据请求参数来改变返回的结果，即通过参数来模拟多种场景的返回数据来协助测试多种场景下的代码应用。 当你单独实现或者使用一个 mock 服务时，你可以通过 proxy 来配置部分路径代理到对应的 mock 服务上去，从而把 mock 服务集成到当前的开发服务中去，相对来说也很简单。 当你和后端开发进行联调时，亦可使用 proxy 代理到对应联调使用的机器上，从而可以使用本地前端代码的开发环境来进行联调。当然了，连线上环境的异常都可以这样来尝试定位问题。 小结 本小节介绍了 webpack-dev-server 的基础使用及其更多的一些配置选项，如何使用 webpack-dev-middleware 来将 webpack 的开发环境集成到现有的 Node 服务中去，以及如何在 webpack-dev-server 和 webpack-dev-middleware 的基础上实现简单的 mock 服务。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/07.开发和生产环境的构建配置差异.html":{"url":"使用webpack定制前端开发环境/07.开发和生产环境的构建配置差异.html","title":"07.开发和生产环境的构建配置差异","keywords":"","body":"开发和生产环境的构建配置差异 我们在日常的前端开发工作中，一般都会有两套构建环境：一套开发时使用，构建结果用于本地开发调试，不进行代码压缩，打印 debug 信息，包含 sourcemap 文件；另外一套构建后的结果是直接应用于线上的，即代码都是压缩后，运行时不打印 debug 信息，静态文件不包括 sourcemap 的。有的时候可能还需要多一套测试环境，在运行时直接进行请求 mock 等工作。 webpack 4.x 版本引入了 mode 的概念，在运行 webpack 时需要指定使用 production 或 development 两个 mode 其中一个，这个功能也就是我们所需要的运行两套构建环境的能力。 当你指定使用 production mode 时，默认会启用各种性能优化的功能，包括构建结果优化以及 webpack 运行性能优化，而如果是 development mode 的话，则会开启 debug 工具，运行时打印详细的错误信息，以及更加快速的增量编译构建。关于这两个 mode 的更详细区别，可以查阅 webpack 作者的这篇文章：webpack 4: mode and optimization。 虽然 webpack 的 mode 参数已经给我们带来了一些很方便的环境差异化配置，但是针对一些项目情况，例如使用 css-loader 或者 url-loader 等，不同环境传入 loader 的配置也不一样，而 mode 并没有帮助我们做这些事情，因此有些配置还是需要手动区分环境后来进行调整。 在配置文件中区分 mode 之前我们的配置文件都是直接对外暴露一个 JS 对象，这种方式暂时没有办法获取到 webpack 的 mode 参数，我们需要更换一种方式来处理配置。根据官方的文档多种配置类型，配置文件可以对外暴露一个函数，因此我们可以这样做： module.exports = (env, argv) => ({ // ... 其他配置 optimization: { minimize: false, // 使用 argv 来获取 mode 参数的值 minimizer: argv.mode === 'production' ? [ new UglifyJsPlugin({ /* 你自己的配置 */ }), // 仅在我们要自定义压缩配置时才需要这么做 // mode 为 production 时 webpack 会默认使用压缩 JS 的 plugin ] : [], }, }) 这样获取 mode 之后，我们就能够区分不同的构建环境，然后根据不同环境再对特殊的 loader 或 plugin 做额外的配置就可以了。 以上是 webpack 4.x 的做法，由于有了 mode 参数，区分环境变得简单了。不过在当前业界，估计还是使用 webpack 3.x 版本的居多，所以这里也简单介绍一下 3.x 如何区分环境。 webpack 的运行时环境是 Node.js，我们可以通过 Node.js 提供的机制给要运行的 webpack 程序传递环境变量，来控制不同环境下的构建行为。例如，我们在 npm 中的 scripts 字段添加一个用于生产环境的构建命令： { \"scripts\": { \"build\": \"NODE_ENV=production webpack\", \"develop\": \"NODE_ENV=development webpack-dev-server\" } } 然后在 webpack.config.js 文件中可以通过 process.env.NODE_ENV 来获取命令传入的环境变量： const config = { // ... webpack 配置 } if (process.env.NODE_ENV === 'production') { // 生产环境需要做的事情，如使用代码压缩插件等 config.plugins.push(new UglifyJsPlugin()) } module.exports = config 运行时的环境变量 我们使用 webpack 时传递的 mode 参数，是可以在我们的应用代码运行时，通过 process.env.NODE_ENV 这个变量获取的。这样方便我们在运行时判断当前执行的构建环境，使用最多的场景莫过于控制是否打印 debug 信息。 下面这个简单的例子，在应用开发的代码中实现一个简单的 console 打印封装： export default function log(...args) { if (process.env.NODE_ENV === 'development' && console && console.log) { console.log.apply(console, args) } } 同样，以上是 webpack 4.x 的做法，下面简单介绍一下 3.x 版本应该如何实现。这里需要用到 DefinePlugin 插件，它可以帮助我们在构建时给运行时定义变量，那么我们只要在前面 webpack 3.x 版本区分构建环境的例子的基础上，再使用 DefinePlugin 添加环境变量即可影响到运行时的代码。 在 webpack 的配置中添加 DefinePlugin 插件： module.exports = { // ... // webpack 的配置 plugins: [ new webpack.DefinePlugin({ // webpack 3.x 的 process.env.NODE_ENV 是通过手动在命令行中指定 NODE_ENV=... 的方式来传递的 'process.env.NODE_ENV': JSON.stringify(process.env.NODE_ENV), }), ], } 常见的环境差异配置 前面提及的使用环境变量的方式可以让我们在不同的构建环境中完成不同的构建需求，这里列举一下常见的 webpack 构建差异配置： 生产环境可能需要分离 CSS 成单独的文件，以便多个页面共享同一个 CSS 文件 生产环境需要压缩 HTML/CSS/JS 代码 生产环境需要压缩图片 开发环境需要生成 sourcemap 文件 开发环境需要打印 debug 信息 开发环境需要 live reload 或者 hot reload 的功能 以上是常见的构建环境需求差异，可能更加复杂的项目中会有更多的构建需求（如划分静态域名等），但是我们都可以通过判断环境变量来实现这些有环境差异的构建需求。 webpack 4.x 的 mode 已经提供了上述差异配置的大部分功能，mode 为 production 时默认使用 JS 代码压缩，而 mode 为 development 时默认启用 hot reload，等等。这样让我们的配置更为简洁，我们只需要针对特别使用的 loader 和 plugin 做区分配置就可以了。 webpack 3.x 版本还是只能自己动手修改配置来满足大部分环境差异需求，所以如果你要开始一个新的项目，建议直接使用 webpack 4.x 版本。 拆分配置 前面我们列出了几个环境差异配置，可能这些构建需求就已经有点多了，会让整个 webpack 的配置变得复杂，尤其是有着大量环境变量判断的配置。我们可以把 webpack 的配置按照不同的环境拆分成多个文件，运行时直接根据环境变量加载对应的配置即可。基本的划分如下： webpack.base.js：基础部分，即多个文件中共享的配置 webpack.development.js：开发环境使用的配置 webpack.production.js：生产环境使用的配置 webpack.test.js：测试环境使用的配置 一些复杂的项目可能会有更多配置。这里介绍一下如何处理这样的配置拆分。 首先我们要明白，对于 webpack 的配置，其实是对外暴露一个 JS 对象，所以对于这个对象，我们都可以用 JS 代码来修改它，例如： const config = { // ... webpack 配置 } // 我们可以修改这个 config 来调整配置，例如添加一个新的插件 config.plugins.push(new YourPlugin()); module.exports = config; 当然，如果是对外暴露一个 JS 函数的话，像本小节第一个例子那样，那么修改配置就更加容易了，这里不再举例说明。 因此，只要有一个工具能比较智能地合并多个配置对象，我们就可以很轻松地拆分 webpack 配置，然后通过判断环境变量，使用工具将对应环境的多个配置对象整合后提供给 webpack 使用。这个工具就是 webpack-merge。 我们的 webpack 配置基础部分，即 webpack.base.js 应该大致是这样的： module.exports = { entry: '...', output: { // ... }, resolve: { // ... }, module: { // 这里是一个简单的例子，后面介绍 API 时会用到 rules: [ { test: /\\.js$/, use: ['babel'], }, ], // ... }, plugins: [ // ... ], } 然后 webpack.development.js 需要添加 loader 或 plugin，就可以使用 webpack-merge 的 API，例如： const { smart } = require('webpack-merge') const webpack = require('webpack') const base = require('./webpack.base.js') module.exports = smart(base, { module: { rules: [ // 用 smart API，当这里的匹配规则相同且 use 值都是数组时，smart 会识别后处理 // 和上述 base 配置合并后，这里会是 { test: /\\.js$/, use: ['babel', 'coffee'] } // 如果这里 use 的值用的是字符串或者对象的话，那么会替换掉原本的规则 use 的值 { test: /\\.js$/, use: ['coffee'], }, // ... ], }, plugins: [ // plugins 这里的数组会和 base 中的 plugins 数组进行合并 new webpack.DefinePlugin({ 'process.env.NODE_ENV': JSON.stringify(process.env.NODE_ENV), }), ], }) 可见 webpack-merge 提供的 smart 方法，可以帮助我们更加轻松地处理 loader 配置的合并。webpack-merge 还有其他 API 可以用于自定义合并行为，这里就不详细介绍了，需要深入了解的同学可以查阅官方文档 webpack-merge。 小结 本小节介绍了 webpack 4.x 和 3.x 如何在配置文件中区分环境来应用不同的配置选项（4.x 使用 mode 参数，3.x 使用 Node.js 的 process.env.NODE_ENV），如何在应用代码运行时携带当前构建环境的相关信息，以及如何利用 webpack-merge 这个工具来更好地维护不同构建环境中对应的构建需求配置。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/08.用HMR提高开发效率.html":{"url":"使用webpack定制前端开发环境/08.用HMR提高开发效率.html","title":"08.用HMR提高开发效率","keywords":"","body":"用 HMR 提高开发效率 HMR 全称是 Hot Module Replacement，即模块热替换。在这个概念出来之前，我们使用过 Hot Reloading，当代码变更时通知浏览器刷新页面，以避免频繁手动刷新浏览器页面。HMR 可以理解为增强版的 Hot Reloading，但不用整个页面刷新，而是局部替换掉部分模块代码并且使其生效，可以看到代码变更后的效果。所以，HMR 既避免了频繁手动刷新页面，也减少了页面刷新时的等待，可以极大地提高前端页面开发效率。 配置使用 HMR HMR 是 webpack 提供的非常有用的一个功能，跟我们之前提到的一样，安装好 webpack-dev-server， 添加一些简单的配置，即在 webpack 的配置文件中添加启用 HMR 需要的两个插件： const webpack = require('webpack') module.exports = { // ... devServer: { hot: true // dev server 的配置要启动 hot，或者在命令行中带参数开启 }, plugins: [ // ... new webpack.NamedModulesPlugin(), // 用于启动 HMR 时可以显示模块的相对路径 new webpack.HotModuleReplacementPlugin(), // Hot Module Replacement 的插件 ], } 笔者觉得 HMR 应该是 development mode 默认启动的功能，这个希望 webpack 后续能有优化。 HMR 运行原理 HMR 的实现和运行相对复杂，需要多个部分协同配合，这里稍微介绍一下 HRM 的运行原理。 首先我们要知道一个概念：webpack 内部运行时，会维护一份用于管理构建代码时各个模块之间交互的表数据，webpack 官方称之为 Manifest，其中包括入口代码文件和构建出来的 bundle 文件的对应关系。可以使用 WebpackManifestPlugin 插件来输出这样的一份数据。 了解这个概念后，我们来看一下 HMR 的大致运行流程图。 当你使用前面的配置启动了支持 HMR 的 webpack-dev-server，然后在浏览器打开页面时，你也可以从控制台看到大概的 HMR 执行流程： 开启了 hot 功能的 webpack 会往我们应用的主要代码中添加 WS 相关的代码，用于和服务器保持连接，等待更新动作。 当你配置了 HMR 的插件时，会往应用代码中添加 HMR 运行时的代码，主要用于定义代码模块应用更新时的 API，后面会详细介绍。 有兴趣可以查看源码：HotModuleReplacement.runtime.js。 有了这两个部分就可以支持整个 HMR 的功能了。我们先忽略流程图的右上角部分，左下角的流程相对容易理解：当有更新时，webpack-dev-server 发送更新信号给 HMR 运行时，然后 HMR 再请求所需要的更新数据，请求的更新数据没有问题的话就应用更新。 如果 HMR 只是简单替换了代码模块的内容，如替换掉所谓的 installedModules 中需要更新的部分，那么这样并没有办法把更新后的结果实时地在浏览器上显示出来，所以才会需要流程图的右上角部分。 如果无法理解 installedModules，可以参考第 13 小节中的「bundler 的基础流程」这一部分的内容 前面提到的 HMR 运行时代码会提供定义代码模块应用更新时执行的 API，这些 API 可以让我们在模块中定义接收到 HMR 更新应用信号时，需要额外做什么工作。例如， style-loader 就需要实现 HMR 接口，当收到更新时，使用新的样式替换掉旧的样式，大概是这样： if (module.hot) { module.hot.accept('/some/path', function() { // ... 用新样式替换旧样式 }) } 详情可以参考 style-loader 中的代码实现：HMR interface implemention in style-loader。 HMR 应用更新时是使用 webpackHotUpdate 来处理的： webpackHotUpdate(id, { 'modulePath': function() { // 模块更新后的代码 } }) 执行 webpackHotUpdate 时如发现模块代码实现了 HMR 接口，就会执行相应的回调或者方法，从而达到应用更新时，模块可以自行管理自己所需要额外做的工作。不过，并不是所有的模块都需要做相关的处理，当遇见没有实现 HMR 接口的模块时，就会往上层冒泡，如本节开头部分的流程图所示。 这里还有一个问题是，webpack 如何保证 HMR 接口中的引用是最新的模块代码？我们看一个简单的例子： import './index.css' import hello from './bar' hello() if (module.hot) { module.hot.accept('./bar', () => { // console.log('Accepting the updated bar module!') hello() }) } 从代码上看，hello 都是同一个，这样的话并没有办法引用最新的模块代码，但是我们看一下上述代码在 webpack 构建后的结果： if (true) { module.hot.accept(\"./src/bar.js\", function(__WEBPACK_OUTDATED_DEPENDENCIES__) { /* harmony import */ __WEBPACK_IMPORTED_MODULE_1__bar__ = __webpack_require__(\"./src/bar.js\"); (() => { // console.log('Accepting the updated bar module!') Object(__WEBPACK_IMPORTED_MODULE_1__bar__[\"default\"])() })(__WEBPACK_OUTDATED_DEPENDENCIES__); }) } 其他代码比较杂，我们集中看 module.hot 的处理部分。这里可以发现，我们的 hello 已经重新使用 __webpack_require__ 来引用了，所以可以确保它是最新的模块代码。 基本上 HMR 的执行原理就是这样，更具体的实现部分就不展开讲解了。在日常开发中，我们需要更多的工具来帮助我们实现 HMR 的接口，避免编写过多 HMR 需要的代码。例如，React 在组件代码更新时可能需要触发重新 render 来实现实时的组件展示效果，官方提供了一些现有的工具，需要的可以参考一下：hot module replacement tools。 module.hot 常见的 API 前面 HMR 实现部分已经讲解了实现 HMR 接口的重要性，下面来看看常见的 module.hot API 有哪些，以及如何使用。 之前已经简单介绍过，module.hot.accept 方法指定在应用特定代码模块更新时执行相应的 callback，第一个参数可以是字符串或者数组，如： if (module.hot) { module.hot.accept(['./bar.js', './index.css'], () => { // ... 这样当 bar.js 或者 index.css 更新时都会执行该函数 }) } module.hot.decline 对于指定的代码模块，拒绝进行模块代码的更新，进入更新失败状态，如 module.hot.decline('./bar.js')。这个方法比较少用到。 module.hot.dispose 用于添加一个处理函数，在当前模块代码被替换时运行该函数，例如： if (module.hot) { module.hot.dispose((data) => { // data 用于传递数据，如果有需要传递的数据可以挂在 data 对象上，然后在模块代码更新后可以通过 module.hot.data 来获取 }) } module.hot.accept 通常用于指定当前依赖的某个模块更新时需要做的处理，如果是当前模块更新时需要处理的动作，使用 module.hot.dispose 会更加容易方便。 module.hot.removeDisposeHandler 用于移除 dispose 方法添加的 callback。 关于 module.hot 的更多 API 详情可以参考官方文档：Hot Module Replacement APIs。 小结 Hot Module Replacement 是 webpack 具备的一个相当重要的特性，用于提升开发效率和体验。在这一小节中，我们介绍了： 在 webpack 中配置使用 HMR HMR 的运行原理 模块中的 HMR 接口 API 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/09.优化前端资源加载1-图片加载优化和代码压缩.html":{"url":"使用webpack定制前端开发环境/09.优化前端资源加载1-图片加载优化和代码压缩.html","title":"09.优化前端资源加载1-图片加载优化和代码压缩","keywords":"","body":"优化前端资源加载 1 - 图片加载优化和代码压缩 前面我们已经提及如何使用 webpack 来满足不同环境的构建需求，其中在生产环境构建时会做额外的一些工作，例如代码压缩等。这一部分的工作就是这一小节的主题，即优化前端资源的加载性能。 我们总是希望浏览器在加载页面时用的时间越短越好，所以构建出来的文件应该越少越小越好，一来减少浏览器需要发起请求的数量，二来减少下载静态资源的时间。 其实 webpack 把多个代码文件打包成几个必需的静态资源，已经很大程度减少了静态资源请求数量了，接下来我们来介绍下如何使用 webpack 实现更多的前端资源加载的优化需求。 CSS Sprites CSS Sprites 技术是前端领域一种很常见的用于减少图片资源请求数的优化方式，这里不做详细的介绍。 在了解 webpack 配置之前，需要明白 CSS Sprites 的原理。 如果你使用的 webpack 3.x 版本，需要 CSS Sprites 的话，可以使用 webpack-spritesmith 或者 sprite-webpack-plugin。 我们以 webpack-spritesmith 为例，先安装依赖： npm install webpack-spritesmith --save-dev 在 webpack 的配置中应用该插件： module: { loaders: [ // ... 这里需要有处理图片的 loader，如 file-loader ] }, resolve: { modules: [ 'node_modules', 'spritesmith-generated', // webpack-spritesmith 生成所需文件的目录 ], }, plugins: [ new SpritesmithPlugin({ src: { cwd: path.resolve(__dirname, 'src/ico'), // 多个图片所在的目录 glob: '*.png' // 匹配图片的路径 }, target: { // 生成最终图片的路径 image: path.resolve(__dirname, 'src/spritesmith-generated/sprite.png'), // 生成所需 SASS/LESS/Stylus mixins 代码，我们使用 Stylus 预处理器做例子 css: path.resolve(__dirname, 'src/spritesmith-generated/sprite.styl'), }, apiOptions: { cssImageRef: \"~sprite.png\" }, }), ], 在你需要的样式代码中引入 sprite.styl 后调用需要的 mixins 即可： @import '~sprite.styl' .close-button sprite($close) .open-button sprite($open) 更多的 webpack-spritesmith 配置可以参考：Config of webpack-spritesmith。 遗憾的是，上面提到的这两个 plugin 还没更新到支持 webpack 4.x 版本，如果你使用的是 webpack 4.x，你需要配合使用 postcss 和 postcss-sprites，才能实现 CSS Sprites 的相关构建。 图片压缩 在一般的项目中，图片资源会占前端资源的很大一部分，既然代码都进行压缩了，占大头的图片就更不用说了。 我们之前提及使用 file-loader 来处理图片文件，在此基础上，我们再添加一个 image-webpack-loader 来压缩图片文件。简单的配置如下： module.exports = { // ... module: { rules: [ { test: /.*\\.(gif|png|jpe?g|svg|webp)$/i, use: [ { loader: 'file-loader', options: {} }, { loader: 'image-webpack-loader', options: { mozjpeg: { // 压缩 jpeg 的配置 progressive: true, quality: 65 }, optipng: { // 使用 imagemin-optipng 压缩 png，enable: false 为关闭 enabled: false, }, pngquant: { // 使用 imagemin-pngquant 压缩 png quality: '65-90', speed: 4 }, gifsicle: { // 压缩 gif 的配置 interlaced: false, }, webp: { // 开启 webp，会把 jpg 和 png 图片压缩为 webp 格式 quality: 75 }, }, ], }, ], }, } image-webpack-loader 的压缩是使用 imagemin 提供的一系列图片压缩类库来处理的，如果需要进一步了解详细的配置，可以查看对应类库的官方文档 usage of image-webpack-loader。 使用 DataURL 有的时候我们的项目中会有一些很小的图片，因为某些缘故并不想使用 CSS Sprites 的方式来处理（譬如小图片不多，因此引入 CSS Sprites 感觉麻烦），那么我们可以在 webpack 中使用 url-loader 来处理这些很小的图片。 url-loader 和 file-loader 的功能类似，但是在处理文件的时候，可以通过配置指定一个大小，当文件小于这个配置值时，url-loader 会将其转换为一个 base64 编码的 DataURL，配置如下： module.exports = { // ... module: { rules: [ { test: /\\.(png|jpg|gif)$/, use: [ { loader: 'url-loader', options: { limit: 8192, // 单位是 Byte，当文件小于 8KB 时作为 DataURL 处理 }, }, ], }, ], }, } 更多关于 url-loader 的配置可以参考官方文档 url-loader，一般情况仅使用 limit 即可。 代码压缩 webpack 4.x 版本运行时，mode 为 production 即会启动压缩 JS 代码的插件，而对于 webpack 3.x，使用压缩 JS 代码插件的方式也已经介绍过了。在生产环境中，压缩 JS 代码基本是一个必不可少的步骤，这样可以大大减小 JavaScript 的体积，相关内容这里不再赘述。 除了 JS 代码之外，我们一般还需要 HTML 和 CSS 文件，这两种文件也都是可以压缩的，虽然不像 JS 的压缩那么彻底（替换掉长变量等），只能移除空格换行等无用字符，但也能在一定程度上减小文件大小。在 webpack 中的配置使用也不是特别麻烦，所以我们通常也会使用。 对于 HTML 文件，之前介绍的 html-webpack-plugin 插件可以帮助我们生成需要的 HTML 并对其进行压缩： module.exports = { // ... plugins: [ new HtmlWebpackPlugin({ filename: 'index.html', // 配置输出文件名和路径 template: 'assets/index.html', // 配置文件模板 minify: { // 压缩 HTML 的配置 minifyCSS: true, // 压缩 HTML 中出现的 CSS 代码 minifyJS: true // 压缩 HTML 中出现的 JS 代码 } }), ], } 如上，使用 minify 字段配置就可以使用 HTML 压缩，这个插件是使用 html-minifier 来实现 HTML 代码压缩的，minify 下的配置项直接透传给 html-minifier，配置项参考 html-minifier 文档即可。 对于 CSS 文件，我们之前介绍过用来处理 CSS 文件的 css-loader，也提供了压缩 CSS 代码的功能： module.exports = { module: { rules: [ // ... { test: /\\.css/, include: [ path.resolve(__dirname, 'src'), ], use: [ 'style-loader', { loader: 'css-loader', options: { minimize: true, // 使用 css 的压缩功能 }, }, ], }, ], } } 在 css-loader 的选项中配置 minimize 字段为 true 来使用 CSS 压缩代码的功能。css-loader 是使用 cssnano 来压缩代码的，minimize 字段也可以配置为一个对象，来将相关配置传递给 cssnano。更多详细内容请参考 cssnano 官方文档。 小结 由于优化前端资源加载这个主题相关的内容比较多，所以拆分成多个小节。本小节先介绍了比较基础的部分：CSS Sprites、图片压缩、使用 DataURL，以及基本的代码压缩，接下来的第 10、11 小节还会继续围绕前端资源加载优化的这个主题，介绍更加深入的内容。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/10.优化前端资源加载2-分离代码文件.html":{"url":"使用webpack定制前端开发环境/10.优化前端资源加载2-分离代码文件.html","title":"10.优化前端资源加载2-分离代码文件","keywords":"","body":"优化前端资源加载 2 - 分离代码文件 上一小节介绍了如何做图片加载相关的优化以及压缩代码，这一部分内容会稍微深入点，讲解如何利用浏览器的缓存以及在 webpack 中实现按需加载代码。 分离代码文件 关于分离 CSS 文件这个主题，之前在介绍如何搭建基本的前端开发环境时有提及，在 webpack 中使用 extract-text-webpack-plugin 插件即可。 先简单解释一下为何要把 CSS 文件分离出来，而不是直接一起打包在 JS 中。最主要的原因是我们希望更好地利用缓存。 假设我们原本页面的静态资源都打包成一个 JS 文件，加载页面时虽然只需要加载一个 JS 文件，但是我们的代码一旦改变了，用户访问新的页面时就需要重新加载一个新的 JS 文件。有些情况下，我们只是单独修改了样式，这样也要重新加载整个应用的 JS 文件，相当不划算。 还有一种情况是我们有多个页面，它们都可以共用一部分样式（这是很常见的，CSS Reset、基础组件样式等基本都是跨页面通用），如果每个页面都单独打包一个 JS 文件，那么每次访问页面都会重复加载原本可以共享的那些 CSS 代码。如果分离开来，第二个页面就有了 CSS 文件的缓存，访问速度自然会加快。虽然对第一个页面来说多了一个请求，但是对随后的页面来说，缓存带来的速度提升相对更加可观。 因此当我们考虑更好地利用缓存来加速静态资源访问时，会尝试把一些公共资源单独分离开来，利用缓存加速，以避免重复的加载。除了公共的 CSS 文件或者图片资源等，当我们的 JS 代码文件过大的时候，也可以用代码文件拆分的办法来进行优化。 那么，如何使用 webpack 来把代码中公共使用的部分分离成为独立的文件呢？由于 webpack 4.x 和 webpack 3.x 在代码分离这一块的内容差别比较大，因而我们分别都介绍一下。 3.x 以前的版本是使用 CommonsChunkPlugin 来做代码分离的，而 webpack 4.x 则是把相关的功能包到了 optimize.splitChunks 中，直接使用该配置就可以实现代码分离。 我们先介绍在 webpack 4.x 中如何使用这个配置来实现代码分离。 webpack 4.x 的 optimization webpack 的作者推荐直接这样简单地配置： module.exports = { // ... webpack 配置 optimization: { splitChunks: { chunks: \"all\", // 所有的 chunks 代码公共的部分分离出来成为一个单独的文件 }, }, } 我们需要在 HTML 中引用两个构建出来的 JS 文件，并且 commons.js 需要在入口代码之前。下面是个简单的例子： 如果你使用了 html-webpack-plugin，那么对应需要的 JS 文件都会在 HTML 文件中正确引用，不用担心。如果没有使用，那么你需要从 stats 的 entrypoints 属性来获取入口应该引用哪些 JS 文件，可以参考 Node API 了解如何从 stats 中获取信息，或者开发一个 plugin 来处理正确引用 JS 文件这个问题。第 15 小节会介绍如何开发 webpack plugin，plugin 提供的 API 也可以正确获取到 stats 中的数据。 之前我们提到拆分文件是为了更好地利用缓存，分离公共类库很大程度上是为了让多页面利用缓存，从而减少下载的代码量，同时，也有代码变更时可以利用缓存减少下载代码量的好处。从这个角度出发，笔者建议将公共使用的第三方类库显式地配置为公共的部分，而不是 webpack 自己去判断处理。因为公共的第三方类库通常升级频率相对低一些，这样可以避免因公共 chunk 的频繁变更而导致缓存失效。 显式配置共享类库可以这么操作： module.exports = { entry: { vendor: [\"react\", \"lodash\", \"angular\", ...], // 指定公共使用的第三方类库 }, optimization: { splitChunks: { cacheGroups: { vendor: { chunks: \"initial\", test: \"vendor\", name: \"vendor\", // 使用 vendor 入口作为公共部分 enforce: true, }, }, }, }, // ... 其他配置 } // 或者 module.exports = { optimization: { splitChunks: { cacheGroups: { vendor: { test: /react|angluar|lodash/, // 直接使用 test 来做路径匹配 chunks: \"initial\", name: \"vendor\", enforce: true, }, }, }, }, } // 或者 module.exports = { optimization: { splitChunks: { cacheGroups: { vendor: { chunks: \"initial\", test: path.resolve(__dirname, \"node_modules\") // 路径在 node_modules 目录下的都作为公共部分 name: \"vendor\", // 使用 vendor 入口作为公共部分 enforce: true, }, }, }, }, } 上述第一种做法是显示指定哪些类库作为公共部分，第二种做法实现的功能差不多，只是利用了 test 来做模块路径的匹配，第三种做法是把所有在 node_modules 下的模块，即作为依赖安装的，都作为公共部分。你可以针对项目情况，选择最合适的做法。 webpack 3.x 的 CommonsChunkPlugin 下面我们简单介绍一下在 webpack 3.x 中如何配置代码分离。webpack 3.x 以下的版本需要用到 webpack 自身提供的 CommonsChunkPlugin 插件。我们先来看一个最简单的例子： module.exports = { // ... plugins: [ new webpack.optimize.CommonsChunkPlugin({ name: \"commons\", // 公共使用的 chunk 的名称 filename: \"commons.js\", // 公共 chunk 的生成文件名 minChunks: 3, // 公共的部分必须被 3 个 chunk 共享 }), ], } chunk 在这里是构建的主干，可以简单理解为一个入口对应一个 chunk。 以上插件配置在构建后会生成一个 commons.js 文件，该文件就是代码中的公共部分。上面的配置中 minChunks 字段为 3，该字段的意思是当一个模块被 3 个以上的 chunk 依赖时，这个模块就会被划分到 commons chunk 中去。单从这个配置的角度上讲，这种方式并没有 4.x 的 chunks: \"all\" 那么方便。 CommonsChunkPlugin 也是支持显式配置共享类库的： module.exports = { entry: { vendor: ['react', 'react-redux'], // 指定公共使用的第三方类库 app: './src/entry', // ... }, // ... plugins: [ new webpack.optimize.CommonsChunkPlugin({ name: 'vendor' // 使用 vendor 入口作为公共部分 filename: \"vendor.js\", minChunks: Infinity, // 这个配置会让 webpack 不再自动抽离公共模块 }), ], } 上述配置会生成一个名为 vendor.js 的共享代码文件，里面包含了 React 和 React-Redux 库的代码，可以提供给多个不同的入口代码使用。这里的 minChunks 字段的配置，我们使用了 Infinity，可以理解为 webpack 不自动抽离公共模块。如果这里和之前一样依旧设置为 3，那么被 3 个以上的 chunk 依赖的模块会和 React、React-Redux 一同打包进 vendor，这样就失去显式指定的意义了。 minChunks 其实还可以是一个函数，如： minChunks: (module, count) => { console.log(module, count); return true; }, 该函数在分析每一个依赖的时候会被调用，传入当前依赖模块的信息 module，以及已经被作为公共模块的数量 count，你可以在函数中针对每一个模块做更加精细化的控制。看一个简单的例子： minChunks: (module, count) => { return module.context && module.context.includes(\"node_modules\"); // node_modules 目录下的模块都作为公共部分，效果就如同 webpack 4.x 中的 test: path.resolve(__dirname, \"node_modules\") }, 更多使用 CommonsChunkPlugin 的配置参考官方文档 commons-chunk-plugin。 而关于 webpack 4.x 的 splitChunks 配置，笔者写这一部分的时候官方文档还没有更新出来，上述配置预估可以满足大部分项目的需求，更加详细的内容还请等待官方文档更新后查阅。 小结 本小节是优化前端资源加载这个主题的第二部分，主要分别介绍了在 webpack 4.x 版本和 3.x 版本中，如何配置分离代码文件来更加高效地利用浏览器缓存。webpack 两个版本关于分离代码这一块的使用差异比较大，笔者还是推荐使用 4.x 版本，因为它的配置相对来说要更加简单一些。接下来第 11 小节会介绍优化前端资源加载的最后一个部分的内容。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/11.优化前端资源加载3-进一步控制JS大小.html":{"url":"使用webpack定制前端开发环境/11.优化前端资源加载3-进一步控制JS大小.html","title":"11.优化前端资源加载3-进一步控制JS大小","keywords":"","body":"优化前端资源加载 3 - 进一步控制 JS 大小 前面已经介绍了一些优化资源加载的方法，这一小节是这个主题的最后一部分，内容更为深入，主要介绍如何把我们的 JS 代码文件变得更小。 按需加载模块 前面讲述了如何把大的代码文件进行拆分，抽离出多个页面共享的部分，但是当你的 Web 应用是单个页面，并且极其复杂的时候，你会发现有一些代码并不是每一个用户都需要用到的。你可能希望将这一部分代码抽离出去，仅当用户真正需要用到时才加载，这个时候就需要用到 webpack 提供的一个优化功能 —— 按需加载代码模块。 在 webpack 的构建环境中，要按需加载代码模块很简单，遵循 ES 标准的动态加载语法 dynamic-import 来编写代码即可，webpack 会自动处理使用该语法编写的模块： // import 作为一个方法使用，传入模块名即可，返回一个 promise 来获取模块暴露的对象 // 注释 webpackChunkName: \"lodash\" 可以用于指定 chunk 的名称，在输出文件时有用 import(/* webpackChunkName: \"lodash\" */ 'lodash').then((_) => { console.log(_.lash([1, 2, 3])) // 打印 3 }) 注意一下，如果你使用了 Babel 的话，还需要 Syntax Dynamic Import 这个 Babel 插件来处理 import() 这种语法。 由于动态加载代码模块的语法依赖于 promise，对于低版本的浏览器，需要添加 promise 的 polyfill 后才能使用。 如上的代码，webpack 构建时会自动把 lodash 模块分离出来，并且在代码内部实现动态加载 lodash 的功能。动态加载代码时依赖于网络，其模块内容会异步返回，所以 import 方法是返回一个 promise 来获取动态加载的模块内容。 import 后面的注释 webpackChunkName: \"lodash\" 用于告知 webpack 所要动态加载模块的名称。我们在 webpack 配置中添加一个 output.chunkFilename 的配置： output: { path: path.resolve(__dirname, 'dist'), filename: '[name].[hash:8].js', chunkFilename: '[name].[hash:8].js' // 指定分离出来的代码文件的名称 }, 这样就可以把分离出来的文件名称用 lodash 标识了，如下图： 如果没有添加注释 webpackChunkName: \"lodash\" 以及 output.chunkFilename 配置，那么分离出来的文件名称会以简单数字的方式标识，不便于识别。 Tree shaking Tree shaking 这个术语起源于 ES2015 模块打包工具 rollup，依赖于 ES2015 模块系统中的静态结构特性，可以移除 JavaScript 上下文中的未引用代码，删掉用不着的代码，能够有效减少 JS 代码文件的大小。拿官方文档的例子来说明一下。 // src/math.js export function square(x) { return x * x; } export function cube(x) { return x * x * x; } // src/index.js import { cube } from './math.js' // 在这里只是引用了 cube 这个方法 console.log(cube(3)) 如果整个项目代码只是上述两个文件，那么很明显，square 这个方法是未被引用的代码，是可以删掉的。在 webpack 中，只有启动了 JS 代码压缩功能（即使用 uglify）时，会做 Tree shaking 的优化。webpack 4.x 需要指定 mode 为 production，而 webpack 3.x 的话需要配置 UglifyJsPlugin。启动了之后，构建出来的结果就会移除 square 的那一部分代码了。 如果你在项目中使用了 Babel 的话，要把 Babel 解析模块语法的功能关掉，在 .babelrc 配置中增加 \"modules\": false 这个配置： { \"presets\": [[\"env\", { \"modules\": false }]] } 这样可以把 import/export 的这一部分模块语法交由 webpack 处理，否则没法使用 Tree shaking 的优化。 有的时候你启用了 Tree shaking 功能，但是发现好像并没有什么用，例如这样一个例子： // src/component.js export class Person { constructor ({ name }) { this.name = name } getName () { return this.name } } export class Apple { constructor ({ model }) { this.model = model } getModel () { return this.model } } // src/index.js import { Apple } from './components' const appleModel = new Apple({ model: 'X' }).getModel() console.log(appleModel) 打包压缩后还是可以发现，Person 这一块看起来没用到的代码出现在文件中。关于这个问题，详细讲解的话篇幅太长了，建议自行阅读这一篇文章：你的Tree-Shaking并没什么卵用。 这篇文章最近没有更新，但是 uglify 的相关 issue Class declaration in IIFE considered as side effect 是有进展的，现在如果你在 Babel 配置中增加 \"loose\": true 配置的话，Person 这一块代码就可以在构建时移除掉了。 sideEffects 这是 webpack 4.x 才具备的特性，暂时官方还没有比较全面的介绍文档，笔者从 webpack 的 examples 里找到一个东西：side-effects/README.md。 我们拿 lodash 举个例子。有些同学可能对 lodash 已经蛮熟悉了，它是一个工具库，提供了大量的对字符串、数组、对象等常见数据类型的处理函数，但是有的时候我们只是使用了其中的几个函数，全部函数的实现都打包到我们的应用代码中，其实很浪费。 webpack 的 sideEffects 可以帮助解决这个问题。现在 lodash 的 ES 版本 的 package.json 文件中已经有 sideEffects: false 这个声明了，当某个模块的 package.json 文件中有了这个声明之后，webpack 会认为这个模块没有任何副作用，只是单纯用来对外暴露模块使用，那么在打包的时候就会做一些额外的处理。 例如你这么使用 lodash： import { forEach, includes } from 'lodash-es' forEach([1, 2], (item) => { console.log(item) }) console.log(includes([1, 2, 3], 1)) 由于 lodash-es 这个模块的 package.json 文件有 sideEffects: false 的声明，所以 webpack 会将上述的代码转换为以下的代码去处理： import { default as forEach } from 'lodash-es/forEach' import { default as includes } from 'lodash-es/includes' // ... 其他代码 最终 webpack 不会把 lodash-es 所有的代码内容打包进来，只是打包了你用到的那两个方法，这便是 sideEffects 的作用。 小结 本小节主要是介绍如何使用 webpack 来进一步控制 JS 文件的大小： 如何在 webpack 中实现按需加载模块 如何利用 webpack 的 Tree shaking 特性 如何利用 webpack 的 sideEffects 特性 前端资源加载优化的道路还很远，我们前面介绍的这些内容都是 webpack 可以提供给我们的关于这个方面的一些功能，而如何利用好这些功能取决于我们开发者。我们在日常的开发工作中可以多多思考，将更多的前端资源优化加载的思路和 webpack 整合在一起，应用到实践中去。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/12.提升webpack的构建速度.html":{"url":"使用webpack定制前端开发环境/12.提升webpack的构建速度.html","title":"12.提升webpack的构建速度","keywords":"","body":"提升 webpack 的构建速度 我们的前端项目随着时间推移和业务发展，页面可能会越来越多，或者功能和业务代码会越来越多，又或者依赖的外部类库会越来越多，这个时候原本不足为道的 webpack 构建时间消耗就会慢慢地进入我们的视野。 构建消耗的时间变长了，如果是使用 CI 服务来做构建，大部分情况下我们无须等待，其实影响不大。但是本地的 webpack 开发环境服务启动时的速度和我们日常开发工作息息相关，在一些性能不是特别突出的设备上（例如便携式笔记本等等），启动时的长时间等待可能会让你越来越受不了。 笔者亲身经历的一个项目，使用 webpack 构建的时长可以达到 6 分钟左右，这种场景下，就算用 CI 服务，在遇见需要紧急发布修复问题时，也会让人很抓狂。所以这一小节我们来聊聊如何提升 webpack 的构建速度，也许某一天你负责的项目也会到了需要优化 webpack 构建性能的时候。 让 webpack 少干点活 提升 webpack 构建速度本质上就是想办法让 webpack 少干点活，活少了速度自然快了，尽量避免 webpack 去做一些不必要的事情。 减少 resolve 的解析 在前边第三小节我们详细介绍了 webpack 的 resolve 配置，如果我们可以精简 resolve 配置，让 webpack 在查询模块路径时尽可能快速地定位到需要的模块，不做额外的查询工作，那么 webpack 的构建速度也会快一些，下面举个例子，介绍如何在 resolve 这一块做优化： resolve: { modules: [ path.resolve(__dirname, 'node_modules'), // 使用绝对路径指定 node_modules，不做过多查询 ], // 删除不必要的后缀自动补全，少了文件后缀的自动匹配，即减少了文件路径查询的工作 // 其他文件可以在编码时指定后缀，如 import('./index.scss') extensions: [\".js\"], // 避免新增默认文件，编码时使用详细的文件路径，代码会更容易解读，也有益于提高构建速度 mainFiles: ['index'], }, 上述是可以从配置 resolve 下手提升 webpack 构建速度的配置例子。 我们在编码时，如果是使用我们自己本地的代码模块，尽可能编写完整的路径，避免使用目录名，如：import './lib/slider/index.js'，这样的代码既清晰易懂，webpack 也不用去多次查询来确定使用哪个文件，一步到位。 把 loader 应用的文件范围缩小 我们在使用 loader 的时候，尽可能把 loader 应用的文件范围缩小，只在最少数必须的代码模块中去使用必要的 loader，例如 node_modules 目录下的其他依赖类库文件，基本就是直接编译好可用的代码，无须再经过 loader 处理了： rules: [ { test: /\\.jsx?/, include: [ path.resolve(__dirname, 'src'), // 限定只在 src 目录下的 js/jsx 文件需要经 babel-loader 处理 // 通常我们需要 loader 处理的文件都是存放在 src 目录 ], use: 'babel-loader', }, // ... ], 如上边这个例子，如果没有配置 include，所有的外部依赖模块都经过 Babel 处理的话，构建速度也是会收很大影响的。 减少 plugin 的消耗 webpack 的 plugin 会在构建的过程中加入其它的工作步骤，如果可以的话，适当地移除掉一些没有必要的 plugin。 这里再提一下 webpack 4.x 的 mode，区分 mode 会让 webpack 的构建更加有针对性，更加高效。例如当 mode 为 development 时，webpack 会避免使用一些提高应用代码加载性能的配置项，如 UglifyJsPlugin，ExtractTextPlugin 等，这样可以更快地启动开发环境的服务，而当 mode 为 production 时，webpack 会避免使用一些便于 debug 的配置，来提升构建时的速度，例如极其消耗性能的 Source Maps 支持。 换种方式处理图片 我们在前边的小节提到图片可以使用 webpack 的 image-webpack-loader 来压缩图片，在对 webpack 构建性能要求不高的时候，这样是一种很简便的处理方式，但是要考虑提高 webpack 构建速度时，这一块的处理就得重新考虑一下了，思考一下是否有必要在 webpack 每次构建时都处理一次图片压缩。 这里介绍一种解决思路，我们可以直接使用 imagemin 来做图片压缩，编写简单的命令即可。然后使用 pre-commit 这个类库来配置对应的命令，使其在 git commit 的时候触发，并且将要提交的文件替换为压缩后的文件。 这样提交到代码仓库的图片就已经是压缩好的了，以后在项目中再次使用到的这些图片就无需再进行压缩处理了，image-webpack-loader 也就没有必要了。 使用 DLLPlugin DLLPlugin 是 webpack 官方提供的一个插件，也是用来分离代码的，和 optimization.splitChunks（3.x 版本的是 CommonsChunkPlugin）有异曲同工之妙，之所以把 DLLPlugin 放到 webpack 构建性能优化这一部分，是因为它的配置相对繁琐，如果项目不涉及性能优化这一块，基本上使用 optimization.splitChunks 即可。 我们来看一下 DLLPlugin 如何使用，使用这个插件时需要额外的一个构建配置，用来打包公共的那一部分代码，举个例子，假设这个额外配置是 webpack.dll.config.js： module.exports = { name: 'vendor', entry: ['lodash'], // 这个例子我们打包 lodash 作为公共类库 output: { path: path.resolve(__dirname, \"dist\"), filename: \"vendor.js\", library: \"vendor_[hash]\" // 打包后对外暴露的类库名称 }, plugins: [ new webpack.DllPlugin({ name: 'vendor_[hash]', path: path.resolve(__dirname, \"dist/manifest.json\"), // 使用 DLLPlugin 在打包的时候生成一个 manifest 文件 }) ], } 然后就是我们正常的应用构建配置，在那个的基础上添加两个一个新的 webpack.DllReferencePlugin 配置： module.exports = { plugins: [ new webpack.DllReferencePlugin({ manifest: path.resolve(__dirname, 'dist/manifest.json'), // 指定需要用到的 manifest 文件， // webpack 会根据这个 manifest 文件的信息，分析出哪些模块无需打包，直接从另外的文件暴露出来的内容中获取 }), ], } 在构建的时候，我们需要优先使用 webpack.dll.config.js 来打包，如 webpack -c webpack.dll.config.js --mode production，构建后生成公共代码模块的文件 vendor.js 和 manifest.json，然后再进行应用代码的构建。 你会发现构建结果的应用代码中不包含 lodash 的代码内容，这一部分代码内容会放在 vendor.js 这个文件中，而你的应用要正常使用的话，需要在 HTML 文件中按顺序引用这两个代码文件，如： 作用是不是和 optimization.splitChunks 很相似，但是有个区别，DLLPlugin 构建出来的内容无需每次都重新构建，后续应用代码部分变更时，你不用再执行配置为 webpack.dll.config.js 这一部分的构建，沿用原本的构建结果即可，所以相比 optimization.splitChunks，使用 DLLPlugin 时，构建速度是会有显著提高的。 但是很显然，DLLPlugin 的配置要麻烦得多，并且需要关心你公共部分代码的变化，当你升级 lodash（即你的公共部分代码的内容变更）时，要重新去执行 webpack.dll.config.js 这一部分的构建，不然沿用的依旧是旧的构建结果，使用上并不如 optimization.splitChunks 来得方便。这是一种取舍，根据项目的实际情况采用合适的做法。 还有一点需要注意的是，html-webpack-plugin 并不会自动处理 DLLPlugin 分离出来的那个公共代码文件，我们需要自己处理这一部分的内容，可以考虑使用 add-asset-html-webpack-plugin，关于这一个的使用就不讲解了，详细参考官方的说明文档：使用 add-asset-html-webpack-plugin。 webpack 4.x 的构建性能 从官方发布的 webpack 4.0 更新日志来看，webpack 4.0 版本做了很多关于提升构建性能的工作，我觉得比较重要的改进有这么几个： AST 可以直接从 loader 直接传递给 webpack，避免额外的解析，对这一个优化细节有兴趣的可以查看这个 PR。 使用速度更快的 md4 作为默认的 hash 方法，对于大型项目来说，文件一多，需要 hash 处理的内容就多，webpack 的 hash 处理优化对整体的构建速度提升应该还是有一定的效果的。 Node 语言层面的优化，如用 for of 替换 forEach，用 Map 和 Set 替换普通的对象字面量等等，这一部分就不展开讲了，有兴趣的同学可以去 webpack 的 PRs 寻找更多的内容。 默认开启 uglifyjs-webpack-plugin 的 cache 和 parallel，即缓存和并行处理，这样能大大提高 production mode 下压缩代码的速度。 除此之外，还有比较琐碎的一些内容，可以查阅：webpack release 4.0，留意 performance 关键词。 很显然，webpack 的开发者们越来越关心 webpack 构建性能的问题，有一个关于 webpack 4.x 和 3.x 构建性能的简单对比： 6 entries, dev mode, source maps off, using a bunch of loaders and plugins. dat speed ⚡️ 从这个对比的例子上看，4.x 的构建性能对比 3.x 是有很显著的提高，而 webpack 官方后续计划加入多核运算，持久化缓存等特性来进一步提升性能（可能要等到 5.x 版本了），所以，及时更新 webpack 版本，也是提升构建性能的一个有效方式。 换个角度 webpack 的构建性能优化是比较琐碎的工作，当我们需要去考虑 webpack 的构建性能问题时，往往面对的是项目过大，涉及的代码模块过多的情况。在这种场景下你单独做某一个点的优化其实很难看出效果，你可能需要从我们上述提到的多个方面入手，逐一处理，验证，有些时候你甚至会觉得吃力不讨好，投入产出比太低了，这个时候我们可以考虑换一个角度来思考我们遇到的问题。 例如，拆分项目的代码，根据一定的粒度，把不同的业务代码拆分到不同的代码库去维护和管理，这样子单一业务下的代码变更就无须整个项目跟着去做构建，这样也是解决因项目过大导致的构建速度慢的一种思路，并且如果处理妥当，从工程角度上可能会给你带来其他的一些好处，例如发布异常时的局部代码回滚相对方便等等。 这可能有点跑题，但是不得不说，webpack 的确是一个好工具，但总归多多少少会有一些局限性，再怎么优化，不可能总能达到理想的效果，因为它确确实实完成那些构建任务就是需要这么一些时间。作为开发者，面对项目中各种各样的情况要随机应变，灵活处理，不能被好工具捆绑了思维模式，很多问题你不要过于依赖于 webpack，换个角度，可能可以找到更好的处理方式。 小结 本小节中我们介绍了提高 webpack 构建速度的一些方法： 减少 resolve 的解析 减少 plugin 的消耗 换种方式处理图片 使用 DLLPlugin 积极更新 webpack 版本 当我们面对因项目过大而导致的构建性能问题时，我们也可以换个角度，思考在 webpack 之上的另外一些解决方案，不要过分依赖于 webpack。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/13.探究webpack内部工作流程.html":{"url":"使用webpack定制前端开发环境/13.探究webpack内部工作流程.html","title":"13.探究webpack内部工作流程","keywords":"","body":"探究 webpack 内部工作流程 了解 webpack 整个基础工作流程，有助于我们解决日常使用 webpack 时遇到的一些问题，也有助于我们更好地理解 webpack loader 和 plugin 的使用。 抛开复杂的 loader 和 plugin 机制，webpack 本质上就是一个 JS Module Bundler，用于将多个代码模块进行打包，所以我们先撇开 webpack 错综复杂的整体实现，来看一下一个相对简单的 JS Module Bunlder 的基础工作流程是怎么样的，在了解了 bundler 如何工作的基础上，再进一步去整理 webpack 整个流程，将 loader 和 plugin 的机制弄明白。 以下内容将 module bundler 简称为 bundler。 bundler 的基础流程 首先，bundler 从一个构建入口出发，解析代码，分析出代码模块依赖关系，然后将依赖的代码模块组合在一起，在 JavaScript bundler 中，还需要提供一些胶水代码让多个代码模块可以协同工作，相互引用。下边会举一些简单的例子来说明一下这几个关键的部分是怎么工作的。 首先是解析代码，分析依赖关系，对于 ES6 Module 以及 CommonJS Modules 语法定义的模块，例如这样的代码： // entry.js import { bar } from './bar.js'; // 依赖 ./bar.js 模块 // bar.js const foo = require('./foo.js'); // 依赖 ./foo.js 模块 bundler 需要从这个入口代码（第一段）中解析出依赖 bar.js，然后再读取 bar.js 这个代码文件，解析出依赖 foo.js 代码文件，继续解析其依赖，递归下去，直至没有更多的依赖模块，最终形成一颗模块依赖树。 至于如何从 JavaScript 代码中解析出这些依赖，作者写过一篇文章，可以参考下：使用 Acorn 来解析 JavaScript。 如果 foo.js 文件没有依赖其他的模块的话，那么这个简单例子的依赖树也就相对简单：entry.js -> bar.js -> foo.js，当然，日常开发中遇见的一般都是相当复杂的代码模块依赖关系。 分析出依赖关系后，bunlder 需要将依赖关系中涉及的所有文件组合到一起，但由于依赖代码的执行是有先后顺序以及会引用模块内部不同的内容，不能简单地将代码拼接到一起。webpack 会利用 JavaScript Function 的特性提供一些代码来将各个模块整合到一起，即是将每一个模块包装成一个 JS Function，提供一个引用依赖模块的方法，如下面例子中的 __webpack__require__，这样做，既可以避免变量相互干扰，又能够有效控制执行顺序，简单的代码例子如下： // 分别将各个依赖模块的代码用 modules 的方式组织起来打包成一个文件 // entry.js modules['./entry.js'] = function() { const { bar } = __webpack__require__('./bar.js') } // bar.js modules['./bar.js'] = function() { const foo = __webpack__require__('./foo.js') }; // foo.js modules['./foo.js'] = function() { // ... } // 已经执行的代码模块结果会保存在这里 const installedModules = {} function __webpack__require__(id) { // ... // 如果 installedModules 中有就直接获取 // 没有的话从 modules 中获取 function 然后执行，将结果缓存在 installedModules 中然后返回结果 } 这只是 webpack 的实现方式的简单例子，rollup 有另外的实现方式，并且笔者个人觉得 rollup 的实现方式比 webpack 要更加优秀一些，rollup 可以让你构建出来的代码量更少一点，有兴趣的同学可以看看这个文章：Webpack and Rollup: the same but different，也可以使用 rollup 来构建一个简单的例子，看看结果是什么样子的。 我们在介绍 bundler 的基础流程时，把各个部分的实现细节简化了，这有利于我们从整体的角度去看清楚整个轮廓，至于某一部分的具体实现，例如解析代码依赖，模块依赖关系管理，胶水代码的生成等，深入细节的话会比较复杂，这里不再作相关的展开。 webpack 的结构 webpack 需要强大的扩展性，尤其是插件实现这一块，webpack 利用了 tapable 这个库（其实也是 webpack 作者开发的库）来协助实现对于整个构建流程各个步骤的控制。 关于这个库更多的使用内容可以去查看官方的文档：tapable，使用上并不算十分复杂，最主要的功能就是用来添加各种各样的钩子方法（即 Hook）。 webpack 基于 tapable 定义了主要构建流程后，使用 tapable 这个库添加了各种各样的钩子方法来将 webpack 扩展至功能十分丰富，同时对外提供了相对强大的扩展性，即 plugin 的机制。 在这个基础上，我们来了解一下 webpack 工作的主要流程和其中几个重要的概念。 Compiler，webpack 的运行入口，实例化时定义 webpack 构建主要流程，同时创建构建时使用的核心对象 compilation Compilation，由 Compiler 实例化，存储构建过程中各流程使用到的数据，用于控制这些数据的变化 Chunk，即用于表示 chunk 的类，对于构建时需要的 chunk 对象由 Compilation 创建后保存管理 Module，用于表示代码模块的类，衍生出很多子类用于处理不同的情况，关于代码模块的所有信息都会存在 Module 实例中，例如 dependencies 记录代码模块的依赖等 Parser，其中相对复杂的一个部分，基于 acorn 来分析 AST 语法树，解析出代码模块的依赖 Dependency，解析时用于保存代码模块对应的依赖使用的对象 Template，生成最终代码要使用到的代码模板，像上述提到的胶水代码就是用对应的 Template 来生成 官方对于 Compiler 和 Compilation 的定义是： compiler 对象代表了完整的 webpack 环境配置。这个对象在启动 webpack 时被一次性建立，并配置好所有可操作的设置，包括 options，loader 和 plugin。当在 webpack 环境中应用一个插件时，插件将收到此 compiler 对象的引用。可以使用它来访问 webpack 的主环境。 compilation 对象代表了一次资源版本构建。当运行 webpack 开发环境中间件时，每当检测到一个文件变化，就会创建一个新的 compilation，从而生成一组新的编译资源。一个 compilation 对象表现了当前的模块资源、编译生成资源、变化的文件、以及被跟踪依赖的状态信息。compilation 对象也提供了很多关键步骤的回调，以供插件做自定义处理时选择使用。 上述是 webpack 源码实现中比较重要的几个部分，webpack 运行的大概工作流程是这样的： 创建 Compiler -> 调用 compiler.run 开始构建 -> 创建 Compilation -> 基于配置开始创建 Chunk -> 使用 Parser 从 Chunk 开始解析依赖 -> 使用 Module 和 Dependency 管理代码模块相互关系 -> 使用 Template 基于 Compilation 的数据生成结果代码 上述只是笔者理解中的大概流程，细节相对复杂，一方面是技术实现的细节有一定复杂度，另一方面是实现的功能逻辑上也有一定复杂度，深入介绍的话，篇幅会很长，并且可能效果不理想，当我们还没到了要去实现具体功能的时候，无须关注那么具体的实现细节，只需要站在更高的层面去分析整体的流程。 有兴趣探究某一部分实现细节的同学，可以查阅 webpack 源码，从 webpack 基础流程入手：Compiler Hooks。 这里提供的是 4.x 版本的源码 master 分支的链接地址，webpack 的源码相对难懂，如果是想要学习 bundler 的整个工作流程，可以考虑看阅读 rollup 的源码，可读性相对会好很多。 从源码中探索 webpack webpack 主要的构建处理方法都在 Compilation 中，我们要了解 loader 和 plugin 的机制，就要深入 Compilation 这一部分的内容。 Compilation 的实现也是比较复杂的，lib/Compilation.js 单个文件代码就有近 2000 行之多，我们挑关键的几个部分来介绍一下。 addEntry 和 _addModuleChain addEntry 这个方法顾名思义，用于把配置的入口加入到构建的任务中去，当解析好 webpack 配置，准备好开始构建时，便会执行 addEntry 方法，而 addEntry 会调用 _addModuleChain 来为入口文件（入口文件这个时候等同于第一个依赖）创建一个对应的 Module 实例。 _addModuleChain 方法会根据入口文件这第一个依赖的类型创建一个 moduleFactory，然后再使用这个 moduleFactory 给入口文件创建一个 Module 实例，这个 Module 实例用来管理后续这个入口构建的相关数据信息，关于 Module 类的具体实现可以参考这个源码：lib/Module.js，这个是个基础类，大部分我们构建时使用的代码模块的 Module 实例是 lib/NormalModule.js 这个类创建的。 我们介绍 addEntry 主要是为了寻找整个构建的起点，让这一切有迹可循，后续的深入可以从这个点出发。 buildModule 当一个 Module 实例被创建后，比较重要的一步是执行 compilation.buildModule 这个方法，这个方法主要会调用 Module 实例的 build 方法，这个方法主要就是创建 Module 实例需要的一些东西，对我们梳理流程来说，这里边最重要的部分就是调用自身的 runLoaders 方法。 runLoaders 这个方法是 webpack 依赖的这个类库实现的：loader-runner，这个方法也比较容易理解，就是执行对应的 loaders，将代码源码内容一一交由配置中指定的 loader 处理后，再把处理的结果保存起来。 我们之前介绍过，webpack 的 loader 就是转换器，loader 就是在这个时候发挥作用的，至于 loader 执行的细节，有兴趣深入的同学可以去了解 loader-runner 的实现。 上述提到的 Module 实例的 build 方法在执行完对应的 loader，处理完模块代码自身的转换后，还有相当重要的一步是调用 Parser 的实例来解析自身依赖的模块，解析后的结果存放在 module.dependencies 中，首先保存的是依赖的路径，后续会经由 compilation.processModuleDependencies 方法，再来处理各个依赖模块，递归地去建立整个依赖关系树。 Compilation 的钩子 我们前边提到了 webpack 会使用 tapable 给整个构建流程中的各个步骤定义钩子，用于注册事件，然后在特定的步骤执行时触发相应的事件，注册的事件函数便可以调整构建时的上下文数据，或者做额外的处理工作，这就是 webpack 的 plugin 机制。 在 webpack 执行入口处 lib/webpack.js 有这么一段代码： if (options.plugins && Array.isArray(options.plugins)) { for (const plugin of options.plugins) { plugin.apply(compiler); // 调用每一个 plugin 的 apply 方法，把 compiler 实例传递过去 } } 这个 plugin 的 apply 方法就是用来给 compiler 实例注册事件钩子函数的，而 compiler 的一些事件钩子中可以获得 compilation 实例的引用，通过引用又可以给 compilation 实例注册事件函数，以此类推，便可以将 plugin 的能力覆盖到整个 webpack 构建过程。 而关于这些事件函数的名称和定义可以查看官方的文档：compiler 的事件钩子 和 compilation 的事件钩子。 后续的 15 小节会介绍如何编写 webpack plugin，可以将两部分的内容结合一下，来帮助理解 webpack plugin 的执行机制。 产出构建结果 最后还有一个部分，即用 Template 产出最终构建结果的代码内容，这一部分不作详细介绍了，仅留下一些线索，供有兴趣继续深入的同学使用： Template 基础类：lib/Template.js 常用的主要 Template 类：lib/MainTemplate.js Compilation 中产出构建结果的代码：compilation.createChunkAssets 这一部分内容的介绍就到这里了，对此部分内容有兴趣继续深入探索的同学，建议使用断点调试的方式，结合笔者介绍的这些内容，大致走一遍 webpack 的构建流程，会对这一部分的内容印象更加深刻，同时也可以通过断点更有针对性地了解某一部分的细节处理。 小结 本小节介绍了一个 bundler 的基础流程应该是怎么样的，以及 webpack 在 bundler 的基础上如何去增强自己的扩展性，同时我们介绍了 webpack 主要构建流程中比较重要的几个概念，并且从 webpack 这些概念的关键部分的源码来探索 webpack 的主要执行流程，希望这些内容可以帮助你更好地理解 webpack。 "},"使用webpack定制前端开发环境/14.创建自己的loader.html":{"url":"使用webpack定制前端开发环境/14.创建自己的loader.html","title":"14.创建自己的loader","keywords":"","body":"创建自己的 loader 在这一小节我们会来介绍如何创建一个 webpack 可用的 loader。 loader 是一个函数 先来看一个简单的例子： \"use strict\"; const marked = require(\"marked\"); const loaderUtils = require(\"loader-utils\"); module.exports = function (markdown) { // 使用 loaderUtils 来获取 loader 的配置项 // this 是构建运行时的一些上下文信息 const options = loaderUtils.getOptions(this); this.cacheable(); // 把配置项直接传递给 marked marked.setOptions(options); // 使用 marked 处理 markdown 字符串，然后返回 return marked(markdown); }; 这是 markdown-loader 的实现代码，笔者添加了一些代码说明，看上去很简单。 markdown-loader 本身仅仅只是一个函数，接收模块代码的内容，然后返回代码内容转化后的结果。webpack loader 的本质就是这样的一个函数。 上述代码中用到的 loader-utils 是 webpack 官方提供的一个工具库，提供 loader 处理时需要用到的一些工具方法，例如用来解析上下文 loader 配置项的 getOptions。关于这个工具库的内容和功能不是特别复杂，就不展开了，直接参考这个库的官方文档即可。 代码中还用到了 marked，marked 是一个用于解析 Markdown 的类库，可以把 Markdown 转为 HTML，markdown-loader 的核心功能就是用它来实现的。基本上，webpack loader 都是基于一个实现核心功能的类库来开发的，例如 sass-loader 是基于 node-sass 实现的，等等。 开始一个 loader 的开发 我们可以在 webpack 配置中直接使用路径来指定使用本地的 loader，或者在 loader 路径解析中加入本地开发 loader 的目录。看看配置例子： // ... module: { rules: [ { test: /\\.js$/, exclude: /node_modules/, loader: path.resolve('./loader/index.js'), // 使用本地的 ./loader/index.js 作为 loader }, ], }, // 在 resolveLoader 中添加本地开发的 loaders 存放路径 // 如果你同时需要开发多个 loader，那么这个方式会更加适合你 resolveLoader: { modules: [ 'node_modules', path.resolver(__dirname, 'loaders') ], }, 如果你熟悉 Node 的话，也可以使用 npm link 的方式来开发和调试，关于这个方式，可以参考 npm 的官方文档 npm-link。 复杂一点的情况 当我们选择上述任意一种方法，并且做好相应的准备后，我们就可以开始写 loader 的代码了，然后通过执行 webpack 构建来查看 loader 是否正常工作。 上面已经提到，loader 是一个函数，接收代码内容，然后返回处理结果，有一些 loader 的实现基本上就是这么简单，但是有时候会遇见相对复杂一点的情况。 首先 loader 函数接受的参数是有三个的：content, map, meta。content 是模块内容，但不仅限于字符串，也可以是 buffer，例如一些图片或者字体等文件。map 则是 sourcemap 对象，meta 是其他的一些元数据。loader 函数单纯返回一个值，这个值是当成 content 去处理，但如果你需要返回 sourcemap 对象或者 meta 数据，甚至是抛出一个 loader 异常给 webpack 时，你需要使用 this.callback(err, content, map, meta) 来传递这些数据。 我们日常使用 webpack，有时候会把多个 loader 串起来一起使用，最常见的莫过于 css-loader 和 style-loader 了。当我们配置 use: ['bar-loader', 'foo-loader'] 时，loader 是以相反的顺序执行的，即先跑 foo-loader，再跑 bar-loader。这一部分内容在配置 loader 的小节中有提及，这里再以开发 loader 的角度稍稍强调下，搬运官网的一段说明： 最后的 loader 最早调用，传入原始的资源内容（可能是代码，也可能是二进制文件，用 buffer 处理） 第一个 loader 最后调用，期望返回是 JS 代码和 sourcemap 对象（可选） 中间的 loader 执行时，传入的是上一个 loader 执行的结果 虽然有多个 loader 时遵循这样的执行顺序，但对于大多数单个 loader 来说无须感知这一点，只负责好处理接受的内容就好。 还有一个场景是 loader 中的异步处理。有一些 loader 在执行过程中可能依赖于外部 I/O 的结果，导致它必须使用异步的方式来处理，这个使用需要在 loader 执行时使用 this.async() 来标识该 loader 是异步处理的，然后使用 this.callback 来返回 loader 处理结果。例子可以参考官方文档：异步 loader。 Pitching loader 我们可以使用 pitch 来跳过 loader 的处理，pitch 方法是 loader 额外实现的一个函数，看下官方文档中的一个例子： module.exports = function(content) { return someSyncOperation(content, this.data.value); // pitch 的缘故，这里的 data.value 为 42 } // 挂在 loader 函数上的 pitch 函数 module.exports.pitch = function(remainingRequest, precedingRequest, data) { data.value = 42; } 我们可以简单把 pitch 理解为 loader 的前置钩子，它可以使用 this.data 来传递数据，然后具备跳过剩余 loader 的能力。 在一个 use 配置中所有 loader 执行前会先执行它们对应的 pitch，并且与 loader 执行顺序是相反的，如： use: [ 'bar-loader', 'foo-loader', ], // 执行 bar-loader 的 pitch // 执行 foo-loader 的 pitch // bar-loader // foo-loader 其中，当 pitch 中返回了结果，那么执行顺序会回过头来，跳掉剩余的 loader，如 bar-loader 的 pitch 返回结果了，那么执行只剩下 // 执行 bar-loader 的 pitch 可能只有比较少的 loader 会用到 pitch 这个功能，但有的时候考虑实现 loader 功能需求时把 pitch 纳入范围会有不一样的灵感，它可以让你更加灵活地去定义 loader 的执行。 这里的简单介绍仅做抛砖引玉之用，详细的学习和了解可以参考官方文档 Pitching loader 或者 bundler-loader 源码 bundler-loader。 loader 上下文 上述提及的一些代码会使用到 this，即 loader 函数的上下文，包括 this.callback 和 this.data 等，可以这样简单地理解： this 是作为 loader 运行时数据和调用方法的补充载体。 loader 上下文有很多运行时的信息，如 this.context 和 this.request 等等，而最重要的方法莫过于 this.callback 和 this.async，关于上下文这里不做展开，官方文档有比较详细的说明：loader API。当你在开发 loader 过程中发现需要某些运行时数据时，就可以查阅 loader API，基本上该有的数据都有了。 一个好 loader 是怎么样的 loader 作为 webpack 解析资源的一种扩展方式，最重要的是足够简单易用，专注于处理自己那一块的内容，便于维护，可以和其他多个 loader 协同来处理更加复杂的情况。 官方对于 loader 的使用和开发有一些准则，一个好的 loader 应该符合官方的这些定义：Loader 准则。 社区中有相当多的优秀 loader 可以作为参考，例如刚开始提及的 markdown-loader，相当地简单易用。由于 loader 的这种准则和特性，大部分的 loader 源码都相对容易解读，便于我们学习参考。 作为一个 loader 开发者，你应该尽可能遵循这些准则（有些特殊情况需要特殊处理），这样会让你开发出质量更高、更易维护和使用的 webpack loader。 小结 本小节我们从下面几个方面介绍了如何开发一个 webpack loader： loader 本质上的实现是一个函数 如何开始着手开发一个 loader loader 的输入和输出 pitch 函数的作用 loader 函数的上下文 一个好的 loader 是怎么样的 loader 的实现相对简单，webpack 社区现成可用的 loader 很多，当你在开发 loader 时遇见了问题，不妨去查阅一下现有 loader 的源码，或许会有不一样的灵感。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/15.创建自己的plugin.html":{"url":"使用webpack定制前端开发环境/15.创建自己的plugin.html","title":"15.创建自己的plugin","keywords":"","body":"创建自己的 plugin 前面一些小节中，有一些相对复杂一点的构建功能，例如分离 CSS 代码文件等，都是通过 webpack 的插件来实现的，webpack 强大扩展性的基础就是它的插件机制。当我们需要一个构建功能是 webpack 本身暂未支持的，我们便可以通过寻找合适的 webpack 插件来帮助实现需要的功能，或者我们也可以尝试自己开发一个 webpack 插件来满足项目的构建需求，这一小节会介绍如何开发一个 webpack 插件。 一个简单的 plugin plugin 的实现可以是一个类，使用时传入相关配置来创建一个实例，然后放到配置的 plugins 字段中，而 plugin 实例中最重要的方法是 apply，该方法在 webpack compiler 安装插件时会被调用一次，apply 接收 webpack compiler 对象实例的引用，你可以在 compiler 对象实例上注册各种事件钩子函数，来影响 webpack 的所有构建流程，以便完成更多其他的构建任务。 下边的这个例子，是一个可以创建 webpack 构建文件列表 markdown 的 plugin，实现上相对简单，但呈现了一个 webpack plugin 的基本形态。 class FileListPlugin { constructor(options) {} apply(compiler) { // 在 compiler 的 emit hook 中注册一个方法，当 webpack 执行到该阶段时会调用这个方法 compiler.hooks.emit.tap('FileListPlugin', (compilation) => { // 给生成的 markdown 文件创建一个简单标题 var filelist = 'In this build:\\n\\n' // 遍历所有编译后的资源，每一个文件添加一行说明 for (var filename in compilation.assets) { filelist += ('- '+ filename +'\\n') } // 将列表作为一个新的文件资源插入到 webpack 构建结果中 compilation.assets['filelist.md'] = { source: function() { return filelist }, size: function() { return filelist.length }, } }) } } module.exports = FileListPlugin webpack 4.0 版本之前使用的是旧版本的 tapable，API 和新版本的差别很大，但是事件钩子基本还是那一些，只是注册的方式有了变化，现在官方关于 plugin 新版本的文档还没有出来，对于各个钩子返回什么数据，调整后的影响，我们可以在 3.x 版本的官方文档基础上合理猜测，然后编码测试结果。 开发和调试 plugin 你要在本地开发和调试 webpack plugin 是很容易的一件事情，你只需要创建一个 js 代码文件，如同上述的例子一样，该文件对外暴露一个类，然后在 webpack 配置文件中引用这个文件的代码，照样运行 webpack 构建查看结果即可。大概的配置方式如下： // 假设我们上述那个例子的代码是 ./plugins/FileListPlugin 这个文件 const FileListPlugin = require('./plugins/FileListPlugin.js') module.exports = { // ... 其他配置 plugins: [ new FileListPlugin(), // 实例化这个插件，有的时候需要传入对应的配置 ], } webpack 是基于 Node.js 开发的，plugin 也不例外，所以 plugin 的调试和调试 Node.js 代码并无两样，简单的使用 console 来打印相关信息，复杂一点的使用断点，或者利用编辑器提供的功能，例如 VSCode 的 DEBUG，对于这一部分内容，有兴趣的同学可以去查找相关资料，不再展开。 webpack 中的事件钩子 当开发 plugin 需要时，我们可以查阅官方文档中提供的事件钩子列表：compiler 的事件钩子 和 compilation 的事件钩子。 或者查看源码：compiler hooks 和 compilation hooks 来寻找更加详细的信息。 我们可以看到在事件钩子列表中看到，webpack 中会有相当多的事件钩子，基本覆盖了 webpack 构建流程中的每一个步骤，你可以在这些步骤都注册自己的处理函数，来添加额外的功能，这就是 webpack 提供的 plugin 扩展。 如果你查看了前面 compiler hooks 或者 compilation hooks 的源码链接，你会看到事件钩子是这样声明的： this.hooks = { shouldEmit: new SyncBailHook([\"compilation\"]), // 这里的声明的事件钩子函数接收的参数是 compilation， done: new AsyncSeriesHook([\"stats\"]), // 这里接收的参数是 stats，以此类推 additionalPass: new AsyncSeriesHook([]), beforeRun: new AsyncSeriesHook([\"compilation\"]), run: new AsyncSeriesHook([\"compilation\"]), emit: new AsyncSeriesHook([\"compilation\"]), afterEmit: new AsyncSeriesHook([\"compilation\"]), thisCompilation: new SyncHook([\"compilation\", \"params\"]), // ... }; 从这里你可以看到各个事件钩子函数接收的参数是什么，你还会发现事件钩子会有不同的类型，例如 SyncBailHook，AsyncSeriesHook，SyncHook，接下来我们再介绍一下事件钩子的类型以及我们可以如何更好地利用各种事件钩子的类型来开发我们需要的 plugin。 了解事件钩子类型 上述提到的 webpack compiler 中使用了多种类型的事件钩子，根据其名称就可以区分出是同步还是异步的，对于同步的事件钩子来说，注册事件的方法只有 tap 可用，例如上述的 shouldEmit 应该这样来注册事件函数的： apply(compiler) { compiler.hooks.shouldEmit.tap('PluginName', (compilation) => { /* ... */ }) } 但如果是异步的事件钩子，那么可以使用 tapPromise 或者 tapAsync 来注册事件函数，tapPromise 要求方法返回 Promise 以便处理异步，而 tapAsync 则是需要用 callback 来返回结果，例如： compiler.hooks.done.tapPromise('PluginName', (stats) => { // 返回 promise return new Promise((resolve, reject) => { // 这个例子是写一个记录 stats 的文件 fs.writeFile('path/to/file', stats.toJson(), (err) => err ? reject(err) : resolve()) }) }) // 或者 compiler.hooks.done.tapAsync('PluginName', (stats, callback) => { // 使用 callback 来返回结果 fs.writeFile('path/to/file', stats.toJson(), (err) => callback(err)) }) // 如果插件处理中没有异步操作要求的话，也可以用同步的方式 compiler.hooks.done.tap('PluginName', (stats, callback) => { callback(fs.writeFileSync('path/to/file', stats.toJson()) }) 然而 tapable 这个工具库提供的钩子类型远不止这几种，多样化的钩子类型，主要是为了能够覆盖多种使用场景： 连续地执行注册的事件函数 并行地执行注册的事件函数 一个接一个地执行注册的事件函数，从前边的事件函数获取输入，即瀑布流的方式 异步地执行注册的事件函数 在允许时停止执行注册的事件函数，一旦一个方法返回了一个非 undefined 的值，就跳出执行流 除了同步和异步的区别，我们再参考上述这一些使用场景，以及官方文档的 Plugin API，进一步将事件钩子类型做一个区分。 名称带有 parallel 的，注册的事件函数会并行调用，如： AsyncParallelHook AsyncParallelBailHook 名称带有 bail 的，注册的事件函数会被顺序调用，直至一个处理方法有返回值（ParallelBail 的事件函数则会并行调用，第一个返回值会被使用）： SyncBailHook AsyncParallelBailHook AsyncSeriesBailHook 名称带有 waterfall 的，每个注册的事件函数，会将上一个方法的返回结果作为输入参数，如： SyncWaterfallHook AsyncSeriesWaterfallHook 通过上面的名称可以看出，有一些类型是可以结合到一起的，如 AsyncParallelBailHook，这样它就具备了更加多样化的特性。 了解了 webpack 中使用的各个事件钩子的类型，才能在开发 plugin 更好地去把握注册事件的输入和输出，同步和异步，来更好地完成我们想要的构建需求。 关于 webpack 3.x 的 plugin API，现在还可以参考官方文档，趁着还没更新到 4.x 版本：plugin API。 小结 本小节我们介绍了一个简单的 webpack plugin 是怎么样的，以及如何去开发和调试 plugin。 webpack plugin 的实现本质上就是基于 webpack 的构建流程注册各种各样的钩子事件函数来添加额外的构建功能，所以我们也介绍了 webpack 流程中的事件钩子以及事件钩子的类型和区别，以便我们更好地在开发 plugin 时把握输入输出。 例子 本小节提及的一些简单的 Demo 可以在 webpack-examples 找到。 "},"使用webpack定制前端开发环境/16.总结.html":{"url":"使用webpack定制前端开发环境/16.总结.html","title":"16.总结","keywords":"","body":"总结 从 webpack 3.x 到 4.x 我们整个小册主要内容是基于最新的 webpack 4.x 版本来写的，但其实从一开始就提及 webpack 3.x 到 4.x 的变化，各个小节的内容多多少少都介绍到了 3.x 和 4.x 的差异，这里再作一下简单的关于 3.x 到 4.x 变化的总结。 首先，第 1 小节的时候就已经提到了，4.x 拆出来了一个 webpack-cli，把 webpack 实际核心和命令行接口工具分开，并且 webpack-cli 担任了一些项目上管理的工作，例如项目初始化，webpack 版本升级的迁移等等，功能相对全面，并且这些的确不应该归由 webpack 核心去处理。 之前 parcel-bundler 的出现，对 webpack 还是有一定的冲击，webpack 4.x 立马就引入了零配置的概念，同时新增了 mode 参数（4.x 是必要的参数），这样既协助开发者去区分环境，也可以更加自然地根据不同 mode 来添加更多默认的配置，如开发环境的 HMR、生产环境的代码压缩等，更加顺应零配置的需求。 然后 webpack 4.x 删除了 CommonsChunkPlugin，把代码分离的功能纳入到 optimization 配置去管理。 顺应整个开发社区的需求，webpack 4.x 默认支持 WebAssembly 了，同时为了以后的发展，开始着重强调代码模块类型的概念，现在主要还是支持了 JS 相关的代码模块类型，后续计划是添加更多的类型，如 HTML、CSS 等。 还有很重要的一点，4.x 做了很多构建性能方面的优化，让 webpack 在以后面对大型项目构建时更加游刃有余。 上面提到的是变化比较大的点，其实 webpack 3.x 从 4.x 做了很多很多，可以看出 webpack 自身项目的维护工作是相当活跃和优秀的，这里再把官方比较重要、详细的介绍内容放在这里，方便希望更加详细和深入了解的同学们查阅： webpack 4 released today webpack 4 release log webpack 4 import and commonjs webpack 4: Code Splitting, chunk graph and the splitChunks optimization webpack 4 mode and optimization webpack 4: migration guide for plugins/loaders 回顾 我们上面提到了，webpack 从 4.x 开始支持零配置，这让我们的基础使用变得更加简单，但是根据不同项目的实际需要，我们还是需要花费一定时间去配置 webpack。 在 webpack 配置中，resolve 字段下的选项可以用来控制 webpack 如何解析代码模块的路径，webpack 解析代码模块路径的这部分功能是使用 enhanced-resolve 来实现的。 我们可以在 webpack 中配置使用不同的 loader 来处理不同的代码文件类型，例如使用 less-loader 来使用 Less 预处理器，利用好 loader 可以打包前端中使用到的各种各样的资源文件。 webpack 社区提供了很多优秀的 plugin 供前端开发者使用，我们在 webpack 配置中的 plugins 字段中添加需要的 plugin 实例即可，plugin 的具体使用选项由各个插件自身去定义，所以要用好插件，需要耐心地阅读插件官方提供的使用文档。 webpack 提供了 webpack-dev-server 和 webpack-dev-middleware 来简单快速地创建开发环境中使用的静态服务，通过该静态服务可以访问 webpack 构建好的结果，并且在这个基础上，webpack 提供了 hot reload 的能力，代码变更时自动更新页面。 在日常的前端开发工作中，我们需要进一步掌握使用 webpack 来优化前端资源加载的技巧，包括图片处理、代码压缩、分离代码和按需加载模块等。在处理各种前端资源加载优化的问题时，要学会灵活地思考应用场景，将 webpack 提供的各种能力与实际项目中的实践结合一起。 当我们能够自由地使用社区中的 loader 和 plugin 之后，我们可以尝试进一步地去开发自己需要的 loader 和 plugin，来满足更多项目中需要的特殊构建需求。 webpack 是个相当优秀的前端构建工具，webpack 优秀的开发者们和 webpack 本身强大的扩展能力造就了现在热闹非凡的 webpack 前端社区，周边工具和产品非常多，这也是 webpack 最最核心的竞争力。 我们可以利用 webpack 超级灵活的配置来帮助我们尽可能地去优化 webpack 的构建速度，但是这些努力可能会有一定的局限性，有的时候要学会跳出 webpack 构建工具，从另外的角度去思考问题，来帮助我们更好地解决实际项目中的问题。 未来的展望 webpack 未来的一些发展方向和更新计划也都在筹备中了，在 4.x 到 5.x 的一些预备特性中，不乏相当让人期待的东西： ESM 模块导出支持 构建结果的持久缓存 Preset 的支持，类似 Babel 的 Preset 来做预设的配置，实现更加灵活的零配置 CSS 模块类型的支持，可以用 CSS 文件作为入口 HTML 模块类型的支持，可以用 HTML 文件作为入口 自定义的代码模块类型 多线程的构建方式 让我们期待 webpack 越来越好。 "},"前端性能优化/01.开篇：知识体系与小册格局.html":{"url":"前端性能优化/01.开篇：知识体系与小册格局.html","title":"01.开篇：知识体系与小册格局","keywords":"","body":"无耻硬广入：你言出新书啦！欢迎大家品鉴JavaScript 设计模式核⼼原理与应⽤实践，干货满满，考点密集，李雷和韩梅梅的故事，帮你像读小说一样轻松掌握设计模式~光读书不交友，我咋知道你们喜欢看啥？快来加我微信 xyalinode 告诉我你害怕哪些知识，我们一起来把它干掉！：） 知识体系与小册格局 写给读者 提起性能优化，大家现在脑海里第一时间会映射出什么内容呢？ 可能是类似“雅虎军规”和《高性能 JavaScript》这样历久弥香的经典之作，也可能是搜索引擎聚合给你的一篇又一篇以性能优化为主题的个人或团队实践而来的“私货”。至少当我确定自己的研发方向、并接到第一个性能优化任务时，我做的第一件事是向搜索引擎求助，第二件事是买书，然后开始了摸着石头过河，前后花费了大量的时间和精力。我深感性能优化实在是前端知识树中特别的一环——当你需要学习前端框架时，文档和源码几乎可以告诉你所有问题的答案，当你需要学习 Git 时，你也可以找到放之四海皆准的实践方案。但性能优化却不一样，它好像只能是一个摸索的过程。 这个摸索的过程是痛苦的、漫长的，也是紧要的。因为在如今的互联网环境下，一个前端团队如果只把性能优化这个任务写在纸上，而不投入实践，它将缺失最基本的竞争力。 笔者写这本小册，是希望通过短短十数个章节的讲解，尽可能降低一些大家学习性能优化的成本。 一方面，这本小册为没有接触过性能优化的新同学建立起一个正确的前端性能优化的“世界观”，知道性能优化是什么、为什么、怎么做，从而使性能优化这件事情有迹可循，有路可走。这样在面试现场被问到性能优化层面的问题时，能够做到滔滔不绝、言之有物，而非像背书一样罗列干巴巴的知识点，最终淹没在茫茫的求职大军中。另一方面，小册可以为在职的工程师们提供一线团队已经实践过的“方法论”，知道什么场景下该做什么事情，最终在脑海中留下一张涵盖核心原理和实践的、可随时查阅并且高度可扩展的性能优化思路索引表。然后在今后的开发生活中可以去践行它，更进一步去挖掘它。把性能优化变作你前端工程师生涯的一门必修课，进而演化为自己研发方面的核心竞争力。 同时，相信大家可以明确这样一个学习观念：任何技术的掌握，都离不开一定比例的理论基础和实际操作的支撑。 具体到前端性能优化这件事情上，我认为它是 20% 的理论，加上至少 80% 的实践，甚至很多理论本身也都是我们在具体的业务场景中实践出来的。所以希望大家阅读本小册时，能够读到一些“书本之外的东西”——最好是一边读一边回忆自己既有的开发经历，尝试去留意哪些知识是已知的，哪些是未知的。 这样读完之后，就可以有的放矢地把这些知识转换为自己的项目实践——前端技术日新月异，性能方案永远都在更迭，所以一定要形成自己的学习思路。 建议每一位读者都带着“学了就要用”的心态去读这本小册。如果阅读结束，能够为你带来哪怕一个小小的开发习惯或者优化观念上的改变，这数小时的阅读时间就算没有白费。 知识体系： 从一道面试题说起 在展开性能优化的话题之前，我想先抛出一个老生常谈的面试问题： 从输入 URL 到页面加载完成，发生了什么？ 这个问题非常重要，因为我们后续的内容都将以这个问题的答案为骨架展开。我希望正在阅读这本小册的各位可以在心里琢磨一下这个问题——无须你调动太多计算机的专业知识，只需要你用最快的速度在脑海中架构起这个抽象的过程——我们接下来所有的工作，就是围绕这个过程来做文章。 我们现在站在性能优化的角度，一起简单地复习一遍这个经典的过程：首先我们需要通过 DNS（域名解析系统）将 URL 解析为对应的 IP 地址，然后与这个 IP 地址确定的那台服务器建立起 TCP 网络连接，随后我们向服务端抛出我们的 HTTP 请求，服务端处理完我们的请求之后，把目标数据放在 HTTP 响应里返回给客户端，拿到响应数据的浏览器就可以开始走一个渲染的流程。渲染完毕，页面便呈现给了用户，并时刻等待响应用户的操作（如下图所示）。 我们将这个过程切分为如下的过程片段： DNS 解析 TCP 连接 HTTP 请求抛出 服务端处理请求，HTTP 响应返回 浏览器拿到响应数据，解析响应内容，把解析的结果展示给用户 大家谨记，我们任何一个用户端的产品，都需要把这 5 个过程滴水不漏地考虑到自己的性能优化方案内、反复权衡，从而打磨出用户满意的速度。 从原理到实践：各个击破 我们接下来要做的事情，就是针对这五个过程进行分解，各个提问，各个击破。 具体来说，DNS 解析花时间，能不能尽量减少解析次数或者把解析前置？能——浏览器 DNS 缓存和 DNS prefetch。TCP 每次的三次握手都急死人，有没有解决方案？有——长连接、预连接、接入 SPDY 协议。如果说这两个过程的优化往往需要我们和团队的服务端工程师协作完成，前端单方面可以做的努力有限，那么 HTTP 请求呢？——在减少请求次数和减小请求体积方面，我们应该是专家！再者，服务器越远，一次请求就越慢，那部署时就把静态资源放在离我们更近的 CDN 上是不是就能更快一些？ 以上提到的都是网络层面的性能优化。再往下走就是浏览器端的性能优化——这部分涉及资源加载优化、服务端渲染、浏览器缓存机制的利用、DOM 树的构建、网页排版和渲染过程、回流与重绘的考量、DOM 操作的合理规避等等——这正是前端工程师可以真正一展拳脚的地方。学习这些知识，不仅可以帮助我们从根本上提升页面性能，更能够大大加深个人对浏览器底层原理、运行机制的理解，一举两得！ 我们整个的知识图谱，用思维导图展示如下： 小册格局 总的来说，我们将从网络层面和渲染层面两个大的维度来逐个点亮前端性能优化的技能树。 这两个维度的知识面貌各有千秋：在网络层面，我们需要学习一些必需的理论基础作为前置知识。这部分的学习或许不需要大家写特别多的代码，但需要大家对每一个知识点理解透彻，进而应用到自己日常优化的决策中去。网络层面结束后，由本地存储开始，我们会渐渐过渡到浏览器这一端的优化，大家喜闻乐见的“真代码”就会相应地多起来。 为了使同学们耐心学习一些理论性稍强的知识，我也会尽自己所能去讲述得有趣、易读、可用，同时希望大家可以真的沉下心去理解这些知识，它们与大家喜闻乐见的框架和工具无异，一样是实实在在的生产力。 “经验丰富的人读书用两只眼睛，一只眼睛看到纸面上的话，另一只眼睛看到纸的背面”。在这本小册，代码片段固然有用，它们是“纸面上的话”，我自然希望大家可以记下来、用起来。而代码之外那些反复讲解的原理，则是“纸的背面”，同样是我希望引起大家重视的内容。 现在相信大家已经对我们的优化观念、知识结构、小册格局都有了基本认知，那么我们就赶快趁热打铁，进入实战技能的学习吧~ "},"前端性能优化/02.网络篇1：webpack性能调优与Gzip原理.html":{"url":"前端性能优化/02.网络篇1：webpack性能调优与Gzip原理.html","title":"02.网络篇1：webpack性能调优与Gzip原理","keywords":"","body":"webpack 性能调优与 Gzip 原理 从本节开始，我们进入网络层面的性能优化世界。 大家可以从第一节的示意图中看出，我们从输入 URL 到显示页面这个过程中，涉及到网络层面的，有三个主要过程： DNS 解析 TCP 连接 HTTP 请求/响应 对于 DNS 解析和 TCP 连接两个步骤，我们前端可以做的努力非常有限。相比之下，HTTP 连接这一层面的优化才是我们网络优化的核心。因此我们开门见山，抓主要矛盾，直接从 HTTP 开始讲起。 HTTP 优化有两个大的方向： 减少请求次数 减少单次请求所花费的时间 这两个优化点直直地指向了我们日常开发中非常常见的操作——资源的压缩与合并。没错，这就是我们每天用构建工具在做的事情。而时下最主流的构建工具无疑是 webpack，所以我们这节的主要任务就是围绕业界霸主 webpack 来做文章。 webpack 的性能瓶颈 相信每个用过 webpack 的同学都对“打包”和“压缩”这样的事情烂熟于心。这些老生常谈的特性，我更推荐大家去阅读文档。而关于 webpack 的详细操作，则推荐大家读读这本 关于 webpack 的掘金小册，这里我们把注意力放在 webpack 的性能优化上。 webpack 的优化瓶颈，主要是两个方面： webpack 的构建过程太花时间 webpack 打包的结果体积太大 webpack 优化方案 构建过程提速策略 不要让 loader 做太多事情——以 babel-loader 为例 babel-loader 无疑是强大的，但它也是慢的。 最常见的优化方式是，用 include 或 exclude 来帮我们避免不必要的转译，比如 webpack 官方在介绍 babel-loader 时给出的示例： module: { rules: [ { test: /\\.js$/, exclude: /(node_modules|bower_components)/, use: { loader: 'babel-loader', options: { presets: ['@babel/preset-env'] } } } ] } 这段代码帮我们规避了对庞大的 node_modules 文件夹或者 bower_components 文件夹的处理。但通过限定文件范围带来的性能提升是有限的。除此之外，如果我们选择开启缓存将转译结果缓存至文件系统，则至少可以将 babel-loader 的工作效率提升两倍。要做到这点，我们只需要为 loader 增加相应的参数设定： loader: 'babel-loader?cacheDirectory=true' 以上都是在讨论针对 loader 的配置，但我们的优化范围不止是 loader 们。 举个🌰，尽管我们可以在 loader 配置时通过写入 exclude 去避免 babel-loader 对不必要的文件的处理，但是考虑到这个规则仅作用于这个 loader，像一些类似 UglifyJsPlugin 的 webpack 插件在工作时依然会被这些庞大的第三方库拖累，webpack 构建速度依然会因此大打折扣。所以针对这些庞大的第三方库，我们还需要做一些额外的努力。 不要放过第三方库 第三方库以 node_modules 为代表，它们庞大得可怕，却又不可或缺。 处理第三方库的姿势有很多，其中，Externals 不够聪明，一些情况下会引发重复打包的问题；而 CommonsChunkPlugin 每次构建时都会重新构建一次 vendor；出于对效率的考虑，我们这里为大家推荐 DllPlugin。 DllPlugin 是基于 Windows 动态链接库（dll）的思想被创作出来的。这个插件会把第三方库单独打包到一个文件中，这个文件就是一个单纯的依赖库。这个依赖库不会跟着你的业务代码一起被重新打包，只有当依赖自身发生版本变化时才会重新打包。 用 DllPlugin 处理文件，要分两步走： 基于 dll 专属的配置文件，打包 dll 库 基于 webpack.config.js 文件，打包业务代码 以一个基于 React 的简单项目为例，我们的 dll 的配置文件可以编写如下： const path = require('path') const webpack = require('webpack') module.exports = { entry: { // 依赖的库数组 vendor: [ 'prop-types', 'babel-polyfill', 'react', 'react-dom', 'react-router-dom', ] }, output: { path: path.join(__dirname, 'dist'), filename: '[name].js', library: '[name]_[hash]', }, plugins: [ new webpack.DllPlugin({ // DllPlugin的name属性需要和libary保持一致 name: '[name]_[hash]', path: path.join(__dirname, 'dist', '[name]-manifest.json'), // context需要和webpack.config.js保持一致 context: __dirname, }), ], } 编写完成之后，运行这个配置文件，我们的 dist 文件夹里会出现这样两个文件： vendor-manifest.json vendor.js vendor.js 不必解释，是我们第三方库打包的结果。这个多出来的 vendor-manifest.json，则用于描述每个第三方库对应的具体路径，我这里截取一部分给大家看下： { \"name\": \"vendor_397f9e25e49947b8675d\", \"content\": { \"./node_modules/core-js/modules/_export.js\": { \"id\": 0, \"buildMeta\": { \"providedExports\": true } }, \"./node_modules/prop-types/index.js\": { \"id\": 1, \"buildMeta\": { \"providedExports\": true } }, ... } } 随后，我们只需在 webpack.config.js 里针对 dll 稍作配置： const path = require('path'); const webpack = require('webpack') module.exports = { mode: 'production', // 编译入口 entry: { main: './src/index.js' }, // 目标文件 output: { path: path.join(__dirname, 'dist/'), filename: '[name].js' }, // dll相关配置 plugins: [ new webpack.DllReferencePlugin({ context: __dirname, // manifest就是我们第一步中打包出来的json文件 manifest: require('./dist/vendor-manifest.json'), }) ] } 一次基于 dll 的 webpack 构建过程优化，便大功告成了！ Happypack——将 loader 由单进程转为多进程 大家知道，webpack 是单线程的，就算此刻存在多个任务，你也只能排队一个接一个地等待处理。这是 webpack 的缺点，好在我们的 CPU 是多核的，Happypack 会充分释放 CPU 在多核并发方面的优势，帮我们把任务分解给多个子进程去并发执行，大大提升打包效率。 HappyPack 的使用方法也非常简单，只需要我们把对 loader 的配置转移到 HappyPack 中去就好，我们可以手动告诉 HappyPack 我们需要多少个并发的进程： const HappyPack = require('happypack') // 手动创建进程池 const happyThreadPool = HappyPack.ThreadPool({ size: os.cpus().length }) module.exports = { module: { rules: [ ... { test: /\\.js$/, // 问号后面的查询参数指定了处理这类文件的HappyPack实例的名字 loader: 'happypack/loader?id=happyBabel', ... }, ], }, plugins: [ ... new HappyPack({ // 这个HappyPack的“名字”就叫做happyBabel，和楼上的查询参数遥相呼应 id: 'happyBabel', // 指定进程池 threadPool: happyThreadPool, loaders: ['babel-loader?cacheDirectory'] }) ], } 构建结果体积压缩 文件结构可视化，找出导致体积过大的原因 这里为大家介绍一个非常好用的包组成可视化工具——webpack-bundle-analyzer，配置方法和普通的 plugin 无异，它会以矩形树图的形式将包内各个模块的大小和依赖关系呈现出来，格局如官方所提供这张图所示： 在使用时，我们只需要将其以插件的形式引入： const BundleAnalyzerPlugin = require('webpack-bundle-analyzer').BundleAnalyzerPlugin; module.exports = { plugins: [ new BundleAnalyzerPlugin() ] } 拆分资源 这点仍然围绕 DllPlugin 展开，可参考上文。 删除冗余代码 一个比较典型的应用，就是 Tree-Shaking。 从 webpack2 开始，webpack 原生支持了 ES6 的模块系统，并基于此推出了 Tree-Shaking。webpack 官方是这样介绍它的： Tree shaking is a term commonly used in the JavaScript context for dead-code elimination, or more precisely, live-code import. It relies on ES2015 module import/export for the static structure of its module system. 意思是基于 import/export 语法，Tree-Shaking 可以在编译的过程中获悉哪些模块并没有真正被使用，这些没用的代码，在最后打包的时候会被去除。 举个🌰，假设我的主干文件（入口文件）是这么写的： import { page1, page2 } from './pages' // show是事先定义好的函数，大家理解它的功能是展示页面即可 show(page1) pages 文件里，我虽然导出了两个页面： export const page1 = xxx export const page2 = xxx 但因为 page2 事实上并没有被用到（这个没有被用到的情况在静态分析的过程中是可以被感知出来的），所以打包的结果里会把这部分： export const page2 = xxx; 直接删掉，这就是 Tree-Shaking 帮我们做的事情。 相信大家不难看出，Tree-Shaking 的针对性很强，它更适合用来处理模块级别的冗余代码。至于粒度更细的冗余代码的去除，往往会被整合进 JS 或 CSS 的压缩或分离过程中。 这里我们以当下接受度较高的 UglifyJsPlugin 为例，看一下如何在压缩过程中对碎片化的冗余代码（如 console 语句、注释等）进行自动化删除： const UglifyJsPlugin = require('uglifyjs-webpack-plugin'); module.exports = { plugins: [ new UglifyJsPlugin({ // 允许并发 parallel: true, // 开启缓存 cache: true, compress: { // 删除所有的console语句 drop_console: true, // 把使用多次的静态值自动定义为变量 reduce_vars: true, }, output: { // 不保留注释 comment: false, // 使输出的代码尽可能紧凑 beautify: false } }) ] } 有心的同学会注意到，这段手动引入 UglifyJsPlugin 的代码其实是 webpack3 的用法，webpack4 现在已经默认使用 uglifyjs-webpack-plugin 对代码做压缩了——在 webpack4 中，我们是通过配置 optimization.minimize 与 optimization.minimizer 来自定义压缩相关的操作的。 这里也引出了我们学习性能优化的一个核心的理念——用什么工具，怎么用，并不是我们这本小册的重点，因为所有的工具都存在用法迭代的问题。但现在大家知道了在打包的过程中做一些如上文所述的“手脚”可以实现打包结果的最优化，那下次大家再去执行打包操作，会不会对这个操作更加留心，从而自己去寻找彼时操作的具体实现方案呢？我最希望大家掌握的技能就是，先在脑海中留下“这个xx操作是对的，是有用的”，在日后的实践中，可以基于这个认知去寻找把正确的操作落地的具体方案。 按需加载 大家想象这样一个场景。我现在用 React 构建一个单页应用，用 React-Router 来控制路由，十个路由对应了十个页面，这十个页面都不简单。如果我把这整个项目打一个包，用户打开我的网站时，会发生什么？有很大机率会卡死，对不对？更好的做法肯定是先给用户展示主页，其它页面等请求到了再加载。当然这个情况也比较极端，但却能很好地引出按需加载的思想： 一次不加载完所有的文件内容，只加载此刻需要用到的那部分（会提前做拆分） 当需要更多内容时，再对用到的内容进行即时加载 好，既然说到这十个 Router 了，我们就拿其中一个开刀，假设我这个 Router 对应的组件叫做 BugComponent，来看看我们如何利用 webpack 做到该组件的按需加载。 当我们不需要按需加载的时候，我们的代码是这样的： import BugComponent from '../pages/BugComponent' ... 为了开启按需加载，我们要稍作改动。 首先 webpack 的配置文件要走起来： output: { path: path.join(__dirname, '/../dist'), filename: 'app.js', publicPath: defaultSettings.publicPath, // 指定 chunkFilename chunkFilename: '[name].[chunkhash:5].chunk.js', }, 路由处的代码也要做一下配合： const getComponent => (location, cb) { require.ensure([], (require) => { cb(null, require('../pages/BugComponent').default) }, 'bug') }, ... 对，核心就是这个方法： require.ensure(dependencies, callback, chunkName) 这是一个异步的方法，webpack 在打包时，BugComponent 会被单独打成一个文件，只有在我们跳转 bug 这个路由的时候，这个异步方法的回调才会生效，才会真正地去获取 BugComponent 的内容。这就是按需加载。 按需加载的粒度，还可以继续细化，细化到更小的组件、细化到某个功能点，都是 ok 的。 等等，这和说好的不一样啊？不是说 Code-Splitting 才是 React-Router 的按需加载实践吗？ 没错，在 React-Router4 中，我们确实是用 Code-Splitting 替换掉了楼上这个操作。而且如果有使用过 React-Router4 实现过路由级别的按需加载的同学，可能会对 React-Router4 里用到的一个叫“Bundle-Loader”的东西印象深刻。我想很多同学读到按需加载这里，心里的预期或许都是时下大热的 Code-Splitting，而非我呈现出来的这段看似“陈旧”的代码。 但是，如果大家稍微留个心眼，去看一下 Bundle Loader 并不长的源代码的话，你会发现它竟然还是使用 require.ensure 来实现的——这也是我要把 require.ensure 单独拎出来的重要原因。所谓按需加载，根本上就是在正确的时机去触发相应的回调。理解了这个 require.ensure 的玩法，大家甚至可以结合业务自己去修改一个按需加载模块来用。 这也应了我之前跟大家强调那段话，工具永远在迭代，唯有掌握核心思想，才可以真正做到举一反三——唯“心”不破！ 彩蛋：Gzip 压缩原理 恭喜大家迎来了本小册的第一个彩蛋。彩蛋为选学内容，以原理性知识为主。意在拓宽大家的技术视野，加深大家对优化相关知识的理解。 前面说了不少 webpack 的故事，目的还是帮大家更好地实现压缩和合并。说到压缩，可不只是构建工具的专利。我们日常开发中，其实还有一个便宜又好用的压缩操作：开启 Gzip。 具体的做法非常简单，只需要你在你的 request headers 中加上这么一句： accept-encoding:gzip 相信很多同学对 Gzip 也是了解到这里。之所以为大家开这个彩蛋性的小节，绝不是出于炫技要来给大家展示一下 Gzip 的压缩算法，而是想和大家聊一个和我们前端关系更密切的话题：HTTP 压缩。 HTTP 压缩是一种内置到网页服务器和网页客户端中以改进传输速度和带宽利用率的方式。在使用 HTTP 压缩的情况下，HTTP 数据在从服务器发送前就已压缩：兼容的浏览器将在下载所需的格式前宣告支持何种方法给服务器；不支持压缩方法的浏览器将下载未经压缩的数据。最常见的压缩方案包括 Gzip 和 Deflate。 以上是摘自百科的解释，事实上，大家可以这么理解： HTTP 压缩就是以缩小体积为目的，对 HTTP 内容进行重新编码的过程 Gzip 的内核就是 Deflate，目前我们压缩文件用得最多的就是 Gzip。可以说，Gzip 就是 HTTP 压缩的经典例题。 该不该用 Gzip 如果你的项目不是极端迷你的超小型文件，我都建议你试试 Gzip。 有的同学或许存在这样的疑问：压缩 Gzip，服务端要花时间；解压 Gzip，浏览器要花时间。中间节省出来的传输时间，真的那么可观吗？ 答案是肯定的。如果你手上的项目是 1k、2k 的小文件，那确实有点高射炮打蚊子的意思，不值当。但更多的时候，我们处理的都是具备一定规模的项目文件。实践证明，这种情况下压缩和解压带来的时间开销相对于传输过程中节省下的时间开销来说，可以说是微不足道的。 Gzip 是万能的吗 首先要承认 Gzip 是高效的，压缩后通常能帮我们减少响应 70% 左右的大小。 但它并非万能。Gzip 并不保证针对每一个文件的压缩都会使其变小。 Gzip 压缩背后的原理，是在一个文本文件中找出一些重复出现的字符串、临时替换它们，从而使整个文件变小。根据这个原理，文件中代码的重复率越高，那么压缩的效率就越高，使用 Gzip 的收益也就越大。反之亦然。 webpack 的 Gzip 和服务端的 Gzip 一般来说，Gzip 压缩是服务器的活儿：服务器了解到我们这边有一个 Gzip 压缩的需求，它会启动自己的 CPU 去为我们完成这个任务。而压缩文件这个过程本身是需要耗费时间的，大家可以理解为我们以服务器压缩的时间开销和 CPU 开销（以及浏览器解析压缩文件的开销）为代价，省下了一些传输过程中的时间开销。 既然存在着这样的交换，那么就要求我们学会权衡。服务器的 CPU 性能不是无限的，如果存在大量的压缩需求，服务器也扛不住的。服务器一旦因此慢下来了，用户还是要等。Webpack 中 Gzip 压缩操作的存在，事实上就是为了在构建过程中去做一部分服务器的工作，为服务器分压。 因此，这两个地方的 Gzip 压缩，谁也不能替代谁。它们必须和平共处，好好合作。作为开发者，我们也应该结合业务压力的实际强度情况，去做好这其中的权衡。 小结 说了这么多，我们都在讨论文件——准确地说，是文本文件及其构建过程的优化。 但一个完整的现代前端应用，除了要包含 HTML、CSS 和 JS，往往还需要借助图片来提高用户的视觉体验。而图片优化的思路、场景与措施，又是另外一个说来话长的故事了。下面，我们就一起进入图片的小天地，一窥究竟。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/03.网络篇2：图片优化——质量与性能的博弈.html":{"url":"前端性能优化/03.网络篇2：图片优化——质量与性能的博弈.html","title":"03.网络篇2：图片优化——质量与性能的博弈","keywords":"","body":"图片优化——质量与性能的博弈 《高性能网站建设指南》的作者 Steve Souders 曾在 2013 年的一篇 博客 中提到： 我的大部分性能优化工作都集中在 JavaScript 和 CSS 上，从早期的 Move Scripts to the Bottom 和 Put Stylesheets at the Top 规则。为了强调这些规则的重要性，我甚至说过，“JS 和 CSS 是页面上最重要的部分”。 几个月后，我意识到这是错误的。图片才是页面上最重要的部分。 我关注 JS 和 CSS 的重点也是如何能够更快地下载图片。图片是用户可以直观看到的。他们并不会关注 JS 和 CSS。确实，JS 和 CSS 会影响图片内容的展示，尤其是会影响图片的展示方式（比如图片轮播，CSS 背景图和媒体查询）。但是我认为 JS 和 CSS 只是展示图片的方式。在页面加载的过程中，应当先让图片和文字先展示，而不是试图保证 JS 和 CSS 更快下载完成。 这段话可谓字字珠玑。此外，雅虎军规和 Google 官方的最佳实践也都将图片优化列为前端性能优化必不可少的环节——图片优化的优先级可见一斑。 就图片这块来说，与其说我们是在做“优化”，不如说我们是在做“权衡”。因为我们要做的事情，就是去压缩图片的体积（或者一开始就选取体积较小的图片格式）。但这个优化操作，是以牺牲一部分成像质量为代价的。因此我们的主要任务，是尽可能地去寻求一个质量与性能之间的平衡点。 2018 年，图片依然很大 这里先给大家介绍 HTTP-Archive 这个网站，它会定期抓取 Web 上的站点，并记录资源的加载情况、Web API 的使用情况等页面的详细信息，并会对这些数据进行处理和分析以确定趋势。通过它我们可以实时地看到世界范围内的 Web 资源的统计结果。 截止到 2018 年 8 月，过去一年总的 web 资源的平均请求体积是这样的： 而具体到图片这一类的资源，平均请求体积是这样的： 当然，随着我们工程师在性能方面所做的努力越来越有成效，平均来说，不管是资源总量还是图片体积，都在往越来越轻量的方向演化。这是一种值得肯定的进步。 但同时我们不得不承认，如图所示的这个图片体积，依然是太大了。图片在所有资源中所占的比重，也足够“触目惊心”了。为了改变这个现状，我们必须把图片优化提上日程。 不同业务场景下的图片方案选型 时下应用较为广泛的 Web 图片格式有 JPEG/JPG、PNG、WebP、Base64、SVG 等，这些格式都是很有故事的，值得我们好好研究一把。此外，老生常谈的雪碧图（CSS Sprites）至今也仍在一线的前端应用中发光发热，我们也会有所提及。 不谈业务场景的选型都是耍流氓。下面我们就结合具体的业务场景，一起来解开图片选型的神秘面纱！ 前置知识：二进制位数与色彩的关系 在计算机中，像素用二进制数来表示。不同的图片格式中像素与二进制位数之间的对应关系是不同的。一个像素对应的二进制位数越多，它可以表示的颜色种类就越多，成像效果也就越细腻，文件体积相应也会越大。 一个二进制位表示两种颜色（0|1 对应黑|白），如果一种图片格式对应的二进制位数有 n 个，那么它就可以呈现 2^n 种颜色。 JPEG/JPG 关键字：有损压缩、体积小、加载快、不支持透明 JPG 的优点 JPG 最大的特点是有损压缩。这种高效的压缩算法使它成为了一种非常轻巧的图片格式。另一方面，即使被称为“有损”压缩，JPG的压缩方式仍然是一种高质量的压缩方式：当我们把图片体积压缩至原有体积的 50% 以下时，JPG 仍然可以保持住 60% 的品质。此外，JPG 格式以 24 位存储单个图，可以呈现多达 1600 万种颜色，足以应对大多数场景下对色彩的要求，这一点决定了它压缩前后的质量损耗并不容易被我们人类的肉眼所察觉——前提是你用对了业务场景。 使用场景 JPG 适用于呈现色彩丰富的图片，在我们日常开发中，JPG 图片经常作为大的背景图、轮播图或 Banner 图出现。 两大电商网站对大图的处理，是 JPG 图片应用场景的最佳写照： 打开淘宝首页，我们可以发现页面中最醒目、最庞大的图片，一定是以 .jpg 为后缀的： 京东首页也不例外： 使用 JPG 呈现大图，既可以保住图片的质量，又不会带来令人头疼的图片体积，是当下比较推崇的一种方案。 JPG 的缺陷 有损压缩在上文所展示的轮播图上确实很难露出马脚，但当它处理矢量图形和 Logo 等线条感较强、颜色对比强烈的图像时，人为压缩导致的图片模糊会相当明显。 此外，JPEG 图像不支持透明度处理，透明图片需要召唤 PNG 来呈现。 PNG-8 与 PNG-24 关键字：无损压缩、质量高、体积大、支持透明 PNG 的优点 PNG（可移植网络图形格式）是一种无损压缩的高保真的图片格式。8 和 24，这里都是二进制数的位数。按照我们前置知识里提到的对应关系，8 位的 PNG 最多支持 256 种颜色，而 24 位的可以呈现约 1600 万种颜色。 PNG 图片具有比 JPG 更强的色彩表现力，对线条的处理更加细腻，对透明度有良好的支持。它弥补了上文我们提到的 JPG 的局限性，唯一的 BUG 就是体积太大。 PNG-8 与 PNG-24 的选择题 什么时候用 PNG-8，什么时候用 PNG-24，这是一个问题。 理论上来说，当你追求最佳的显示效果、并且不在意文件体积大小时，是推荐使用 PNG-24 的。 但实践当中，为了规避体积的问题，我们一般不用PNG去处理较复杂的图像。当我们遇到适合 PNG 的场景时，也会优先选择更为小巧的 PNG-8。 如何确定一张图片是该用 PNG-8 还是 PNG-24 去呈现呢？好的做法是把图片先按照这两种格式分别输出，看 PNG-8 输出的结果是否会带来肉眼可见的质量损耗，并且确认这种损耗是否在我们（尤其是你的 UI 设计师）可接受的范围内，基于对比的结果去做判断。 应用场景 前面我们提到，复杂的、色彩层次丰富的图片，用 PNG 来处理的话，成本会比较高，我们一般会交给 JPG 去存储。 考虑到 PNG 在处理线条和颜色对比度方面的优势，我们主要用它来呈现小的 Logo、颜色简单且对比强烈的图片或背景等。 此时我们再次把目光转向性能方面堪称业界楷模的淘宝首页，我们会发现它页面上的 Logo，无论大小，还真的都是 PNG 格式： 主 Logo： 较小的 Logo： 颜色简单、对比度较强的透明小图也在 PNG 格式下有着良好的表现： SVG 关键字：文本文件、体积小、不失真、兼容性好 SVG（可缩放矢量图形）是一种基于 XML 语法的图像格式。它和本文提及的其它图片种类有着本质的不同：SVG 对图像的处理不是基于像素点，而是是基于对图像的形状描述。 SVG 的特性 和性能关系最密切的一点就是：SVG 与 PNG 和 JPG 相比，文件体积更小，可压缩性更强。 当然，作为矢量图，它最显著的优势还是在于图片可无限放大而不失真这一点上。这使得 SVG 即使是被放到视网膜屏幕上，也可以一如既往地展现出较好的成像品质——1 张 SVG 足以适配 n 种分辨率。 此外，SVG 是文本文件。我们既可以像写代码一样定义 SVG，把它写在 HTML 里、成为 DOM 的一部分，也可以把对图形的描述写入以 .svg 为后缀的独立文件（SVG 文件在使用上与普通图片文件无异）。这使得 SVG 文件可以被非常多的工具读取和修改，具有较强的灵活性。 SVG 的局限性主要有两个方面，一方面是它的渲染成本比较高，这点对性能来说是很不利的。另一方面，SVG 存在着其它图片格式所没有的学习成本（它是可编程的）。 SVG 的使用方式与应用场景 SVG 是文本文件，我们既可以像写代码一样定义 SVG，把它写在 HTML 里、成为 DOM 的一部分，也可以把对图形的描述写入以 .svg 为后缀的独立文件（SVG 文件在使用上与普通图片文件无异）。 将 SVG 写入 HTML： 将 SVG 写入独立文件后引入 HTML: 在实际开发中，我们更多用到的是后者。很多情况下设计师会给到我们 SVG 文件，就算没有设计师，我们还有非常好用的 在线矢量图形库。对于矢量图，我们无须深究过多，只需要对其核心特性有所掌握、日后在应用时做到有迹可循即可。 Base64 关键字：文本文件、依赖编码、小图标解决方案 Base64 并非一种图片格式，而是一种编码方式。Base64 和雪碧图一样，是作为小图标解决方案而存在的。在了解 Base64 之前，我们先来了解一下雪碧图。 前置知识：最经典的小图标解决方案——雪碧图（CSS Sprites） 雪碧图、CSS 精灵、CSS Sprites、图像精灵，说的都是这个东西——一种将小图标和背景图像合并到一张图片上，然后利用 CSS 的背景定位来显示其中的每一部分的技术。 MDN 对雪碧图的解释已经非常到位： 图像精灵（sprite，意为精灵），被运用于众多使用大量小图标的网页应用之上。它可取图像的一部分来使用，使得使用一个图像文件替代多个小文件成为可能。相较于一个小图标一个图像文件，单独一张图片所需的 HTTP 请求更少，对内存和带宽更加友好。 我们几乎可以在每一个有小图标出现的网站里找到雪碧图的影子（下图截取自京东首页）： 和雪碧图一样，Base64 图片的出现，也是为了减少加载网页图片时对服务器的请求次数，从而提升网页性能。Base64 是作为雪碧图的补充而存在的。 理解 Base64 通过我们上文的演示，大家不难看出，每次加载图片，都是需要单独向服务器请求这个图片对应的资源的——这也就意味着一次 HTTP 请求的开销。 Base64 是一种用于传输 8Bit 字节码的编码方式，通过对图片进行 Base64 编码，我们可以直接将编码结果写入 HTML 或者写入 CSS，从而减少 HTTP 请求的次数。 我们来一起看一个实例，现在我有这么一个小小的放大镜 Logo： 它对应的链接如下： https://user-gold-cdn.xitu.io/2018/9/15/165db7e94699824b?w=22&h=22&f=png&s=3680 按照一贯的思路，我们加载图片需要把图片链接写入 img 标签： 浏览器就会针对我们的图片链接去发起一个资源请求。 但是如果我们对这个图片进行 Base64 编码，我们会得到一个这样的字符串： data:image/png;base64,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 字符串比较长，我们可以直接用这个字符串替换掉上文中的链接地址。你会发现浏览器原来是可以理解这个字符串的，它自动就将这个字符串解码为了一个图片，而不需再去发送 HTTP 请求。 Base64 的应用场景 上面这个实例，其实源自我们 掘金 网站 Header 部分的搜索栏 Logo： 大家不妨打开小册首页，然后打开开发者工具，在源码中搜索“base64”关键字，你会发现 Base64 码出现的地方真的不少。而且它对应的图片往往是非常小的 Logo。 既然 Base64 这么棒，我们何不把大图也换成 Base64 呢？ 这是因为，Base64 编码后，图片大小会膨胀为原文件的 4/3（这是由 Base64 的编码原理决定的）。如果我们把大图也编码到 HTML 或 CSS 文件中，后者的体积会明显增加，即便我们减少了 HTTP 请求，也无法弥补这庞大的体积带来的性能开销，得不偿失。在传输非常小的图片的时候，Base64 带来的文件体积膨胀、以及浏览器解析 Base64 的时间开销，与它节省掉的 HTTP 请求开销相比，可以忽略不计，这时候才能真正体现出它在性能方面的优势。 因此，Base64 并非万全之策，我们往往在一张图片满足以下条件时会对它应用 Base64 编码： 图片的实际尺寸很小（大家可以观察一下掘金页面的 Base64 图，几乎没有超过 2kb 的） 图片无法以雪碧图的形式与其它小图结合（合成雪碧图仍是主要的减少 HTTP 请求的途径，Base64 是雪碧图的补充） 图片的更新频率非常低（不需我们重复编码和修改文件内容，维护成本较低） Base64 编码工具推荐 这里最推荐的是利用 webpack 来进行 Base64 的编码——webpack 的 url-loader 非常聪明，它除了具备基本的 Base64 转码能力，还可以结合文件大小，帮我们判断图片是否有必要进行 Base64 编码。 除此之外，市面上免费的 Base64 编解码工具种类是非常多样化的，有很多网站都提供在线编解码的服务，大家选取自己认为顺手的工具就好。 WebP 关键字：年轻的全能型选手 WebP 是今天在座各类图片格式中最年轻的一位，它于 2010 年被提出， 是 Google 专为 Web 开发的一种旨在加快图片加载速度的图片格式，它支持有损压缩和无损压缩。 WebP 的优点 WebP 像 JPEG 一样对细节丰富的图片信手拈来，像 PNG 一样支持透明，像 GIF 一样可以显示动态图片——它集多种图片文件格式的优点于一身。WebP 的官方介绍对这一点有着更权威的阐述： 与 PNG 相比，WebP 无损图像的尺寸缩小了 26％。在等效的 SSIM 质量指数下，WebP 有损图像比同类 JPEG 图像小 25-34％。 无损 WebP 支持透明度（也称为 alpha 通道），仅需 22％ 的额外字节。对于有损 RGB 压缩可接受的情况，有损 WebP 也支持透明度，与 PNG 相比，通常提供 3 倍的文件大小。 我们开篇提到，图片优化是质量与性能的博弈，从这个角度看，WebP 无疑是真正的赢家。 WebP 的局限性 WebP 纵有千般好，但它毕竟太年轻。我们知道，任何新生事物，都逃不开兼容性的大坑。现在是 2018 年 9 月，WebP 的支持情况是这样的： 坦白地说，虽然没有特别惨（毕竟还有亲爹 Chrome 在撑腰），但也足够让人望而却步了。 此外，WebP 还会增加服务器的负担——和编码 JPG 文件相比，编码同样质量的 WebP 文件会占用更多的计算资源。 WebP 的应用场景 现在限制我们使用 WebP 的最大问题不是“这个图片是否适合用 WebP 呈现”的问题，而是“浏览器是否允许 WebP”的问题，即我们上文谈到的兼容性问题。具体来说，一旦我们选择了 WebP，就要考虑在 Safari 等浏览器下它无法显示的问题，也就是说我们需要准备 PlanB，准备降级方案。 目前真正把 WebP 格式落地到网页中的网站并不是很多，这其中淘宝首页对 WebP 兼容性问题的处理方式就非常有趣。我们可以打开 Chrome 的开发者工具搜索其源码里的 WebP 关键字： 我们会发现检索结果还是挺多的（单就图示的加载结果来看，足足有 200 多条），下面大家注意一下这些 WebP 图片的链接地址（以其中一个为例）： .webp 前面，还跟了一个 .jpg 后缀！ 我们现在先大胆地猜测，这个图片应该至少存在 jpg 和 webp 两种格式，程序会根据浏览器的型号、以及该型号是否支持 WebP 这些信息来决定当前浏览器显示的是 .webp 后缀还是 .jpg 后缀。带着这个预判，我们打开并不支持 WebP 格式的 Safari 来进入同样的页面，再次搜索 WebP 关键字： Safari 提示我们找不到，这也是情理之中。我们定位到刚刚示例的 WebP 图片所在的元素，查看一下它在 Safari 里的图片链接： 我们看到同样的一张图片，在 Safari 中的后缀从 .webp 变成了 .jpg！看来果然如此——站点确实是先进行了兼容性的预判，在浏览器环境支持 WebP 的情况下，优先使用 WebP 格式，否则就把图片降级为 JPG 格式（本质是对图片的链接地址作简单的字符串切割）。 此外，还有另一个维护性更强、更加灵活的方案——把判断工作交给后端，由服务器根据 HTTP 请求头部的 Accept 字段来决定返回什么格式的图片。当 Accept 字段包含 image/webp 时，就返回 WebP 格式的图片，否则返回原图。这种做法的好处是，当浏览器对 WebP 格式图片的兼容支持发生改变时，我们也不用再去更新自己的兼容判定代码，只需要服务端像往常一样对 Accept 字段进行检查即可。 由此也可以看出，我们 WebP 格式的局限性确实比较明显，如果决定使用 WebP，兼容性处理是必不可少的。 小结 不知道大家有没有注意到这一点：在图片这一节，我用到的许多案例图示，都是源于一线的电商网站。 为什么这么做？因为图片是电商平台的重要资源，甚至有人说“做电商就是做图片”。淘宝和京东，都是流量巨大、技术成熟的站点，它们在性能优化方面起步早、成效好，很多方面说是教科书般的案例也不为过。 这也是非常重要的一个学习方法。在小册开篇我提到，性能优化不那么好学，有很大原因是因为这块的知识不成体系、难以切入，同时技术方案又迭代得飞快。当我们不知道怎么切入的时候，或者说当我们面对一个具体的问题无从下手的时候，除了翻阅手中的书本（很可能是已经过时的）和网络上收藏的文章（也许没那么权威），现在是不是又多了“打开那些优秀的网站看一看”这条路可以走了呢？ 好了，至此，我们终于结束了图片优化的征程。下面，我们以存储篇为过渡，进入 JS 和 CSS 的世界！ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/04.存储篇1：浏览器缓存机制介绍与缓存策略剖析.html":{"url":"前端性能优化/04.存储篇1：浏览器缓存机制介绍与缓存策略剖析.html","title":"04.存储篇1：浏览器缓存机制介绍与缓存策略剖析","keywords":"","body":"浏览器缓存机制介绍与缓存策略剖析 缓存可以减少网络 IO 消耗，提高访问速度。浏览器缓存是一种操作简单、效果显著的前端性能优化手段。对于这个操作的必要性，Chrome 官方给出的解释似乎更有说服力一些： 通过网络获取内容既速度缓慢又开销巨大。较大的响应需要在客户端与服务器之间进行多次往返通信，这会延迟浏览器获得和处理内容的时间，还会增加访问者的流量费用。因此，缓存并重复利用之前获取的资源的能力成为性能优化的一个关键方面。 很多时候，大家倾向于将浏览器缓存简单地理解为“HTTP 缓存”。但事实上，浏览器缓存机制有四个方面，它们按照获取资源时请求的优先级依次排列如下： Memory Cache Service Worker Cache HTTP Cache Push Cache 大家对 HTTP Cache（即 Cache-Control、expires 等字段控制的缓存）应该比较熟悉，如果对其它几种缓存可能还没什么概念，我们可以先来看一张线上网站的 Network 面板截图： 我们给 size 这一栏一个特写： 大家注意一下非数字——即形如“（from xxx）”这样的描述——对应的资源，这些资源就是我们通过缓存获取到的。其中，“from memory cache”对标到 Memory Cache 类型，“from ServiceWorker”对标到 Service Worker Cache 类型。至于 Push Cache，这个比较特殊，是 HTTP2 的新特性。 本节将会针对这四个方面各个击破。考虑到 HTTP 缓存是最主要、最具有代表性的缓存策略，也是每一位前端工程师都应该深刻理解掌握的性能优化知识点，我们下面优先针对 HTTP 缓存机制进行剖析。 HTTP 缓存机制探秘 HTTP 缓存是我们日常开发中最为熟悉的一种缓存机制。它又分为强缓存和协商缓存。优先级较高的是强缓存，在命中强缓存失败的情况下，才会走协商缓存。 强缓存的特征 强缓存是利用 http 头中的 Expires 和 Cache-Control 两个字段来控制的。强缓存中，当请求再次发出时，浏览器会根据其中的 expires 和 cache-control 判断目标资源是否“命中”强缓存，若命中则直接从缓存中获取资源，不会再与服务端发生通信。 命中强缓存的情况下，返回的 HTTP 状态码为 200 （如下图）。 强缓存的实现：从 expires 到 cache-control 实现强缓存，过去我们一直用 expires。当服务器返回响应时，在 Response Headers 中将过期时间写入 expires 字段。像这样： 我们给 expires 一个特写： expires: Wed, 11 Sep 2019 16:12:18 GMT 可以看到，expires 是一个时间戳，接下来如果我们试图再次向服务器请求资源，浏览器就会先对比本地时间和 expires 的时间戳，如果本地时间小于 expires 设定的过期时间，那么就直接去缓存中取这个资源。 从这样的描述中大家也不难猜测，expires 是有问题的，它最大的问题在于对“本地时间”的依赖。如果服务端和客户端的时间设置可能不同，或者我直接手动去把客户端的时间改掉，那么 expires 将无法达到我们的预期。 考虑到 expires 的局限性，HTTP1.1 新增了 Cache-Control 字段来完成 expires 的任务。expires 能做的事情，Cache-Control 都能做；expires 完成不了的事情，Cache-Control 也能做。因此，Cache-Control 可以视作是 expires 的完全替代方案。在当下的前端实践里，我们继续使用 expires 的唯一目的就是向下兼容。 现在我们给 Cache-Control 字段一个特写： cache-control: max-age=31536000 如大家所见，在 Cache-Control 中，我们通过 max-age 来控制资源的有效期。max-age 不是一个时间戳，而是一个时间长度。在本例中，max-age 是 31536000 秒，它意味着该资源在 31536000 秒以内都是有效的，完美地规避了时间戳带来的潜在问题。 Cache-Control 相对于 expires 更加准确，它的优先级也更高。当 Cache-Control 与 expires 同时出现时，我们以 Cache-Control 为准。 Cache-Control 应用分析 Cache-Control 的神通，可不止于这一个小小的 max-age。如下的用法也非常常见： cache-control: max-age=3600, s-maxage=31536000 s-maxage 优先级高于 max-age，两者同时出现时，优先考虑 s-maxage。如果 s-maxage 未过期，则向代理服务器请求其缓存内容。 这个 s-maxage 不像 max-age 一样为大家所熟知。的确，在项目不是特别大的场景下，max-age 足够用了。但在依赖各种代理的大型架构中，我们不得不考虑代理服务器的缓存问题。s-maxage 就是用于表示 cache 服务器上（比如 cache CDN）的缓存的有效时间的，并只对 public 缓存有效。 (10.24晚更新。感谢评论区@敖天羽的补充，此处应注意这样一个细节：s-maxage仅在代理服务器中生效，客户端中我们只考虑max-age。) 那么什么是 public 缓存呢？说到这里，Cache-Control 中有一些适合放在一起理解的知识点，我们集中梳理一下： public 与 private public 与 private 是针对资源是否能够被代理服务缓存而存在的一组对立概念。 如果我们为资源设置了 public，那么它既可以被浏览器缓存，也可以被代理服务器缓存；如果我们设置了 private，则该资源只能被浏览器缓存。private 为默认值。但多数情况下，public 并不需要我们手动设置，比如有很多线上网站的 cache-control 是这样的： 设置了 s-maxage，没设置 public，那么 CDN 还可以缓存这个资源吗？答案是肯定的。因为明确的缓存信息（例如“max-age”）已表示响应是可以缓存的。 no-store与no-cache no-cache 绕开了浏览器：我们为资源设置了 no-cache 后，每一次发起请求都不会再去询问浏览器的缓存情况，而是直接向服务端去确认该资源是否过期（即走我们下文即将讲解的协商缓存的路线）。 no-store 比较绝情，顾名思义就是不使用任何缓存策略。在 no-cache 的基础上，它连服务端的缓存确认也绕开了，只允许你直接向服务端发送请求、并下载完整的响应。 协商缓存：浏览器与服务器合作之下的缓存策略 协商缓存依赖于服务端与浏览器之间的通信。 协商缓存机制下，浏览器需要向服务器去询问缓存的相关信息，进而判断是重新发起请求、下载完整的响应，还是从本地获取缓存的资源。 如果服务端提示缓存资源未改动（Not Modified），资源会被重定向到浏览器缓存，这种情况下网络请求对应的状态码是 304（如下图）。 协商缓存的实现：从 Last-Modified 到 Etag Last-Modified 是一个时间戳，如果我们启用了协商缓存，它会在首次请求时随着 Response Headers 返回： Last-Modified: Fri, 27 Oct 2017 06:35:57 GMT 随后我们每次请求时，会带上一个叫 If-Modified-Since 的时间戳字段，它的值正是上一次 response 返回给它的 last-modified 值： If-Modified-Since: Fri, 27 Oct 2017 06:35:57 GMT 服务器接收到这个时间戳后，会比对该时间戳和资源在服务器上的最后修改时间是否一致，从而判断资源是否发生了变化。如果发生了变化，就会返回一个完整的响应内容，并在 Response Headers 中添加新的 Last-Modified 值；否则，返回如上图的 304 响应，Response Headers 不会再添加 Last-Modified 字段。 使用 Last-Modified 存在一些弊端，这其中最常见的就是这样两个场景： 我们编辑了文件，但文件的内容没有改变。服务端并不清楚我们是否真正改变了文件，它仍然通过最后编辑时间进行判断。因此这个资源在再次被请求时，会被当做新资源，进而引发一次完整的响应——不该重新请求的时候，也会重新请求。 当我们修改文件的速度过快时（比如花了 100ms 完成了改动），由于 If-Modified-Since 只能检查到以秒为最小计量单位的时间差，所以它是感知不到这个改动的——该重新请求的时候，反而没有重新请求了。 这两个场景其实指向了同一个 bug——服务器并没有正确感知文件的变化。为了解决这样的问题，Etag 作为 Last-Modified 的补充出现了。 Etag 是由服务器为每个资源生成的唯一的标识字符串，这个标识字符串是基于文件内容编码的，只要文件内容不同，它们对应的 Etag 就是不同的，反之亦然。因此 Etag 能够精准地感知文件的变化。 Etag 和 Last-Modified 类似，当首次请求时，我们会在响应头里获取到一个最初的标识符字符串，举个🌰，它可以是这样的： ETag: W/\"2a3b-1602480f459\" 那么下一次请求时，请求头里就会带上一个值相同的、名为 if-None-Match 的字符串供服务端比对了： If-None-Match: W/\"2a3b-1602480f459\" Etag 的生成过程需要服务器额外付出开销，会影响服务端的性能，这是它的弊端。因此启用 Etag 需要我们审时度势。正如我们刚刚所提到的——Etag 并不能替代 Last-Modified，它只能作为 Last-Modified 的补充和强化存在。 Etag 在感知文件变化上比 Last-Modified 更加准确，优先级也更高。当 Etag 和 Last-Modified 同时存在时，以 Etag 为准。 HTTP 缓存决策指南 行文至此，当代 HTTP 缓存技术用到的知识点，我们已经从头到尾挖掘了一遍了。那么在面对一个具体的缓存需求时，我们到底该怎么决策呢？ 走到决策建议这一步，我本来想给大家重新画一个流程图。但是画来画去终究不如 Chrome 官方给出的这张清晰、权威： 我们现在一起解读一下这张流程图： 当我们的资源内容不可复用时，直接为 Cache-Control 设置 no-store，拒绝一切形式的缓存；否则考虑是否每次都需要向服务器进行缓存有效确认，如果需要，那么设 Cache-Control 的值为 no-cache；否则考虑该资源是否可以被代理服务器缓存，根据其结果决定是设置为 private 还是 public；然后考虑该资源的过期时间，设置对应的 max-age 和 s-maxage 值；最后，配置协商缓存需要用到的 Etag、Last-Modified 等参数。 我个人非常推崇这张流程图给出的决策建议，也强烈推荐大家在理解以上知识点的基础上，将这张图保存下来、在日常开发中用用看，它的可行度非常高。 OK，走到这里，本节最大的一座山已经被大家翻过去了。接下来的内容会相对比较轻松，大家放松心情，我们继续前行！ MemoryCache MemoryCache，是指存在内存中的缓存。从优先级上来说，它是浏览器最先尝试去命中的一种缓存。从效率上来说，它是响应速度最快的一种缓存。 内存缓存是快的，也是“短命”的。它和渲染进程“生死相依”，当进程结束后，也就是 tab 关闭以后，内存里的数据也将不复存在。 那么哪些文件会被放入内存呢？ 事实上，这个划分规则，一直以来是没有定论的。不过想想也可以理解，内存是有限的，很多时候需要先考虑即时呈现的内存余量，再根据具体的情况决定分配给内存和磁盘的资源量的比重——资源存放的位置具有一定的随机性。 虽然划分规则没有定论，但根据日常开发中观察的结果，包括我们开篇给大家展示的 Network 截图，我们至少可以总结出这样的规律：资源存不存内存，浏览器秉承的是“节约原则”。我们发现，Base64 格式的图片，几乎永远可以被塞进 memory cache，这可以视作浏览器为节省渲染开销的“自保行为”；此外，体积不大的 JS、CSS 文件，也有较大地被写入内存的几率——相比之下，较大的 JS、CSS 文件就没有这个待遇了，内存资源是有限的，它们往往被直接甩进磁盘。 Service Worker Cache Service Worker 是一种独立于主线程之外的 Javascript 线程。它脱离于浏览器窗体，因此无法直接访问 DOM。这样独立的个性使得 Service Worker 的“个人行为”无法干扰页面的性能，这个“幕后工作者”可以帮我们实现离线缓存、消息推送和网络代理等功能。我们借助 Service worker 实现的离线缓存就称为 Service Worker Cache。 Service Worker 的生命周期包括 install、active、working 三个阶段。一旦 Service Worker 被 install，它将始终存在，只会在 active 与 working 之间切换，除非我们主动终止它。这是它可以用来实现离线存储的重要先决条件。 下面我们就通过实战的方式，一起见识一下 Service Worker 如何为我们实现离线缓存（注意看注释）： 我们首先在入口文件中插入这样一段 JS 代码，用以判断和引入 Service Worker： window.navigator.serviceWorker.register('/test.js').then( function () { console.log('注册成功') }).catch(err => { console.error(\"注册失败\") }) 在 test.js 中，我们进行缓存的处理。假设我们需要缓存的文件分别是 test.html,test.css 和 test.js： // Service Worker会监听 install事件，我们在其对应的回调里可以实现初始化的逻辑 self.addEventListener('install', event => { event.waitUntil( // 考虑到缓存也需要更新，open内传入的参数为缓存的版本号 caches.open('test-v1').then(cache => { return cache.addAll([ // 此处传入指定的需缓存的文件名 '/test.html', '/test.css', '/test.js' ]) }) ) }) // Service Worker会监听所有的网络请求，网络请求的产生触发的是fetch事件，我们可以在其对应的监听函数中实现对请求的拦截，进而判断是否有对应到该请求的缓存，实现从Service Worker中取到缓存的目的 self.addEventListener('fetch', event => { event.respondWith( // 尝试匹配该请求对应的缓存值 caches.match(event.request).then(res => { // 如果匹配到了，调用Server Worker缓存 if (res) { return res; } // 如果没匹配到，向服务端发起这个资源请求 return fetch(event.request).then(response => { if (!response || response.status !== 200) { return response; } // 请求成功的话，将请求缓存起来。 caches.open('test-v1').then(function(cache) { cache.put(event.request, response); }); return response.clone(); }); }) ); }); PS：大家注意 Server Worker 对协议是有要求的，必须以 https 协议为前提。 Push Cache 预告：本小节定位为基础科普向，对 Push Cache 有深入挖掘兴趣的同学，强烈推荐拓展阅读 Chrome 工程师 Jake Archibald 的这篇 HTTP/2 push is tougher than I thought。 Push Cache 是指 HTTP2 在 server push 阶段存在的缓存。这块的知识比较新，应用也还处于萌芽阶段，我找了好几个网站也没找到一个合适的案例来给大家做具体的介绍。但应用范围有限不代表不重要——HTTP2 是趋势、是未来。在它还未被推而广之的此时此刻，我仍希望大家能对 Push Cache 的关键特性有所了解： Push Cache 是缓存的最后一道防线。浏览器只有在 Memory Cache、HTTP Cache 和 Service Worker Cache 均未命中的情况下才会去询问 Push Cache。 Push Cache 是一种存在于会话阶段的缓存，当 session 终止时，缓存也随之释放。 不同的页面只要共享了同一个 HTTP2 连接，那么它们就可以共享同一个 Push Cache。 更多的特性和应用，期待大家可以在日后的开发过程中去挖掘和实践。 小结 小建议！很多同学在学习缓存这块知识的时候可能多少会有这样的感觉：对浏览器缓存，只能描述个大致，却说不上深层原理；好不容易记住了每个字段怎么用，过几天又给忘了。这是因为缓存部分的知识，具有“细碎、迭代快”的特点。对于这样的知识，我们应该尝试先划分出层次和重点，归纳出完整的体系，然后针对每个知识点去各个击破。 终于结束了对缓存世界的探索，不知道大家有没有一种意犹未尽的感觉。开篇我们谈过，缓存非常重要，它几乎是我们性能优化的首选方案。 但页面的数据存储方案除了缓存，还有本地存储。在下一节中，我们就将围绕本地存储展开探索。 "},"前端性能优化/05.存储篇2：本地存储——从Cookie到WebStorage、IndexedDB.html":{"url":"前端性能优化/05.存储篇2：本地存储——从Cookie到WebStorage、IndexedDB.html","title":"05.存储篇2：本地存储——从Cookie到WebStorage、IndexedDB","keywords":"","body":"本地存储——从 Cookie 到 Web Storage、IndexedDB 随着移动网络的发展与演化，我们手机上现在除了有原生 App，还能跑“WebApp”——它即开即用，用完即走。一个优秀的 WebApp 甚至可以拥有和原生 App 媲美的功能和体验。 我认为，WebApp 就是我们前端性能优化的产物，是我们前端工程师对体验不懈追求的结果，是 Web 网页在性能上向 Native 应用的一次“宣战”。 WebApp 优异的性能表现，要归功于浏览器存储技术的广泛应用——这其中除了我们上节提到的缓存，本地存储技术也功不可没。 故事的开始：从 Cookie 说起 Cookie 的本职工作并非本地存储，而是“维持状态”。 在 Web 开发的早期，人们亟需解决的一个问题就是状态管理的问题：HTTP 协议是一个无状态协议，服务器接收客户端的请求，返回一个响应，故事到此就结束了，服务器并没有记录下关于客户端的任何信息。那么下次请求的时候，如何让服务器知道“我是我”呢？ 在这样的背景下，Cookie 应运而生。 Cookie 说白了就是一个存储在浏览器里的一个小小的文本文件，它附着在 HTTP 请求上，在浏览器和服务器之间“飞来飞去”。它可以携带用户信息，当服务器检查 Cookie 的时候，便可以获取到客户端的状态。 关于 Cookie 的详细内容，我们可以在 Chrome 的 Application 面板中查看到： 如大家所见，Cookie 以键值对的形式存在。 Cookie的性能劣势 Cookie 不够大 大家知道，Cookie 是有体积上限的，它最大只能有 4KB。当 Cookie 超过 4KB 时，它将面临被裁切的命运。这样看来，Cookie 只能用来存取少量的信息。 过量的 Cookie 会带来巨大的性能浪费 Cookie 是紧跟域名的。我们通过响应头里的 Set-Cookie 指定要存储的 Cookie 值。默认情况下，domain 被设置为设置 Cookie 页面的主机名，我们也可以手动设置 domain 的值： Set-Cookie: name=xiuyan; domain=xiuyan.me 同一个域名下的所有请求，都会携带 Cookie。大家试想，如果我们此刻仅仅是请求一张图片或者一个 CSS 文件，我们也要携带一个 Cookie 跑来跑去（关键是 Cookie 里存储的信息我现在并不需要），这是一件多么劳民伤财的事情。Cookie 虽然小，请求却可以有很多，随着请求的叠加，这样的不必要的 Cookie 带来的开销将是无法想象的。 随着前端应用复杂度的提高，Cookie 也渐渐演化为了一个“存储多面手”——它不仅仅被用于维持状态，还被塞入了一些乱七八糟的其它信息，被迫承担起了本地存储的“重任”。在没有更好的本地存储解决方案的年代里，Cookie 小小的身体里承载了 4KB 内存所不能承受的压力。 为了弥补 Cookie 的局限性，让“专业的人做专业的事情”，Web Storage 出现了。 向前一步：Web Storage Web Storage 是 HTML5 专门为浏览器存储而提供的数据存储机制。它又分为 Local Storage 与 Session Storage。这两组概念非常相近，我们不妨先理解它们之间的区别，再对它们的共性进行研究。 Local Storage 与 Session Storage 的区别 两者的区别在于生命周期与作用域的不同。 生命周期：Local Storage 是持久化的本地存储，存储在其中的数据是永远不会过期的，使其消失的唯一办法是手动删除；而 Session Storage 是临时性的本地存储，它是会话级别的存储，当会话结束（页面被关闭）时，存储内容也随之被释放。 作用域：Local Storage、Session Storage 和 Cookie 都遵循同源策略。但 Session Storage 特别的一点在于，即便是相同域名下的两个页面，只要它们不在同一个浏览器窗口中打开，那么它们的 Session Storage 内容便无法共享。 Web Storage 的特性 存储容量大： Web Storage 根据浏览器的不同，存储容量可以达到 5-10M 之间。 仅位于浏览器端，不与服务端发生通信。 Web Storage 核心 API 使用示例 Web Storage 保存的数据内容和 Cookie 一样，是文本内容，以键值对的形式存在。Local Storage 与 Session Storage 在 API 方面无异，这里我们以 localStorage 为例： 存储数据：setItem() localStorage.setItem('user_name', 'xiuyan') 读取数据： getItem() localStorage.getItem('user_name') 删除某一键名对应的数据： removeItem() localStorage.removeItem('user_name') 清空数据记录：clear() localStorage.clear() 应用场景 Local Storage Local Storage 在存储方面没有什么特别的限制，理论上 Cookie 无法胜任的、可以用简单的键值对来存取的数据存储任务，都可以交给 Local Storage 来做。 这里给大家举个例子，考虑到 Local Storage 的特点之一是持久，有时我们更倾向于用它来存储一些内容稳定的资源。比如图片内容丰富的电商网站会用它来存储 Base64 格式的图片字符串： 有的网站还会用它存储一些不经常更新的 CSS、JS 等静态资源。 Session Storage Session Storage 更适合用来存储生命周期和它同步的会话级别的信息。这些信息只适用于当前会话，当你开启新的会话时，它也需要相应的更新或释放。比如微博的 Session Storage 就主要是存储你本次会话的浏览足迹： lasturl 对应的就是你上一次访问的 URL 地址，这个地址是即时的。当你切换 URL 时，它随之更新，当你关闭页面时，留着它也确实没有什么意义了，干脆释放吧。这样的数据用 Session Storage 来处理再合适不过。 这样看来，Web Storage 确实也够强大了。那么 Web Storage 是否能 hold 住所有的存储场景呢？ 答案是否定的。大家也看到了，Web Storage 是一个从定义到使用都非常简单的东西。它使用键值对的形式进行存储，这种模式有点类似于对象，却甚至连对象都不是——它只能存储字符串，要想得到对象，我们还需要先对字符串进行一轮解析。 说到底，Web Storage 是对 Cookie 的拓展，它只能用于存储少量的简单数据。当遇到大规模的、结构复杂的数据时，Web Storage 也爱莫能助了。这时候我们就要清楚我们的终极大 boss——IndexedDB！ 终极形态：IndexedDB IndexedDB 是一个运行在浏览器上的非关系型数据库。既然是数据库了，那就不是 5M、10M 这样小打小闹级别了。理论上来说，IndexedDB 是没有存储上限的（一般来说不会小于 250M）。它不仅可以存储字符串，还可以存储二进制数据。 IndexedDB 从推出之日起，其优质教程就层出不绝，我们今天不再着重讲解它的详细操作。接下来，我们遵循 MDN 推荐的操作模式，通过一个基本的 IndexedDB 使用流程，旨在对 IndexedDB 形成一个感性的认知： 打开/创建一个 IndexedDB 数据库（当该数据库不存在时，open 方法会直接创建一个名为 xiaoceDB 新数据库）。 // 后面的回调中，我们可以通过event.target.result拿到数据库实例 let db // 参数1位数据库名，参数2为版本号 const request = window.indexedDB.open(\"xiaoceDB\", 1) // 使用IndexedDB失败时的监听函数 request.onerror = function(event) { console.log('无法使用IndexedDB') } // 成功 request.onsuccess = function(event){ // 此处就可以获取到db实例 db = event.target.result console.log(\"你打开了IndexedDB\") } 创建一个 object store（object store 对标到数据库中的“表”单位）。 // onupgradeneeded事件会在初始化数据库/版本发生更新时被调用，我们在它的监听函数中创建object store request.onupgradeneeded = function(event){ let objectStore // 如果同名表未被创建过，则新建test表 if (!db.objectStoreNames.contains('test')) { objectStore = db.createObjectStore('test', { keyPath: 'id' }) } } 构建一个事务来执行一些数据库操作，像增加或提取数据等。 // 创建事务，指定表格名称和读写权限 const transaction = db.transaction([\"test\"],\"readwrite\") // 拿到Object Store对象 const objectStore = transaction.objectStore(\"test\") // 向表格写入数据 objectStore.add({id: 1, name: 'xiuyan'}) 通过监听正确类型的事件以等待操作完成。 // 操作成功时的监听函数 transaction.oncomplete = function(event) { console.log(\"操作成功\") } // 操作失败时的监听函数 transaction.onerror = function(event) { console.log(\"这里有一个Error\") } IndexedDB 的应用场景 通过上面的示例大家可以看出，在 IndexedDB 中，我们可以创建多个数据库，一个数据库中创建多张表，一张表中存储多条数据——这足以 hold 住复杂的结构性数据。IndexedDB 可以看做是 LocalStorage 的一个升级，当数据的复杂度和规模上升到了 LocalStorage 无法解决的程度，我们毫无疑问可以请出 IndexedDB 来帮忙。 小结 浏览器缓存/存储技术的出现和发展，为我们的前端应用带来了无限的转机。近年来基于缓存/存储技术的第三方库层出不绝，此外还衍生出了 PWA 这样优秀的 Web 应用模型。可以说，现代前端应用，尤其是移动端应用，之所以可以发展到在体验上叫板 Native 的地步，主要就是仰仗缓存/存储立下的汗马功劳。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/06.彩蛋篇：CDN的缓存与回源机制解析.html":{"url":"前端性能优化/06.彩蛋篇：CDN的缓存与回源机制解析.html","title":"06.彩蛋篇：CDN的缓存与回源机制解析","keywords":"","body":"CDN 的缓存与回源机制解析 写在小册的半山腰 不知不觉，小册内容已经过了小半了。 回顾一下走过的路：在对知识体系进行一番梳理后，我们操起 webpack 开始优化文件（顺便还学了点 Gzip），随后又马不停蹄进入图片的小天地，最后把缓存和本地存储的味道逐一品尝，终于得以窥见网络层面核心优化技术的全貌。 古人云：学而不思则罔。 站在性能优化的半山腰，我希望大家可以缓一缓，停下来思考一个问题：我得到了什么？ 作为作者，我在自己写的每一行字背后都费了思量。在过去的每个章节里我都预先为知识点做了权重划分，力求“详略得当”，而非盲目地求大求全。孰详孰略，只能根据知识点本身的重要性来划分，但读者的知识结构是多样的。“如何使阅读效益最大化”的金钥匙不在我手中，而是在各位自己手中。 本小册中我有所提及的每一个知识点，都有大公司在实践。即便是略写的内容，大家也值得进一步去推敲。可以尝试深挖这本小册的可能性，把它用起来，用到自己的工作中去，去看看它能否给你的业务带来提升，看看是否还有更精进的方案。 我是一个“啰嗦”的人。尤其是意识到这本书可能会成为一些同学的性能优化启蒙读物时，我更加认为有必要在行文小半时再啰嗦这么一遍：如果读到这里，脑海中无法复现出网络层面的知识体系，无法在回忆每个技术点时记起它的场景和特性，我建议不要急于往下走，而是回过头去再看看学过的这部分的内容——走马观花不是学习，主动理解+动手实践才是。 彩蛋：CDN的缓存与回源机制解析 CDN （Content Delivery Network，即内容分发网络）指的是一组分布在各个地区的服务器。这些服务器存储着数据的副本，因此服务器可以根据哪些服务器与用户距离最近，来满足数据的请求。 CDN 提供快速服务，较少受高流量影响。 为什么要用 CDN 浏览器存储的相关知识此刻离我们还不太远，大家趁热回忆一下：缓存、本地存储带来的性能提升，是不是只能在“获取到资源并把它们存起来”这件事情发生之后？也就是说，首次请求资源的时候，这些招数都是救不了我们的。要提升首次请求的响应能力，除了我们 2、3、4 节提到的方案之外，我们还需要借助 CDN 的能力。 CDN 如何工作 借中国地图一角来给大家举一个简单的🌰： 假设我的根服务器在杭州，同时在图示的五个城市里都有自己可用的机房。 此时有一位北京的用户向我请求资源。在网络带宽小、用户访问量大的情况下，杭州的这一台服务器或许不那么给力，不能给用户非常快的响应速度。于是我灵机一动，把这批资源 copy 了一批放在北京的机房里。当用户请求资源时，就近请求北京的服务器，北京这台服务器低头一看，这个资源我存了，离得这么近，响应速度肯定噌噌的！那如果北京这台服务器没有 copy 这批资源呢？它会再向杭州的根服务器去要这个资源。在这个过程中，北京这台服务器就扮演着 CDN 的角色。 CDN的核心功能特写 CDN 的核心点有两个，一个是缓存，一个是回源。 这两个概念都非常好理解。对标到上面描述的过程，“缓存”就是说我们把资源 copy 一份到 CDN 服务器上这个过程，“回源”就是说 CDN 发现自己没有这个资源（一般是缓存的数据过期了），转头向根服务器（或者它的上层服务器）去要这个资源的过程。 CDN 与前端性能优化 一个彩蛋的自我修养——CDN 往往是被前端认为前端不需要了解的东西。 具体来说，我身边许多同学对其的了解止步于：部署界面上有一个“部署到CDN”按钮，我去点一下，资源就在 CDN 上啦！ “眼下业务开发用不到的可以暂缓了解”，这是没毛病的。但正如我小册开篇所说的，前端工程师首先是软件工程师。对整个技术架构的理解，将会反哺我们对某一具体环节的理解；知识点的适当拓展，也会对大家技术高度和技术广度的提升大有裨益。 那么，我们了解一下 CDN 是怎么帮助前端的。 CDN 往往被用来存放静态资源。上文中我们举例所提到的“根服务器”本质上是业务服务器，它的核心任务在于生成动态页面或返回非纯静态页面，这两种过程都是需要计算的。业务服务器仿佛一个车间，车间里运转的机器轰鸣着为我们产出所需的资源；相比之下，CDN 服务器则像一个仓库，它只充当资源的“栖息地”和“搬运工”。 所谓“静态资源”，就是像 JS、CSS、图片等不需要业务服务器进行计算即得的资源。而“动态资源”，顾名思义是需要后端实时动态生成的资源，较为常见的就是 JSP、ASP 或者依赖服务端渲染得到的 HTML 页面。 什么是“非纯静态资源”呢？它是指需要服务器在页面之外作额外计算的 HTML 页面。具体来说，当我打开某一网站之前，该网站需要通过权限认证等一系列手段确认我的身份、进而决定是否要把 HTML 页面呈现给我。这种情况下 HTML 确实是静态的，但它和业务服务器的操作耦合，我们把它丢到CDN 上显然是不合适的。 CDN 的实际应用 静态资源本身具有访问频率高、承接流量大的特点，因此静态资源加载速度始终是前端性能的一个非常关键的指标。CDN 是静态资源提速的重要手段，在许多一线的互联网公司，“静态资源走 CDN”并不是一个建议，而是一个规定。 比如以淘宝为代表的阿里系产品，就遵循着这个“规定”。打开淘宝首页，我们可以在 Network 面板中看到，“非纯静态”的 HTML 页面，是向业务服务器请求来的： 我们点击 preview，可以看到业务服务器确实是返回给了我们一个尚未被静态资源加持过的简单 HTML 页面，所有的图片内容都是先以一个 div 占位： 相应地，我们随便点开一个静态资源，可以看到它都是从 CDN 服务器上请求来的。 比如说图片： 再比如 JS、CSS 文件： CDN 优化细节 如何让 CDN 的效用最大化？这又是需要前后端程序员一起思考的庞大命题。它涉及到 CDN 服务器本身的性能优化、CDN 节点的地址选取等。但我们今天不写高深的论文，只谈离前端最近的这部分细节：CDN 的域名选取。 大家先回头看一下我刚刚选取的淘宝首页的例子，我们注意到业务服务器的域名是这个： www.taobao.com 而 CDN 服务器的域名是这个： g.alicdn.com 没错，我们不一样！ 再看另一方面，我们讲到 Cookie 的时候，为了凸显 Local Storage 的优越性，曾经提到过： Cookie 是紧跟域名的。同一个域名下的所有请求，都会携带 Cookie。大家试想，如果我们此刻仅仅是请求一张图片或者一个 CSS 文件，我们也要携带一个 Cookie 跑来跑去（关键是 Cookie 里存储的信息我现在并不需要），这是一件多么劳民伤财的事情。Cookie 虽然小，请求却可以有很多，随着请求的叠加，这样的不必要的 Cookie 带来的开销将是无法想象的…… 同一个域名下的请求会不分青红皂白地携带 Cookie，而静态资源往往并不需要 Cookie 携带什么认证信息。把静态资源和主页面置于不同的域名下，完美地避免了不必要的 Cookie 的出现！ 看起来是一个不起眼的小细节，但带来的效用却是惊人的。以电商网站静态资源的流量之庞大，如果没把这个多余的 Cookie 拿下来，不仅用户体验会大打折扣，每年因性能浪费带来的经济开销也将是一个非常恐怖的数字。 如此看来，性能优化还真是要步步为营！ 小结 结束了对 CDN 的剖析，我们网络层面的优化之旅也终于告一段落了。接下来等待大家的就是另一个庞大的知识板块——渲染层面的挑战。 与其说是“渲染层面的优化”，不如说是“浏览器端的优化”。这个板块旨在要大家对浏览器及其相关运行机制“知根知底”，进而通过具体的代码片段学习代码层面的应用手段。这部分是实打实的“硬骨头”，需要大家花些精力。 过去的几个小节里，我们考虑了服务端，考虑了网络，考虑了协议。那么接下来，我们就以“服务端渲染”为引子，承上启下，切入浏览器渲染的世界。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/07.渲染篇1：服务端渲染的探索与实践.html":{"url":"前端性能优化/07.渲染篇1：服务端渲染的探索与实践.html","title":"07.渲染篇1：服务端渲染的探索与实践","keywords":"","body":"服务端渲染的探索与实践 服务端渲染（SSR）近两年炒得很火热，相信各位同学对这个名词多少有所耳闻。本节我们将围绕“是什么”（服务端渲染的运行机制）、“为什么”（服务端渲染解决了什么性能问题 ）、“怎么做”（服务端渲染的应用实例与使用场景）这三个点，对服务端渲染进行探索。 服务端渲染是一个相对的概念，它的对立面是“客户端渲染”。在运行机制解析这部分，我们会借力客户端渲染的概念，来帮大家理解服务端渲染的工作方式。基于对工作方式的了解，再去深挖它的原理与优势。 任何知识点都不是“一座孤岛”，服务端渲染的实践往往与当下流行的前端技术（譬如 Vue，React，Redux 等）紧密结合。本节下半场将以 React 和 Vue 下的服务端渲染实现为例，为大家呈现一个完整的 SSR 实现过程。 服务端渲染的运行机制 相对于服务端渲染，同学们普遍对客户端渲染接受度更高一些，所以我们先从大家喜闻乐见的客户端渲染说起。 客户端渲染 客户端渲染模式下，服务端会把渲染需要的静态文件发送给客户端，客户端加载过来之后，自己在浏览器里跑一遍 JS，根据 JS 的运行结果，生成相应的 DOM。这种特性使得客户端渲染的源代码总是特别简洁，往往是这个德行： 我是客户端渲染的页面 根节点下到底是什么内容呢？你不知道，我不知道，只有浏览器把 index.js 跑过一遍后才知道，这就是典型的客户端渲染。 页面上呈现的内容，你在 html 源文件里里找不到——这正是它的特点。 服务端渲染 服务端渲染的模式下，当用户第一次请求页面时，由服务器把需要的组件或页面渲染成 HTML 字符串，然后把它返回给客户端。客户端拿到手的，是可以直接渲染然后呈现给用户的 HTML 内容，不需要为了生成 DOM 内容自己再去跑一遍 JS 代码。 使用服务端渲染的网站，可以说是“所见即所得”，页面上呈现的内容，我们在 html 源文件里也能找到。 比如知乎就是典型的服务端渲染案例： zhihu.com 返回的 HTML 文件已经是可以直接进行渲染的内容了。 服务端渲染解决了什么性能问题 事实上，很多网站是出于效益的考虑才启用服务端渲染，性能倒是在其次。 假设 A 网站页面中有一个关键字叫“前端性能优化”，这个关键字是 JS 代码跑过一遍后添加到 HTML 页面中的。那么客户端渲染模式下，我们在搜索引擎搜索这个关键字，是找不到 A 网站的——搜索引擎只会查找现成的内容，不会帮你跑 JS 代码。A 网站的运营方见此情形，感到很头大：搜索引擎搜不出来，用户找不到我们，谁还会用我的网站呢？为了把“现成的内容”拿给搜索引擎看，A 网站不得不启用服务端渲染。 但性能在其次，不代表性能不重要。服务端渲染解决了一个非常关键的性能问题——首屏加载速度过慢。在客户端渲染模式下，我们除了加载 HTML，还要等渲染所需的这部分 JS 加载完，之后还得把这部分 JS 在浏览器上再跑一遍。这一切都是发生在用户点击了我们的链接之后的事情，在这个过程结束之前，用户始终见不到我们网页的庐山真面目，也就是说用户一直在等！相比之下，服务端渲染模式下，服务器给到客户端的已经是一个直接可以拿来呈现给用户的网页，中间环节早在服务端就帮我们做掉了，用户岂不“美滋滋”？ 服务端渲染的应用实例 下面我们先来看一下在一个 React 项目里，服务端渲染是怎么实现的。本例中，我们使用 Express 搭建后端服务。 项目中有一个叫做 VDom 的 React 组件，它的内容如下。 VDom.js: import React from 'react' const VDom = () => { return 我是一个被渲染为真实DOM的虚拟DOM } export default VDom 在服务端的入口文件中，我引入这个组件，对它进行渲染： import express from 'express' import React from 'react' import { renderToString } from 'react-dom/server' import VDom from './VDom' // 创建一个express应用 const app = express() // renderToString 是把虚拟DOM转化为真实DOM的关键方法 const RDom = renderToString() // 编写HTML模板，插入转化后的真实DOM内容 const Page = ` test 服务端渲染出了真实DOM: ${RDom} ` // 配置HTML内容对应的路由 app.get('/index', function(req, res) { res.send(Page) }) // 配置端口号 const server = app.listen(8000) 根据我们的路由配置，当我访问 http://localhost:8000/index 时，就可以呈现出服务端渲染的结果了： 我们可以看到，VDom 组件已经被 renderToString 转化为了一个内容为我是一个被渲染为真实DOM的虚拟DOM的字符串，这个字符串被插入 HTML 代码，成为了真实 DOM 树的一部分。 那么 Vue 是如何实现服务端渲染的呢？ 其实是一个套路，我这里基于 Vue SSR 指南 中官方给出的例子为大家讲解 Vue 中的实现思路（思路见注释）。 该示例直接将 Vue 实例整合进了服务端的入口文件中： const Vue = require('vue') // 创建一个express应用 const server = require('express')() // 提取出renderer实例 const renderer = require('vue-server-renderer').createRenderer() server.get('*', (req, res) => { // 编写Vue实例（虚拟DOM节点） const app = new Vue({ data: { url: req.url }, // 编写模板HTML的内容 template: `访问的 URL 是： {{ url }}` }) // renderToString 是把Vue实例转化为真实DOM的关键方法 renderer.renderToString(app, (err, html) => { if (err) { res.status(500).end('Internal Server Error') return } // 把渲染出来的真实DOM字符串插入HTML模板中 res.end(` Hello ${html} `) }) }) server.listen(8080) 大家对比一下 React 项目中的注释内容，是不是发现这两段代码从本质上来说区别不大呢？ 以上两个小🌰，为大家演示了基本的服务端渲染实现流程。 实际项目比这些复杂很多，但万变不离其宗。强调的只有两点：一是这个 renderToString() 方法；二是把转化结果“塞”进模板里的这一步。这两个操作是服务端渲染的灵魂操作。在虚拟 DOM“横行”的当下，服务端渲染不再是早年 JSP 里简单粗暴的字符串拼接过程，它还要求这一端要具备将虚拟 DOM 转化为真实 DOM 的能力。与其说是“把 JS 在服务器上先跑一遍”，不如说是“把 Vue、React 等框架代码先在 Node 上跑一遍”。 服务端渲染的应用场景 打眼一看，这个服务端渲染给浏览器省了这么多事儿，性能肯定是质的飞跃啊！喜闻乐见！但是大家打开自己经常访问的那些网页看一看，会发现仍然有许多网站压根儿不用服务端渲染——看来这个东西也不是万能的。 根据我们前面的描述，不难看出，服务端渲染本质上是本该浏览器做的事情，分担给服务器去做。这样当资源抵达浏览器时，它呈现的速度就快了。乍一看好像很合理：浏览器性能毕竟有限，服务器多牛逼！能者多劳，就该让服务器多干点活！ 但仔细想想，在这个网民遍地的时代，几乎有多少个用户就有多少台浏览器。用户拥有的浏览器总量多到数不清，那么一个公司的服务器又有多少台呢？我们把这么多台浏览器的渲染压力集中起来，分散给相比之下数量并不多的服务器，服务器肯定是承受不住的。 这样分析下来，服务端渲染也并非万全之策。在实践中，我一般会建议大家先忘记服务端渲染这个事情——服务器稀少而宝贵，但首屏渲染体验和 SEO 的优化方案却很多——我们最好先把能用的低成本“大招”都用完。除非网页对性能要求太高了，以至于所有的招式都用完了，性能表现还是不尽人意，这时候我们就可以考虑向老板多申请几台服务器，把服务端渲染搞起来了~ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/08.渲染篇2：知己知彼——解锁浏览器背后的运行机制.html":{"url":"前端性能优化/08.渲染篇2：知己知彼——解锁浏览器背后的运行机制.html","title":"08.渲染篇2：知己知彼——解锁浏览器背后的运行机制","keywords":"","body":"知己知彼——解锁浏览器背后的运行机制 从本章开始，我们的性能优化探险也正式进入到了“深水区”——浏览器端的性能优化。 平时我们几乎每天都在和浏览器打交道，在一些兼容任务比较繁重的团队里，苦逼的前端攻城师们甚至为了兼容各个浏览器而不断地去测试和调试，还要在脑子中记下各种遇到的 BUG 及解决方案。即便如此，我们好像并没有去主动地关注和了解下浏览器的工作原理。我想如果我们对此做一点了解，在项目过程中就可以有效地避免一些问题，并对页面性能做出相应的改进。 “知己知彼，百战不殆”，今天，我们就一起来揭开浏览器渲染过程的神秘面纱！ 浏览器的“心” 浏览器的“心”，说的就是浏览器的内核。在研究浏览器微观的运行机制之前，我们首先要对浏览器内核有一个宏观的把握。 开篇我提到许多工程师因为业务需要，免不了需要去处理不同浏览器下代码渲染结果的差异性。这些差异性正是因为浏览器内核的不同而导致的——浏览器内核决定了浏览器解释网页语法的方式。浏览器内核可以分成两部分：渲染引擎（Layout Engine 或者 Rendering Engine）和 JS 引擎。早期渲染引擎和 JS 引擎并没有十分明确的区分，但随着 JS 引擎越来越独立，内核也成了渲染引擎的代称（下文我们将沿用这种叫法）。渲染引擎又包括了 HTML 解释器、CSS 解释器、布局、网络、存储、图形、音视频、图片解码器等等零部件。 目前市面上常见的浏览器内核可以分为这四种：Trident（IE）、Gecko（火狐）、Blink（Chrome、Opera）、Webkit（Safari）。 这里面大家最耳熟能详的可能就是 Webkit 内核了。很多同学可能会听说过 Chrome 的内核就是 Webkit，殊不知 Chrome 内核早已迭代为了 Blink。但是换汤不换药，Blink 其实也是基于 Webkit 衍生而来的一个分支，因此，Webkit 内核仍然是当下浏览器世界真正的霸主。 下面我们就以 Webkit 为例，对现代浏览器的渲染过程进行一个深度的剖析。 开启浏览器渲染“黑盒” 什么是渲染过程？简单来说，渲染引擎根据 HTML 文件描述构建相应的数学模型，调用浏览器各个零部件，从而将网页资源代码转换为图像结果，这个过程就是渲染过程（如下图）。 从这个流程来看，浏览器呈现网页这个过程，宛如一个黑盒。在这个神秘的黑盒中，有许多功能模块，内核内部的实现正是这些功能模块相互配合协同工作进行的。其中我们最需要关注的，就是HTML 解释器、CSS 解释器、图层布局计算模块、视图绘制模块与JavaScript 引擎这几大模块： HTML 解释器：将 HTML 文档经过词法分析输出 DOM 树。 CSS 解释器：解析 CSS 文档, 生成样式规则。 图层布局计算模块：布局计算每个对象的精确位置和大小。 视图绘制模块：进行具体节点的图像绘制，将像素渲染到屏幕上。 JavaScript 引擎：编译执行 Javascript 代码。 浏览器渲染过程解析 有了对零部件的了解打底，我们就可以一起来走一遍浏览器的渲染流程了。在浏览器里，每一个页面的首次渲染都经历了如下阶段（图中箭头不代表串行，有一些操作是并行进行的，下文会说明）： 解析 HTML 在这一步浏览器执行了所有的加载解析逻辑，在解析 HTML 的过程中发出了页面渲染所需的各种外部资源请求。 计算样式 浏览器将识别并加载所有的 CSS 样式信息与 DOM 树合并，最终生成页面 render 树（:after :before 这样的伪元素会在这个环节被构建到 DOM 树中）。 计算图层布局 页面中所有元素的相对位置信息，大小等信息均在这一步得到计算。 绘制图层 在这一步中浏览器会根据我们的 DOM 代码结果，把每一个页面图层转换为像素，并对所有的媒体文件进行解码。 整合图层，得到页面 最后一步浏览器会合并合各个图层，将数据由 CPU 输出给 GPU 最终绘制在屏幕上。（复杂的视图层会给这个阶段的 GPU 计算带来一些压力，在实际应用中为了优化动画性能，我们有时会手动区分不同的图层）。 几棵重要的“树” 上面的内容没有理解透彻？别着急，我们一起来捋一捋这个过程中的重点——树！ 为了使渲染过程更明晰一些，我们需要给这些”树“们一个特写: DOM 树：解析 HTML 以创建的是 DOM 树（DOM tree ）：渲染引擎开始解析 HTML 文档，转换树中的标签到 DOM 节点，它被称为“内容树”。 CSSOM 树：解析 CSS（包括外部 CSS 文件和样式元素）创建的是 CSSOM 树。CSSOM 的解析过程与 DOM 的解析过程是并行的。 渲染树：CSSOM 与 DOM 结合，之后我们得到的就是渲染树（Render tree ）。 布局渲染树：从根节点递归调用，计算每一个元素的大小、位置等，给每个节点所应该出现在屏幕上的精确坐标，我们便得到了基于渲染树的布局渲染树（Layout of the render tree）。 绘制渲染树: 遍历渲染树，每个节点将使用 UI 后端层来绘制。整个过程叫做绘制渲染树（Painting the render tree）。 基于这些“树”，我们再梳理一番： 渲染过程说白了，首先是基于 HTML 构建一个 DOM 树，这棵 DOM 树与 CSS 解释器解析出的 CSSOM 相结合，就有了布局渲染树。最后浏览器以布局渲染树为蓝本，去计算布局并绘制图像，我们页面的初次渲染就大功告成了。 之后每当一个新元素加入到这个 DOM 树当中，浏览器便会通过 CSS 引擎查遍 CSS 样式表，找到符合该元素的样式规则应用到这个元素上，然后再重新去绘制它。 有心的同学可能已经在思考了，查表是个花时间的活，我怎么让浏览器的查询工作又快又好地实现呢？OK，讲了这么多原理，我们终于引出了我们的第一个可转化为代码的优化点——CSS 样式表规则的优化！ 不做无用功：基于渲染流程的 CSS 优化建议 在给出 CSS 选择器方面的优化建议之前，先告诉大家一个小知识：CSS 引擎查找样式表，对每条规则都按从右到左的顺序去匹配。 看如下规则： #myList li {} 这样的写法其实很常见。大家平时习惯了从左到右阅读的文字阅读方式，会本能地以为浏览器也是从左到右匹配 CSS 选择器的，因此会推测这个选择器并不会费多少力气：#myList 是一个 id 选择器，它对应的元素只有一个，查找起来应该很快。定位到了 myList 元素，等于是缩小了范围后再去查找它后代中的 li 元素，没毛病。 事实上，CSS 选择符是从右到左进行匹配的。我们这个看似“没毛病”的选择器，实际开销相当高：浏览器必须遍历页面上每个 li 元素，并且每次都要去确认这个 li 元素的父元素 id 是不是 myList，你说坑不坑！ 说到坑，不知道大家还记不记得这个经典的通配符： * {} 入门 CSS 的时候，不少同学拿通配符清除默认样式（我曾经也是通配符用户的一员）。但这个家伙很恐怖，它会匹配所有元素，所以浏览器必须去遍历每一个元素！大家低头看看自己页面里的元素个数，是不是心凉了——这得计算多少次呀！ 这样一看，一个小小的 CSS 选择器，也有不少的门道！好的 CSS 选择器书写习惯，可以为我们带来非常可观的性能提升。根据上面的分析，我们至少可以总结出如下性能提升的方案： 避免使用通配符，只对需要用到的元素进行选择。 关注可以通过继承实现的属性，避免重复匹配重复定义。 少用标签选择器。如果可以，用类选择器替代，举个🌰： 错误示范： #myList li{} 课代表： .myList_li {} 不要画蛇添足，id 和 class 选择器不应该被多余的标签选择器拖后腿。举个🌰： 错误示范 .myList#title 课代表 #title 减少嵌套。后代选择器的开销是最高的，因此我们应该尽量将选择器的深度降到最低（最高不要超过三层），尽可能使用类来关联每一个标签元素。 搞定了 CSS 选择器，万里长征才刚刚开始的第一步。但现在你已经理解了浏览器的工作过程，接下来的征程对你来说并不再是什么难题~ 告别阻塞：CSS 与 JS 的加载顺序优化 说完了过程，我们来说一说特性。 HTML、CSS 和 JS，都具有阻塞渲染的特性。 HTML 阻塞，天经地义——没有 HTML，何来 DOM？没有 DOM，渲染和优化，都是空谈。 那么 CSS 和 JS 的阻塞又是怎么回事呢？ CSS 的阻塞 在刚刚的过程中，我们提到 DOM 和 CSSOM 合力才能构建渲染树。这一点会给性能造成严重影响：默认情况下，CSS 是阻塞的资源。浏览器在构建 CSSOM 的过程中，不会渲染任何已处理的内容。即便 DOM 已经解析完毕了，只要 CSSOM 不 OK，那么渲染这个事情就不 OK（这主要是为了避免没有 CSS 的 HTML 页面丑陋地“裸奔”在用户眼前）。 我们知道，只有当我们开始解析 HTML 后、解析到 link 标签或者 style 标签时，CSS 才登场，CSSOM 的构建才开始。很多时候，DOM 不得不等待 CSSOM。因此我们可以这样总结： CSS 是阻塞渲染的资源。需要将它尽早、尽快地下载到客户端，以便缩短首次渲染的时间。 事实上，现在很多团队都已经做到了尽早（将 CSS 放在 head 标签里）和尽快（启用 CDN 实现静态资源加载速度的优化）。这个“把 CSS 往前放”的动作，对很多同学来说已经内化为一种编码习惯。那么现在我们还应该知道，这个“习惯”不是空穴来风，它是由 CSS 的特性决定的。 JS 的阻塞 不知道大家注意到没有，前面我们说过程的时候，花了很多笔墨去说 HTML、说 CSS。相比之下，JS 的出镜率也太低了点。这当然不是因为 JS 不重要。而是因为，在首次渲染过程中，JS 并不是一个非登场不可的角色——没有 JS，CSSOM 和 DOM 照样可以组成渲染树，页面依然会呈现——即使它死气沉沉、毫无交互。 JS 的作用在于修改，它帮助我们修改网页的方方面面：内容、样式以及它如何响应用户交互。这“方方面面”的修改，本质上都是对 DOM 和 CSSDOM 进行修改。因此 JS 的执行会阻止 CSSOM，在我们不作显式声明的情况下，它也会阻塞 DOM。 我们通过一个🌰来理解一下这个机制： JS阻塞测试 #container { background-color: yellow; width: 100px; height: 100px; } // 尝试获取container元素 var container = document.getElementById(\"container\") console.log('container', container) // 尝试获取container元素 var container = document.getElementById(\"container\") console.log('container', container) // 输出container元素此刻的背景色 console.log('container bgColor', getComputedStyle(container).backgroundColor) #container { background-color: blue; } 三个 console 的结果分别为： 注：本例仅使用了内联 JS 做测试。感兴趣的同学可以把这部分 JS 当做外部文件引入看看效果——它们的表现一致。 第一次尝试获取 id 为 container 的 DOM 失败，这说明 JS 执行时阻塞了 DOM，后续的 DOM 无法构建；第二次才成功，这说明脚本块只能找到在它前面构建好的元素。这两者结合起来，“阻塞 DOM”得到了验证。再看第三个 console，尝试获取 CSS 样式，获取到的是在 JS 代码执行前的背景色（yellow），而非后续设定的新样式（blue），说明 CSSOM 也被阻塞了。那么在阻塞的背后，到底发生了什么呢？ 我们前面说过，JS 引擎是独立于渲染引擎存在的。我们的 JS 代码在文档的何处插入，就在何处执行。当 HTML 解析器遇到一个 script 标签时，它会暂停渲染过程，将控制权交给 JS 引擎。JS 引擎对内联的 JS 代码会直接执行，对外部 JS 文件还要先获取到脚本、再进行执行。等 JS 引擎运行完毕，浏览器又会把控制权还给渲染引擎，继续 CSSOM 和 DOM 的构建。 因此与其说是 JS 把 CSS 和 HTML 阻塞了，不如说是 JS 引擎抢走了渲染引擎的控制权。 现在理解了阻塞的表现与原理，我们开始思考一个问题。浏览器之所以让 JS 阻塞其它的活动，是因为它不知道 JS 会做什么改变，担心如果不阻止后续的操作，会造成混乱。但是我们是写 JS 的人，我们知道 JS 会做什么改变。假如我们可以确认一个 JS 文件的执行时机并不一定非要是此时此刻，我们就可以通过对它使用 defer 和 async 来避免不必要的阻塞，这里我们就引出了外部 JS 的三种加载方式。 JS的三种加载方式 正常模式： 这种情况下 JS 会阻塞浏览器，浏览器必须等待 index.js 加载和执行完毕才能去做其它事情。 async 模式： async 模式下，JS 不会阻塞浏览器做任何其它的事情。它的加载是异步的，当它加载结束，JS 脚本会立即执行。 defer 模式： defer 模式下，JS 的加载是异步的，执行是被推迟的。等整个文档解析完成、DOMContentLoaded 事件即将被触发时，被标记了 defer 的 JS 文件才会开始依次执行。 从应用的角度来说，一般当我们的脚本与 DOM 元素和其它脚本之间的依赖关系不强时，我们会选用 async；当脚本依赖于 DOM 元素和其它脚本的执行结果时，我们会选用 defer。 通过审时度势地向 script 标签添加 async/defer，我们就可以告诉浏览器在等待脚本可用期间不阻止其它的工作，这样可以显著提升性能。 小结 我们知道，当 JS 登场时，往往意味着对 DOM 的操作。DOM 操作所导致的性能开销的“昂贵”，大家可能早就有所耳闻，雅虎军规里很重要的一条就是“尽量减少 DOM 访问”。 那么 DOM 到底为什么慢，我们如何去规避这种慢呢？这里我们就引出了下一个章节需要重点解释的两个概念：CSS 中的回流（Reflow）与重绘（Repaint）。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/09.渲染篇3：对症下药——DOM优化原理与基本实践.html":{"url":"前端性能优化/09.渲染篇3：对症下药——DOM优化原理与基本实践.html","title":"09.渲染篇3：对症下药——DOM优化原理与基本实践","keywords":"","body":"对症下药—— DOM 优化原理与基本实践 从本节开始，我们要关心的两大核心问题就是：“DOM 为什么这么慢”以及“如何使 DOM 变快”。 后者是一个比“生存还是毁灭”更加经典的问题。不仅我们为它“肝肠寸断”，许多优秀前端框架的作者大大们也曾为其绞尽脑汁。这一点可喜可贺——研究的人越多，产出优秀实践的概率就越大。因此在本章的方法论环节，我们不仅会根据 DOM 特性及渲染原理为大家讲解基本的优化思路，还会涉及到一部分生产实践。 循着这个思路，我们把 DOM 优化这块划分为三个小专题：“DOM 优化思路”、“异步更新策略”及“回流与重绘”。本节对应第一个小专题。三个小专题休戚与共、你侬我侬，在思路上相互依赖、一脉相承，因此此处严格禁止任何姿势的跳读行为。 考虑到本节内容与上一节有着密不可分的关系，因此强烈不建议没有读完上一节的同学直接跳读本节。 望闻问切：DOM 为什么这么慢 因为收了“过路费” 把 DOM 和 JavaScript 各自想象成一个岛屿，它们之间用收费桥梁连接。——《高性能 JavaScript》 JS 是很快的，在 JS 中修改 DOM 对象也是很快的。在JS的世界里，一切是简单的、迅速的。但 DOM 操作并非 JS 一个人的独舞，而是两个模块之间的协作。 上一节我们提到，JS 引擎和渲染引擎（浏览器内核）是独立实现的。当我们用 JS 去操作 DOM 时，本质上是 JS 引擎和渲染引擎之间进行了“跨界交流”。这个“跨界交流”的实现并不简单，它依赖了桥接接口作为“桥梁”（如下图）。 过“桥”要收费——这个开销本身就是不可忽略的。我们每操作一次 DOM（不管是为了修改还是仅仅为了访问其值），都要过一次“桥”。过“桥”的次数一多，就会产生比较明显的性能问题。因此“减少 DOM 操作”的建议，并非空穴来风。 对 DOM 的修改引发样式的更迭 过桥很慢，到了桥对岸，我们的更改操作带来的结果也很慢。 很多时候，我们对 DOM 的操作都不会局限于访问，而是为了修改它。当我们对 DOM 的修改会引发它外观（样式）上的改变时，就会触发回流或重绘。 这个过程本质上还是因为我们对 DOM 的修改触发了渲染树（Render Tree）的变化所导致的： 回流：当我们对 DOM 的修改引发了 DOM 几何尺寸的变化（比如修改元素的宽、高或隐藏元素等）时，浏览器需要重新计算元素的几何属性（其他元素的几何属性和位置也会因此受到影响），然后再将计算的结果绘制出来。这个过程就是回流（也叫重排）。 重绘：当我们对 DOM 的修改导致了样式的变化、却并未影响其几何属性（比如修改了颜色或背景色）时，浏览器不需重新计算元素的几何属性、直接为该元素绘制新的样式（跳过了上图所示的回流环节）。这个过程叫做重绘。 由此我们可以看出，重绘不一定导致回流，回流一定会导致重绘。硬要比较的话，回流比重绘做的事情更多，带来的开销也更大。但这两个说到底都是吃性能的，所以都不是什么善茬。我们在开发中，要从代码层面出发，尽可能把回流和重绘的次数最小化。 药到病除：给你的 DOM “提提速” 知道了 DOM 慢的原因，我们就可以对症下药了。 减少 DOM 操作：少交“过路费”、避免过度渲染 我们来看这样一个🌰，HTML 内容如下： DOM操作测试 此时我有一个假需求——我想往 container 元素里写 10000 句一样的话。如果我这么做： for(var count=0;count我是一个小测试' } 这段代码有两个明显的可优化点。 第一点，过路费交太多了。我们每一次循环都调用 DOM 接口重新获取了一次 container 元素，相当于每次循环都交了一次过路费。前后交了 10000 次过路费，但其中 9999 次过路费都可以用缓存变量的方式节省下来： // 只获取一次container let container = document.getElementById('container') for(let count=0;count我是一个小测试' } 第二点，不必要的 DOM 更改太多了。我们的 10000 次循环里，修改了 10000 次 DOM 树。我们前面说过，对 DOM 的修改会引发渲染树的改变、进而去走一个（可能的）回流或重绘的过程，而这个过程的开销是很“贵”的。这么贵的操作，我们竟然重复执行了 N 多次！其实我们可以通过就事论事的方式节省下来不必要的渲染： let container = document.getElementById('container') let content = '' for(let count=0;count我是一个小测试' } // 内容处理好了,最后再触发DOM的更改 container.innerHTML = content 所谓“就事论事”，就像大家所看到的：JS 层面的事情，JS 自己去处理，处理好了，再来找 DOM 打报告。 事实上，考虑JS 的运行速度，比 DOM 快得多这个特性。我们减少 DOM 操作的核心思路，就是让 JS 去给 DOM 分压。 这个思路，在 DOM Fragment 中体现得淋漓尽致。 DocumentFragment 接口表示一个没有父级文件的最小文档对象。它被当做一个轻量版的 Document 使用，用于存储已排好版的或尚未打理好格式的XML片段。因为 DocumentFragment 不是真实 DOM 树的一部分，它的变化不会引起 DOM 树的重新渲染的操作（reflow），且不会导致性能等问题。 在我们上面的例子里，字符串变量 content 就扮演着一个 DOM Fragment 的角色。其实无论字符串变量也好，DOM Fragment 也罢，它们本质上都作为脱离了真实 DOM 树的容器出现，用于缓存批量化的 DOM 操作。 前面我们直接用 innerHTML 去拼接目标内容，这样做固然有用，但却不够优雅。相比之下，DOM Fragment 可以帮助我们用更加结构化的方式去达成同样的目的，从而在维持性能的同时，保住我们代码的可拓展和可维护性。我们现在用 DOM Fragment 来改写上面的例子： let container = document.getElementById('container') // 创建一个DOM Fragment对象作为容器 let content = document.createDocumentFragment() for(let count=0;count我们运行这段代码，可以得到与前面两种写法相同的运行结果。可以看出，DOM Fragment 对象允许我们像操作真实 DOM 一样去调用各种各样的 DOM API，我们的代码质量因此得到了保证。并且它的身份也非常纯粹：当我们试图将其 append 进真实 DOM 时，它会在乖乖交出自身缓存的所有后代节点后全身而退，完美地完成一个容器的使命，而不会出现在真实的 DOM 结构中。这种结构化、干净利落的特性，使得 DOM Fragment 作为经典的性能优化手段大受欢迎，这一点在 jQuery、Vue 等优秀前端框架的源码中均有体现。 相比 DOM 命题的博大精深，一个简单的循环 Demo 显然不能说明所有问题。不过不用着急，在本节，我只希望大家能牢记原理与宏观思路。“药到病除”到这里才刚刚开了个头，下个小节，我们将深挖事件循环机制，从而深入 JS 层面的生产实践。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/10.渲染篇4：千方百计——EventLoop与异步更新策略.html":{"url":"前端性能优化/10.渲染篇4：千方百计——EventLoop与异步更新策略.html","title":"10.渲染篇4：千方百计——EventLoop与异步更新策略","keywords":"","body":"千方百计——Event Loop 与异步更新策略 Vue 和 React 都实现了异步更新策略。虽然实现的方式不尽相同，但都达到了减少 DOM 操作、避免过度渲染的目的。通过研究框架的运行机制，其设计思路将深化我们对 DOM 优化的理解，其实现手法将拓宽我们对 DOM 实践的认知。 本节我们将基于 Event Loop 机制，对 Vue 的异步更新策略作探讨。 前置知识：Event Loop 中的“渲染时机” 搞懂 Event Loop，是理解 Vue 对 DOM 操作优化的第一步。 Micro-Task 与 Macro-Task 事件循环中的异步队列有两种：macro（宏任务）队列和 micro（微任务）队列。 常见的 macro-task 比如： setTimeout、setInterval、 setImmediate、script（整体代码）、 I/O 操作、UI 渲染等。常见的 micro-task 比如: process.nextTick、Promise、MutationObserver 等。 Event Loop 过程解析 基于对 micro 和 macro 的认知，我们来走一遍完整的事件循环过程。 一个完整的 Event Loop 过程，可以概括为以下阶段： 初始状态：调用栈空。micro 队列空，macro 队列里有且只有一个 script 脚本（整体代码）。 全局上下文（script 标签）被推入调用栈，同步代码执行。在执行的过程中，通过对一些接口的调用，可以产生新的 macro-task 与 micro-task，它们会分别被推入各自的任务队列里。同步代码执行完了，script 脚本会被移出 macro 队列，这个过程本质上是队列的 macro-task 的执行和出队的过程。 上一步我们出队的是一个 macro-task，这一步我们处理的是 micro-task。但需要注意的是：当 macro-task 出队时，任务是一个一个执行的；而 micro-task 出队时，任务是一队一队执行的（如下图所示）。因此，我们处理 micro 队列这一步，会逐个执行队列中的任务并把它出队，直到队列被清空。 执行渲染操作，更新界面（敲黑板划重点）。 检查是否存在 Web worker 任务，如果有，则对其进行处理 。 （上述过程循环往复，直到两个队列都清空） 我们总结一下，每一次循环都是一个这样的过程： 渲染的时机 大家现在思考一个这样的问题：假如我想要在异步任务里进行DOM更新，我该把它包装成 micro 还是 macro 呢？ 我们先假设它是一个 macro 任务，比如我在 script 脚本中用 setTimeout 来处理它： // task是一个用于修改DOM的回调 setTimeout(task, 0) 现在 task 被推入的 macro 队列。但因为 script 脚本本身是一个 macro 任务，所以本次执行完 script 脚本之后，下一个步骤就要去处理 micro 队列了，再往下就去执行了一次 render，对不对？ 但本次render我的目标task其实并没有执行，想要修改的DOM也没有修改，因此这一次的render其实是一次无效的render。 macro 不 ok，我们转向 micro 试试看。我用 Promise 来把 task 包装成是一个 micro 任务： Promise.resolve().then(task) 那么我们结束了对 script 脚本的执行，是不是紧接着就去处理 micro-task 队列了？micro-task 处理完，DOM 修改好了，紧接着就可以走 render 流程了——不需要再消耗多余的一次渲染，不需要再等待一轮事件循环，直接为用户呈现最即时的更新结果。 因此，我们更新 DOM 的时间点，应该尽可能靠近渲染的时机。当我们需要在异步任务中实现 DOM 修改时，把它包装成 micro 任务是相对明智的选择。 生产实践：异步更新策略——以 Vue 为例 什么是异步更新？ 当我们使用 Vue 或 React 提供的接口去更新数据时，这个更新并不会立即生效，而是会被推入到一个队列里。待到适当的时机，队列中的更新任务会被批量触发。这就是异步更新。 异步更新可以帮助我们避免过度渲染，是我们上节提到的“让 JS 为 DOM 分压”的典范之一。 异步更新的优越性 异步更新的特性在于它只看结果，因此渲染引擎不需要为过程买单。 最典型的例子，比如有时我们会遇到这样的情况： // 任务一 this.content = '第一次测试' // 任务二 this.content = '第二次测试' // 任务三 this.content = '第三次测试' 我们在三个更新任务中对同一个状态修改了三次，如果我们采取传统的同步更新策略，那么就要操作三次 DOM。但本质上需要呈现给用户的目标内容其实只是第三次的结果，也就是说只有第三次的操作是有意义的——我们白白浪费了两次计算。 但如果我们把这三个任务塞进异步更新队列里，它们会先在 JS 的层面上被批量执行完毕。当流程走到渲染这一步时，它仅仅需要针对有意义的计算结果操作一次 DOM——这就是异步更新的妙处。 Vue状态更新手法：nextTick Vue 每次想要更新一个状态的时候，会先把它这个更新操作给包装成一个异步操作派发出去。这件事情，在源码中是由一个叫做 nextTick 的函数来完成的： export function nextTick (cb?: Function, ctx?: Object) { let _resolve callbacks.push(() => { if (cb) { try { cb.call(ctx) } catch (e) { handleError(e, ctx, 'nextTick') } } else if (_resolve) { _resolve(ctx) } }) // 检查上一个异步任务队列（即名为callbacks的任务数组）是否派发和执行完毕了。pending此处相当于一个锁 if (!pending) { // 若上一个异步任务队列已经执行完毕，则将pending设定为true（把锁锁上） pending = true // 是否要求一定要派发为macro任务 if (useMacroTask) { macroTimerFunc() } else { // 如果不说明一定要macro 你们就全都是micro microTimerFunc() } } // $flow-disable-line if (!cb && typeof Promise !== 'undefined') { return new Promise(resolve => { _resolve = resolve }) } } 我们看到，Vue 的异步任务默认情况下都是用 Promise 来包装的，也就是是说它们都是 micro-task。这一点和我们“前置知识”中的渲染时机的分析不谋而合。 为了带大家熟悉一下常见的 macro 和 micro 派发方式、加深对 Event Loop 的理解，我们继续细化解析一下 macroTimeFunc() 和 microTimeFunc() 两个方法。 macroTimeFunc() 是这么实现的： // macro首选setImmediate 这个兼容性最差 if (typeof setImmediate !== 'undefined' && isNative(setImmediate)) { macroTimerFunc = () => { setImmediate(flushCallbacks) } } else if (typeof MessageChannel !== 'undefined' && ( isNative(MessageChannel) || // PhantomJS MessageChannel.toString() === '[object MessageChannelConstructor]' )) { const channel = new MessageChannel() const port = channel.port2 channel.port1.onmessage = flushCallbacks macroTimerFunc = () => { port.postMessage(1) } } else { // 兼容性最好的派发方式是setTimeout macroTimerFunc = () => { setTimeout(flushCallbacks, 0) } } microTimeFunc() 是这么实现的： // 简单粗暴 不是ios全都给我去Promise 如果不兼容promise 那么你只能将就一下变成macro了 if (typeof Promise !== 'undefined' && isNative(Promise)) { const p = Promise.resolve() microTimerFunc = () => { p.then(flushCallbacks) // in problematic UIWebViews, Promise.then doesn't completely break, but // it can get stuck in a weird state where callbacks are pushed into the // microtask queue but the queue isn't being flushed, until the browser // needs to do some other work, e.g. handle a timer. Therefore we can // \"force\" the microtask queue to be flushed by adding an empty timer. if (isIOS) setTimeout(noop) } } else { // 如果无法派发micro，就退而求其次派发为macro microTimerFunc = macroTimerFunc } 我们注意到，无论是派发 macro 任务还是派发 micro 任务，派发的任务对象都是一个叫做 flushCallbacks 的东西，这个东西做了什么呢？ flushCallbacks 源码如下： function flushCallbacks () { pending = false // callbacks在nextick中出现过 它是任务数组（队列） const copies = callbacks.slice(0) callbacks.length = 0 // 将callbacks中的任务逐个取出执行 for (let i = 0; i 现在我们理清楚了：Vue 中每产生一个状态更新任务，它就会被塞进一个叫 callbacks 的数组（此处是任务队列的实现形式）中。这个任务队列在被丢进 micro 或 macro 队列之前，会先去检查当前是否有异步更新任务正在执行（即检查 pending 锁）。如果确认 pending 锁是开着的（false），就把它设置为锁上（true），然后对当前 callbacks 数组的任务进行派发（丢进 micro 或 macro 队列）和执行。设置 pending 锁的意义在于保证状态更新任务的有序进行，避免发生混乱。 本小节我们从性能优化的角度出发，通过解析Vue源码，对异步更新这一高效的 DOM 优化手段有了感性的认知。同时帮助大家进一步熟悉了 micro 与 macro 在生产中的应用，加深了对 Event Loop 的理解。事实上，Vue 源码中还有许多值得称道的生产实践，其设计模式与编码细节都值得我们去细细品味。对这个话题感兴趣的同学，课后不妨移步 Vue运行机制解析 进行探索。 小结 至此，我们的 DOM 优化之路才走完了一半。 以上我们都在讨论“如何减少 DOM 操作”的话题。这个话题比较宏观——DOM 操作也分很多种，它们带来的变化各不相同。有的操作只触发重绘，这时我们的性能损耗就小一些；有的操作会触发回流，这时我们更“肉疼”一些。那么如何理解回流与重绘，如何借助这些理解去提升页面渲染效率呢？ 结束了 JS 的征程，我们下面就走进 CSS 的世界一窥究竟。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/11.渲染篇5：最后一击——回流（Reflow）与重绘（Repaint）.html":{"url":"前端性能优化/11.渲染篇5：最后一击——回流（Reflow）与重绘（Repaint）.html","title":"11.渲染篇5：最后一击——回流（Reflow）与重绘（Repaint）","keywords":"","body":"最后一击——回流（Reflow）与重绘（Repaint） 开篇我们先对上上节介绍的回流与重绘的基础知识做个复习（跳读的同学请自觉回到上上节补齐 →_→）。 回流：当我们对 DOM 的修改引发了 DOM 几何尺寸的变化（比如修改元素的宽、高或隐藏元素等）时，浏览器需要重新计算元素的几何属性（其他元素的几何属性和位置也会因此受到影响），然后再将计算的结果绘制出来。这个过程就是回流（也叫重排）。 重绘：当我们对 DOM 的修改导致了样式的变化、却并未影响其几何属性（比如修改了颜色或背景色）时，浏览器不需重新计算元素的几何属性、直接为该元素绘制新的样式（跳过了上图所示的回流环节）。这个过程叫做重绘。 由此我们可以看出，重绘不一定导致回流，回流一定会导致重绘。硬要比较的话，回流比重绘做的事情更多，带来的开销也更大。但这两个说到底都是吃性能的，所以都不是什么善茬。我们在开发中，要从代码层面出发，尽可能把回流和重绘的次数最小化。 哪些实际操作会导致回流与重绘 要避免回流与重绘的发生，最直接的做法是避免掉可能会引发回流与重绘的 DOM 操作，就好像拆弹专家在解决一颗炸弹时，最重要的是掐灭它的导火索。 触发重绘的“导火索”比较好识别——只要是不触发回流，但又触发了样式改变的 DOM 操作，都会引起重绘，比如背景色、文字色、可见性(可见性这里特指形如visibility: hidden这样不改变元素位置和存在性的、单纯针对可见性的操作，注意与display:none进行区分)等。为此，我们要着重理解一下那些可能触发回流的操作。 回流的“导火索” 最“贵”的操作：改变 DOM 元素的几何属性 这个改变几乎可以说是“牵一发动全身”——当一个DOM元素的几何属性发生变化时，所有和它相关的节点（比如父子节点、兄弟节点等）的几何属性都需要进行重新计算，它会带来巨大的计算量。 常见的几何属性有 width、height、padding、margin、left、top、border 等等。此处不再给大家一一列举。有的文章喜欢罗列属性表格，但我相信我今天列出来大家也不会看、看了也记不住（因为太多了）。我自己也不会去记这些——其实确实没必要记，️一个属性是不是几何属性、会不会导致空间布局发生变化，大家写样式的时候完全可以通过代码效果看出来。多说无益，还希望大家可以多写多试，形成自己的“肌肉记忆”。 “价格适中”的操作：改变 DOM 树的结构 这里主要指的是节点的增减、移动等操作。浏览器引擎布局的过程，顺序上可以类比于树的前序遍历——它是一个从上到下、从左到右的过程。通常在这个过程中，当前元素不会再影响其前面已经遍历过的元素。 最容易被忽略的操作：获取一些特定属性的值 当你要用到像这样的属性：offsetTop、offsetLeft、 offsetWidth、offsetHeight、scrollTop、scrollLeft、scrollWidth、scrollHeight、clientTop、clientLeft、clientWidth、clientHeight 时，你就要注意了！ “像这样”的属性，到底是像什么样？——这些值有一个共性，就是需要通过即时计算得到。因此浏览器为了获取这些值，也会进行回流。 除此之外，当我们调用了 getComputedStyle 方法，或者 IE 里的 currentStyle 时，也会触发回流。原理是一样的，都为求一个“即时性”和“准确性”。 如何规避回流与重绘 了解了回流与重绘的“导火索”，我们就要尽量规避它们。但很多时候，我们不得不使用它们。当避无可避时，我们就要学会更聪明地使用它们。 将“导火索”缓存起来，避免频繁改动 有时我们想要通过多次计算得到一个元素的布局位置，我们可能会这样做： Document #el { width: 100px; height: 100px; background-color: yellow; position: absolute; } // 获取el元素 const el = document.getElementById('el') // 这里循环判定比较简单，实际中或许会拓展出比较复杂的判定需求 for(let i=0;i 这样做，每次循环都需要获取多次“敏感属性”，是比较糟糕的。我们可以将其以 JS 变量的形式缓存起来，待计算完毕再提交给浏览器发出重计算请求： // 缓存offsetLeft与offsetTop的值 const el = document.getElementById('el') let offLeft = el.offsetLeft, offTop = el.offsetTop // 在JS层面进行计算 for(let i=0;i避免逐条改变样式，使用类名去合并样式 比如我们可以把这段单纯的代码： const container = document.getElementById('container') container.style.width = '100px' container.style.height = '200px' container.style.border = '10px solid red' container.style.color = 'red' 优化成一个有 class 加持的样子： Document .basic_style { width: 100px; height: 200px; border: 10px solid red; color: red; } const container = document.getElementById('container') container.classList.add('basic_style') 前者每次单独操作，都去触发一次渲染树更改，从而导致相应的回流与重绘过程。 合并之后，等于我们将所有的更改一次性发出，用一个 style 请求解决掉了。 将 DOM “离线” 我们上文所说的回流和重绘，都是在“该元素位于页面上”的前提下会发生的。一旦我们给元素设置 display: none，将其从页面上“拿掉”，那么我们的后续操作，将无法触发回流与重绘——这个将元素“拿掉”的操作，就叫做 DOM 离线化。 仍以我们上文的代码片段为例： const container = document.getElementById('container') container.style.width = '100px' container.style.height = '200px' container.style.border = '10px solid red' container.style.color = 'red' ...（省略了许多类似的后续操作） 离线化后就是这样： let container = document.getElementById('container') container.style.display = 'none' container.style.width = '100px' container.style.height = '200px' container.style.border = '10px solid red' container.style.color = 'red' ...（省略了许多类似的后续操作） container.style.display = 'block' 有的同学会问，拿掉一个元素再把它放回去，这不也会触发一次昂贵的回流吗？这话不假，但我们把它拿下来了，后续不管我操作这个元素多少次，每一步的操作成本都会非常低。当我们只需要进行很少的 DOM 操作时，DOM 离线化的优越性确实不太明显。一旦操作频繁起来，这“拿掉”和“放回”的开销都将会是非常值得的。 Flush 队列：浏览器并没有那么简单 以我们现在的知识基础，理解上面的优化操作并不难。那么现在我问大家一个问题： let container = document.getElementById('container') container.style.width = '100px' container.style.height = '200px' container.style.border = '10px solid red' container.style.color = 'red' 这段代码里，浏览器进行了多少次的回流或重绘呢？ “width、height、border是几何属性，各触发一次回流；color只造成外观的变化，会触发一次重绘。”——如果你立刻这么想了，说明你是个能力不错的同学，认真阅读了前面的内容。那么我们现在立刻跑一跑这段代码，看看浏览器怎么说： 这里为大家截取有“Layout”和“Paint”出镜的片段（这个图是通过 Chrome 的 Performance 面板得到的，后面会教大家用这个东西）。我们看到浏览器只进行了一次回流和一次重绘——和我们想的不一样啊，为啥呢？ 因为现代浏览器是很聪明的。浏览器自己也清楚，如果每次 DOM 操作都即时地反馈一次回流或重绘，那么性能上来说是扛不住的。于是它自己缓存了一个 flush 队列，把我们触发的回流与重绘任务都塞进去，待到队列里的任务多起来、或者达到了一定的时间间隔，或者“不得已”的时候，再将这些任务一口气出队。因此我们看到，上面就算我们进行了 4 次 DOM 更改，也只触发了一次 Layout 和一次 Paint。 大家这里尤其小心这个“不得已”的时候。前面我们在介绍回流的“导火索”的时候，提到过有一类属性很特别，它们有很强的“即时性”。当我们访问这些属性时，浏览器会为了获得此时此刻的、最准确的属性值，而提前将 flush 队列的任务出队——这就是所谓的“不得已”时刻。具体是哪些属性值，我们已经在“最容易被忽略的操作”这个小模块介绍过了，此处不再赘述。 小结 整个一节读下来，可能会有同学感到疑惑：既然浏览器已经为我们做了批处理优化，为什么我们还要自己操心这么多事情呢？今天避免这个明天避免那个，多麻烦！ 问题在于，并不是所有的浏览器都是聪明的。我们刚刚的性能图表，是 Chrome 的开发者工具呈现给我们的。Chrome 里行得通的东西，到了别处（比如 IE）就不一定行得通了。而我们并不知道用户会使用什么样的浏览器。如果不手动做优化，那么一个页面在不同的环境下就会呈现不同的性能效果，这对我们、对用户都是不利的。因此，养成良好的编码习惯、从根源上解决问题，仍然是最周全的方法。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/12.应用篇1：优化首屏体验——Lazy-Load初探.html":{"url":"前端性能优化/12.应用篇1：优化首屏体验——Lazy-Load初探.html","title":"12.应用篇1：优化首屏体验——Lazy-Load初探","keywords":"","body":"优化首屏体验——Lazy-Load 初探 首先要告诉大家的是，截止到上个章节，我们需要大家绞尽脑汁去理解的“硬核”操作基本告一段落了。从本节开始，我们会一起去实现一些必知必会、同时难度不大的常用优化手段。 这部分内容不难，但很关键。尤其是近期有校招或跳槽需求的同学，还请务必对这部分内容多加留心，说不定下一次的面试题里就有它们的身影。 Lazy-Load 初相见 Lazy-Load，翻译过来是“懒加载”。它是针对图片加载时机的优化：在一些图片量比较大的网站（比如电商网站首页，或者团购网站、小游戏首页等），如果我们尝试在用户打开页面的时候，就把所有的图片资源加载完毕，那么很可能会造成白屏、卡顿等现象，因为图片真的太多了，一口气处理这么多任务，浏览器做不到啊！ 但我们再想，用户真的需要这么多图片吗？不对，用户点开页面的瞬间，呈现给他的只有屏幕的一部分（我们称之为首屏）。只要我们可以在页面打开的时候把首屏的图片资源加载出来，用户就会认为页面是没问题的。至于下面的图片，我们完全可以等用户下拉的瞬间再即时去请求、即时呈现给他。这样一来，性能的压力小了，用户的体验却没有变差——这个延迟加载的过程，就是 Lazy-Load。 现在我们打开掘金首页： 大家留意一栏文章右侧可能会出现的图片，这里咱们给个特写： 大家现在以尽可能快的速度，疯狂向下拉动页面。发现什么？是不是发现我们图示的这个图片的位置，会出现闪动——有时候我们明明已经拉到目标位置了，文字也呈现完毕了，图片却慢半拍才显示出来。这是因为，掘金首页也采用了懒加载策略。当我们的页面并未滚动至包含图片的 div 元素所在的位置时，它的样式是这样的： 我们把代码提出来看一下： 我们注意到 style 内联样式中，背景图片设置为了 none。也就是说这个 div 是没有内容的，它只起到一个占位的作用。 这个“占位”的概念，在这个例子里或许体现得不够直观。最直观的应该是淘宝首页的 HTML Preview 效果： 我们看到，这个还没来得及被图片填充完全的网页，是用大大小小的空 div 元素来占位的。掘金首页也是如此。 一旦我们通过滚动使得这个 div 出现在了可见范围内，那么 div 元素的内容就会发生变化，呈现如下的内容： 我们给 style 一个特写： style=\"background-image: url(&quot;https://user-gold-cdn.xitu.io/2018/9/27/16619f449ee24252?imageView2/1/w/120/h/120/q/85/format/webp/interlace/1&quot;); background-size: cover;\" 可以看出，style 内联样式中的背景图片属性从 none 变成了一个在线图片的 URL。也就是说，出现在可视区域的瞬间，div 元素的内容被即时地修改掉了——它被写入了有效的图片 URL，于是图片才得以呈现。这就是懒加载的实现思路。 一起写一个 Lazy-Load 吧！ 基于上面的实现思路，我们完全可以手动实现一个属于自己的 Lazy-Load。 （此处敲黑板划重点，Lazy-Load 的思路及实现方式为大厂面试常考题，还望诸位同学引起重视） 首先新建一个空项目，目录结构如下： 大家可以往 images 文件夹里塞入各种各样自己喜欢的图片。 我们在 index.html 中，为这些图片预置 img 标签： Lazy-Load .img { width: 200px; height:200px; background-color: gray; } .pic { // 必要的img样式 } // 注意我们并没有为它引入真实的src 在懒加载的实现中，有两个关键的数值：一个是当前可视区域的高度，另一个是元素距离可视区域顶部的高度。 当前可视区域的高度， 在和现代浏览器及 IE9 以上的浏览器中，可以用 window.innerHeight 属性获取。在低版本 IE 的标准模式中，可以用 document.documentElement.clientHeight 获取，这里我们兼容两种情况： const viewHeight = window.innerHeight || document.documentElement.clientHeight 而元素距离可视区域顶部的高度，我们这里选用 getBoundingClientRect() 方法来获取返回元素的大小及其相对于视口的位置。对此 MDN 给出了非常清晰的解释： 该方法的返回值是一个 DOMRect 对象，这个对象是由该元素的 getClientRects() 方法返回的一组矩形的集合, 即：是与该元素相关的 CSS 边框集合 。 DOMRect 对象包含了一组用于描述边框的只读属性——left、top、right 和 bottom，单位为像素。除了 width 和 height 外的属性都是相对于视口的左上角位置而言的。 其中需要引起我们注意的就是 left、top、right 和 bottom，它们对应到元素上是这样的： 可以看出，top 属性代表了元素距离可视区域顶部的高度，正好可以为我们所用！ Lazy-Load 方法开工啦！ // 获取所有的图片标签 const imgs = document.getElementsByTagName('img') // 获取可视区域的高度 const viewHeight = window.innerHeight || document.documentElement.clientHeight // num用于统计当前显示到了哪一张图片，避免每次都从第一张图片开始检查是否露出 let num = 0 function lazyload(){ for(let i=num; i= 0 ){ // 给元素写入真实的src，展示图片 imgs[i].src = imgs[i].getAttribute('data-src') // 前i张图片已经加载完毕，下次从第i+1张开始检查是否露出 num = i + 1 } } } // 监听Scroll事件 window.addEventListener('scroll', lazyload, false); 小结 本节我们实现出了一个最基本的懒加载功能。但是大家要注意一点：这个 scroll 事件，是一个危险的事件——它太容易被触发了。试想，用户在访问网页的时候，是不是可以无限次地去触发滚动？尤其是一个页面死活加载不出来的时候，疯狂调戏鼠标滚轮（或者浏览器滚动条）的用户可不在少数啊！ 再回头看看我们上面写的代码。按照我们的逻辑，用户的每一次滚动都将触发我们的监听函数。函数执行是吃性能的，频繁地响应某个事件将造成大量不必要的页面计算。因此，我们需要针对那些有可能被频繁触发的事件作进一步地优化。这里就引出了我们下一节的两位主角——throttle 与 debounce。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/13.应用篇2：事件的节流（throttle）与防抖（debounce）.html":{"url":"前端性能优化/13.应用篇2：事件的节流（throttle）与防抖（debounce）.html","title":"13.应用篇2：事件的节流（throttle）与防抖（debounce）","keywords":"","body":"事件的节流（throttle）与防抖（debounce） 上一节我们一起通过监听滚动事件，实现了各大网站喜闻乐见的懒加载效果。但我们提到，scroll 事件是一个非常容易被反复触发的事件。其实不止 scroll 事件，resize 事件、鼠标事件（比如 mousemove、mouseover 等）、键盘事件（keyup、keydown 等）都存在被频繁触发的风险。 频繁触发回调导致的大量计算会引发页面的抖动甚至卡顿。为了规避这种情况，我们需要一些手段来控制事件被触发的频率。就是在这样的背景下，throttle（事件节流）和 debounce（事件防抖）出现了。 “节流”与“防抖”的本质 这两个东西都以闭包的形式存在。 它们通过对事件对应的回调函数进行包裹、以自由变量的形式缓存时间信息，最后用 setTimeout 来控制事件的触发频率。 Throttle： 第一个人说了算 throttle 的中心思想在于：在某段时间内，不管你触发了多少次回调，我都只认第一次，并在计时结束时给予响应。 先给大家讲个小故事：现在有一个旅客刚下了飞机，需要用车，于是打电话叫了该机场唯一的一辆机场大巴来接。司机开到机场，心想来都来了，多接几个人一起走吧，这样这趟才跑得值——我等个十分钟看看。于是司机一边打开了计时器，一边招呼后面的客人陆陆续续上车。在这十分钟内，后面下飞机的乘客都只能乘这一辆大巴，十分钟过去后，不管后面还有多少没挤上车的乘客，这班车都必须发走。 在这个故事里，“司机” 就是我们的节流阀，他控制发车的时机；“乘客”就是因为我们频繁操作事件而不断涌入的回调任务，它需要接受“司机”的安排；而“计时器”，就是我们上文提到的以自由变量形式存在的时间信息，它是“司机”决定发车的依据；最后“发车”这个动作，就对应到回调函数的执行。 总结下来，所谓的“节流”，是通过在一段时间内无视后来产生的回调请求来实现的。只要一位客人叫了车，司机就会为他开启计时器，一定的时间内，后面需要乘车的客人都得排队上这一辆车，谁也无法叫到更多的车。 对应到实际的交互上是一样一样的：每当用户触发了一次 scroll 事件，我们就为这个触发操作开启计时器。一段时间内，后续所有的 scroll 事件都会被当作“一辆车的乘客”——它们无法触发新的 scroll 回调。直到“一段时间”到了，第一次触发的 scroll 事件对应的回调才会执行，而“一段时间内”触发的后续的 scroll 回调都会被节流阀无视掉。 理解了大致的思路，我们现在一起实现一个 throttle： // fn是我们需要包装的事件回调, interval是时间间隔的阈值 function throttle(fn, interval) { // last为上一次触发回调的时间 let last = 0 // 将throttle处理结果当作函数返回 return function () { // 保留调用时的this上下文 let context = this // 保留调用时传入的参数 let args = arguments // 记录本次触发回调的时间 let now = +new Date() // 判断上次触发的时间和本次触发的时间差是否小于时间间隔的阈值 if (now - last >= interval) { // 如果时间间隔大于我们设定的时间间隔阈值，则执行回调 last = now; fn.apply(context, args); } } } // 用throttle来包装scroll的回调 const better_scroll = throttle(() => console.log('触发了滚动事件'), 1000) document.addEventListener('scroll', better_scroll) Debounce： 最后一个人说了算 防抖的中心思想在于：我会等你到底。在某段时间内，不管你触发了多少次回调，我都只认最后一次。 继续讲司机开车的故事。这次的司机比较有耐心。第一个乘客上车后，司机开始计时（比如说十分钟）。十分钟之内，如果又上来了一个乘客，司机会把计时器清零，重新开始等另一个十分钟（延迟了等待）。直到有这么一位乘客，从他上车开始，后续十分钟都没有新乘客上车，司机会认为确实没有人需要搭这趟车了，才会把车开走。 我们对比 throttle 来理解 debounce：在throttle的逻辑里，“第一个人说了算”，它只为第一个乘客计时，时间到了就执行回调。而 debounce 认为，“最后一个人说了算”，debounce 会为每一个新乘客设定新的定时器。 我们基于上面的理解，一起来写一个 debounce： // fn是我们需要包装的事件回调, delay是每次推迟执行的等待时间 function debounce(fn, delay) { // 定时器 let timer = null // 将debounce处理结果当作函数返回 return function () { // 保留调用时的this上下文 let context = this // 保留调用时传入的参数 let args = arguments // 每次事件被触发时，都去清除之前的旧定时器 if(timer) { clearTimeout(timer) } // 设立新定时器 timer = setTimeout(function () { fn.apply(context, args) }, delay) } } // 用debounce来包装scroll的回调 const better_scroll = debounce(() => console.log('触发了滚动事件'), 1000) document.addEventListener('scroll', better_scroll) 用 Throttle 来优化 Debounce debounce 的问题在于它“太有耐心了”。试想，如果用户的操作十分频繁——他每次都不等 debounce 设置的 delay 时间结束就进行下一次操作，于是每次 debounce 都为该用户重新生成定时器，回调函数被延迟了不计其数次。频繁的延迟会导致用户迟迟得不到响应，用户同样会产生“这个页面卡死了”的观感。 为了避免弄巧成拙，我们需要借力 throttle 的思想，打造一个“有底线”的 debounce——等你可以，但我有我的原则：delay 时间内，我可以为你重新生成定时器；但只要delay的时间到了，我必须要给用户一个响应。这个 throttle 与 debounce “合体”思路，已经被很多成熟的前端库应用到了它们的加强版 throttle 函数的实现中： // fn是我们需要包装的事件回调, delay是时间间隔的阈值 function throttle(fn, delay) { // last为上一次触发回调的时间, timer是定时器 let last = 0, timer = null // 将throttle处理结果当作函数返回 return function () { // 保留调用时的this上下文 let context = this // 保留调用时传入的参数 let args = arguments // 记录本次触发回调的时间 let now = +new Date() // 判断上次触发的时间和本次触发的时间差是否小于时间间隔的阈值 if (now - last console.log('触发了滚动事件'), 1000) document.addEventListener('scroll', better_scroll) 小结 throttle 和 debounce 不仅是我们日常开发中的常用优质代码片段，更是前端面试中不可不知的高频考点。“看懂了代码”、“理解了过程”在本节都是不够的，重要的是把它写到自己的项目里去，亲自体验一把节流和防抖带来的性能提升。 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/14.性能监测篇：Performance、LightHouse与性能API.html":{"url":"前端性能优化/14.性能监测篇：Performance、LightHouse与性能API.html","title":"14.性能监测篇：Performance、LightHouse与性能API","keywords":"","body":"Performance、LightHouse 与性能 API 性能监测是前端性能优化的重要一环。监测的目的是为了确定性能瓶颈，从而有的放矢地开展具体的优化工作。 平时我们比较推崇的性能监测方案主要有两种：可视化方案、可编程方案。这两种方案下都有非常优秀、且触手可及的相关工具供大家选择，本节我们就一起来研究一下这些工具的用法。 可视化监测：从 Performance 面板说起 Performance 是 Chrome 提供给我们的开发者工具，用于记录和分析我们的应用在运行时的所有活动。它呈现的数据具有实时性、多维度的特点，可以帮助我们很好地定位性能问题。 开始记录 右键打开开发者工具，选中我们的 Performance 面板： 当我们选中图中所标示的实心圆按钮，Performance 会开始帮我们记录我们后续的交互操作；当我们选中圆箭头按钮，Performance 会将页面重新加载，计算加载过程中的性能表现。tips：使用 Performance 工具时，为了规避其它 Chrome 插件对页面的性能影响，我们最好在无痕模式下打开页面： 简要分析 这里我打开掘金首页，选中 Performance 面板中的圆箭头，来看一下页面加载过程中的性能表现： 从上到下，依次为概述面板、详情面板。下我们先来观察一下概述面板，了解页面的基本表现： 我们看右上角的三个栏目：FPS、CPU 和 NET。 FPS：这是一个和动画性能密切相关的指标，它表示每一秒的帧数。图中绿色柱状越高表示帧率越高，体验就越流畅。若出现红色块，则代表长时间帧，很可能会出现卡顿。图中以绿色为主，偶尔出现红块，说明网页性能并不糟糕，但仍有可优化的空间。 CPU：表示CPU的使用情况，不同的颜色片段代表着消耗CPU资源的不同事件类型。这部分的图像和下文详情面板中的Summary内容有对应关系，我们可以结合这两者挖掘性能瓶颈。 NET：粗略的展示了各请求的耗时与前后顺序。这个指标一般来说帮助不大。 挖掘性能瓶颈 详情面板中的内容有很多。但一般来说，我们会主要去看 Main 栏目下的火焰图和 Summary 提供给我们的饼图——这两者和概述面板中的 CPU 一栏结合，可以帮我们迅速定位性能瓶颈（如下图）。 先看 CPU 图表和 Summary 饼图。CPU 图表中，我们可以根据颜色填充的饱满程度，确定 CPU 的忙闲，进而了解该页面的总的任务量。而 Summary 饼图则以一种直观的方式告诉了我们，哪个类型的任务最耗时（从本例来看是脚本执行过程）。这样我们在优化的时候，就可以抓到“主要矛盾”，进而有的放矢地开展后续的工作了。 再看 Main 提供给我们的火焰图。这个火焰图非常关键，它展示了整个运行时主进程所做的每一件事情（包括加载、脚本运行、渲染、布局、绘制等）。x 轴表示随时间的记录。每个长条就代表一个活动。更宽的条形意味着事件需要更长时间。y 轴表示调用堆栈，我们可以看到事件是相互堆叠的，上层的事件触发了下层的事件。 CPU 图标和 Summary 图都是按照“类型”给我们提供性能信息，而 Main 火焰图则将粒度细化到了每一个函数的调用。到底是从哪个过程开始出问题、是哪个函数拖了后腿、又是哪个事件触发了这个函数，这些具体的、细致的问题都将在 Main 火焰图中得到解答。 可视化监测： 更加聪明的 LightHouse Performance 无疑可以为我们提供很多有价值的信息，但它的展示作用大于分析作用。它要求使用者对工具本身及其所展示的信息有充分的理解，能够将晦涩的数据“翻译”成具体的性能问题。 程序员们许了个愿：如果工具能帮助我们把页面的问题也分析出来就好了！上帝听到了这个愿望，于是给了我们 LightHouse： Lighthouse 是一个开源的自动化工具，用于改进网络应用的质量。 你可以将其作为一个 Chrome 扩展程序运行，或从命令行运行。 为Lighthouse 提供一个需要审查的网址，它将针对此页面运行一连串的测试，然后生成一个有关页面性能的报告。 敲黑板划重点：它生成的是一个报告！Report！不是干巴巴地数据，而是一个通过测试与分析呈现出来的结果（它甚至会给你的页面跑一个分数出来）。这个东西看起来也真是太赞了，我们这就来体验一下！ 首先在 Chrome 的应用商店里下载一个 LightHouse。这一步 OK 之后，我们浏览器右上角会出现一个小小的灯塔 ICON。打开我们需要测试的那个页面，点击这个 ICON，唤起如下的面板： 然后点击“Generate report”按钮，只需静候数秒，LightHouse 就会为我们输出一个完美的性能报告。 这里我拿掘金小册首页“开刀”： 稍事片刻，Report 便输出成功了，LightHouse 默认会帮我们打开一个新的标签页来展示报告内容。报告内容非常丰富，首先我们看到的是整体的跑分情况： 上述分别是页面性能、PWA（渐进式 Web 应用）、可访问性（无障碍）、最佳实践、SEO 五项指标的跑分。孰强孰弱，我们一看便知。 向下拉动 Report 页，我们还可以看到每一个指标的细化评估： 在“Opportunities”中，LightHouse 甚至针对我们的性能问题给出了可行的建议、以及每一项优化操作预期会帮我们节省的时间。这份报告的可操作性是很强的——我们只需要对着 LightHouse 给出的建议，一条一条地去尝试，就可以看到自己的页面，在一秒一秒地变快。 除了直接下载，我们还可以通过命令行使用 LightHouse： npm install -g lighthouse lighthouse https://juejin.im/books 同样可以得到掘金小册的性能报告。 此外，从 Chrome 60 开始，DevTools 中直接加入了基于 LightHouse 的 Audits 面板： LightHouse 因此变得更加触手可及了，这一操作也足以证明 Chrome 团队对 LightHouse 的推崇。 可编程的性能上报方案： W3C 性能 API W3C 规范为我们提供了 Performance 相关的接口。它允许我们获取到用户访问一个页面的每个阶段的精确时间，从而对性能进行分析。我们可以将其理解为 Performance 面板的进一步细化与可编程化。 当下的前端世界里，数据可视化的概念已经被炒得非常热了，Performance 面板就是数据可视化的典范。那么为什么要把已经可视化的数据再掏出来处理一遍呢？这是因为，需要这些数据的人不止我们前端——很多情况下，后端也需要我们提供性能信息的上报。此外，Performance 提供的可视化结果并不一定能够满足我们实际的业务需求，只有拿到了真实的数据，我们才可以对它进行二次处理，去做一个更加深层次的可视化。 在这种需求背景下，我们就不得不祭出 Performance API了。 访问 performance 对象 performance 是一个全局对象。我们在控制台里输入 window.performance，就可一窥其全貌： 关键时间节点 在 performance 的 timing 属性中，我们可以查看到如下的时间戳： 这些时间戳与页面整个加载流程中的关键时间节点有着一一对应的关系： 通过求两个时间点之间的差值，我们可以得出某个过程花费的时间，举个🌰： const timing = window.performance.timing // DNS查询耗时 timing.domainLookupEnd - timing.domainLookupStart // TCP连接耗时 timing.connectEnd - timing.connectStart // 内容加载耗时 timing.responseEnd - timing.requestStart ··· 除了这些常见的耗时情况，我们更应该去关注一些关键性能指标：firstbyte、fpt、tti、ready 和 load 时间。这些指标数据与真实的用户体验息息相关，是我们日常业务性能监测中不可或缺的一部分： // firstbyte：首包时间 timing.responseStart – timing.domainLookupStart // fpt：First Paint Time, 首次渲染时间 / 白屏时间 timing.responseEnd – timing.fetchStart // tti：Time to Interact，首次可交互时间 timing.domInteractive – timing.fetchStart // ready：HTML 加载完成时间，即 DOM 就位的时间 timing.domContentLoaded – timing.fetchStart // load：页面完全加载时间 timing.loadEventStart – timing.fetchStart 以上这些通过 Performance API 获取到的时间信息都具有较高的准确度。我们可以对此进行一番格式处理之后上报给服务端，也可以基于此去制作相应的统计图表，从而实现更加精准、更加个性化的性能耗时统计。 此外，通过访问 performance 的 memory 属性，我们还可以获取到内存占用相关的数据；通过对 performance 的其它属性方法的灵活运用，我们还可以把它耦合进业务里，实现更加多样化的性能监测需求——灵活，是可编程化方案最大的优点。 小结 本节我们介绍了 Performance 开发者工具、LightHouse 与 Performance API 三种性能监测的方案。只要有 Chrome 浏览器，我们就可以实现上述的所有操作。 由此可以看出，性能监测本身并不难。它的复杂度是在与业务发生耦合的过程中提升的。我们今天打下了坚实的地基，后续需要大家在业务中去成长、去发掘这些工具的更多的潜力，这样才能建立起属于我们自己的技术金字塔。 推荐阅读： Performance 官方文档 使用 Lighthouse 审查网络应用 MDN Performance API 介绍 （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端性能优化/15.前方的路：希望以此为你的起点.html":{"url":"前端性能优化/15.前方的路：希望以此为你的起点.html","title":"15.前方的路：希望以此为你的起点","keywords":"","body":"前方的路：希望成为你的起点 感谢 首先要谢谢每一位读到最后一章的同学。这是我的第一本小册，也是我第一次撰写对外开放的知识内容，谢谢大家选择了这本小册，选择了我这个作者。 未完成的故事 对笔者来说，撰写小册的两个月，是挑战重重的两个月。在这个过程中，笔者时时刻刻都在与“程序员”和“技术作者”这两个角色较劲。前者要求我锱铢必较、求深求全，后者则需要我在小册内容的深度、广度与可读性之间作出权衡。正是因为有了这一番又一番的权衡，它才终于被打磨成了一本篇幅短小、卖相可爱的“小册”，而非一本庞大的、令人望而生畏的“手册”。 但也是因为如此，小册里多出了一些“未完成的故事”。比如网络优化这部分，我想可能会有同学兴致勃勃地想听一听 DNS 的预解析或者 TCP 协议的负载均衡；再比如资源加载这一块，为什么说了 async 和 defer，却没有提 preload 和 prefetch 呢？又或者比较追逐“潮流”的同学，心心念念的是 Service Worker 和 Web Worker 的应用方案；甚至所在团队性能这块还没做起来的同学，希望我可以提供能够耦合进业务的性能监测方案，等等（这些都是非常实际的阅读需求）。 但正如我开篇所说的，我的初心并非是为大家提供一本面面俱到的“手册”。前端性能优化的知识点零碎、不成体系，这是它学习的痛点，也是小册想要解决的问题。有许多同样精彩的性能知识，我们可以针对它做技术方案测试、可以为它开研讨会，但它并不适合出现在小册的写作大纲里、以短文的形式呈现。我希望呈现给大家的内容，是前后相连，自成体系的“一串”知识。是大家在学习、工作之余，在等公交、搭地铁的间隙，在碎片化的时间里，仍然能够轻松阅读并理解的友好内容。 前方的路 小册之愿，是希望成为大家性能优化这条路上的起点。 相对于模式成熟、方案完善的服务端性能优化来说，前端性能优化整体的起步是比较晚的。但在当今的大环境下，它又是极其重要的一个工作。我们是离用户最近的工程师，需要直接对用户的体验负责。因此，我们需要做的努力还有太多太多。 既然已经读到了最后一章，我想大家应该都收获了一张属于自己的前端性能优化的核心知识“索引表”——我希望它能成为大家的起点，成为各位今后拓展相关技能的素材。当下前端世界里，提起技术，许多初学者第一反应仍然是学框架、学工具。框架和工具固然重要，但一个合格的前端工程师，还应该具有抽象思维的能力和技术攻关的实力——这两点，都可以在性能优化的学习和实践过程中得到磨炼和凸显。 在庞大的前端性能知识体系面前，一本单薄的小册是远远不够的。接下来大家要做的，就是实践、实践、再实践！反复地阅读文字、一味地深究理论是无法使我们的技能变“厚”的，最好的办法就是去做，去用，在用的过程中发现问题、解决问题、拓展问题——那些“未完成的故事”，一定会在这个过程中被你书写圆满。 把这张“索引表”装进行囊，继续征战你的前端性能优化之旅吧！ （阅读过程中有任何想法或疑问，或者单纯希望和笔者交个朋友啥的，欢迎大家添加我的微信xyalinode与我交流哈~） "},"前端面试之道/01.小册食用指南.html":{"url":"前端面试之道/01.小册食用指南.html","title":"01.小册食用指南","keywords":"","body":"小册食用指南 这本小册涉及的内容十分广，在这里我提供了一份小册的食用指南，帮助你更好地阅读小册。 无论是你刚刚开始学习小册还是想复习小册内容，这份食用指南都能很好地帮助到你。 购买前警告⚠️ 此小册不适合完全没有前端基础的人阅读，需要各位掌握基本的 HTML、JS，担心小册质量或者是内容是否适合自己的，请先浏览试读章节再做购买决定 小册还在预售中，所以内容是还没有完结的，但是大家不需要担心作者是否会跑路的问题。因为小册没有完结之前，钱都是在掘金手里的，只有当完结内容才会和作者结账。 此小册不会让你的技术一蹴而就，直接从三线公司跳到一线大厂，想进大公司必定是需要个人实力足够才行，当然小册的内容应付一般的公司完全没什么问题。 发售福利 当下预售售价为 39.9 元，小册完结后将会提价到 49.9 元 欢迎大家在交流群中多交流学习及面试相关的内容，目前群内交流气氛很浓厚，通过交流可以了解到很多面试相关的内容。 加群途径 内容 在今年，我搜集了各大公司的面试题，有自己去面试获得的，也有身边的朋友分享给我的。我一直认为，面向题目应对面试是没什么大的帮助的，即使有，也只是治标不治本。 因为每道面试题背后都会涉及到几个知识点，如果我们能够扎实地学习这些知识点的话，那么无论题目怎么变，只要涉及的知识点不变，那我们就能以不变应万变。 所以，我将这些收罗到的面试题背后所涉及的知识点一一提炼出来，并整理出了常考的知识点。当然小册所涉及的内容远远不止常考的知识点，还包罗了一部分我认为重要的知识点（虽然考的不多）、面试技巧和学习资料。 总的来说，整本小册涉及到了十四个模块，每一模块中又包含了许许多多的知识点。每一模块都自成体系但是又会与其他模块中的内容有交集。比如说浏览器、Webpack、网络协议这几个模块中涉及到的部分内容和性能优化模块是相互关联的。 如果你是刚刚开始阅读小册的内容，可以根据自己的薄弱点，对症下药，学习相应的模块。但是学习单个模块中的内容时不推荐跳着阅读，因为很可能后面的内容与之前的有所联系，没有理解之前的知识点的话，可能会对后续的学习会造成困扰。 在你学习的过程中，我又给大部分的知识点提供了 1 - 3 道面试题，你可以通过学习知识点的方式尝试自己去攻克面试题。当你学习完整个模块后，我又提供了几道思考题，帮助你检验自身的学习成果，查漏补缺。 小册的内容会持续的更新（更新日志都放在首页），毕竟面试涉及的知识点很广，内容可能会存在勘误或者不清楚的地方，并且前端技术更新很快，我会尽可能的让小册内容符合当下最新的技术。可预见的是 Vue 3.0 更新以后，小册中关于 Vue 的内容势必也会更新。如果你是在非官方渠道阅读到这本小册的话，为了你学习到的内容符合当下，你可以选择 支持正版，购买小册。 最后，学习知识一定要配合实践，没有实践的知识是没有灵魂的。另外，碍于篇幅，我不可能深挖每个知识点，所以推荐大家去尝试挖掘我没有涉及到的内容。 思考题 在大部分的模块内容结束后，我都提供了几道思考题。虽然每道思考题通过题意我们可能只能理解到背后所考的 1 - 2 个知识点，但是其实很多知识点是有串联关系的。 在面试过程中，如果经常和面试官出现一问一答的情况的话，其实是不够理想的。虽然一道面试题看起来只涉及了一个知识点，但是如果你脑海中的知识点是串联起来的话，就可以引申出其他的知识点，这样能给到面试官一个好的印象。 每道思考题我都给出了一些个人的思路引导，帮助大家建立起知识点之间的串联关系，彻底理解这个模块中所涉及到的知识点。 记录与分享 我个人写博客已经持续了三年了。写博客是一个很好的习惯，一方面能帮助自己理解知识，另一方面也能打造个人的影响力，所以我也很推荐大家能养成这个习惯。 为了推动大家更有动力的去记录与分享，我后面会单独用一个章节的内容去存放我认为写的不错的博客。如果你想对知识点有所记录，或者分享解答面试题、思考题的个人理解，都可以在评论中给出你的分享地址。我都会认真地去阅读，挑选出好的内容单独放入一个章节中，这样就有更多的人能看到你的分享。 最后，这本小册不一定能让你在很短的时间内就让你的技术一夜突飞猛进，但是如果你能细细阅读的话，绝对能让你醍醐灌顶。好了，食用指南结束了，接下来让我们进入小册的知识海洋吧。 "},"前端面试之道/02.JS基础知识点及常考面试题（一）.html":{"url":"前端面试之道/02.JS基础知识点及常考面试题（一）.html","title":"02.JS基础知识点及常考面试题（一）","keywords":"","body":"JS 基础知识点及常考面试题（一） JS 对于每位前端开发都是必备技能，在小册中我们也会有多个章节去讲述这部分的知识。首先我们先来熟悉下 JS 的一些常考和容易混乱的基础知识点。 原始（Primitive）类型 涉及面试题：原始类型有哪几种？null 是对象嘛？ 在 JS 中，存在着 6 种原始值，分别是： boolean null undefined number string symbol 首先原始类型存储的都是值，是没有函数可以调用的，比如 undefined.toString() 此时你肯定会有疑问，这不对呀，明明 '1'.toString() 是可以使用的。其实在这种情况下，'1' 已经不是原始类型了，而是被强制转换成了 String 类型也就是对象类型，所以可以调用 toString 函数。 除了会在必要的情况下强转类型以外，原始类型还有一些坑。 其中 JS 的 number 类型是浮点类型的，在使用中会遇到某些 Bug，比如 0.1 + 0.2 !== 0.3，但是这一块的内容会在进阶部分讲到。string 类型是不可变的，无论你在 string 类型上调用何种方法，都不会对值有改变。 另外对于 null 来说，很多人会认为他是个对象类型，其实这是错误的。虽然 typeof null 会输出 object，但是这只是 JS 存在的一个悠久 Bug。在 JS 的最初版本中使用的是 32 位系统，为了性能考虑使用低位存储变量的类型信息，000 开头代表是对象，然而 null 表示为全零，所以将它错误的判断为 object 。虽然现在的内部类型判断代码已经改变了，但是对于这个 Bug 却是一直流传下来。 对象（Object）类型 涉及面试题：对象类型和原始类型的不同之处？函数参数是对象会发生什么问题？ 在 JS 中，除了原始类型那么其他的都是对象类型了。对象类型和原始类型不同的是，原始类型存储的是值，对象类型存储的是地址（指针）。当你创建了一个对象类型的时候，计算机会在内存中帮我们开辟一个空间来存放值，但是我们需要找到这个空间，这个空间会拥有一个地址（指针）。 const a = [] 对于常量 a 来说，假设内存地址（指针）为 #001，那么在地址 #001 的位置存放了值 []，常量 a 存放了地址（指针） #001，再看以下代码 const a = [] const b = a b.push(1) 当我们将变量赋值给另外一个变量时，复制的是原本变量的地址（指针），也就是说当前变量 b 存放的地址（指针）也是 #001，当我们进行数据修改的时候，就会修改存放在地址（指针） #001 上的值，也就导致了两个变量的值都发生了改变。 接下来我们来看函数参数是对象的情况 function test(person) { person.age = 26 person = { name: 'yyy', age: 30 } return person } const p1 = { name: 'yck', age: 25 } const p2 = test(p1) console.log(p1) // -> ? console.log(p2) // -> ? 对于以上代码，你是否能正确的写出结果呢？接下来让我为你解析一番： 首先，函数传参是传递对象指针的副本 到函数内部修改参数的属性这步，我相信大家都知道，当前 p1 的值也被修改了 但是当我们重新为 person 分配了一个对象时就出现了分歧，请看下图 所以最后 person 拥有了一个新的地址（指针），也就和 p1 没有任何关系了，导致了最终两个变量的值是不相同的。 typeof vs instanceof 涉及面试题：typeof 是否能正确判断类型？instanceof 能正确判断对象的原理是什么？ typeof 对于原始类型来说，除了 null 都可以显示正确的类型 typeof 1 // 'number' typeof '1' // 'string' typeof undefined // 'undefined' typeof true // 'boolean' typeof Symbol() // 'symbol' typeof 对于对象来说，除了函数都会显示 object，所以说 typeof 并不能准确判断变量到底是什么类型 typeof [] // 'object' typeof {} // 'object' typeof console.log // 'function' 如果我们想判断一个对象的正确类型，这时候可以考虑使用 instanceof，因为内部机制是通过原型链来判断的，在后面的章节中我们也会自己去实现一个 instanceof。 const Person = function() {} const p1 = new Person() p1 instanceof Person // true var str = 'hello world' str instanceof String // false var str1 = new String('hello world') str1 instanceof String // true 对于原始类型来说，你想直接通过 instanceof 来判断类型是不行的，当然我们还是有办法让 instanceof 判断原始类型的 class PrimitiveString { static [Symbol.hasInstance](x) { return typeof x === 'string' } } console.log('hello world' instanceof PrimitiveString) // true 你可能不知道 Symbol.hasInstance 是什么东西，其实就是一个能让我们自定义 instanceof 行为的东西，以上代码等同于 typeof 'hello world' === 'string'，所以结果自然是 true 了。这其实也侧面反映了一个问题， instanceof 也不是百分之百可信的。 类型转换 涉及面试题：该知识点常在笔试题中见到，熟悉了转换规则就不惧怕此类题目了。 首先我们要知道，在 JS 中类型转换只有三种情况，分别是： 转换为布尔值 转换为数字 转换为字符串 我们先来看一个类型转换表格，然后再进入正题 注意图中有一个错误，Boolean 转字符串这行结果我指的是 true 转字符串的例子，不是说 Boolean、函数、Symblo 转字符串都是 `true` 转Boolean 在条件判断时，除了 undefined， null， false， NaN， ''， 0， -0，其他所有值都转为 true，包括所有对象。 对象转原始类型 对象在转换类型的时候，会调用内置的 [[ToPrimitive]] 函数，对于该函数来说，算法逻辑一般来说如下： 如果已经是原始类型了，那就不需要转换了 如果需要转字符串类型就调用 x.toString()，转换为基础类型的话就返回转换的值。不是字符串类型的话就先调用 valueOf，结果不是基础类型的话再调用 toString 调用 x.valueOf()，如果转换为基础类型，就返回转换的值 如果都没有返回原始类型，就会报错 当然你也可以重写 Symbol.toPrimitive ，该方法在转原始类型时调用优先级最高。 let a = { valueOf() { return 0 }, toString() { return '1' }, [Symbol.toPrimitive]() { return 2 } } 1 + a // => 3 四则运算符 加法运算符不同于其他几个运算符，它有以下几个特点： 运算中其中一方为字符串，那么就会把另一方也转换为字符串 如果一方不是字符串或者数字，那么会将它转换为数字或者字符串 1 + '1' // '11' true + true // 2 4 + [1,2,3] // \"41,2,3\" 如果你对于答案有疑问的话，请看解析： 对于第一行代码来说，触发特点一，所以将数字 1 转换为字符串，得到结果 '11' 对于第二行代码来说，触发特点二，所以将 true 转为数字 1 对于第三行代码来说，触发特点二，所以将数组通过 toString 转为字符串 1,2,3，得到结果 41,2,3 另外对于加法还需要注意这个表达式 'a' + + 'b' 'a' + + 'b' // -> \"aNaN\" 因为 + 'b' 等于 NaN，所以结果为 \"aNaN\"，你可能也会在一些代码中看到过 + '1' 的形式来快速获取 number 类型。 那么对于除了加法的运算符来说，只要其中一方是数字，那么另一方就会被转为数字 4 * '3' // 12 4 * [] // 0 4 * [1, 2] // NaN 比较运算符 如果是对象，就通过 toPrimitive 转换对象 如果是字符串，就通过 unicode 字符索引来比较 let a = { valueOf() { return 0 }, toString() { return '1' } } a > -1 // true 在以上代码中，因为 a 是对象，所以会通过 valueOf 转换为原始类型再比较值。 this 涉及面试题：如何正确判断 this？箭头函数的 this 是什么？ this 是很多人会混淆的概念，但是其实它一点都不难，只是网上很多文章把简单的东西说复杂了。在这一小节中，你一定会彻底明白 this 这个概念的。 我们先来看几个函数调用的场景 function foo() { console.log(this.a) } var a = 1 foo() const obj = { a: 2, foo: foo } obj.foo() const c = new foo() 接下来我们一个个分析上面几个场景 对于直接调用 foo 来说，不管 foo 函数被放在了什么地方，this 一定是 window 对于 obj.foo() 来说，我们只需要记住，谁调用了函数，谁就是 this，所以在这个场景下 foo 函数中的 this 就是 obj 对象 对于 new 的方式来说，this 被永远绑定在了 c 上面，不会被任何方式改变 this 说完了以上几种情况，其实很多代码中的 this 应该就没什么问题了，下面让我们看看箭头函数中的 this function a() { return () => { return () => { console.log(this) } } } console.log(a()()()) 首先箭头函数其实是没有 this 的，箭头函数中的 this 只取决包裹箭头函数的第一个普通函数的 this。在这个例子中，因为包裹箭头函数的第一个普通函数是 a，所以此时的 this 是 window。另外对箭头函数使用 bind 这类函数是无效的。 最后种情况也就是 bind 这些改变上下文的 API 了，对于这些函数来说，this 取决于第一个参数，如果第一个参数为空，那么就是 window。 那么说到 bind，不知道大家是否考虑过，如果对一个函数进行多次 bind，那么上下文会是什么呢？ let a = {} let fn = function () { console.log(this) } fn.bind().bind(a)() // => ? 如果你认为输出结果是 a，那么你就错了，其实我们可以把上述代码转换成另一种形式 // fn.bind().bind(a) 等于 let fn2 = function fn1() { return function() { return fn.apply() }.apply(a) } fn2() 可以从上述代码中发现，不管我们给函数 bind 几次，fn 中的 this 永远由第一次 bind 决定，所以结果永远是 window。 let a = { name: 'yck' } function foo() { console.log(this.name) } foo.bind(a)() // => 'yck' 以上就是 this 的规则了，但是可能会发生多个规则同时出现的情况，这时候不同的规则之间会根据优先级最高的来决定 this 最终指向哪里。 首先，new 的方式优先级最高，接下来是 bind 这些函数，然后是 obj.foo() 这种调用方式，最后是 foo 这种调用方式，同时，箭头函数的 this 一旦被绑定，就不会再被任何方式所改变。 如果你还是觉得有点绕，那么就看以下的这张流程图吧，图中的流程只针对于单个规则。 小结 以上就是我们 JS 基础知识点的第一部分内容了。这一小节中涉及到的知识点在我们日常的开发中经常可以看到，并且很多容易出现的坑 也出自于这些知识点，相信认真读完的你一定会在日后的开发中少踩很多坑。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/03.JS基础知识点及常考面试题（二）.html":{"url":"前端面试之道/03.JS基础知识点及常考面试题（二）.html","title":"03.JS基础知识点及常考面试题（二）","keywords":"","body":"JS 基础知识点及常考面试题（二） 在这一章节中我们继续来了解 JS 的一些常考和容易混乱的基础知识点。 \\== vs === 涉及面试题：== 和 === 有什么区别？ 对于 == 来说，如果对比双方的类型不一样的话，就会进行类型转换，这也就用到了我们上一章节讲的内容。 假如我们需要对比 x 和 y 是否相同，就会进行如下判断流程： 首先会判断两者类型是否相同。相同的话就是比大小了 类型不相同的话，那么就会进行类型转换 会先判断是否在对比 null 和 undefined，是的话就会返回 true 判断两者类型是否为 string 和 number，是的话就会将字符串转换为 number 1 == '1' ↓ 1 == 1 判断其中一方是否为 boolean，是的话就会把 boolean 转为 number 再进行判断 '1' == true ↓ '1' == 1 ↓ 1 == 1 判断其中一方是否为 object 且另一方为 string、number 或者 symbol，是的话就会把 object 转为原始类型再进行判断 '1' == { name: 'yck' } ↓ '1' == '[object Object]' 思考题：看完了上面的步骤，对于 [] == ![] 你是否能正确写出答案呢？ 如果你觉得记忆步骤太麻烦的话，我还提供了流程图供大家使用： 当然了，这个流程图并没有将所有的情况都列举出来，我这里只将常用到的情况列举了，如果你想了解更多的内容可以参考 标准文档。 对于 === 来说就简单多了，就是判断两者类型和值是否相同。 更多的对比可以阅读这篇 文章 闭包 涉及面试题：什么是闭包？ 闭包的定义其实很简单：函数 A 内部有一个函数 B，函数 B 可以访问到函数 A 中的变量，那么函数 B 就是闭包。 function A() { let a = 1 window.B = function () { console.log(a) } } A() B() // 1 很多人对于闭包的解释可能是函数嵌套了函数，然后返回一个函数。其实这个解释是不完整的，就比如我上面这个例子就可以反驳这个观点。 在 JS 中，闭包存在的意义就是让我们可以间接访问函数内部的变量。 经典面试题，循环中使用闭包解决 `var` 定义函数的问题 for (var i = 1; i 首先因为 setTimeout 是个异步函数，所以会先把循环全部执行完毕，这时候 i 就是 6 了，所以会输出一堆 6。 解决办法有三种，第一种是使用闭包的方式 for (var i = 1; i 在上述代码中，我们首先使用了立即执行函数将 i 传入函数内部，这个时候值就被固定在了参数 j 上面不会改变，当下次执行 timer 这个闭包的时候，就可以使用外部函数的变量 j，从而达到目的。 第二种就是使用 setTimeout 的第三个参数，这个参数会被当成 timer 函数的参数传入。 for (var i = 1; i 第三种就是使用 let 定义 i 了来解决问题了，这个也是最为推荐的方式 for (let i = 1; i 深浅拷贝 涉及面试题：什么是浅拷贝？如何实现浅拷贝？什么是深拷贝？如何实现深拷贝？ 在上一章节中，我们了解了对象类型在赋值的过程中其实是复制了地址，从而会导致改变了一方其他也都被改变的情况。通常在开发中我们不希望出现这样的问题，我们可以使用浅拷贝来解决这个情况。 let a = { age: 1 } let b = a a.age = 2 console.log(b.age) // 2 浅拷贝 首先可以通过 Object.assign 来解决这个问题，很多人认为这个函数是用来深拷贝的。其实并不是，Object.assign 只会拷贝所有的属性值到新的对象中，如果属性值是对象的话，拷贝的是地址，所以并不是深拷贝。 let a = { age: 1 } let b = Object.assign({}, a) a.age = 2 console.log(b.age) // 1 另外我们还可以通过展开运算符 ... 来实现浅拷贝 let a = { age: 1 } let b = { ...a } a.age = 2 console.log(b.age) // 1 通常浅拷贝就能解决大部分问题了，但是当我们遇到如下情况就可能需要使用到深拷贝了 let a = { age: 1, jobs: { first: 'FE' } } let b = { ...a } a.jobs.first = 'native' console.log(b.jobs.first) // native 浅拷贝只解决了第一层的问题，如果接下去的值中还有对象的话，那么就又回到最开始的话题了，两者享有相同的地址。要解决这个问题，我们就得使用深拷贝了。 深拷贝 这个问题通常可以通过 JSON.parse(JSON.stringify(object)) 来解决。 let a = { age: 1, jobs: { first: 'FE' } } let b = JSON.parse(JSON.stringify(a)) a.jobs.first = 'native' console.log(b.jobs.first) // FE 但是该方法也是有局限性的： 会忽略 undefined 会忽略 symbol 不能序列化函数 不能解决循环引用的对象 let obj = { a: 1, b: { c: 2, d: 3, }, } obj.c = obj.b obj.e = obj.a obj.b.c = obj.c obj.b.d = obj.b obj.b.e = obj.b.c let newObj = JSON.parse(JSON.stringify(obj)) console.log(newObj) 如果你有这么一个循环引用对象，你会发现并不能通过该方法实现深拷贝 在遇到函数、 undefined 或者 symbol 的时候，该对象也不能正常的序列化 let a = { age: undefined, sex: Symbol('male'), jobs: function() {}, name: 'yck' } let b = JSON.parse(JSON.stringify(a)) console.log(b) // {name: \"yck\"} 你会发现在上述情况中，该方法会忽略掉函数和 undefined 。 但是在通常情况下，复杂数据都是可以序列化的，所以这个函数可以解决大部分问题。 如果你所需拷贝的对象含有内置类型并且不包含函数，可以使用 MessageChannel function structuralClone(obj) { return new Promise(resolve => { const { port1, port2 } = new MessageChannel() port2.onmessage = ev => resolve(ev.data) port1.postMessage(obj) }) } var obj = { a: 1, b: { c: 2 } } obj.b.d = obj.b // 注意该方法是异步的 // 可以处理 undefined 和循环引用对象 const test = async () => { const clone = await structuralClone(obj) console.log(clone) } test() 当然你可能想自己来实现一个深拷贝，但是其实实现一个深拷贝是很困难的，需要我们考虑好多种边界情况，比如原型链如何处理、DOM 如何处理等等，所以这里我们实现的深拷贝只是简易版，并且我其实更推荐使用 lodash 的深拷贝函数。 function deepClone(obj) { function isObject(o) { return (typeof o === 'object' || typeof o === 'function') && o !== null } if (!isObject(obj)) { throw new Error('非对象') } let isArray = Array.isArray(obj) let newObj = isArray ? [...obj] : { ...obj } Reflect.ownKeys(newObj).forEach(key => { newObj[key] = isObject(obj[key]) ? deepClone(obj[key]) : obj[key] }) return newObj } let obj = { a: [1, 2, 3], b: { c: 2, d: 3 } } let newObj = deepClone(obj) newObj.b.c = 1 console.log(obj.b.c) // 2 原型 涉及面试题：如何理解原型？如何理解原型链？ 当我们创建一个对象时 let obj = { age: 25 }，我们可以发现能使用很多种函数，但是我们明明没有定义过它们，对于这种情况你是否有过疑惑？ 当我们在浏览器中打印 obj 时你会发现，在 obj 上居然还有一个 __proto__ 属性，那么看来之前的疑问就和这个属性有关系了。 其实每个 JS 对象都有 __proto__ 属性，这个属性指向了原型。这个属性在现在来说已经不推荐直接去使用它了，这只是浏览器在早期为了让我们访问到内部属性 [[prototype]] 来实现的一个东西。 讲到这里好像还是没有弄明白什么是原型，接下来让我们再看看 __proto__ 里面有什么吧。 看到这里你应该明白了，原型也是一个对象，并且这个对象中包含了很多函数，所以我们可以得出一个结论：对于 obj 来说，可以通过 __proto__ 找到一个原型对象，在该对象中定义了很多函数让我们来使用。 在上面的图中我们还可以发现一个 constructor 属性，也就是构造函数 打开 constructor 属性我们又可以发现其中还有一个 prototype 属性，并且这个属性对应的值和先前我们在 __proto__ 中看到的一模一样。所以我们又可以得出一个结论：原型的 constructor 属性指向构造函数，构造函数又通过 prototype 属性指回原型，但是并不是所有函数都具有这个属性，Function.prototype.bind() 就没有这个属性。 其实原型就是那么简单，接下来我们再来看一张图，相信这张图能让你彻底明白原型和原型链 看完这张图，我再来解释下什么是原型链吧。其实原型链就是多个对象通过 __proto__ 的方式连接了起来。为什么 obj 可以访问到 valueOf 函数，就是因为 obj 通过原型链找到了 valueOf 函数。 对于这一小节的知识点，总结起来就是以下几点： Object 是所有对象的爸爸，所有对象都可以通过 __proto__ 找到它 Function 是所有函数的爸爸，所有函数都可以通过 __proto__ 找到它 函数的 prototype 是一个对象 对象的 __proto__ 属性指向原型， __proto__ 将对象和原型连接起来组成了原型链 如果你还想深入学习原型这部分的内容，可以阅读我之前写的文章 小结 以上就是全部的常考和容易混乱的基础知识点了，下一章节我们将会学习 ES6 部分的知识。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/04.ES6知识点及常考面试题.html":{"url":"前端面试之道/04.ES6知识点及常考面试题.html","title":"04.ES6知识点及常考面试题","keywords":"","body":"ES6 知识点及常考面试题 本章节我们将来学习 ES6 部分的内容。 var、let 及 const 区别 涉及面试题：什么是提升？什么是暂时性死区？var、let 及 const 区别？ 对于这个问题，我们应该先来了解提升（hoisting）这个概念。 console.log(a) // undefined var a = 1 从上述代码中我们可以发现，虽然变量还没有被声明，但是我们却可以使用这个未被声明的变量，这种情况就叫做提升，并且提升的是声明。 对于这种情况，我们可以把代码这样来看 var a console.log(a) // undefined a = 1 接下来我们再来看一个例子 var a = 10 var a console.log(a) 对于这个例子，如果你认为打印的值为 undefined 那么就错了，答案应该是 10，对于这种情况，我们这样来看代码 var a var a a = 10 console.log(a) 到这里为止，我们已经了解了 var 声明的变量会发生提升的情况，其实不仅变量会提升函数也会被提升。 console.log(a) // ƒ a() {} function a() {} var a = 1 对于上述代码，打印结果会是 ƒ a() {}，即使变量声明在函数之后，这也说明了函数会被提升，并且优先于变量提升。 说完了这些，想必大家也知道 var 存在的问题了，使用 var 声明的变量会被提升到作用域的顶部，接下来我们再来看 let 和 const 。 我们先来看一个例子： var a = 1 let b = 1 const c = 1 console.log(window.b) // undefined console.log(window. c) // undefined function test(){ console.log(a) let a } test() 首先在全局作用域下使用 let 和 const 声明变量，变量并不会被挂载到 window 上，这一点就和 var 声明有了区别。 再者当我们在声明 a 之前如果使用了 a，就会出现报错的情况 你可能会认为这里也出现了提升的情况，但是因为某些原因导致不能访问。 首先报错的原因是因为存在暂时性死区，我们不能在声明前就使用变量，这也是 let 和 const 优于 var 的一点。然后这里你认为的提升和 var 的提升是有区别的，虽然变量在编译的环节中被告知在这块作用域中可以访问，但是访问是受限制的。 那么到这里，想必大家也都明白 var、let 及 const 区别了，不知道你是否会有这么一个疑问，为什么要存在提升这个事情呢，其实提升存在的根本原因就是为了解决函数间互相调用的情况 function test1() { test2() } function test2() { test1() } test1() 假如不存在提升这个情况，那么就实现不了上述的代码，因为不可能存在 test1 在 test2 前面然后 test2 又在 test1 前面。 那么最后我们总结下这小节的内容： 函数提升优先于变量提升，函数提升会把整个函数挪到作用域顶部，变量提升只会把声明挪到作用域顶部 var 存在提升，我们能在声明之前使用。let、const 因为暂时性死区的原因，不能在声明前使用 var 在全局作用域下声明变量会导致变量挂载在 window 上，其他两者不会 let 和 const 作用基本一致，但是后者声明的变量不能再次赋值 原型继承和 Class 继承 涉及面试题：原型如何实现继承？Class 如何实现继承？Class 本质是什么？ 首先先来讲下 class，其实在 JS 中并不存在类，class 只是语法糖，本质还是函数。 class Person {} Person instanceof Function // true 在上一章节中我们讲解了原型的知识点，在这一小节中我们将会分别使用原型和 class 的方式来实现继承。 组合继承 组合继承是最常用的继承方式， function Parent(value) { this.val = value } Parent.prototype.getValue = function() { console.log(this.val) } function Child(value) { Parent.call(this, value) } Child.prototype = new Parent() const child = new Child(1) child.getValue() // 1 child instanceof Parent // true 以上继承的方式核心是在子类的构造函数中通过 Parent.call(this) 继承父类的属性，然后改变子类的原型为 new Parent() 来继承父类的函数。 这种继承方式优点在于构造函数可以传参，不会与父类引用属性共享，可以复用父类的函数，但是也存在一个缺点就是在继承父类函数的时候调用了父类构造函数，导致子类的原型上多了不需要的父类属性，存在内存上的浪费。 寄生组合继承 这种继承方式对组合继承进行了优化，组合继承缺点在于继承父类函数时调用了构造函数，我们只需要优化掉这点就行了。 function Parent(value) { this.val = value } Parent.prototype.getValue = function() { console.log(this.val) } function Child(value) { Parent.call(this, value) } Child.prototype = Object.create(Parent.prototype, { constructor: { value: Child, enumerable: false, writable: true, configurable: true } }) const child = new Child(1) child.getValue() // 1 child instanceof Parent // true 以上继承实现的核心就是将父类的原型赋值给了子类，并且将构造函数设置为子类，这样既解决了无用的父类属性问题，还能正确的找到子类的构造函数。 Class 继承 以上两种继承方式都是通过原型去解决的，在 ES6 中，我们可以使用 class 去实现继承，并且实现起来很简单 class Parent { constructor(value) { this.val = value } getValue() { console.log(this.val) } } class Child extends Parent { constructor(value) { super(value) } } let child = new Child(1) child.getValue() // 1 child instanceof Parent // true class 实现继承的核心在于使用 extends 表明继承自哪个父类，并且在子类构造函数中必须调用 super，因为这段代码可以看成 Parent.call(this, value)。 当然了，之前也说了在 JS 中并不存在类，class 的本质就是函数。 模块化 涉及面试题：为什么要使用模块化？都有哪几种方式可以实现模块化，各有什么特点？ 使用一个技术肯定是有原因的，那么使用模块化可以给我们带来以下好处 解决命名冲突 提供复用性 提高代码可维护性 立即执行函数 在早期，使用立即执行函数实现模块化是常见的手段，通过函数作用域解决了命名冲突、污染全局作用域的问题 (function(globalVariable){ globalVariable.test = function() {} // ... 声明各种变量、函数都不会污染全局作用域 })(globalVariable) AMD 和 CMD 鉴于目前这两种实现方式已经很少见到，所以不再对具体特性细聊，只需要了解这两者是如何使用的。 // AMD define(['./a', './b'], function(a, b) { // 加载模块完毕可以使用 a.do() b.do() }) // CMD define(function(require, exports, module) { // 加载模块 // 可以把 require 写在函数体的任意地方实现延迟加载 var a = require('./a') a.doSomething() }) CommonJS CommonJS 最早是 Node 在使用，目前也仍然广泛使用，比如在 Webpack 中你就能见到它，当然目前在 Node 中的模块管理已经和 CommonJS 有一些区别了。 // a.js module.exports = { a: 1 } // or exports.a = 1 // b.js var module = require('./a.js') module.a // -> log 1 因为 CommonJS 还是会使用到的，所以这里会对一些疑难点进行解析 先说 require 吧 var module = require('./a.js') module.a // 这里其实就是包装了一层立即执行函数，这样就不会污染全局变量了， // 重要的是 module 这里，module 是 Node 独有的一个变量 module.exports = { a: 1 } // module 基本实现 var module = { id: 'xxxx', // 我总得知道怎么去找到他吧 exports: {} // exports 就是个空对象 } // 这个是为什么 exports 和 module.exports 用法相似的原因 var exports = module.exports var load = function (module) { // 导出的东西 var a = 1 module.exports = a return module.exports }; // 然后当我 require 的时候去找到独特的 // id，然后将要使用的东西用立即执行函数包装下，over 另外虽然 exports 和 module.exports 用法相似，但是不能对 exports 直接赋值。因为 var exports = module.exports 这句代码表明了 exports 和 module.exports 享有相同地址，通过改变对象的属性值会对两者都起效，但是如果直接对 exports 赋值就会导致两者不再指向同一个内存地址，修改并不会对 module.exports 起效。 ES Module ES Module 是原生实现的模块化方案，与 CommonJS 有以下几个区别 CommonJS 支持动态导入，也就是 require(${path}/xx.js)，后者目前不支持，但是已有提案 CommonJS 是同步导入，因为用于服务端，文件都在本地，同步导入即使卡住主线程影响也不大。而后者是异步导入，因为用于浏览器，需要下载文件，如果也采用同步导入会对渲染有很大影响 CommonJS 在导出时都是值拷贝，就算导出的值变了，导入的值也不会改变，所以如果想更新值，必须重新导入一次。但是 ES Module 采用实时绑定的方式，导入导出的值都指向同一个内存地址，所以导入值会跟随导出值变化 ES Module 会编译成 require/exports 来执行的 // 引入模块 API import XXX from './a.js' import { XXX } from './a.js' // 导出模块 API export function a() {} export default function() {} Proxy 涉及面试题：Proxy 可以实现什么功能？ 如果你平时有关注 Vue 的进展的话，可能已经知道了在 Vue3.0 中将会通过 Proxy 来替换原本的 Object.defineProperty 来实现数据响应式。 Proxy 是 ES6 中新增的功能，它可以用来自定义对象中的操作。 let p = new Proxy(target, handler) target 代表需要添加代理的对象，handler 用来自定义对象中的操作，比如可以用来自定义 set 或者 get 函数。 接下来我们通过 Proxy 来实现一个数据响应式 let onWatch = (obj, setBind, getLogger) => { let handler = { get(target, property, receiver) { getLogger(target, property) return Reflect.get(target, property, receiver) }, set(target, property, value, receiver) { setBind(value, property) return Reflect.set(target, property, value) } } return new Proxy(obj, handler) } let obj = { a: 1 } let p = onWatch( obj, (v, property) => { console.log(`监听到属性${property}改变为${v}`) }, (target, property) => { console.log(`'${property}' = ${target[property]}`) } ) p.a = 2 // 监听到属性a改变 p.a // 'a' = 2 在上述代码中，我们通过自定义 set 和 get 函数的方式，在原本的逻辑中插入了我们的函数逻辑，实现了在对对象任何属性进行读写时发出通知。 当然这是简单版的响应式实现，如果需要实现一个 Vue 中的响应式，需要我们在 get 中收集依赖，在 set 派发更新，之所以 Vue3.0 要使用 Proxy 替换原本的 API 原因在于 Proxy 无需一层层递归为每个属性添加代理，一次即可完成以上操作，性能上更好，并且原本的实现有一些数据更新不能监听到，但是 Proxy 可以完美监听到任何方式的数据改变，唯一缺陷可能就是浏览器的兼容性不好了。 更新：评论中有同学对于 Proxy 无需一层层递归为每个属性添加代理有疑问，以下是实现代码。 get(target, property, receiver) { getLogger(target, property) // 这句判断代码是新增的 if (typeof target[property] === 'object' && target[property] !== null) { return new Proxy(target[property], handler); } else { return Reflect.get(target, property); } } map, filter, reduce 涉及面试题：map, filter, reduce 各自有什么作用？ map 作用是生成一个新数组，遍历原数组，将每个元素拿出来做一些变换然后放入到新的数组中。 [1, 2, 3].map(v => v + 1) // -> [2, 3, 4] 另外 map 的回调函数接受三个参数，分别是当前索引元素，索引，原数组 ['1','2','3'].map(parseInt) 第一轮遍历 parseInt('1', 0) -> 1 第二轮遍历 parseInt('2', 1) -> NaN 第三轮遍历 parseInt('3', 2) -> NaN filter 的作用也是生成一个新数组，在遍历数组的时候将返回值为 true 的元素放入新数组，我们可以利用这个函数删除一些不需要的元素 let array = [1, 2, 4, 6] let newArray = array.filter(item => item !== 6) console.log(newArray) // [1, 2, 4] 和 map 一样，filter 的回调函数也接受三个参数，用处也相同。 最后我们来讲解 reduce 这块的内容，同时也是最难理解的一块内容。reduce 可以将数组中的元素通过回调函数最终转换为一个值。 如果我们想实现一个功能将函数里的元素全部相加得到一个值，可能会这样写代码 const arr = [1, 2, 3] let total = 0 for (let i = 0; i 但是如果我们使用 reduce 的话就可以将遍历部分的代码优化为一行代码 const arr = [1, 2, 3] const sum = arr.reduce((acc, current) => acc + current, 0) console.log(sum) 对于 reduce 来说，它接受两个参数，分别是回调函数和初始值，接下来我们来分解上述代码中 reduce 的过程 首先初始值为 0，该值会在执行第一次回调函数时作为第一个参数传入 回调函数接受四个参数，分别为累计值、当前元素、当前索引、原数组，后三者想必大家都可以明白作用，这里着重分析第一个参数 在一次执行回调函数时，当前值和初始值相加得出结果 1，该结果会在第二次执行回调函数时当做第一个参数传入 所以在第二次执行回调函数时，相加的值就分别是 1 和 2，以此类推，循环结束后得到结果 6 想必通过以上的解析大家应该明白 reduce 是如何通过回调函数将所有元素最终转换为一个值的，当然 reduce 还可以实现很多功能，接下来我们就通过 reduce 来实现 map 函数 const arr = [1, 2, 3] const mapArray = arr.map(value => value * 2) const reduceArray = arr.reduce((acc, current) => { acc.push(current * 2) return acc }, []) console.log(mapArray, reduceArray) // [2, 4, 6] 如果你对这个实现还有困惑的话，可以根据上一步的解析步骤来分析过程。 小结 这一章节我们了解了部分 ES6 常考的知识点，其他的一些异步内容我们会放在下一章节去讲。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/05.JS异步编程及常考面试题.html":{"url":"前端面试之道/05.JS异步编程及常考面试题.html","title":"05.JS异步编程及常考面试题","keywords":"","body":"JS 异步编程及常考面试题 在上一章节中我们了解了常见 ES6 语法的一些知识点。这一章节我们将会学习异步编程这一块的内容，鉴于异步编程是 JS 中至关重要的内容，所以我们将会用三个章节来学习异步编程涉及到的重点和难点，同时这一块内容也是面试常考范围，希望大家认真学习。 并发（concurrency）和并行（parallelism）区别 涉及面试题：并发与并行的区别？ 异步和这小节的知识点其实并不是一个概念，但是这两个名词确实是很多人都常会混淆的知识点。其实混淆的原因可能只是两个名词在中文上的相似，在英文上来说完全是不同的单词。 并发是宏观概念，我分别有任务 A 和任务 B，在一段时间内通过任务间的切换完成了这两个任务，这种情况就可以称之为并发。 并行是微观概念，假设 CPU 中存在两个核心，那么我就可以同时完成任务 A、B。同时完成多个任务的情况就可以称之为并行。 回调函数（Callback） 涉及面试题：什么是回调函数？回调函数有什么缺点？如何解决回调地狱问题？ 回调函数应该是大家经常使用到的，以下代码就是一个回调函数的例子： ajax(url, () => { // 处理逻辑 }) 但是回调函数有一个致命的弱点，就是容易写出回调地狱（Callback hell）。假设多个请求存在依赖性，你可能就会写出如下代码： ajax(url, () => { // 处理逻辑 ajax(url1, () => { // 处理逻辑 ajax(url2, () => { // 处理逻辑 }) }) }) 以上代码看起来不利于阅读和维护，当然，你可能会想说解决这个问题还不简单，把函数分开来写不就得了 function firstAjax() { ajax(url1, () => { // 处理逻辑 secondAjax() }) } function secondAjax() { ajax(url2, () => { // 处理逻辑 }) } ajax(url, () => { // 处理逻辑 firstAjax() }) 以上的代码虽然看上去利于阅读了，但是还是没有解决根本问题。 回调地狱的根本问题就是： 嵌套函数存在耦合性，一旦有所改动，就会牵一发而动全身 嵌套函数一多，就很难处理错误 当然，回调函数还存在着别的几个缺点，比如不能使用 try catch 捕获错误，不能直接 return。在接下来的几小节中，我们将来学习通过别的技术解决这些问题。 Generator 涉及面试题：你理解的 Generator 是什么？ Generator 算是 ES6 中难理解的概念之一了，Generator 最大的特点就是可以控制函数的执行。在这一小节中我们不会去讲什么是 Generator，而是把重点放在 Generator 的一些容易困惑的地方。 function *foo(x) { let y = 2 * (yield (x + 1)) let z = yield (y / 3) return (x + y + z) } let it = foo(5) console.log(it.next()) // => {value: 6, done: false} console.log(it.next(12)) // => {value: 8, done: false} console.log(it.next(13)) // => {value: 42, done: true} 你也许会疑惑为什么会产生与你预想不同的值，接下来就让我为你逐行代码分析原因 首先 Generator 函数调用和普通函数不同，它会返回一个迭代器 当执行第一次 next 时，传参会被忽略，并且函数暂停在 yield (x + 1) 处，所以返回 5 + 1 = 6 当执行第二次 next 时，传入的参数等于上一个 yield 的返回值，如果你不传参，yield 永远返回 undefined。此时 let y = 2 * 12，所以第二个 yield 等于 2 * 12 / 3 = 8 当执行第三次 next 时，传入的参数会传递给 z，所以 z = 13, x = 5, y = 24，相加等于 42 Generator 函数一般见到的不多，其实也于他有点绕有关系，并且一般会配合 co 库去使用。当然，我们可以通过 Generator 函数解决回调地狱的问题，可以把之前的回调地狱例子改写为如下代码： function *fetch() { yield ajax(url, () => {}) yield ajax(url1, () => {}) yield ajax(url2, () => {}) } let it = fetch() let result1 = it.next() let result2 = it.next() let result3 = it.next() Promise 涉及面试题：Promise 的特点是什么，分别有什么优缺点？什么是 Promise 链？Promise 构造函数执行和 then 函数执行有什么区别？ Promise 翻译过来就是承诺的意思，这个承诺会在未来有一个确切的答复，并且该承诺有三种状态，分别是： 等待中（pending） 完成了 （resolved） 拒绝了（rejected） 这个承诺一旦从等待状态变成为其他状态就永远不能更改状态了，也就是说一旦状态变为 resolved 后，就不能再次改变 new Promise((resolve, reject) => { resolve('success') // 无效 reject('reject') }) 当我们在构造 Promise 的时候，构造函数内部的代码是立即执行的 new Promise((resolve, reject) => { console.log('new Promise') resolve('success') }) console.log('finifsh') // new Promise -> finifsh Promise 实现了链式调用，也就是说每次调用 then 之后返回的都是一个 Promise，并且是一个全新的 Promise，原因也是因为状态不可变。如果你在 then 中 使用了 return，那么 return 的值会被 Promise.resolve() 包装 Promise.resolve(1) .then(res => { console.log(res) // => 1 return 2 // 包装成 Promise.resolve(2) }) .then(res => { console.log(res) // => 2 }) 当然了，Promise 也很好地解决了回调地狱的问题，可以把之前的回调地狱例子改写为如下代码： ajax(url) .then(res => { console.log(res) return ajax(url1) }).then(res => { console.log(res) return ajax(url2) }).then(res => console.log(res)) 前面都是在讲述 Promise 的一些优点和特点，其实它也是存在一些缺点的，比如无法取消 Promise，错误需要通过回调函数捕获。 async 及 await 涉及面试题：async 及 await 的特点，它们的优点和缺点分别是什么？await 原理是什么？ 一个函数如果加上 async ，那么该函数就会返回一个 Promise async function test() { return \"1\" } console.log(test()) // -> Promise {: \"1\"} async 就是将函数返回值使用 Promise.resolve() 包裹了下，和 then 中处理返回值一样，并且 await 只能配套 async 使用 async function test() { let value = await sleep() } async 和 await 可以说是异步终极解决方案了，相比直接使用 Promise 来说，优势在于处理 then 的调用链，能够更清晰准确的写出代码，毕竟写一大堆 then 也很恶心，并且也能优雅地解决回调地狱问题。当然也存在一些缺点，因为 await 将异步代码改造成了同步代码，如果多个异步代码没有依赖性却使用了 await 会导致性能上的降低。 async function test() { // 以下代码没有依赖性的话，完全可以使用 Promise.all 的方式 // 如果有依赖性的话，其实就是解决回调地狱的例子了 await fetch(url) await fetch(url1) await fetch(url2) } 下面来看一个使用 await 的例子： let a = 0 let b = async () => { a = a + await 10 console.log('2', a) // -> '2' 10 } b() a++ console.log('1', a) // -> '1' 1 对于以上代码你可能会有疑惑，让我来解释下原因 首先函数 b 先执行，在执行到 await 10 之前变量 a 还是 0，因为 await 内部实现了 generator ，generator 会保留堆栈中东西，所以这时候 a = 0 被保存了下来 因为 await 是异步操作，后来的表达式不返回 Promise 的话，就会包装成 Promise.reslove(返回值)，然后会去执行函数外的同步代码 同步代码执行完毕后开始执行异步代码，将保存下来的值拿出来使用，这时候 a = 0 + 10 上述解释中提到了 await 内部实现了 generator，其实 await 就是 generator 加上 Promise 的语法糖，且内部实现了自动执行 generator。如果你熟悉 co 的话，其实自己就可以实现这样的语法糖。 常用定时器函数 涉及面试题：setTimeout、setInterval、requestAnimationFrame 各有什么特点？ 异步编程当然少不了定时器了，常见的定时器函数有 setTimeout、setInterval、requestAnimationFrame。我们先来讲讲最常用的setTimeout，很多人认为 setTimeout 是延时多久，那就应该是多久后执行。 其实这个观点是错误的，因为 JS 是单线程执行的，如果前面的代码影响了性能，就会导致 setTimeout 不会按期执行。当然了，我们可以通过代码去修正 setTimeout，从而使定时器相对准确 let period = 60 * 1000 * 60 * 2 let startTime = new Date().getTime() let count = 0 let end = new Date().getTime() + period let interval = 1000 let currentInterval = interval function loop() { count++ // 代码执行所消耗的时间 let offset = new Date().getTime() - (startTime + count * interval); let diff = end - new Date().getTime() let h = Math.floor(diff / (60 * 1000 * 60)) let hdiff = diff % (60 * 1000 * 60) let m = Math.floor(hdiff / (60 * 1000)) let mdiff = hdiff % (60 * 1000) let s = mdiff / (1000) let sCeil = Math.ceil(s) let sFloor = Math.floor(s) // 得到下一次循环所消耗的时间 currentInterval = interval - offset console.log('时：'+h, '分：'+m, '毫秒：'+s, '秒向上取整：'+sCeil, '代码执行时间：'+offset, '下次循环间隔'+currentInterval) setTimeout(loop, currentInterval) } setTimeout(loop, currentInterval) 接下来我们来看 setInterval，其实这个函数作用和 setTimeout 基本一致，只是该函数是每隔一段时间执行一次回调函数。 通常来说不建议使用 setInterval。第一，它和 setTimeout 一样，不能保证在预期的时间执行任务。第二，它存在执行累积的问题，请看以下伪代码 function demo() { setInterval(function(){ console.log(2) },1000) sleep(2000) } demo() 以上代码在浏览器环境中，如果定时器执行过程中出现了耗时操作，多个回调函数会在耗时操作结束以后同时执行，这样可能就会带来性能上的问题。 如果你有循环定时器的需求，其实完全可以通过 requestAnimationFrame 来实现 function setInterval(callback, interval) { let timer const now = Date.now let startTime = now() let endTime = startTime const loop = () => { timer = window.requestAnimationFrame(loop) endTime = now() if (endTime - startTime >= interval) { startTime = endTime = now() callback(timer) } } timer = window.requestAnimationFrame(loop) return timer } let a = 0 setInterval(timer => { console.log(1) a++ if (a === 3) cancelAnimationFrame(timer) }, 1000) 首先 requestAnimationFrame 自带函数节流功能，基本可以保证在 16.6 毫秒内只执行一次（不掉帧的情况下），并且该函数的延时效果是精确的，没有其他定时器时间不准的问题，当然你也可以通过该函数来实现 setTimeout。 小结 异步编程是 JS 中较难掌握的内容，同时也是很重要的知识点。以上提到的每个知识点其实都可以作为一道面试题，希望大家可以好好掌握以上内容如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 异步编程相关内容并非一章节就能讲完，需要继续浏览后续章节。 "},"前端面试之道/06.手写Promise.html":{"url":"前端面试之道/06.手写Promise.html","title":"06.手写Promise","keywords":"","body":"手写 Promise 在上一章节中我们了解了 Promise 的一些易错点，在这一章节中，我们会通过手写一个符合 Promise/A+ 规范的 Promise 来深入理解它，并且手写 Promise 也是一道大厂常考题，在进入正题之前，推荐各位阅读一下 Promise/A+ 规范，这样才能更好地理解这个章节的代码。 实现一个简易版 Promise 在完成符合 Promise/A+ 规范的代码之前，我们可以先来实现一个简易版 Promise，因为在面试中，如果你能实现出一个简易版的 Promise 基本可以过关了。 那么我们先来搭建构建函数的大体框架 const PENDING = 'pending' const RESOLVED = 'resolved' const REJECTED = 'rejected' function MyPromise(fn) { const that = this that.state = PENDING that.value = null that.resolvedCallbacks = [] that.rejectedCallbacks = [] // 待完善 resolve 和 reject 函数 // 待完善执行 fn 函数 } 首先我们创建了三个常量用于表示状态，对于经常使用的一些值都应该通过常量来管理，便于开发及后期维护 在函数体内部首先创建了常量 that，因为代码可能会异步执行，用于获取正确的 this 对象 一开始 Promise 的状态应该是 pending value 变量用于保存 resolve 或者 reject 中传入的值 resolvedCallbacks 和 rejectedCallbacks 用于保存 then 中的回调，因为当执行完 Promise 时状态可能还是等待中，这时候应该把 then 中的回调保存起来用于状态改变时使用 接下来我们来完善 resolve 和 reject 函数，添加在 MyPromise 函数体内部 function resolve(value) { if (that.state === PENDING) { that.state = RESOLVED that.value = value that.resolvedCallbacks.map(cb => cb(that.value)) } } function reject(value) { if (that.state === PENDING) { that.state = REJECTED that.value = value that.rejectedCallbacks.map(cb => cb(that.value)) } } 这两个函数代码类似，就一起解析了 首先两个函数都得判断当前状态是否为等待中，因为规范规定只有等待态才可以改变状态 将当前状态更改为对应状态，并且将传入的值赋值给 value 遍历回调数组并执行 完成以上两个函数以后，我们就该实现如何执行 Promise 中传入的函数了 try { fn(resolve, reject) } catch (e) { reject(e) } 实现很简单，执行传入的参数并且将之前两个函数当做参数传进去 要注意的是，可能执行函数过程中会遇到错误，需要捕获错误并且执行 reject 函数 最后我们来实现较为复杂的 then 函数 MyPromise.prototype.then = function(onFulfilled, onRejected) { const that = this onFulfilled = typeof onFulfilled === 'function' ? onFulfilled : v => v onRejected = typeof onRejected === 'function' ? onRejected : r => { throw r } if (that.state === PENDING) { that.resolvedCallbacks.push(onFulfilled) that.rejectedCallbacks.push(onRejected) } if (that.state === RESOLVED) { onFulfilled(that.value) } if (that.state === REJECTED) { onRejected(that.value) } } 首先判断两个参数是否为函数类型，因为这两个参数是可选参数 当参数不是函数类型时，需要创建一个函数赋值给对应的参数，同时也实现了透传，比如如下代码 // 该代码目前在简单版中会报错 // 只是作为一个透传的例子 Promise.resolve(4).then().then((value) => console.log(value)) 接下来就是一系列判断状态的逻辑，当状态不是等待态时，就去执行相对应的函数。如果状态是等待态的话，就往回调函数中 push 函数，比如如下代码就会进入等待态的逻辑 new MyPromise((resolve, reject) => { setTimeout(() => { resolve(1) }, 0) }).then(value => { console.log(value) }) 以上就是简单版 Promise 实现，接下来一小节是实现完整版 Promise 的解析，相信看完完整版的你，一定会对于 Promise 的理解更上一层楼。 实现一个符合 Promise/A+ 规范的 Promise 这小节代码需要大家配合规范阅读，因为大部分代码都是根据规范去实现的。 我们先来改造一下 resolve 和 reject 函数 function resolve(value) { if (value instanceof MyPromise) { return value.then(resolve, reject) } setTimeout(() => { if (that.state === PENDING) { that.state = RESOLVED that.value = value that.resolvedCallbacks.map(cb => cb(that.value)) } }, 0) } function reject(value) { setTimeout(() => { if (that.state === PENDING) { that.state = REJECTED that.value = value that.rejectedCallbacks.map(cb => cb(that.value)) } }, 0) } 对于 resolve 函数来说，首先需要判断传入的值是否为 Promise 类型 为了保证函数执行顺序，需要将两个函数体代码使用 setTimeout 包裹起来 接下来继续改造 then 函数中的代码，首先我们需要新增一个变量 promise2，因为每个 then 函数都需要返回一个新的 Promise 对象，该变量用于保存新的返回对象，然后我们先来改造判断等待态的逻辑 if (that.state === PENDING) { return (promise2 = new MyPromise((resolve, reject) => { that.resolvedCallbacks.push(() => { try { const x = onFulfilled(that.value) resolutionProcedure(promise2, x, resolve, reject) } catch (r) { reject(r) } }) that.rejectedCallbacks.push(() => { try { const x = onRejected(that.value) resolutionProcedure(promise2, x, resolve, reject) } catch (r) { reject(r) } }) })) } 首先我们返回了一个新的 Promise 对象，并在 Promise 中传入了一个函数 函数的基本逻辑还是和之前一样，往回调数组中 push 函数 同样，在执行函数的过程中可能会遇到错误，所以使用了 try...catch 包裹 规范规定，执行 onFulfilled 或者 onRejected 函数时会返回一个 x，并且执行 Promise 解决过程，这是为了不同的 Promise 都可以兼容使用，比如 JQuery 的 Promise 能兼容 ES6 的 Promise 接下来我们改造判断执行态的逻辑 if (that.state === RESOLVED) { return (promise2 = new MyPromise((resolve, reject) => { setTimeout(() => { try { const x = onFulfilled(that.value) resolutionProcedure(promise2, x, resolve, reject) } catch (reason) { reject(reason) } }) })) } 其实大家可以发现这段代码和判断等待态的逻辑基本一致，无非是传入的函数的函数体需要异步执行，这也是规范规定的 对于判断拒绝态的逻辑这里就不一一赘述了，留给大家自己完成这个作业 最后，当然也是最难的一部分，也就是实现兼容多种 Promise 的 resolutionProcedure 函数 function resolutionProcedure(promise2, x, resolve, reject) { if (promise2 === x) { return reject(new TypeError('Error')) } } 首先规范规定了 x 不能与 promise2 相等，这样会发生循环引用的问题，比如如下代码 let p = new MyPromise((resolve, reject) => { resolve(1) }) let p1 = p.then(value => { return p1 }) 然后需要判断 x 的类型 if (x instanceof MyPromise) { x.then(function(value) { resolutionProcedure(promise2, value, resolve, reject) }, reject) } 这里的代码是完全按照规范实现的。如果 x 为 Promise 的话，需要判断以下几个情况： 如果 x 处于等待态，Promise 需保持为等待态直至 x 被执行或拒绝 如果 x 处于其他状态，则用相同的值处理 Promise 当然以上这些是规范需要我们判断的情况，实际上我们不判断状态也是可行的。 接下来我们继续按照规范来实现剩余的代码 let called = false if (x !== null && (typeof x === 'object' || typeof x === 'function')) { try { let then = x.then if (typeof then === 'function') { then.call( x, y => { if (called) return called = true resolutionProcedure(promise2, y, resolve, reject) }, e => { if (called) return called = true reject(e) } ) } else { resolve(x) } } catch (e) { if (called) return called = true reject(e) } } else { resolve(x) } 首先创建一个变量 called 用于判断是否已经调用过函数 然后判断 x 是否为对象或者函数，如果都不是的话，将 x 传入 resolve 中 如果 x 是对象或者函数的话，先把 x.then 赋值给 then，然后判断 then 的类型，如果不是函数类型的话，就将 x 传入 resolve 中 如果 then 是函数类型的话，就将 x 作为函数的作用域 this 调用之，并且传递两个回调函数作为参数，第一个参数叫做 resolvePromise ，第二个参数叫做 rejectPromise，两个回调函数都需要判断是否已经执行过函数，然后进行相应的逻辑 以上代码在执行的过程中如果抛错了，将错误传入 reject 函数中 以上就是符合 Promise/A+ 规范的实现了，如果你对于这部分代码尚有疑问，欢迎在评论中与我互动。 小结 这一章节我们分别实现了简单版和符合 Promise/A+ 规范的 Promise，前者已经足够应付大部分面试的手写题目，毕竟写出一个符合规范的 Promise 在面试中不大现实。后者能让你更加深入地理解 Promise 的运行原理，做技术的深挖者。 "},"前端面试之道/07.EventLoop.html":{"url":"前端面试之道/07.EventLoop.html","title":"07.EventLoop","keywords":"","body":"Event Loop 在前两章节中我们了解了 JS 异步相关的知识。在实践的过程中，你是否遇到过以下场景，为什么 setTimeout 会比 Promise 后执行，明明代码写在 Promise 之前。这其实涉及到了 Event Loop 相关的知识，这一章节我们会来详细地了解 Event Loop 相关知识，知道 JS 异步运行代码的原理，并且这一章节也是面试常考知识点。 进程与线程 涉及面试题：进程与线程区别？JS 单线程带来的好处？ 相信大家经常会听到 JS 是单线程执行的，但是你是否疑惑过什么是线程？ 讲到线程，那么肯定也得说一下进程。本质上来说，两个名词都是 CPU 工作时间片的一个描述。 进程描述了 CPU 在运行指令及加载和保存上下文所需的时间，放在应用上来说就代表了一个程序。线程是进程中的更小单位，描述了执行一段指令所需的时间。 把这些概念拿到浏览器中来说，当你打开一个 Tab 页时，其实就是创建了一个进程，一个进程中可以有多个线程，比如渲染线程、JS 引擎线程、HTTP 请求线程等等。当你发起一个请求时，其实就是创建了一个线程，当请求结束后，该线程可能就会被销毁。 上文说到了 JS 引擎线程和渲染线程，大家应该都知道，在 JS 运行的时候可能会阻止 UI 渲染，这说明了两个线程是互斥的。这其中的原因是因为 JS 可以修改 DOM，如果在 JS 执行的时候 UI 线程还在工作，就可能导致不能安全的渲染 UI。这其实也是一个单线程的好处，得益于 JS 是单线程运行的，可以达到节省内存，节约上下文切换时间，没有锁的问题的好处。当然前面两点在服务端中更容易体现，对于锁的问题，形象的来说就是当我读取一个数字 15 的时候，同时有两个操作对数字进行了加减，这时候结果就出现了错误。解决这个问题也不难，只需要在读取的时候加锁，直到读取完毕之前都不能进行写入操作。 执行栈 涉及面试题：什么是执行栈？ 可以把执行栈认为是一个存储函数调用的栈结构，遵循先进后出的原则。 执行栈可视化 当开始执行 JS 代码时，首先会执行一个 main 函数，然后执行我们的代码。根据先进后出的原则，后执行的函数会先弹出栈，在图中我们也可以发现，foo 函数后执行，当执行完毕后就从栈中弹出了。 平时在开发中，大家也可以在报错中找到执行栈的痕迹 function foo() { throw new Error('error') } function bar() { foo() } bar() 函数执行顺序 大家可以在上图清晰的看到报错在 foo 函数，foo 函数又是在 bar 函数中调用的。 当我们使用递归的时候，因为栈可存放的函数是有限制的，一旦存放了过多的函数且没有得到释放的话，就会出现爆栈的问题 function bar() { bar() } bar() 爆栈 浏览器中的 Event Loop 涉及面试题：异步代码执行顺序？解释一下什么是 Event Loop ？ 上一小节我们讲到了什么是执行栈，大家也知道了当我们执行 JS 代码的时候其实就是往执行栈中放入函数，那么遇到异步代码的时候该怎么办？其实当遇到异步的代码时，会被挂起并在需要执行的时候加入到 Task（有多种 Task） 队列中。一旦执行栈为空，Event Loop 就会从 Task 队列中拿出需要执行的代码并放入执行栈中执行，所以本质上来说 JS 中的异步还是同步行为。 事件循环 不同的任务源会被分配到不同的 Task 队列中，任务源可以分为 微任务（microtask） 和 宏任务（macrotask）。在 ES6 规范中，microtask 称为 jobs，macrotask 称为 task。下面来看以下代码的执行顺序： console.log('script start') async function async1() { await async2() console.log('async1 end') } async function async2() { console.log('async2 end') } async1() setTimeout(function() { console.log('setTimeout') }, 0) new Promise(resolve => { console.log('Promise') resolve() }) .then(function() { console.log('promise1') }) .then(function() { console.log('promise2') }) console.log('script end') // script start => async2 end => Promise => script end => promise1 => promise2 => async1 end => setTimeout 注意：新的浏览器中不是如上打印的，因为 await 变快了，具体内容可以往下看 首先先来解释下上述代码的 async 和 await 的执行顺序。当我们调用 async1 函数时，会马上输出 async2 end，并且函数返回一个 Promise，接下来在遇到 await的时候会就让出线程开始执行 async1 外的代码，所以我们完全可以把 await 看成是让出线程的标志。 然后当同步代码全部执行完毕以后，就会去执行所有的异步代码，那么又会回到 await 的位置执行返回的 Promise 的 resolve 函数，这又会把 resolve 丢到微任务队列中，接下来去执行 then 中的回调，当两个 then 中的回调全部执行完毕以后，又会回到 await 的位置处理返回值，这时候你可以看成是 Promise.resolve(返回值).then()，然后 await 后的代码全部被包裹进了 then 的回调中，所以 console.log('async1 end') 会优先执行于 setTimeout。 如果你觉得上面这段解释还是有点绕，那么我把 async 的这两个函数改造成你一定能理解的代码 new Promise((resolve, reject) => { console.log('async2 end') // Promise.resolve() 将代码插入微任务队列尾部 // resolve 再次插入微任务队列尾部 resolve(Promise.resolve()) }).then(() => { console.log('async1 end') }) 也就是说，如果 await 后面跟着 Promise 的话，async1 end 需要等待三个 tick 才能执行到。那么其实这个性能相对来说还是略慢的，所以 V8 团队借鉴了 Node 8 中的一个 Bug，在引擎底层将三次 tick 减少到了二次 tick。但是这种做法其实是违法了规范的，当然规范也是可以更改的，这是 V8 团队的一个 PR，目前已被同意这种做法。 所以 Event Loop 执行顺序如下所示： 首先执行同步代码，这属于宏任务 当执行完所有同步代码后，执行栈为空，查询是否有异步代码需要执行 执行所有微任务 当执行完所有微任务后，如有必要会渲染页面 然后开始下一轮 Event Loop，执行宏任务中的异步代码，也就是 setTimeout 中的回调函数 所以以上代码虽然 setTimeout 写在 Promise 之前，但是因为 Promise 属于微任务而 setTimeout 属于宏任务，所以会有以上的打印。 微任务包括 process.nextTick ，promise ，MutationObserver，其中 process.nextTick 为 Node 独有。 宏任务包括 script ， setTimeout ，setInterval ，setImmediate ，I/O ，UI rendering。 这里很多人会有个误区，认为微任务快于宏任务，其实是错误的。因为宏任务中包括了 script ，浏览器会先执行一个宏任务，接下来有异步代码的话才会先执行微任务。 Node 中的 Event Loop 涉及面试题：Node 中的 Event Loop 和浏览器中的有什么区别？process.nexttick 执行顺序？ Node 中的 Event Loop 和浏览器中的是完全不相同的东西。 Node 的 Event Loop 分为 6 个阶段，它们会按照顺序反复运行。每当进入某一个阶段的时候，都会从对应的回调队列中取出函数去执行。当队列为空或者执行的回调函数数量到达系统设定的阈值，就会进入下一阶段。 timer timers 阶段会执行 setTimeout 和 setInterval 回调，并且是由 poll 阶段控制的。 同样，在 Node 中定时器指定的时间也不是准确时间，只能是尽快执行。 I/O I/O 阶段会处理一些上一轮循环中的少数未执行的 I/O 回调 idle, prepare idle, prepare 阶段内部实现，这里就忽略不讲了。 poll poll 是一个至关重要的阶段，这一阶段中，系统会做两件事情 回到 timer 阶段执行回调 执行 I/O 回调 并且在进入该阶段时如果没有设定了 timer 的话，会发生以下两件事情 如果 poll 队列不为空，会遍历回调队列并同步执行，直到队列为空或者达到系统限制 如果 poll 队列为空时，会有两件事发生 如果有 setImmediate 回调需要执行，poll 阶段会停止并且进入到 check 阶段执行回调 如果没有 setImmediate 回调需要执行，会等待回调被加入到队列中并立即执行回调，这里同样会有个超时时间设置防止一直等待下去 当然设定了 timer 的话且 poll 队列为空，则会判断是否有 timer 超时，如果有的话会回到 timer 阶段执行回调。 check check 阶段执行 setImmediate close callbacks close callbacks 阶段执行 close 事件 在以上的内容中，我们了解了 Node 中的 Event Loop 的执行顺序，接下来我们将会通过代码的方式来深入理解这块内容。 首先在有些情况下，定时器的执行顺序其实是随机的 setTimeout(() => { console.log('setTimeout') }, 0) setImmediate(() => { console.log('setImmediate') }) 对于以上代码来说，setTimeout 可能执行在前，也可能执行在后 首先 setTimeout(fn, 0) === setTimeout(fn, 1)，这是由源码决定的 进入事件循环也是需要成本的，如果在准备时候花费了大于 1ms 的时间，那么在 timer 阶段就会直接执行 setTimeout 回调 那么如果准备时间花费小于 1ms，那么就是 setImmediate 回调先执行了 当然在某些情况下，他们的执行顺序一定是固定的，比如以下代码： const fs = require('fs') fs.readFile(__filename, () => { setTimeout(() => { console.log('timeout'); }, 0) setImmediate(() => { console.log('immediate') }) }) 在上述代码中，setImmediate 永远先执行。因为两个代码写在 IO 回调中，IO 回调是在 poll 阶段执行，当回调执行完毕后队列为空，发现存在 setImmediate 回调，所以就直接跳转到 check 阶段去执行回调了。 上面介绍的都是 macrotask 的执行情况，对于 microtask 来说，它会在以上每个阶段完成前清空 microtask 队列，下图中的 Tick 就代表了 microtask setTimeout(() => { console.log('timer21') }, 0) Promise.resolve().then(function() { console.log('promise1') }) 对于以上代码来说，其实和浏览器中的输出是一样的，microtask 永远执行在 macrotask 前面。 最后我们来讲讲 Node 中的 process.nextTick，这个函数其实是独立于 Event Loop 之外的，它有一个自己的队列，当每个阶段完成后，如果存在 nextTick 队列，就会清空队列中的所有回调函数，并且优先于其他 microtask 执行。 setTimeout(() => { console.log('timer1') Promise.resolve().then(function() { console.log('promise1') }) }, 0) process.nextTick(() => { console.log('nextTick') process.nextTick(() => { console.log('nextTick') process.nextTick(() => { console.log('nextTick') process.nextTick(() => { console.log('nextTick') }) }) }) }) 对于以上代码，大家可以发现无论如何，永远都是先把 nextTick 全部打印出来。 小结 这一章节我们学习了 JS 实现异步的原理，并且了解了在浏览器和 Node 中 Event Loop 其实是不相同的。Event Loop 这个知识点对于我们理解 JS 是如何执行的至关重要，同时也是常考题。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/08.JS进阶知识点及常考面试题.html":{"url":"前端面试之道/08.JS进阶知识点及常考面试题.html","title":"08.JS进阶知识点及常考面试题","keywords":"","body":"JS 进阶知识点及常考面试题 在这一章节中，我们将会学习到一些原理相关的知识，不会解释涉及到的知识点的作用及用法，如果大家对于这些内容还不怎么熟悉，推荐先去学习相关的知识点内容再来学习原理知识。 手写 call、apply 及 bind 函数 涉及面试题：call、apply 及 bind 函数内部实现是怎么样的？ 首先从以下几点来考虑如何实现这几个函数 不传入第一个参数，那么上下文默认为 window 改变了 this 指向，让新的对象可以执行该函数，并能接受参数 那么我们先来实现 call Function.prototype.myCall = function(context) { if (typeof this !== 'function') { throw new TypeError('Error') } context = context || window context.fn = this const args = [...arguments].slice(1) const result = context.fn(...args) delete context.fn return result } 以下是对实现的分析： 首先 context 为可选参数，如果不传的话默认上下文为 window 接下来给 context 创建一个 fn 属性，并将值设置为需要调用的函数 因为 call 可以传入多个参数作为调用函数的参数，所以需要将参数剥离出来 然后调用函数并将对象上的函数删除 以上就是实现 call 的思路，apply 的实现也类似，区别在于对参数的处理，所以就不一一分析思路了 Function.prototype.myApply = function(context) { if (typeof this !== 'function') { throw new TypeError('Error') } context = context || window context.fn = this let result // 处理参数和 call 有区别 if (arguments[1]) { result = context.fn(...arguments[1]) } else { result = context.fn() } delete context.fn return result } bind 的实现对比其他两个函数略微地复杂了一点，因为 bind 需要返回一个函数，需要判断一些边界问题，以下是 bind 的实现 Function.prototype.myBind = function (context) { if (typeof this !== 'function') { throw new TypeError('Error') } const _this = this const args = [...arguments].slice(1) // 返回一个函数 return function F() { // 因为返回了一个函数，我们可以 new F()，所以需要判断 if (this instanceof F) { return new _this(...args, ...arguments) } return _this.apply(context, args.concat(...arguments)) } } 以下是对实现的分析： 前几步和之前的实现差不多，就不赘述了 bind 返回了一个函数，对于函数来说有两种方式调用，一种是直接调用，一种是通过 new 的方式，我们先来说直接调用的方式 对于直接调用来说，这里选择了 apply 的方式实现，但是对于参数需要注意以下情况：因为 bind 可以实现类似这样的代码 f.bind(obj, 1)(2)，所以我们需要将两边的参数拼接起来，于是就有了这样的实现 args.concat(...arguments) 最后来说通过 new 的方式，在之前的章节中我们学习过如何判断 this，对于 new 的情况来说，不会被任何方式改变 this，所以对于这种情况我们需要忽略传入的 this new 涉及面试题：new 的原理是什么？通过 new 的方式创建对象和通过字面量创建有什么区别？ 在调用 new 的过程中会发生以上四件事情： 新生成了一个对象 链接到原型 绑定 this 返回新对象 根据以上几个过程，我们也可以试着来自己实现一个 new function create() { let obj = {} let Con = [].shift.call(arguments) obj.__proto__ = Con.prototype let result = Con.apply(obj, arguments) return result instanceof Object ? result : obj } 以下是对实现的分析： 创建一个空对象 获取构造函数 设置空对象的原型 绑定 this 并执行构造函数 确保返回值为对象 对于对象来说，其实都是通过 new 产生的，无论是 function Foo() 还是 let a = { b : 1 } 。 对于创建一个对象来说，更推荐使用字面量的方式创建对象（无论性能上还是可读性）。因为你使用 new Object() 的方式创建对象需要通过作用域链一层层找到 Object，但是你使用字面量的方式就没这个问题。 function Foo() {} // function 就是个语法糖 // 内部等同于 new Function() let a = { b: 1 } // 这个字面量内部也是使用了 new Object() 更多关于 new 的内容可以阅读我写的文章 聊聊 new 操作符。 instanceof 的原理 涉及面试题：instanceof 的原理是什么？ instanceof 可以正确的判断对象的类型，因为内部机制是通过判断对象的原型链中是不是能找到类型的 prototype。 我们也可以试着实现一下 instanceof function myInstanceof(left, right) { let prototype = right.prototype left = left.__proto__ while (true) { if (left === null || left === undefined) return false if (prototype === left) return true left = left.__proto__ } } 以下是对实现的分析： 首先获取类型的原型 然后获得对象的原型 然后一直循环判断对象的原型是否等于类型的原型，直到对象原型为 null，因为原型链最终为 null 为什么 0.1 + 0.2 != 0.3 涉及面试题：为什么 0.1 + 0.2 != 0.3？如何解决这个问题？ 先说原因，因为 JS 采用 IEEE 754 双精度版本（64位），并且只要采用 IEEE 754 的语言都有该问题。 我们都知道计算机是通过二进制来存储东西的，那么 0.1 在二进制中会表示为 // (0011) 表示循环 0.1 = 2^-4 * 1.10011(0011) 我们可以发现，0.1 在二进制中是无限循环的一些数字，其实不只是 0.1，其实很多十进制小数用二进制表示都是无限循环的。这样其实没什么问题，但是 JS 采用的浮点数标准却会裁剪掉我们的数字。 IEEE 754 双精度版本（64位）将 64 位分为了三段 第一位用来表示符号 接下去的 11 位用来表示指数 其他的位数用来表示有效位，也就是用二进制表示 0.1 中的 10011(0011) 那么这些循环的数字被裁剪了，就会出现精度丢失的问题，也就造成了 0.1 不再是 0.1 了，而是变成了 0.100000000000000002 0.100000000000000002 === 0.1 // true 那么同样的，0.2 在二进制也是无限循环的，被裁剪后也失去了精度变成了 0.200000000000000002 0.200000000000000002 === 0.2 // true 所以这两者相加不等于 0.3 而是 0.300000000000000004 0.1 + 0.2 === 0.30000000000000004 // true 那么可能你又会有一个疑问，既然 0.1 不是 0.1，那为什么 console.log(0.1) 却是正确的呢？ 因为在输入内容的时候，二进制被转换为了十进制，十进制又被转换为了字符串，在这个转换的过程中发生了取近似值的过程，所以打印出来的其实是一个近似值，你也可以通过以下代码来验证 console.log(0.100000000000000002) // 0.1 那么说完了为什么，最后来说说怎么解决这个问题吧。其实解决的办法有很多，这里我们选用原生提供的方式来最简单的解决问题 parseFloat((0.1 + 0.2).toFixed(10)) === 0.3 // true 垃圾回收机制 涉及面试题：V8 下的垃圾回收机制是怎么样的？ V8 实现了准确式 GC，GC 算法采用了分代式垃圾回收机制。因此，V8 将内存（堆）分为新生代和老生代两部分。 新生代算法 新生代中的对象一般存活时间较短，使用 Scavenge GC 算法。 在新生代空间中，内存空间分为两部分，分别为 From 空间和 To 空间。在这两个空间中，必定有一个空间是使用的，另一个空间是空闲的。新分配的对象会被放入 From 空间中，当 From 空间被占满时，新生代 GC 就会启动了。算法会检查 From 空间中存活的对象并复制到 To 空间中，如果有失活的对象就会销毁。当复制完成后将 From 空间和 To 空间互换，这样 GC 就结束了。 老生代算法 老生代中的对象一般存活时间较长且数量也多，使用了两个算法，分别是标记清除算法和标记压缩算法。 在讲算法前，先来说下什么情况下对象会出现在老生代空间中： 新生代中的对象是否已经经历过一次 Scavenge 算法，如果经历过的话，会将对象从新生代空间移到老生代空间中。 To 空间的对象占比大小超过 25 %。在这种情况下，为了不影响到内存分配，会将对象从新生代空间移到老生代空间中。 老生代中的空间很复杂，有如下几个空间 enum AllocationSpace { // TODO(v8:7464): Actually map this space's memory as read-only. RO_SPACE, // 不变的对象空间 NEW_SPACE, // 新生代用于 GC 复制算法的空间 OLD_SPACE, // 老生代常驻对象空间 CODE_SPACE, // 老生代代码对象空间 MAP_SPACE, // 老生代 map 对象 LO_SPACE, // 老生代大空间对象 NEW_LO_SPACE, // 新生代大空间对象 FIRST_SPACE = RO_SPACE, LAST_SPACE = NEW_LO_SPACE, FIRST_GROWABLE_PAGED_SPACE = OLD_SPACE, LAST_GROWABLE_PAGED_SPACE = MAP_SPACE }; 在老生代中，以下情况会先启动标记清除算法： 某一个空间没有分块的时候 空间中被对象超过一定限制 空间不能保证新生代中的对象移动到老生代中 在这个阶段中，会遍历堆中所有的对象，然后标记活的对象，在标记完成后，销毁所有没有被标记的对象。在标记大型对内存时，可能需要几百毫秒才能完成一次标记。这就会导致一些性能上的问题。为了解决这个问题，2011 年，V8 从 stop-the-world 标记切换到增量标志。在增量标记期间，GC 将标记工作分解为更小的模块，可以让 JS 应用逻辑在模块间隙执行一会，从而不至于让应用出现停顿情况。但在 2018 年，GC 技术又有了一个重大突破，这项技术名为并发标记。该技术可以让 GC 扫描和标记对象时，同时允许 JS 运行，你可以点击 该博客 详细阅读。 清除对象后会造成堆内存出现碎片的情况，当碎片超过一定限制后会启动压缩算法。在压缩过程中，将活的对象像一端移动，直到所有对象都移动完成然后清理掉不需要的内存。 小结 以上就是 JS 进阶知识点的内容了，这部分的知识相比于之前的内容更加深入也更加的理论，也是在面试中能够于别的候选者拉开差距的一块内容。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/09.JS思考题.html":{"url":"前端面试之道/09.JS思考题.html","title":"09.JS思考题","keywords":"","body":"JS 思考题 之前我们通过了七个章节来学习关于 JS 这部分的内容，那么接下来，会以几道思考题的方式来确保大家理解这部分的内容。 这种方式不仅能加深你对知识点的理解，同时也能帮助你串联起多个碎片知识点。一旦你拥有将多个碎片知识点串联起来的能力，在面试中就不会经常出现一问一答的情况。如果面试官的每个问题你都能引申出一些相关联的知识点，那么面试官一定会提高对你的评价。 思考题一：JS 分为哪两大类型？都有什么各自的特点？你该如何判断正确的类型？ 首先这几道题目想必很多人都能够很好的答出来，接下来就给大家一点思路讲出与众不同的东西。 思路引导： 对于原始类型来说，你可以指出 null 和 number 存在的一些问题。对于对象类型来说，你可以从垃圾回收的角度去切入，也可以说一下对象类型存在深浅拷贝的问题。 对于判断类型来说，你可以去对比一下 typeof 和 instanceof 之间的区别，也可以指出 instanceof 判断类型也不是完全准确的。 以上就是这道题目的回答思路，当然不是说让大家完全按照这个思路去答题，而是存在一个意识，当回答面试题的时候，尽量去引申出这个知识点的某些坑或者与这个知识点相关联的东西。 思考题二：你理解的原型是什么？ 思路引导： 起码说出原型小节中的总结内容，然后还可以指出一些小点，比如并不是所有函数都有 prototype 属性，然后引申出原型链的概念，提出如何使用原型实现继承，继而可以引申出 ES6 中的 class 实现继承。 思考题三：bind、call 和 apply 各自有什么区别？ 思路引导： 首先肯定是说出三者的不同，如果自己实现过其中的函数，可以尝试说出自己的思路。然后可以聊一聊 this 的内容，有几种规则判断 this 到底是什么，this 规则会涉及到 new，那么最后可以说下自己对于 new 的理解。 思考题四：ES6 中有使用过什么？ 思路引导： 这边可说的实在太多，你可以列举 1 - 2 个点。比如说说 class，那么 class 又可以拉回到原型的问题；可以说说 promise，那么线就被拉到了异步的内容；可以说说 proxy，那么如果你使用过 Vue 这个框架，就可以谈谈响应式原理的内容；同样也可以说说 let 这些声明变量的语法，那么就可以谈及与 var 的不同，说到提升这块的内容。 思考题五：JS 是如何运行的？ 思路引导： 这其实是很大的一块内容。你可以先说 JS 是单线程运行的，这里就可以说说你理解的线程和进程的区别。然后讲到执行栈，接下来的内容就是涉及 Eventloop 了，微任务和宏任务的区别，哪些是微任务，哪些又是宏任务，还可以谈及浏览器和 Node 中的 Eventloop 的不同，最后还可以聊一聊 JS 中的垃圾回收。 小结 虽然思考题不多，但是其实每一道思考题背后都可以引申出很多内容，大家接下去在学习的过程中也应该始终有一个意识，你学习的这块内容到底和你现在脑海里的哪一个知识点有关联。同时也欢迎大家总结这些思考题，并且把总结的内容链接放在评论中，我会挑选出不错的文章单独放入一章节给大家参考。 "},"前端面试之道/10.DevToolsTips.html":{"url":"前端面试之道/10.DevToolsTips.html","title":"10.DevToolsTips","keywords":"","body":"DevTools Tips 这一章节的内容可能和面试没有太大关系，但是如果你能很好地使用 DevTools 的话，它能够很好地帮助你提高生产力和解决问题的能力。在这一章节中，我不会去介绍大家经常使用的功能，重点在于让大家学习到一些使用 DevTools 的技巧。 Elements 这个功能肯定是大家经常用到的，我们可以通过它来可视化所有的 DOM 标签，可以查看任何 DOM 的属性，接下来我们就来学习一下关于这方面的 Tips。 Element 状态 你可能会在开发中遇到这么一个场景：给一个 a 标签设置了多种状态下的样式，但是如果手动去改变状态的话就有点麻烦，这时候这个 Tips 就能帮你解决这个问题。 可以从上图中看到，无论你想看到元素的何种状态下的样式，都只需要勾选相对应的状态就可以了，这是不是比手动更改方便多了？ 快速定位 Element 通常页面都是可以滚动的，那么如果想查看的元素不在当前窗口的话，你还需要滚动页面才能找到元素，这时候这个 Tips 就能帮你解决这个问题。 当点击这个选项的时候，页面就会自动滚动到元素所在的位置，这样比边滚动边查看是否找到元素的方式方便多了。 DOM 断点 给 JS 打断点想必各位都听过，但是 DOM 断点知道的人应该就少了。如果你想查看一个 DOM 元素是如何通过 JS 更改的，你就可以使用这个功能。 当我们给 ul 添加该断点以后，一旦 ul 子元素发生了改动，比如说增加了子元素的个数，那么就会自动跳转到对应的 JS 代码 其实不光可以给 DOM 打断点，我们还可以给 Ajax 或者 Event Listener 打断点。 查看事件 我们还可以通过 DevTools 来查看页面中添加了多少的事件。假如当你发现页面滚动起来有性能上的问题时，就可以查看一下有多少 scroll 事件被添加了 找到之前查看过的 DOM 元素 不知道你是否遇到过这样的问题，找不到之前查看过的 DOM 元素在哪里了，需要一个个去找这就有点麻烦了，这时候你就可以使用这个功能。 我们可以通过 $0 来找到上一次查看过的 DOM 元素，$1 就是上上次的元素，之后以此类推。这时候你可能会说，打印出来元素有啥用，在具体什么位置还要去找啊，不用急，马上我就可以解决这个问题 当你点击这个选项时，页面立马会跳转至元素所在位置，并且 DevTools 也会变到 Elements 标签。 Debugging 给 JS 打断点想必大家都会，但是打断点也是有一个不为人知的 Tips 的。 for (let index = 0; index 对于这段代码来说，如果我只想看到 index 为 5 时相应的断点信息，但是一旦打了断点，就会每次循环都会停下来，很浪费时间，那么通过这个小技巧我们就可以圆满解决这个问题 首先我们先右键断点，然后选择 Edit breakpoint... 选项 在弹框内输入 index === 5，这样断点就会变为橙色，并且只有当符合表达式的情况时断点才会被执行 小结 虽然这一章的内容并不多，但是涉及到的几个场景都是日常经常会碰到的，希望这一章节的内容会对大家有帮助。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/11.浏览器基础知识点及常考面试题.html":{"url":"前端面试之道/11.浏览器基础知识点及常考面试题.html","title":"11.浏览器基础知识点及常考面试题","keywords":"","body":"浏览器基础知识点及常考面试题 这一章节我们将会来学习浏览器的一些基础知识点，包括：事件机制、跨域、存储相关，这几个知识点也是面试经常会考到的内容。 事件机制 涉及面试题：事件的触发过程是怎么样的？知道什么是事件代理嘛？ 事件触发三阶段 事件触发有三个阶段： window 往事件触发处传播，遇到注册的捕获事件会触发 传播到事件触发处时触发注册的事件 从事件触发处往 window 传播，遇到注册的冒泡事件会触发 事件触发一般来说会按照上面的顺序进行，但是也有特例，如果给一个 body 中的子节点同时注册冒泡和捕获事件，事件触发会按照注册的顺序执行。 // 以下会先打印冒泡然后是捕获 node.addEventListener( 'click', event => { console.log('冒泡') }, false ) node.addEventListener( 'click', event => { console.log('捕获 ') }, true ) 注册事件 通常我们使用 addEventListener 注册事件，该函数的第三个参数可以是布尔值，也可以是对象。对于布尔值 useCapture 参数来说，该参数默认值为 false ，useCapture 决定了注册的事件是捕获事件还是冒泡事件。对于对象参数来说，可以使用以下几个属性 capture：布尔值，和 useCapture 作用一样 once：布尔值，值为 true 表示该回调只会调用一次，调用后会移除监听 passive：布尔值，表示永远不会调用 preventDefault 一般来说，如果我们只希望事件只触发在目标上，这时候可以使用 stopPropagation 来阻止事件的进一步传播。通常我们认为 stopPropagation 是用来阻止事件冒泡的，其实该函数也可以阻止捕获事件。stopImmediatePropagation 同样也能实现阻止事件，但是还能阻止该事件目标执行别的注册事件。 node.addEventListener( 'click', event => { event.stopImmediatePropagation() console.log('冒泡') }, false ) // 点击 node 只会执行上面的函数，该函数不会执行 node.addEventListener( 'click', event => { console.log('捕获 ') }, true ) 事件代理 如果一个节点中的子节点是动态生成的，那么子节点需要注册事件的话应该注册在父节点上 1 2 3 4 5 let ul = document.querySelector('#ul') ul.addEventListener('click', (event) => { console.log(event.target); }) 事件代理的方式相较于直接给目标注册事件来说，有以下优点： 节省内存 不需要给子节点注销事件 跨域 涉及面试题：什么是跨域？为什么浏览器要使用同源策略？你有几种方式可以解决跨域问题？了解预检请求嘛？ 因为浏览器出于安全考虑，有同源策略。也就是说，如果协议、域名或者端口有一个不同就是跨域，Ajax 请求会失败。 那么是出于什么安全考虑才会引入这种机制呢？ 其实主要是用来防止 CSRF 攻击的。简单点说，CSRF 攻击是利用用户的登录态发起恶意请求。 也就是说，没有同源策略的情况下，A 网站可以被任意其他来源的 Ajax 访问到内容。如果你当前 A 网站还存在登录态，那么对方就可以通过 Ajax 获得你的任何信息。当然跨域并不能完全阻止 CSRF。 然后我们来考虑一个问题，请求跨域了，那么请求到底发出去没有？ 请求必然是发出去了，但是浏览器拦截了响应。你可能会疑问明明通过表单的方式可以发起跨域请求，为什么 Ajax 就不会。因为归根结底，跨域是为了阻止用户读取到另一个域名下的内容，Ajax 可以获取响应，浏览器认为这不安全，所以拦截了响应。但是表单并不会获取新的内容，所以可以发起跨域请求。同时也说明了跨域并不能完全阻止 CSRF，因为请求毕竟是发出去了。 接下来我们将来学习几种常见的方式来解决跨域的问题。 JSONP JSONP 的原理很简单，就是利用 标签没有跨域限制的漏洞。通过 标签指向一个需要访问的地址并提供一个回调函数来接收数据当需要通讯时。 function jsonp(data) { console.log(data) } JSONP 使用简单且兼容性不错，但是只限于 get 请求。 在开发中可能会遇到多个 JSONP 请求的回调函数名是相同的，这时候就需要自己封装一个 JSONP，以下是简单实现 function jsonp(url, jsonpCallback, success) { let script = document.createElement('script') script.src = url script.async = true script.type = 'text/javascript' window[jsonpCallback] = function(data) { success && success(data) } document.body.appendChild(script) } jsonp('http://xxx', 'callback', function(value) { console.log(value) }) CORS CORS 需要浏览器和后端同时支持。IE 8 和 9 需要通过 XDomainRequest 来实现。 浏览器会自动进行 CORS 通信，实现 CORS 通信的关键是后端。只要后端实现了 CORS，就实现了跨域。 服务端设置 Access-Control-Allow-Origin 就可以开启 CORS。 该属性表示哪些域名可以访问资源，如果设置通配符则表示所有网站都可以访问资源。 虽然设置 CORS 和前端没什么关系，但是通过这种方式解决跨域问题的话，会在发送请求时出现两种情况，分别为简单请求和复杂请求。 简单请求 以 Ajax 为例，当满足以下条件时，会触发简单请求 使用下列方法之一： GET HEAD POST Content-Type 的值仅限于下列三者之一： text/plain multipart/form-data application/x-www-form-urlencoded 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器； XMLHttpRequestUpload 对象可以使用 XMLHttpRequest.upload 属性访问。 复杂请求 那么很显然，不符合以上条件的请求就肯定是复杂请求了。 对于复杂请求来说，首先会发起一个预检请求，该请求是 option 方法的，通过该请求来知道服务端是否允许跨域请求。 对于预检请求来说，如果你使用过 Node 来设置 CORS 的话，可能会遇到过这么一个坑。 以下以 express 框架举例： app.use((req, res, next) => { res.header('Access-Control-Allow-Origin', '*') res.header('Access-Control-Allow-Methods', 'PUT, GET, POST, DELETE, OPTIONS') res.header( 'Access-Control-Allow-Headers', 'Origin, X-Requested-With, Content-Type, Accept, Authorization, Access-Control-Allow-Credentials' ) next() }) 该请求会验证你的 Authorization 字段，没有的话就会报错。 当前端发起了复杂请求后，你会发现就算你代码是正确的，返回结果也永远是报错的。因为预检请求也会进入回调中，也会触发 next 方法，因为预检请求并不包含 Authorization 字段，所以服务端会报错。 想解决这个问题很简单，只需要在回调中过滤 option 方法即可 res.statusCode = 204 res.setHeader('Content-Length', '0') res.end() document.domain 该方式只能用于二级域名相同的情况下，比如 a.test.com 和 b.test.com 适用于该方式。 只需要给页面添加 document.domain = 'test.com' 表示二级域名都相同就可以实现跨域 postMessage 这种方式通常用于获取嵌入页面中的第三方页面数据。一个页面发送消息，另一个页面判断来源并接收消息 // 发送消息端 window.parent.postMessage('message', 'http://test.com') // 接收消息端 var mc = new MessageChannel() mc.addEventListener('message', event => { var origin = event.origin || event.originalEvent.origin if (origin === 'http://test.com') { console.log('验证通过') } }) 存储 涉及面试题：有几种方式可以实现存储功能，分别有什么优缺点？什么是 Service Worker？ cookie，localStorage，sessionStorage，indexDB 我们先来通过表格学习下这几种存储方式的区别 特性 cookie localStorage sessionStorage indexDB 数据生命周期 一般由服务器生成，可以设置过期时间 除非被清理，否则一直存在 页面关闭就清理 除非被清理，否则一直存在 数据存储大小 4K 5M 5M 无限 与服务端通信 每次都会携带在 header 中，对于请求性能影响 不参与 不参与 不参与 从上表可以看到，cookie 已经不建议用于存储。如果没有大量数据存储需求的话，可以使用 localStorage 和 sessionStorage 。对于不怎么改变的数据尽量使用 localStorage 存储，否则可以用 sessionStorage 存储。 对于 cookie 来说，我们还需要注意安全性。 属性 作用 value 如果用于保存用户登录态，应该将该值加密，不能使用明文的用户标识 http-only 不能通过 JS 访问 Cookie，减少 XSS 攻击 secure 只能在协议为 HTTPS 的请求中携带 same-site 规定浏览器不能在跨域请求中携带 Cookie，减少 CSRF 攻击 Service Worker Service Worker 是运行在浏览器背后的独立线程，一般可以用来实现缓存功能。使用 Service Worker的话，传输协议必须为 HTTPS。因为 Service Worker 中涉及到请求拦截，所以必须使用 HTTPS 协议来保障安全。 Service Worker 实现缓存功能一般分为三个步骤：首先需要先注册 Service Worker，然后监听到 install 事件以后就可以缓存需要的文件，那么在下次用户访问的时候就可以通过拦截请求的方式查询是否存在缓存，存在缓存的话就可以直接读取缓存文件，否则就去请求数据。以下是这个步骤的实现： // index.js if (navigator.serviceWorker) { navigator.serviceWorker .register('sw.js') .then(function(registration) { console.log('service worker 注册成功') }) .catch(function(err) { console.log('servcie worker 注册失败') }) } // sw.js // 监听 `install` 事件，回调中缓存所需文件 self.addEventListener('install', e => { e.waitUntil( caches.open('my-cache').then(function(cache) { return cache.addAll(['./index.html', './index.js']) }) ) }) // 拦截所有请求事件 // 如果缓存中已经有请求的数据就直接用缓存，否则去请求数据 self.addEventListener('fetch', e => { e.respondWith( caches.match(e.request).then(function(response) { if (response) { return response } console.log('fetch source') }) ) }) 打开页面，可以在开发者工具中的 Application 看到 Service Worker 已经启动了 在 Cache 中也可以发现我们所需的文件已被缓存 当我们重新刷新页面可以发现我们缓存的数据是从 Service Worker 中读取的 小结 以上就是浏览器基础知识点的内容了，如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/12.浏览器缓存机制.html":{"url":"前端面试之道/12.浏览器缓存机制.html","title":"12.浏览器缓存机制","keywords":"","body":"浏览器缓存机制 注意：该知识点属于性能优化领域，并且整一章节都是一个面试题。 缓存可以说是性能优化中简单高效的一种优化方式了，它可以显著减少网络传输所带来的损耗。 对于一个数据请求来说，可以分为发起网络请求、后端处理、浏览器响应三个步骤。浏览器缓存可以帮助我们在第一和第三步骤中优化性能。比如说直接使用缓存而不发起请求，或者发起了请求但后端存储的数据和前端一致，那么就没有必要再将数据回传回来，这样就减少了响应数据。 接下来的内容中我们将通过以下几个部分来探讨浏览器缓存机制： 缓存位置 缓存策略 实际场景应用缓存策略 缓存位置 从缓存位置上来说分为四种，并且各自有优先级，当依次查找缓存且都没有命中的时候，才会去请求网络 Service Worker Memory Cache Disk Cache Push Cache 网络请求 Service Worker 在上一章节中我们已经介绍了 Service Worker 的内容，这里就不演示相关的代码了。 Service Worker 的缓存与浏览器其他内建的缓存机制不同，它可以让我们自由控制缓存哪些文件、如何匹配缓存、如何读取缓存，并且缓存是持续性的。 当 Service Worker 没有命中缓存的时候，我们需要去调用 fetch 函数获取数据。也就是说，如果我们没有在 Service Worker 命中缓存的话，会根据缓存查找优先级去查找数据。但是不管我们是从 Memory Cache 中还是从网络请求中获取的数据，浏览器都会显示我们是从 Service Worker 中获取的内容。 Memory Cache Memory Cache 也就是内存中的缓存，读取内存中的数据肯定比磁盘快。但是内存缓存虽然读取高效，可是缓存持续性很短，会随着进程的释放而释放。 一旦我们关闭 Tab 页面，内存中的缓存也就被释放了。 当我们访问过页面以后，再次刷新页面，可以发现很多数据都来自于内存缓存 从内存中读取缓存 那么既然内存缓存这么高效，我们是不是能让数据都存放在内存中呢？ 先说结论，这是不可能的。首先计算机中的内存一定比硬盘容量小得多，操作系统需要精打细算内存的使用，所以能让我们使用的内存必然不多。内存中其实可以存储大部分的文件，比如说 JSS、HTML、CSS、图片等等。但是浏览器会把哪些文件丢进内存这个过程就很玄学了，我查阅了很多资料都没有一个定论。 当然，我通过一些实践和猜测也得出了一些结论： 对于大文件来说，大概率是不存储在内存中的，反之优先 当前系统内存使用率高的话，文件优先存储进硬盘 Disk Cache Disk Cache 也就是存储在硬盘中的缓存，读取速度慢点，但是什么都能存储到磁盘中，比之 Memory Cache 胜在容量和存储时效性上。 在所有浏览器缓存中，Disk Cache 覆盖面基本是最大的。它会根据 HTTP Herder 中的字段判断哪些资源需要缓存，哪些资源可以不请求直接使用，哪些资源已经过期需要重新请求。并且即使在跨站点的情况下，相同地址的资源一旦被硬盘缓存下来，就不会再次去请求数据。 Push Cache Push Cache 是 HTTP/2 中的内容，当以上三种缓存都没有命中时，它才会被使用。并且缓存时间也很短暂，只在会话（Session）中存在，一旦会话结束就被释放。 Push Cache 在国内能够查到的资料很少，也是因为 HTTP/2 在国内不够普及，但是 HTTP/2 将会是日后的一个趋势。这里推荐阅读 HTTP/2 push is tougher than I thought 这篇文章，但是内容是英文的，我翻译一下文章中的几个结论，有能力的同学还是推荐自己阅读 所有的资源都能被推送，但是 Edge 和 Safari 浏览器兼容性不怎么好 可以推送 no-cache 和 no-store 的资源 一旦连接被关闭，Push Cache 就被释放 多个页面可以使用相同的 HTTP/2 连接，也就是说能使用同样的缓存 Push Cache 中的缓存只能被使用一次 浏览器可以拒绝接受已经存在的资源推送 你可以给其他域名推送资源 网络请求 如果所有缓存都没有命中的话，那么只能发起请求来获取资源了。 那么为了性能上的考虑，大部分的接口都应该选择好缓存策略，接下来我们就来学习缓存策略这部分的内容。 缓存策略 通常浏览器缓存策略分为两种：强缓存和协商缓存，并且缓存策略都是通过设置 HTTP Header 来实现的。 强缓存 强缓存可以通过设置两种 HTTP Header 实现：Expires 和 Cache-Control 。强缓存表示在缓存期间不需要请求，state code 为 200。 Expires Expires: Wed, 22 Oct 2018 08:41:00 GMT Expires 是 HTTP/1 的产物，表示资源会在 Wed, 22 Oct 2018 08:41:00 GMT 后过期，需要再次请求。并且 Expires 受限于本地时间，如果修改了本地时间，可能会造成缓存失效。 Cache-control Cache-control: max-age=30 Cache-Control 出现于 HTTP/1.1，优先级高于 Expires 。该属性值表示资源会在 30 秒后过期，需要再次请求。 Cache-Control 可以在请求头或者响应头中设置，并且可以组合使用多种指令 多种指令配合流程图 从图中我们可以看到，我们可以将多个指令配合起来一起使用，达到多个目的。比如说我们希望资源能被缓存下来，并且是客户端和代理服务器都能缓存，还能设置缓存失效时间等等。 接下来我们就来学习一些常见指令的作用 常见指令作用 协商缓存 如果缓存过期了，就需要发起请求验证资源是否有更新。协商缓存可以通过设置两种 HTTP Header 实现：Last-Modified 和 ETag 。 当浏览器发起请求验证资源时，如果资源没有做改变，那么服务端就会返回 304 状态码，并且更新浏览器缓存有效期。 协商缓存 Last-Modified 和 If-Modified-Since Last-Modified 表示本地文件最后修改日期，If-Modified-Since 会将 Last-Modified 的值发送给服务器，询问服务器在该日期后资源是否有更新，有更新的话就会将新的资源发送回来，否则返回 304 状态码。 但是 Last-Modified 存在一些弊端： 如果本地打开缓存文件，即使没有对文件进行修改，但还是会造成 Last-Modified 被修改，服务端不能命中缓存导致发送相同的资源 因为 Last-Modified 只能以秒计时，如果在不可感知的时间内修改完成文件，那么服务端会认为资源还是命中了，不会返回正确的资源 因为以上这些弊端，所以在 HTTP / 1.1 出现了 ETag 。 ETag 和 If-None-Match ETag 类似于文件指纹，If-None-Match 会将当前 ETag 发送给服务器，询问该资源 ETag 是否变动，有变动的话就将新的资源发送回来。并且 ETag 优先级比 Last-Modified 高。 以上就是缓存策略的所有内容了，看到这里，不知道你是否存在这样一个疑问。如果什么缓存策略都没设置，那么浏览器会怎么处理？ 对于这种情况，浏览器会采用一个启发式的算法，通常会取响应头中的 Date 减去 Last-Modified 值的 10% 作为缓存时间。 实际场景应用缓存策略 单纯了解理论而不付诸于实践是没有意义的，接下来我们来通过几个场景学习下如何使用这些理论。 频繁变动的资源 对于频繁变动的资源，首先需要使用 Cache-Control: no-cache 使浏览器每次都请求服务器，然后配合 ETag 或者 Last-Modified 来验证资源是否有效。这样的做法虽然不能节省请求数量，但是能显著减少响应数据大小。 代码文件 这里特指除了 HTML 外的代码文件，因为 HTML 文件一般不缓存或者缓存时间很短。 一般来说，现在都会使用工具来打包代码，那么我们就可以对文件名进行哈希处理，只有当代码修改后才会生成新的文件名。基于此，我们就可以给代码文件设置缓存有效期一年 Cache-Control: max-age=31536000，这样只有当 HTML 文件中引入的文件名发生了改变才会去下载最新的代码文件，否则就一直使用缓存。 小结 在这一章节中我们了解了浏览器的缓存机制，并且列举了几个场景来实践我们学习到的理论。如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/13.浏览器渲染原理.html":{"url":"前端面试之道/13.浏览器渲染原理.html","title":"13.浏览器渲染原理","keywords":"","body":"浏览器渲染原理 注意：该章节都是一个面试题。 在这一章节中，我们将来学习浏览器渲染原理这部分的知识。你可能会有疑问，我又不是做浏览器研发的，为什么要来学习这个？其实我们学习浏览器渲染原理更多的是为了解决性能的问题，如果你不了解这部分的知识，你就不知道什么情况下会对性能造成损伤。并且渲染原理在面试中答得好，也是一个能与其他候选人拉开差距的一点。 我们知道执行 JS 有一个 JS 引擎，那么执行渲染也有一个渲染引擎。同样，渲染引擎在不同的浏览器中也不是都相同的。比如在 Firefox 中叫做 Gecko，在 Chrome 和 Safari 中都是基于 WebKit 开发的。在这一章节中，我们也会主要学习关于 WebKit 的这部分渲染引擎内容。 浏览器接收到 HTML 文件并转换为 DOM 树 当我们打开一个网页时，浏览器都会去请求对应的 HTML 文件。虽然平时我们写代码时都会分为 JS、CSS、HTML 文件，也就是字符串，但是计算机硬件是不理解这些字符串的，所以在网络中传输的内容其实都是 0 和 1 这些字节数据。当浏览器接收到这些字节数据以后，它会将这些字节数据转换为字符串，也就是我们写的代码。 当数据转换为字符串以后，浏览器会先将这些字符串通过词法分析转换为标记（token），这一过程在词法分析中叫做标记化（tokenization）。 那么什么是标记呢？这其实属于编译原理这一块的内容了。简单来说，标记还是字符串，是构成代码的最小单位。这一过程会将代码分拆成一块块，并给这些内容打上标记，便于理解这些最小单位的代码是什么意思。 当结束标记化后，这些标记会紧接着转换为 Node，最后这些 Node 会根据不同 Node 之前的联系构建为一颗 DOM 树。 以上就是浏览器从网络中接收到 HTML 文件然后一系列的转换过程。 当然，在解析 HTML 文件的时候，浏览器还会遇到 CSS 和 JS 文件，这时候浏览器也会去下载并解析这些文件，接下来就让我们先来学习浏览器如何解析 CSS 文件。 将 CSS 文件转换为 CSSOM 树 其实转换 CSS 到 CSSOM 树的过程和上一小节的过程是极其类似的 在这一过程中，浏览器会确定下每一个节点的样式到底是什么，并且这一过程其实是很消耗资源的。因为样式你可以自行设置给某个节点，也可以通过继承获得。在这一过程中，浏览器得递归 CSSOM 树，然后确定具体的元素到底是什么样式。 如果你有点不理解为什么会消耗资源的话，我这里举个例子 span { color: red; } div > a > span { color: red; } 对于第一种设置样式的方式来说，浏览器只需要找到页面中所有的 span 标签然后设置颜色，但是对于第二种设置样式的方式来说，浏览器首先需要找到所有的 span 标签，然后找到 span 标签上的 a 标签，最后再去找到 div 标签，然后给符合这种条件的 span 标签设置颜色，这样的递归过程就很复杂。所以我们应该尽可能的避免写过于具体的 CSS 选择器，然后对于 HTML 来说也尽量少的添加无意义标签，保证层级扁平。 生成渲染树 当我们生成 DOM 树和 CSSOM 树以后，就需要将这两棵树组合为渲染树。 在这一过程中，不是简单的将两者合并就行了。渲染树只会包括需要显示的节点和这些节点的样式信息，如果某个节点是 display: none 的，那么就不会在渲染树中显示。 当浏览器生成渲染树以后，就会根据渲染树来进行布局（也可以叫做回流），然后调用 GPU 绘制，合成图层，显示在屏幕上。对于这一部分的内容因为过于底层，还涉及到了硬件相关的知识，这里就不再继续展开内容了。 那么通过以上内容，我们已经详细了解到了浏览器从接收文件到将内容渲染在屏幕上的这一过程。接下来，我们将会来学习上半部分遗留下来的一些知识点。 为什么操作 DOM 慢 想必大家都听过操作 DOM 性能很差，但是这其中的原因是什么呢？ 因为 DOM 是属于渲染引擎中的东西，而 JS 又是 JS 引擎中的东西。当我们通过 JS 操作 DOM 的时候，其实这个操作涉及到了两个线程之间的通信，那么势必会带来一些性能上的损耗。操作 DOM 次数一多，也就等同于一直在进行线程之间的通信，并且操作 DOM 可能还会带来重绘回流的情况，所以也就导致了性能上的问题。 经典面试题：插入几万个 DOM，如何实现页面不卡顿？ 对于这道题目来说，首先我们肯定不能一次性把几万个 DOM 全部插入，这样肯定会造成卡顿，所以解决问题的重点应该是如何分批次部分渲染 DOM。大部分人应该可以想到通过 requestAnimationFrame 的方式去循环的插入 DOM，其实还有种方式去解决这个问题：虚拟滚动（virtualized scroller）。 这种技术的原理就是只渲染可视区域内的内容，非可见区域的那就完全不渲染了，当用户在滚动的时候就实时去替换渲染的内容。 从上图中我们可以发现，即使列表很长，但是渲染的 DOM 元素永远只有那么几个，当我们滚动页面的时候就会实时去更新 DOM，这个技术就能顺利解决这道经典面试题。如果你想了解更多的内容可以了解下这个 react-virtualized。 什么情况阻塞渲染 首先渲染的前提是生成渲染树，所以 HTML 和 CSS 肯定会阻塞渲染。如果你想渲染的越快，你越应该降低一开始需要渲染的文件大小，并且扁平层级，优化选择器。 然后当浏览器在解析到 script 标签时，会暂停构建 DOM，完成后才会从暂停的地方重新开始。也就是说，如果你想首屏渲染的越快，就越不应该在首屏就加载 JS 文件，这也是都建议将 script 标签放在 body 标签底部的原因。 当然在当下，并不是说 script 标签必须放在底部，因为你可以给 script 标签添加 defer 或者 async 属性。 当 script 标签加上 defer 属性以后，表示该 JS 文件会并行下载，但是会放到 HTML 解析完成后顺序执行，所以对于这种情况你可以把 script 标签放在任意位置。 对于没有任何依赖的 JS 文件可以加上 async 属性，表示 JS 文件下载和解析不会阻塞渲染。 重绘（Repaint）和回流（Reflow） 重绘和回流会在我们设置节点样式时频繁出现，同时也会很大程度上影响性能。 重绘是当节点需要更改外观而不会影响布局的，比如改变 color 就叫称为重绘 回流是布局或者几何属性需要改变就称为回流。 回流必定会发生重绘，重绘不一定会引发回流。回流所需的成本比重绘高的多，改变父节点里的子节点很可能会导致父节点的一系列回流。 以下几个动作可能会导致性能问题： 改变 window 大小 改变字体 添加或删除样式 文字改变 定位或者浮动 盒模型 并且很多人不知道的是，重绘和回流其实也和 Eventloop 有关。 当 Eventloop 执行完 Microtasks 后，会判断 document 是否需要更新，因为浏览器是 60Hz 的刷新率，每 16.6ms 才会更新一次。 然后判断是否有 resize 或者 scroll 事件，有的话会去触发事件，所以 resize 和 scroll 事件也是至少 16ms 才会触发一次，并且自带节流功能。 判断是否触发了 media query 更新动画并且发送事件 判断是否有全屏操作事件 执行 requestAnimationFrame 回调 执行 IntersectionObserver 回调，该方法用于判断元素是否可见，可以用于懒加载上，但是兼容性不好 更新界面 以上就是一帧中可能会做的事情。如果在一帧中有空闲时间，就会去执行 requestIdleCallback 回调。 以上内容来自于 HTML 文档。 既然我们已经知道了重绘和回流会影响性能，那么接下来我们将会来学习如何减少重绘和回流的次数。 减少重绘和回流 使用 transform 替代 top .test { position: absolute; top: 10px; width: 100px; height: 100px; background: red; } setTimeout(() => { // 引起回流 document.querySelector('.test').style.top = '100px' }, 1000) 使用 visibility 替换 display: none ，因为前者只会引起重绘，后者会引发回流（改变了布局） 不要把节点的属性值放在一个循环里当成循环里的变量 for(let i = 0; i 不要使用 table 布局，可能很小的一个小改动会造成整个 table 的重新布局 动画实现的速度的选择，动画速度越快，回流次数越多，也可以选择使用 requestAnimationFrame CSS 选择符从右往左匹配查找，避免节点层级过多 将频繁重绘或者回流的节点设置为图层，图层能够阻止该节点的渲染行为影响别的节点。比如对于 video 标签来说，浏览器会自动将该节点变为图层。 设置节点为图层的方式有很多，我们可以通过以下几个常用属性可以生成新图层 will-change video、iframe 标签 思考题 思考题：在不考虑缓存和优化网络协议的前提下，考虑可以通过哪些方式来最快的渲染页面，也就是常说的关键渲染路径，这部分也是性能优化中的一块内容。 首先你可能会疑问，那怎么测量到底有没有加快渲染速度呢 当发生 DOMContentLoaded 事件后，就会生成渲染树，生成渲染树就可以进行渲染了，这一过程更大程度上和硬件有关系了。 提示如何加速： 从文件大小考虑 从 script 标签使用上来考虑 从 CSS、HTML 的代码书写上来考虑 从需要下载的内容是否需要在首屏使用上来考虑 以上提示大家都可以从文中找到，同时也欢迎大家踊跃在评论区写出你的答案。 小结 以上就是我们这一章节的内容了。在这一章节中，我们了解了浏览器如何将文件渲染为页面，同时也掌握了一些优化的小技巧。这部分的内容理解起来不大容易，如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/14.安全防范知识点.html":{"url":"前端面试之道/14.安全防范知识点.html","title":"14.安全防范知识点","keywords":"","body":"安全防范知识点 这一章我们将来学习安全防范这一块的知识点。总的来说安全是很复杂的一个领域，不可能通过一个章节就能学习到这部分的内容。在这一章节中，我们会学习到常见的一些安全问题及如何防范的内容，在当下其实安全问题越来越重要，已经逐渐成为前端开发必备的技能了。 XSS 涉及面试题：什么是 XSS 攻击？如何防范 XSS 攻击？什么是 CSP？ XSS 简单点来说，就是攻击者想尽一切办法将可以执行的代码注入到网页中。 XSS 可以分为多种类型，但是总体上我认为分为两类：持久型和非持久型。 持久型也就是攻击的代码被服务端写入进数据库中，这种攻击危害性很大，因为如果网站访问量很大的话，就会导致大量正常访问页面的用户都受到攻击。 举个例子，对于评论功能来说，就得防范持久型 XSS 攻击，因为我可以在评论中输入以下内容 这种情况如果前后端没有做好防御的话，这段评论就会被存储到数据库中，这样每个打开该页面的用户都会被攻击到。 非持久型相比于前者危害就小的多了，一般通过修改 URL 参数的方式加入攻击代码，诱导用户访问链接从而进行攻击。 举个例子，如果页面需要从 URL 中获取某些参数作为内容的话，不经过过滤就会导致攻击代码被执行 alert(1) --> {{name}} 但是对于这种攻击方式来说，如果用户使用 Chrome 这类浏览器的话，浏览器就能自动帮助用户防御攻击。但是我们不能因此就不防御此类攻击了，因为我不能确保用户都使用了该类浏览器。 对于 XSS 攻击来说，通常有两种方式可以用来防御。 转义字符 首先，对于用户的输入应该是永远不信任的。最普遍的做法就是转义输入输出的内容，对于引号、尖括号、斜杠进行转义 function escape(str) { str = str.replace(/&/g, '&amp;') str = str.replace(//g, '&gt;') str = str.replace(/\"/g, '&quto;') str = str.replace(/'/g, '&#39;') str = str.replace(/`/g, '&#96;') str = str.replace(/\\//g, '&#x2F;') return str } 通过转义可以将攻击代码 alert(1) 变成 // -> &lt;script&gt;alert(1)&lt;&#x2F;script&gt; escape('alert(1)') 但是对于显示富文本来说，显然不能通过上面的办法来转义所有字符，因为这样会把需要的格式也过滤掉。对于这种情况，通常采用白名单过滤的办法，当然也可以通过黑名单过滤，但是考虑到需要过滤的标签和标签属性实在太多，更加推荐使用白名单的方式。 const xss = require('xss') let html = xss('XSS Demoalert(\"xss\");') // -> XSS Demo&lt;script&gt;alert(\"xss\");&lt;/script&gt; console.log(html) 以上示例使用了 js-xss 来实现，可以看到在输出中保留了 h1 标签且过滤了 script 标签。 CSP CSP 本质上就是建立白名单，开发者明确告诉浏览器哪些外部资源可以加载和执行。我们只需要配置规则，如何拦截是由浏览器自己实现的。我们可以通过这种方式来尽量减少 XSS 攻击。 通常可以通过两种方式来开启 CSP： 设置 HTTP Header 中的 Content-Security-Policy 设置 meta 标签的方式 这里以设置 HTTP Header 来举例 只允许加载本站资源 Content-Security-Policy: default-src ‘self’ 只允许加载 HTTPS 协议图片 Content-Security-Policy: img-src https://* 允许加载任何来源框架 Content-Security-Policy: child-src 'none' 当然可以设置的属性远不止这些，你可以通过查阅 文档 的方式来学习，这里就不过多赘述其他的属性了。 对于这种方式来说，只要开发者配置了正确的规则，那么即使网站存在漏洞，攻击者也不能执行它的攻击代码，并且 CSP 的兼容性也不错。 CSRF 涉及面试题：什么是 CSRF 攻击？如何防范 CSRF 攻击？ CSRF 中文名为跨站请求伪造。原理就是攻击者构造出一个后端请求地址，诱导用户点击或者通过某些途径自动发起请求。如果用户是在登录状态下的话，后端就以为是用户在操作，从而进行相应的逻辑。 举个例子，假设网站中有一个通过 GET 请求提交用户评论的接口，那么攻击者就可以在钓鱼网站中加入一个图片，图片的地址就是评论接口 那么你是否会想到使用 POST 方式提交请求是不是就没有这个问题了呢？其实并不是，使用这种方式也不是百分百安全的，攻击者同样可以诱导用户进入某个页面，在页面中通过表单提交 POST 请求。 如何防御 防范 CSRF 攻击可以遵循以下几种规则： Get 请求不对数据进行修改 不让第三方网站访问到用户 Cookie 阻止第三方网站请求接口 请求时附带验证信息，比如验证码或者 Token SameSite 可以对 Cookie 设置 SameSite 属性。该属性表示 Cookie 不随着跨域请求发送，可以很大程度减少 CSRF 的攻击，但是该属性目前并不是所有浏览器都兼容。 验证 Referer 对于需要防范 CSRF 的请求，我们可以通过验证 Referer 来判断该请求是否为第三方网站发起的。 Token 服务器下发一个随机 Token，每次发起请求时将 Token 携带上，服务器验证 Token 是否有效。 点击劫持 涉及面试题：什么是点击劫持？如何防范点击劫持？ 点击劫持是一种视觉欺骗的攻击手段。攻击者将需要攻击的网站通过 iframe 嵌套的方式嵌入自己的网页中，并将 iframe 设置为透明，在页面中透出一个按钮诱导用户点击。 对于这种攻击方式，推荐防御的方法有两种。 X-FRAME-OPTIONS X-FRAME-OPTIONS 是一个 HTTP 响应头，在现代浏览器有一个很好的支持。这个 HTTP 响应头 就是为了防御用 iframe 嵌套的点击劫持攻击。 该响应头有三个值可选，分别是 DENY，表示页面不允许通过 iframe 的方式展示 SAMEORIGIN，表示页面可以在相同域名下通过 iframe 的方式展示 ALLOW-FROM，表示页面可以在指定来源的 iframe 中展示 JS 防御 对于某些远古浏览器来说，并不能支持上面的这种方式，那我们只有通过 JS 的方式来防御点击劫持了。 html { display: none !important; } if (self == top) { var style = document.getElementById('click-jack') document.body.removeChild(style) } else { top.location = self.location } 以上代码的作用就是当通过 iframe 的方式加载页面时，攻击者的网页直接不显示所有内容了。 中间人攻击 涉及面试题：什么是中间人攻击？如何防范中间人攻击？ 中间人攻击是攻击方同时与服务端和客户端建立起了连接，并让对方认为连接是安全的，但是实际上整个通信过程都被攻击者控制了。攻击者不仅能获得双方的通信信息，还能修改通信信息。 通常来说不建议使用公共的 Wi-Fi，因为很可能就会发生中间人攻击的情况。如果你在通信的过程中涉及到了某些敏感信息，就完全暴露给攻击方了。 当然防御中间人攻击其实并不难，只需要增加一个安全通道来传输信息。HTTPS 就可以用来防御中间人攻击，但是并不是说使用了 HTTPS 就可以高枕无忧了，因为如果你没有完全关闭 HTTP 访问的话，攻击方可以通过某些方式将 HTTPS 降级为 HTTP 从而实现中间人攻击。 小结 在这一章中，我们学习到了一些常见的前端安全方面的知识及如何防御这些攻击。但是安全的领域相当大，这些内容只是沧海一粟，如果大家对于安全有兴趣的话，可以阅读 这个仓库的内容 来学习和实践这方面的知识。 "},"前端面试之道/15.从V8中看JS性能优化.html":{"url":"前端面试之道/15.从V8中看JS性能优化.html","title":"15.从V8中看JS性能优化","keywords":"","body":"从 V8 中看 JS 性能优化 注意：该知识点属于性能优化领域。 性能问题越来越成为前端火热的话题，因为随着项目的逐步变大，性能问题也逐步体现出来。为了提高用户的体验，减少加载时间，工程师们想尽一切办法去优化细节。 掘金之前已经出过一本关于性能的小册，我在写涉及性能优化的内容之前就特地去购买了这本小册阅读，目的是为了写出点不一样的东西。当然性能优化归结起来还是那几个点，我只能尽可能地写出那本小册没有提及的内容，部分内容还是会有重叠的。当然它通过了十五个章节去介绍性能，肯定会讲的比我细，有兴趣的可以同时购买还有本 「前端性能优化原理与实践 」小册，形成一个互补。 在这几个章节中不会提及浏览器、Webpack、网络协议这几块如何优化的内容，因为对应的模块中已经讲到了这部分的内容，如果你想学习这几块该如何性能优化的话，可以去对应的章节阅读。 在这一章节中我们将来学习如何让 V8 优化我们的代码，下一章节将会学习性能优化剩余的琐碎点，因为性能优化这个领域所涉及的内容都很碎片化。 在学习如何性能优化之前，我们先来了解下如何测试性能问题，毕竟是先有问题才会去想着该如何改进。 测试性能工具 Chrome 已经提供了一个大而全的性能测试工具 Audits Audits 所处位置 点我们点击 Audits 后，可以看到如下的界面 Audits 界面 在这个界面中，我们可以选择想测试的功能然后点击 Run audits ，工具就会自动运行帮助我们测试问题并且给出一个完整的报告 Audits 工具给出的报告 上图是给掘金首页测试性能后给出的一个报告，可以看到报告中分别为性能、体验、SEO 都给出了打分，并且每一个指标都有详细的评估 指标中的详细评估 评估结束后，工具还提供了一些建议便于我们提高这个指标的分数 优化建议 我们只需要一条条根据建议去优化性能即可。 除了 Audits 工具之外，还有一个 Performance 工具也可以供我们使用。 Performance 工具给出的报告 在这张图中，我们可以详细的看到每个时间段中浏览器在处理什么事情，哪个过程最消耗时间，便于我们更加详细的了解性能瓶颈。 JS 性能优化 JS 是编译型还是解释型语言其实并不固定。首先 JS 需要有引擎才能运行起来，无论是浏览器还是在 Node 中，这是解释型语言的特性。但是在 V8 引擎下，又引入了 TurboFan 编译器，他会在特定的情况下进行优化，将代码编译成执行效率更高的 Machine Code，当然这个编译器并不是 JS 必须需要的，只是为了提高代码执行性能，所以总的来说 JS 更偏向于解释型语言。 那么这一小节的内容主要会针对于 Chrome 的 V8 引擎来讲解。 在这一过程中，JS 代码首先会解析为抽象语法树（AST），然后会通过解释器或者编译器转化为 Bytecode 或者 Machine Code V8 转化代码的过程 从上图中我们可以发现，JS 会首先被解析为 AST，解析的过程其实是略慢的。代码越多，解析的过程也就耗费越长，这也是我们需要压缩代码的原因之一。另外一种减少解析时间的方式是预解析，会作用于未执行的函数，这个我们下面再谈。 2016 年手机解析 JS 代码的速度 这里需要注意一点，对于函数来说，应该尽可能避免声明嵌套函数（类也是函数），因为这样会造成函数的重复解析。 function test1() { // 会被重复解析 function test2() {} } 然后 Ignition 负责将 AST 转化为 Bytecode，TurboFan 负责编译出优化后的 Machine Code，并且 Machine Code 在执行效率上优于 Bytecode 那么我们就产生了一个疑问，什么情况下代码会编译为 Machine Code？ JS 是一门动态类型的语言，并且还有一大堆的规则。简单的加法运算代码，内部就需要考虑好几种规则，比如数字相加、字符串相加、对象和字符串相加等等。这样的情况也就势必导致了内部要增加很多判断逻辑，降低运行效率。 function test(x) { return x + x } test(1) test(2) test(3) test(4) 对于以上代码来说，如果一个函数被多次调用并且参数一直传入 number 类型，那么 V8 就会认为该段代码可以编译为 Machine Code，因为你固定了类型，不需要再执行很多判断逻辑了。 但是如果一旦我们传入的参数类型改变，那么 Machine Code 就会被 DeOptimized 为 Bytecode，这样就有性能上的一个损耗了。所以如果我们希望代码能多的编译为 Machine Code 并且 DeOptimized 的次数减少，就应该尽可能保证传入的类型一致。 那么你可能会有一个疑问，到底优化前后有多少的提升呢，接下来我们就来实践测试一下到底有多少的提升。 const { performance, PerformanceObserver } = require('perf_hooks') function test(x) { return x + x } // node 10 中才有 PerformanceObserver // 在这之前的 node 版本可以直接使用 performance 中的 API const obs = new PerformanceObserver((list, observer) => { console.log(list.getEntries()) observer.disconnect() }) obs.observe({ entryTypes: ['measure'], buffered: true }) performance.mark('start') let number = 10000000 // 不优化代码 %NeverOptimizeFunction(test) while (number--) { test(1) } performance.mark('end') performance.measure('test', 'start', 'end') 以上代码中我们使用了 performance API，这个 API 在性能测试上十分好用。不仅可以用来测量代码的执行时间，还能用来测量各种网络连接中的时间消耗等等，并且这个 API 也可以在浏览器中使用。 优化与不优化代码之间的巨大差距 从上图中我们可以发现，优化过的代码执行时间只需要 9ms，但是不优化过的代码执行时间却是前者的二十倍，已经接近 200ms 了。在这个案例中，我相信大家已经看到了 V8 的性能优化到底有多强，只需要我们符合一定的规则书写代码，引擎底层就能帮助我们自动优化代码。 另外，编译器还有个骚操作 Lazy-Compile，当函数没有被执行的时候，会对函数进行一次预解析，直到代码被执行以后才会被解析编译。对于上述代码来说，test 函数需要被预解析一次，然后在调用的时候再被解析编译。但是对于这种函数马上就被调用的情况来说，预解析这个过程其实是多余的，那么有什么办法能够让代码不被预解析呢？ 其实很简单，我们只需要给函数套上括号就可以了 (function test(obj) { return x + x }) 但是不可能我们为了性能优化，给所有的函数都去套上括号，并且也不是所有函数都需要这样做。我们可以通过 optimize-js 实现这个功能，这个库会分析一些函数的使用情况，然后给需要的函数添加括号，当然这个库很久没人维护了，如果需要使用的话，还是需要测试过相关内容的。 小结 总结一下这一章节我们学习的知识 可以通过 Audit 工具获得网站的多个指标的性能报告 可以通过 Performance 工具了解网站的性能瓶颈 可以通过 Performance API 具体测量时间 为了减少编译时间，我们可以采用减少代码文件的大小或者减少书写嵌套函数的方式 为了让 V8 优化代码，我们应该尽可能保证传入参数的类型一致。这也给我们带来了一个思考，这是不是也是使用 TypeScript 能够带来的好处之一 "},"前端面试之道/16.性能优化琐碎事.html":{"url":"前端面试之道/16.性能优化琐碎事.html","title":"16.性能优化琐碎事","keywords":"","body":"性能优化琐碎事 注意：该知识点属于性能优化领域。 总的来说性能优化这个领域的很多内容都很碎片化，这一章节我们将来学习这些碎片化的内容。 图片优化 计算图片大小 对于一张 100 * 100 像素的图片来说，图像上有 10000 个像素点，如果每个像素的值是 RGBA 存储的话，那么也就是说每个像素有 4 个通道，每个通道 1 个字节（8 位 = 1个字节），所以该图片大小大概为 39KB（10000 * 1 * 4 / 1024）。 但是在实际项目中，一张图片可能并不需要使用那么多颜色去显示，我们可以通过减少每个像素的调色板来相应缩小图片的大小。 了解了如何计算图片大小的知识，那么对于如何优化图片，想必大家已经有 2 个思路了： 减少像素点 减少每个像素点能够显示的颜色 图片加载优化 不用图片。很多时候会使用到很多修饰类图片，其实这类修饰图片完全可以用 CSS 去代替。 对于移动端来说，屏幕宽度就那么点，完全没有必要去加载原图浪费带宽。一般图片都用 CDN 加载，可以计算出适配屏幕的宽度，然后去请求相应裁剪好的图片。 小图使用 base64 格式 将多个图标文件整合到一张图片中（雪碧图） 选择正确的图片格式： 对于能够显示 WebP 格式的浏览器尽量使用 WebP 格式。因为 WebP 格式具有更好的图像数据压缩算法，能带来更小的图片体积，而且拥有肉眼识别无差异的图像质量，缺点就是兼容性并不好 小图使用 PNG，其实对于大部分图标这类图片，完全可以使用 SVG 代替 照片使用 JPEG DNS 预解析 DNS 解析也是需要时间的，可以通过预解析的方式来预先获得域名所对应的 IP。 节流 考虑一个场景，滚动事件中会发起网络请求，但是我们并不希望用户在滚动过程中一直发起请求，而是隔一段时间发起一次，对于这种情况我们就可以使用节流。 理解了节流的用途，我们就来实现下这个函数 // func是用户传入需要防抖的函数 // wait是等待时间 const throttle = (func, wait = 50) => { // 上一次执行该函数的时间 let lastTime = 0 return function(...args) { // 当前时间 let now = +new Date() // 将当前时间和上一次执行函数时间对比 // 如果差值大于设置的等待时间就执行函数 if (now - lastTime > wait) { lastTime = now func.apply(this, args) } } } setInterval( throttle(() => { console.log(1) }, 500), 1 ) 防抖 考虑一个场景，有一个按钮点击会触发网络请求，但是我们并不希望每次点击都发起网络请求，而是当用户点击按钮一段时间后没有再次点击的情况才去发起网络请求，对于这种情况我们就可以使用防抖。 理解了防抖的用途，我们就来实现下这个函数 // func是用户传入需要防抖的函数 // wait是等待时间 const debounce = (func, wait = 50) => { // 缓存一个定时器id let timer = 0 // 这里返回的函数是每次用户实际调用的防抖函数 // 如果已经设定过定时器了就清空上一次的定时器 // 开始一个新的定时器，延迟执行用户传入的方法 return function(...args) { if (timer) clearTimeout(timer) timer = setTimeout(() => { func.apply(this, args) }, wait) } } 预加载 在开发中，可能会遇到这样的情况。有些资源不需要马上用到，但是希望尽早获取，这时候就可以使用预加载。 预加载其实是声明式的 fetch ，强制浏览器请求资源，并且不会阻塞 onload 事件，可以使用以下代码开启预加载 预加载可以一定程度上降低首屏的加载时间，因为可以将一些不影响首屏但重要的文件延后加载，唯一缺点就是兼容性不好。 预渲染 可以通过预渲染将下载的文件预先在后台渲染，可以使用以下代码开启预渲染 预渲染虽然可以提高页面的加载速度，但是要确保该页面大概率会被用户在之后打开，否则就是白白浪费资源去渲染。 懒执行 懒执行就是将某些逻辑延迟到使用时再计算。该技术可以用于首屏优化，对于某些耗时逻辑并不需要在首屏就使用的，就可以使用懒执行。懒执行需要唤醒，一般可以通过定时器或者事件的调用来唤醒。 懒加载 懒加载就是将不关键的资源延后加载。 懒加载的原理就是只加载自定义区域（通常是可视区域，但也可以是即将进入可视区域）内需要加载的东西。对于图片来说，先设置图片标签的 src 属性为一张占位图，将真实的图片资源放入一个自定义属性中，当进入自定义区域时，就将自定义属性替换为 src 属性，这样图片就会去下载资源，实现了图片懒加载。 懒加载不仅可以用于图片，也可以使用在别的资源上。比如进入可视区域才开始播放视频等等。 CDN CDN 的原理是尽可能的在各个地方分布机房缓存数据，这样即使我们的根服务器远在国外，在国内的用户也可以通过国内的机房迅速加载资源。 因此，我们可以将静态资源尽量使用 CDN 加载，由于浏览器对于单个域名有并发请求上限，可以考虑使用多个 CDN 域名。并且对于 CDN 加载静态资源需要注意 CDN 域名要与主站不同，否则每次请求都会带上主站的 Cookie，平白消耗流量。 小结 这些碎片化的性能优化点看似很短，但是却能在出现性能问题时简单高效的提高性能，并且好几个点都是面试高频考点，比如节流、防抖。如果你还没有在项目中使用过这些技术，可以尝试着用到项目中，体验下功效。 "},"前端面试之道/17.Webpack性能优化.html":{"url":"前端面试之道/17.Webpack性能优化.html","title":"17.Webpack性能优化","keywords":"","body":"Webpack 性能优化 在这一的章节中，我不会浪费篇幅给大家讲如何写配置文件。如果你想学习这方面的内容，那么完全可以去官网学习。在这部分的内容中，我们会聚焦于以下两个知识点，并且每一个知识点都属于高频考点： 有哪些方式可以减少 Webpack 的打包时间 有哪些方式可以让 Webpack 打出来的包更小 减少 Webpack 打包时间 优化 Loader 对于 Loader 来说，影响打包效率首当其冲必属 Babel 了。因为 Babel 会将代码转为字符串生成 AST，然后对 AST 继续进行转变最后再生成新的代码，项目越大，转换代码越多，效率就越低。当然了，我们是有办法优化的。 首先我们可以优化 Loader 的文件搜索范围 module.exports = { module: { rules: [ { // js 文件才使用 babel test: /\\.js$/, loader: 'babel-loader', // 只在 src 文件夹下查找 include: [resolve('src')], // 不会去查找的路径 exclude: /node_modules/ } ] } } 对于 Babel 来说，我们肯定是希望只作用在 JS 代码上的，然后 node_modules 中使用的代码都是编译过的，所以我们也完全没有必要再去处理一遍。 当然这样做还不够，我们还可以将 Babel 编译过的文件缓存起来，下次只需要编译更改过的代码文件即可，这样可以大幅度加快打包时间 loader: 'babel-loader?cacheDirectory=true' HappyPack 受限于 Node 是单线程运行的，所以 Webpack 在打包的过程中也是单线程的，特别是在执行 Loader 的时候，长时间编译的任务很多，这样就会导致等待的情况。 HappyPack 可以将 Loader 的同步执行转换为并行的，这样就能充分利用系统资源来加快打包效率了 module: { loaders: [ { test: /\\.js$/, include: [resolve('src')], exclude: /node_modules/, // id 后面的内容对应下面 loader: 'happypack/loader?id=happybabel' } ] }, plugins: [ new HappyPack({ id: 'happybabel', loaders: ['babel-loader?cacheDirectory'], // 开启 4 个线程 threads: 4 }) ] DllPlugin DllPlugin 可以将特定的类库提前打包然后引入。这种方式可以极大的减少打包类库的次数，只有当类库更新版本才有需要重新打包，并且也实现了将公共代码抽离成单独文件的优化方案。 接下来我们就来学习如何使用 DllPlugin // 单独配置在一个文件中 // webpack.dll.conf.js const path = require('path') const webpack = require('webpack') module.exports = { entry: { // 想统一打包的类库 vendor: ['react'] }, output: { path: path.join(__dirname, 'dist'), filename: '[name].dll.js', library: '[name]-[hash]' }, plugins: [ new webpack.DllPlugin({ // name 必须和 output.library 一致 name: '[name]-[hash]', // 该属性需要与 DllReferencePlugin 中一致 context: __dirname, path: path.join(__dirname, 'dist', '[name]-manifest.json') }) ] } 然后我们需要执行这个配置文件生成依赖文件，接下来我们需要使用 DllReferencePlugin 将依赖文件引入项目中 // webpack.conf.js module.exports = { // ...省略其他配置 plugins: [ new webpack.DllReferencePlugin({ context: __dirname, // manifest 就是之前打包出来的 json 文件 manifest: require('./dist/vendor-manifest.json'), }) ] } 代码压缩 在 Webpack3 中，我们一般使用 UglifyJS 来压缩代码，但是这个是单线程运行的，为了加快效率，我们可以使用 webpack-parallel-uglify-plugin 来并行运行 UglifyJS，从而提高效率。 在 Webpack4 中，我们就不需要以上这些操作了，只需要将 mode 设置为 production 就可以默认开启以上功能。代码压缩也是我们必做的性能优化方案，当然我们不止可以压缩 JS 代码，还可以压缩 HTML、CSS 代码，并且在压缩 JS 代码的过程中，我们还可以通过配置实现比如删除 console.log 这类代码的功能。 一些小的优化点 我们还可以通过一些小的优化点来加快打包速度 resolve.extensions：用来表明文件后缀列表，默认查找顺序是 ['.js', '.json']，如果你的导入文件没有添加后缀就会按照这个顺序查找文件。我们应该尽可能减少后缀列表长度，然后将出现频率高的后缀排在前面 resolve.alias：可以通过别名的方式来映射一个路径，能让 Webpack 更快找到路径 module.noParse：如果你确定一个文件下没有其他依赖，就可以使用该属性让 Webpack 不扫描该文件，这种方式对于大型的类库很有帮助 减少 Webpack 打包后的文件体积 注意：该内容也属于性能优化领域。 按需加载 想必大家在开发 SPA 项目的时候，项目中都会存在十几甚至更多的路由页面。如果我们将这些页面全部打包进一个 JS 文件的话，虽然将多个请求合并了，但是同样也加载了很多并不需要的代码，耗费了更长的时间。那么为了首页能更快地呈现给用户，我们肯定是希望首页能加载的文件体积越小越好，这时候我们就可以使用按需加载，将每个路由页面单独打包为一个文件。当然不仅仅路由可以按需加载，对于 loadash 这种大型类库同样可以使用这个功能。 按需加载的代码实现这里就不详细展开了，因为鉴于用的框架不同，实现起来都是不一样的。当然了，虽然他们的用法可能不同，但是底层的机制都是一样的。都是当使用的时候再去下载对应文件，返回一个 Promise，当 Promise 成功以后去执行回调。 Scope Hoisting Scope Hoisting 会分析出模块之间的依赖关系，尽可能的把打包出来的模块合并到一个函数中去。 比如我们希望打包两个文件 // test.js export const a = 1 // index.js import { a } from './test.js' 对于这种情况，我们打包出来的代码会类似这样 [ /* 0 */ function (module, exports, require) { //... }, /* 1 */ function (module, exports, require) { //... } ] 但是如果我们使用 Scope Hoisting 的话，代码就会尽可能的合并到一个函数中去，也就变成了这样的类似代码 [ /* 0 */ function (module, exports, require) { //... } ] 这样的打包方式生成的代码明显比之前的少多了。如果在 Webpack4 中你希望开启这个功能，只需要启用 optimization.concatenateModules 就可以了。 module.exports = { optimization: { concatenateModules: true } } Tree Shaking Tree Shaking 可以实现删除项目中未被引用的代码，比如 // test.js export const a = 1 export const b = 2 // index.js import { a } from './test.js' 对于以上情况，test 文件中的变量 b 如果没有在项目中使用到的话，就不会被打包到文件中。 如果你使用 Webpack 4 的话，开启生产环境就会自动启动这个优化功能。 小结 在这一章节中，我们学习了如何使用 Webpack 去进行性能优化以及如何减少打包时间。 Webpack 的版本更新很快，各个版本之间实现优化的方式可能都会有区别，所以我没有使用过多的代码去展示如何实现一个功能。这一章节的重点是学习到我们可以通过什么方式去优化，具体的代码实现可以查找具体版本对应的代码即可。 "},"前端面试之道/18.实现小型打包工具.html":{"url":"前端面试之道/18.实现小型打包工具.html","title":"18.实现小型打包工具","keywords":"","body":"实现小型打包工具 原本小册计划中是没有这一章节的，Webpack 工作原理应该是上一章节包含的内容。但是考虑到既然讲到工作原理，必然需要讲解源码，但是 Webpack 的源码很难读，不结合源码干巴巴讲原理又没有什么价值。所以在这一章节中，我将会带大家来实现一个几十行的迷你打包工具，该工具可以实现以下两个功能 将 ES6 转换为 ES5 支持在 JS 文件中 import CSS 文件 通过这个工具的实现，大家可以理解到打包工具的原理到底是什么。 实现 因为涉及到 ES6 转 ES5，所以我们首先需要安装一些 Babel 相关的工具 yarn add babylon babel-traverse babel-core babel-preset-env 接下来我们将这些工具引入文件中 const fs = require('fs') const path = require('path') const babylon = require('babylon') const traverse = require('babel-traverse').default const { transformFromAst } = require('babel-core') 首先，我们先来实现如何使用 Babel 转换代码 function readCode(filePath) { // 读取文件内容 const content = fs.readFileSync(filePath, 'utf-8') // 生成 AST const ast = babylon.parse(content, { sourceType: 'module' }) // 寻找当前文件的依赖关系 const dependencies = [] traverse(ast, { ImportDeclaration: ({ node }) => { dependencies.push(node.source.value) } }) // 通过 AST 将代码转为 ES5 const { code } = transformFromAst(ast, null, { presets: ['env'] }) return { filePath, dependencies, code } } 首先我们传入一个文件路径参数，然后通过 fs 将文件中的内容读取出来 接下来我们通过 babylon 解析代码获取 AST，目的是为了分析代码中是否还引入了别的文件 通过 dependencies 来存储文件中的依赖，然后再将 AST 转换为 ES5 代码 最后函数返回了一个对象，对象中包含了当前文件路径、当前文件依赖和当前文件转换后的代码 接下来我们需要实现一个函数，这个函数的功能有以下几点 调用 readCode 函数，传入入口文件 分析入口文件的依赖 识别 JS 和 CSS 文件 function getDependencies(entry) { // 读取入口文件 const entryObject = readCode(entry) const dependencies = [entryObject] // 遍历所有文件依赖关系 for (const asset of dependencies) { // 获得文件目录 const dirname = path.dirname(asset.filePath) // 遍历当前文件依赖关系 asset.dependencies.forEach(relativePath => { // 获得绝对路径 const absolutePath = path.join(dirname, relativePath) // CSS 文件逻辑就是将代码插入到 `style` 标签中 if (/\\.css$/.test(absolutePath)) { const content = fs.readFileSync(absolutePath, 'utf-8') const code = ` const style = document.createElement('style') style.innerText = ${JSON.stringify(content).replace(/\\\\r\\\\n/g, '')} document.head.appendChild(style) ` dependencies.push({ filePath: absolutePath, relativePath, dependencies: [], code }) } else { // JS 代码需要继续查找是否有依赖关系 const child = readCode(absolutePath) child.relativePath = relativePath dependencies.push(child) } }) } return dependencies } 首先我们读取入口文件，然后创建一个数组，该数组的目的是存储代码中涉及到的所有文件 接下来我们遍历这个数组，一开始这个数组中只有入口文件，在遍历的过程中，如果入口文件有依赖其他的文件，那么就会被 push 到这个数组中 在遍历的过程中，我们先获得该文件对应的目录，然后遍历当前文件的依赖关系 在遍历当前文件依赖关系的过程中，首先生成依赖文件的绝对路径，然后判断当前文件是 CSS 文件还是 JS 文件 如果是 CSS 文件的话，我们就不能用 Babel 去编译了，只需要读取 CSS 文件中的代码，然后创建一个 style 标签，将代码插入进标签并且放入 head 中即可 如果是 JS 文件的话，我们还需要分析 JS 文件是否还有别的依赖关系 最后将读取文件后的对象 push 进数组中 现在我们已经获取到了所有的依赖文件，接下来就是实现打包的功能了 function bundle(dependencies, entry) { let modules = '' // 构建函数参数，生成的结构为 // { './entry.js': function(module, exports, require) { 代码 } } dependencies.forEach(dep => { const filePath = dep.relativePath || entry modules += `'${filePath}': ( function (module, exports, require) { ${dep.code} } ),` }) // 构建 require 函数，目的是为了获取模块暴露出来的内容 const result = ` (function(modules) { function require(id) { const module = { exports : {} } modules[id](module, module.exports, require) return module.exports } require('${entry}') })({${modules}}) ` // 当生成的内容写入到文件中 fs.writeFileSync('./bundle.js', result) } 这段代码需要结合着 Babel 转换后的代码来看，这样大家就能理解为什么需要这样写了 // entry.js var _a = require('./a.js') var _a2 = _interopRequireDefault(_a) function _interopRequireDefault(obj) { return obj && obj.__esModule ? obj : { default: obj } } console.log(_a2.default) // a.js Object.defineProperty(exports, '__esModule', { value: true }) var a = 1 exports.default = a Babel 将我们 ES6 的模块化代码转换为了 CommonJS（如果你不熟悉 CommonJS 的话，可以阅读这一章节中关于 模块化的知识点） 的代码，但是浏览器是不支持 CommonJS 的，所以如果这段代码需要在浏览器环境下运行的话，我们需要自己实现 CommonJS 相关的代码，这就是 bundle 函数做的大部分事情。 接下来我们再来逐行解析 bundle 函数 首先遍历所有依赖文件，构建出一个函数参数对象 对象的属性就是当前文件的相对路径，属性值是一个函数，函数体是当前文件下的代码，函数接受三个参数 module、exports、 require module 参数对应 CommonJS 中的 module exports 参数对应 CommonJS 中的 module.export require 参数对应我们自己创建的 require 函数 接下来就是构造一个使用参数的函数了，函数做的事情很简单，就是内部创建一个 require 函数，然后调用 require(entry)，也就是 require('./entry.js')，这样就会从函数参数中找到 ./entry.js 对应的函数并执行，最后将导出的内容通过 module.export 的方式让外部获取到 最后再将打包出来的内容写入到单独的文件中 如果你对于上面的实现还有疑惑的话，可以阅读下打包后的部分简化代码 ;(function(modules) { function require(id) { // 构造一个 CommonJS 导出代码 const module = { exports: {} } // 去参数中获取文件对应的函数并执行 modules[id](module, module.exports, require) return module.exports } require('./entry.js') })({ './entry.js': function(module, exports, require) { // 这里继续通过构造的 require 去找到 a.js 文件对应的函数 var _a = require('./a.js') console.log(_a2.default) }, './a.js': function(module, exports, require) { var a = 1 // 将 require 函数中的变量 module 变成了这样的结构 // module.exports = 1 // 这样就能在外部取到导出的内容了 exports.default = a } // 省略 }) 小结 虽然实现这个工具只写了不到 100 行的代码，但是打包工具的核心原理就是这些了 找出入口文件所有的依赖关系 然后通过构建 CommonJS 代码来获取 exports 导出的内容 如果大家对于这个章节的内容存在疑问，欢迎在评论区与我互动。 "},"前端面试之道/19.React和Vue两大框架之间的相爱相杀.html":{"url":"前端面试之道/19.React和Vue两大框架之间的相爱相杀.html","title":"19.React和Vue两大框架之间的相爱相杀","keywords":"","body":"React 和 Vue 两大框架之间的相爱相杀 React 和 Vue 应该是国内当下最火热的前端框架，当然 Angular 也是一个不错的框架，但是这个产品国内使用的人很少再加上我对 Angular 也不怎么熟悉，所以框架的章节中不会涉及到 Angular 的内容。 这一章节，我们将会来学习以下几个内容 MVVM 是什么 Virtual DOM 是什么 前端路由是如何跳转的 React 和 Vue 之间的区别 MVVM 涉及面试题：什么是 MVVM？比之 MVC 有什么区别？ 首先先申明一点，不管是 React 还是 Vue，它们都不是 MVVM 框架，只是有借鉴 MVVM 的思路。文中拿 Vue 举例也是为了更好地理解 MVVM 的概念。 接下来先说下 View 和 Model： View 很简单，就是用户看到的视图 Model 同样很简单，一般就是本地数据和数据库中的数据 基本上，我们写的产品就是通过接口从数据库中读取数据，然后将数据经过处理展现到用户看到的视图上。当然我们还可以从视图上读取用户的输入，然后又将用户的输入通过接口写入到数据库中。但是，如何将数据展示到视图上，然后又如何将用户的输入写入到数据中，不同的人就产生了不同的看法，从此出现了很多种架构设计。 传统的 MVC 架构通常是使用控制器更新模型，视图从模型中获取数据去渲染。当用户有输入时，会通过控制器去更新模型，并且通知视图进行更新。 MVC 但是 MVC 有一个巨大的缺陷就是控制器承担的责任太大了，随着项目愈加复杂，控制器中的代码会越来越臃肿，导致出现不利于维护的情况。 在 MVVM 架构中，引入了 ViewModel 的概念。ViewModel 只关心数据和业务的处理，不关心 View 如何处理数据，在这种情况下，View 和 Model 都可以独立出来，任何一方改变了也不一定需要改变另一方，并且可以将一些可复用的逻辑放在一个 ViewModel 中，让多个 View 复用这个 ViewModel。 以 Vue 框架来举例，ViewModel 就是组件的实例。View 就是模板，Model 的话在引入 Vuex 的情况下是完全可以和组件分离的。 除了以上三个部分，其实在 MVVM 中还引入了一个隐式的 Binder 层，实现了 View 和 ViewModel 的绑定。 同样以 Vue 框架来举例，这个隐式的 Binder 层就是 Vue 通过解析模板中的插值和指令从而实现 View 与 ViewModel 的绑定。 对于 MVVM 来说，其实最重要的并不是通过双向绑定或者其他的方式将 View 与 ViewModel 绑定起来，而是通过 ViewModel 将视图中的状态和用户的行为分离出一个抽象，这才是 MVVM 的精髓。 Virtual DOM 涉及面试题：什么是 Virtual DOM？为什么 Virtual DOM 比原生 DOM 快？ 大家都知道操作 DOM 是很慢的，为什么慢的原因已经在「浏览器渲染原理」章节中说过，这里就不再赘述了。 那么相较于 DOM 来说，操作 JS 对象会快很多，并且我们也可以通过 JS 来模拟 DOM const ul = { tag: 'ul', props: { class: 'list' }, children: { tag: 'li', children: '1' } } 上述代码对应的 DOM 就是 1 那么既然 DOM 可以通过 JS 对象来模拟，反之也可以通过 JS 对象来渲染出对应的 DOM。当然了，通过 JS 来模拟 DOM 并且渲染对应的 DOM 只是第一步，难点在于如何判断新旧两个 JS 对象的最小差异并且实现局部更新 DOM。 首先 DOM 是一个多叉树的结构，如果需要完整的对比两颗树的差异，那么需要的时间复杂度会是 O(n ^ 3)，这个复杂度肯定是不能接受的。于是 React 团队优化了算法，实现了 O(n) 的复杂度来对比差异。 实现 O(n) 复杂度的关键就是只对比同层的节点，而不是跨层对比，这也是考虑到在实际业务中很少会去跨层的移动 DOM 元素。 所以判断差异的算法就分为了两步 首先从上至下，从左往右遍历对象，也就是树的深度遍历，这一步中会给每个节点添加索引，便于最后渲染差异 一旦节点有子元素，就去判断子元素是否有不同 在第一步算法中我们需要判断新旧节点的 tagName 是否相同，如果不相同的话就代表节点被替换了。如果没有更改 tagName 的话，就需要判断是否有子元素，有的话就进行第二步算法。 在第二步算法中，我们需要判断原本的列表中是否有节点被移除，在新的列表中需要判断是否有新的节点加入，还需要判断节点是否有移动。 举个例子来说，假设页面中只有一个列表，我们对列表中的元素进行了变更 // 假设这里模拟一个 ul，其中包含了 5 个 li [1, 2, 3, 4, 5] // 这里替换上面的 li [1, 2, 5, 4] 从上述例子中，我们一眼就可以看出先前的 ul 中的第三个 li 被移除了，四五替换了位置。 那么在实际的算法中，我们如何去识别改动的是哪个节点呢？这就引入了 key 这个属性，想必大家在 Vue 或者 React 的列表中都用过这个属性。这个属性是用来给每一个节点打标志的，用于判断是否是同一个节点。 当然在判断以上差异的过程中，我们还需要判断节点的属性是否有变化等等。 当我们判断出以上的差异后，就可以把这些差异记录下来。当对比完两棵树以后，就可以通过差异去局部更新 DOM，实现性能的最优化。 另外再来回答「为什么 Virtual DOM 比原生 DOM 快」这个问题。首先这个问题得分场景来说，如果无脑替换所有的 DOM 这种场景来说，Virtual DOM 的局部更新肯定要来的快。但是如果你可以人肉也同样去局部替换 DOM，那么 Virtual DOM 必然没有你直接操作 DOM 来的快，毕竟还有一层 diff 算法的损耗。 当然了 Virtual DOM 提高性能是其中一个优势，其实最大的优势还是在于： 将 Virtual DOM 作为一个兼容层，让我们还能对接非 Web 端的系统，实现跨端开发。 同样的，通过 Virtual DOM 我们可以渲染到其他的平台，比如实现 SSR、同构渲染等等。 实现组件的高度抽象化 路由原理 涉及面试题：前端路由原理？两种实现方式有什么区别？ 前端路由实现起来其实很简单，本质就是监听 URL 的变化，然后匹配路由规则，显示相应的页面，并且无须刷新页面。目前前端使用的路由就只有两种实现方式 Hash 模式 History 模式 Hash 模式 www.test.com/#/ 就是 Hash URL，当 # 后面的哈希值发生变化时，可以通过 hashchange 事件来监听到 URL 的变化，从而进行跳转页面，并且无论哈希值如何变化，服务端接收到的 URL 请求永远是 www.test.com。 window.addEventListener('hashchange', () => { // ... 具体逻辑 }) Hash 模式相对来说更简单，并且兼容性也更好。 History 模式 History 模式是 HTML5 新推出的功能，主要使用 history.pushState 和 history.replaceState 改变 URL。 通过 History 模式改变 URL 同样不会引起页面的刷新，只会更新浏览器的历史记录。 // 新增历史记录 history.pushState(stateObject, title, URL) // 替换当前历史记录 history.replaceState(stateObject, title, URL) 当用户做出浏览器动作时，比如点击后退按钮时会触发 popState 事件 window.addEventListener('popstate', e => { // e.state 就是 pushState(stateObject) 中的 stateObject console.log(e.state) }) 两种模式对比 Hash 模式只可以更改 # 后面的内容，History 模式可以通过 API 设置任意的同源 URL History 模式可以通过 API 添加任意类型的数据到历史记录中，Hash 模式只能更改哈希值，也就是字符串 Hash 模式无需后端配置，并且兼容性好。History 模式在用户手动输入地址或者刷新页面的时候会发起 URL 请求，后端需要配置 index.html 页面用于匹配不到静态资源的时候 Vue 和 React 之间的区别 Vue 的表单可以使用 v-model 支持双向绑定，相比于 React 来说开发上更加方便，当然了 v-model 其实就是个语法糖，本质上和 React 写表单的方式没什么区别。 改变数据方式不同，Vue 修改状态相比来说要简单许多，React 需要使用 setState 来改变状态，并且使用这个 API 也有一些坑点。并且 Vue 的底层使用了依赖追踪，页面更新渲染已经是最优的了，但是 React 还是需要用户手动去优化这方面的问题。 React 16以后，有些钩子函数会执行多次，这是因为引入 Fiber 的原因，这在后续的章节中会讲到。 React 需要使用 JSX，有一定的上手成本，并且需要一整套的工具链支持，但是完全可以通过 JS 来控制页面，更加的灵活。Vue 使用了模板语法，相比于 JSX 来说没有那么灵活，但是完全可以脱离工具链，通过直接编写 render 函数就能在浏览器中运行。 在生态上来说，两者其实没多大的差距，当然 React 的用户是远远高于 Vue 的。 在上手成本上来说，Vue 一开始的定位就是尽可能的降低前端开发的门槛，然而 React 更多的是去改变用户去接受它的概念和思想，相较于 Vue 来说上手成本略高。 小结 这一章节中我们学习了几大框架中的相似点，也对比了 React 和 Vue 之间的区别。其实我们可以发现，React 和 Vue 虽然是两个不同的框架，但是他们的底层原理都是很相似的，无非在上层堆砌了自己的概念上去。所以我们无需去对比到底哪个框架牛逼，引用尤大的一句话 说到底，就算你证明了 A 比 B 牛逼，也不意味着你或者你的项目就牛逼了... 比起争这个，不如多想想怎么让自己变得更牛逼吧。 "},"前端面试之道/20.Vue常考基础知识点.html":{"url":"前端面试之道/20.Vue常考基础知识点.html","title":"20.Vue常考基础知识点","keywords":"","body":"Vue 常考基础知识点 这一章节我们将来学习 Vue 的一些经常考到的基础知识点。 生命周期钩子函数 在 beforeCreate 钩子函数调用的时候，是获取不到 props 或者 data 中的数据的，因为这些数据的初始化都在 initState 中。 然后会执行 created 钩子函数，在这一步的时候已经可以访问到之前不能访问到的数据，但是这时候组件还没被挂载，所以是看不到的。 接下来会先执行 beforeMount 钩子函数，开始创建 VDOM，最后执行 mounted 钩子，并将 VDOM 渲染为真实 DOM 并且渲染数据。组件中如果有子组件的话，会递归挂载子组件，只有当所有子组件全部挂载完毕，才会执行根组件的挂载钩子。 接下来是数据更新时会调用的钩子函数 beforeUpdate 和 updated，这两个钩子函数没什么好说的，就是分别在数据更新前和更新后会调用。 另外还有 keep-alive 独有的生命周期，分别为 activated 和 deactivated 。用 keep-alive 包裹的组件在切换时不会进行销毁，而是缓存到内存中并执行 deactivated 钩子函数，命中缓存渲染后会执行 actived 钩子函数。 最后就是销毁组件的钩子函数 beforeDestroy 和 destroyed。前者适合移除事件、定时器等等，否则可能会引起内存泄露的问题。然后进行一系列的销毁操作，如果有子组件的话，也会递归销毁子组件，所有子组件都销毁完毕后才会执行根组件的 destroyed 钩子函数。 组件通信 组件通信一般分为以下几种情况： 父子组件通信 兄弟组件通信 跨多层级组件通信 任意组件 对于以上每种情况都有多种方式去实现，接下来就来学习下如何实现。 父子通信 父组件通过 props 传递数据给子组件，子组件通过 emit 发送事件传递数据给父组件，这两种方式是最常用的父子通信实现办法。 这种父子通信方式也就是典型的单向数据流，父组件通过 props 传递数据，子组件不能直接修改 props， 而是必须通过发送事件的方式告知父组件修改数据。 另外这两种方式还可以使用语法糖 v-model 来直接实现，因为 v-model 默认会解析成名为 value 的 prop 和名为 input 的事件。这种语法糖的方式是典型的双向绑定，常用于 UI 控件上，但是究其根本，还是通过事件的方法让父组件修改数据。 当然我们还可以通过访问 $parent 或者 $children 对象来访问组件实例中的方法和数据。 另外如果你使用 Vue 2.3 及以上版本的话还可以使用 $listeners 和 .sync 这两个属性。 $listeners 属性会将父组件中的 (不含 .native 修饰器的) v-on 事件监听器传递给子组件，子组件可以通过访问 $listeners 来自定义监听器。 .sync 属性是个语法糖，可以很简单的实现子组件与父组件通信 value = v\"> this.$emit('update:value', 1) 兄弟组件通信 对于这种情况可以通过查找父组件中的子组件实现，也就是 this.$parent.$children，在 $children 中可以通过组件 name 查询到需要的组件实例，然后进行通信。 跨多层次组件通信 对于这种情况可以使用 Vue 2.2 新增的 API provide / inject，虽然文档中不推荐直接使用在业务中，但是如果用得好的话还是很有用的。 假设有父组件 A，然后有一个跨多层级的子组件 B // 父组件 A export default { provide: { data: 1 } } // 子组件 B export default { inject: ['data'], mounted() { // 无论跨几层都能获得父组件的 data 属性 console.log(this.data) // => 1 } } 任意组件 这种方式可以通过 Vuex 或者 Event Bus 解决，另外如果你不怕麻烦的话，可以使用这种方式解决上述所有的通信情况 extend 能做什么 这个 API 很少用到，作用是扩展组件生成一个构造器，通常会与 $mount 一起使用。 // 创建组件构造器 let Component = Vue.extend({ template: 'test' }) // 挂载到 #app 上 new Component().$mount('#app') // 除了上面的方式，还可以用来扩展已有的组件 let SuperComponent = Vue.extend(Component) new SuperComponent({ created() { console.log(1) } }) new SuperComponent().$mount('#app') mixin 和 mixins 区别 mixin 用于全局混入，会影响到每个组件实例，通常插件都是这样做初始化的。 Vue.mixin({ beforeCreate() { // ...逻辑 // 这种方式会影响到每个组件的 beforeCreate 钩子函数 } }) 虽然文档不建议我们在应用中直接使用 mixin，但是如果不滥用的话也是很有帮助的，比如可以全局混入封装好的 ajax 或者一些工具函数等等。 mixins 应该是我们最常使用的扩展组件的方式了。如果多个组件中有相同的业务逻辑，就可以将这些逻辑剥离出来，通过 mixins 混入代码，比如上拉下拉加载数据这种逻辑等等。 另外需要注意的是 mixins 混入的钩子函数会先于组件内的钩子函数执行，并且在遇到同名选项的时候也会有选择性的进行合并，具体可以阅读 文档。 computed 和 watch 区别 computed 是计算属性，依赖其他属性计算值，并且 computed 的值有缓存，只有当计算值变化才会返回内容。 watch 监听到值的变化就会执行回调，在回调中可以进行一些逻辑操作。 所以一般来说需要依赖别的属性来动态获得值的时候可以使用 computed，对于监听到值的变化需要做一些复杂业务逻辑的情况可以使用 watch。 另外 computed 和 watch 还都支持对象的写法，这种方式知道的人并不多。 vm.$watch('obj', { // 深度遍历 deep: true, // 立即触发 immediate: true, // 执行的函数 handler: function(val, oldVal) {} }) var vm = new Vue({ data: { a: 1 }, computed: { aPlus: { // this.aPlus 时触发 get: function () { return this.a + 1 }, // this.aPlus = 1 时触发 set: function (v) { this.a = v - 1 } } } }) keep-alive 组件有什么作用 如果你需要在组件切换的时候，保存一些组件的状态防止多次渲染，就可以使用 keep-alive 组件包裹需要保存的组件。 对于 keep-alive 组件来说，它拥有两个独有的生命周期钩子函数，分别为 activated 和 deactivated 。用 keep-alive 包裹的组件在切换时不会进行销毁，而是缓存到内存中并执行 deactivated 钩子函数，命中缓存渲染后会执行 actived 钩子函数。 v-show 与 v-if 区别 v-show 只是在 display: none 和 display: block 之间切换。无论初始条件是什么都会被渲染出来，后面只需要切换 CSS，DOM 还是一直保留着的。所以总的来说 v-show 在初始渲染时有更高的开销，但是切换开销很小，更适合于频繁切换的场景。 v-if 的话就得说到 Vue 底层的编译了。当属性初始为 false 时，组件就不会被渲染，直到条件为 true，并且切换条件时会触发销毁/挂载组件，所以总的来说在切换时开销更高，更适合不经常切换的场景。 并且基于 v-if 的这种惰性渲染机制，可以在必要的时候才去渲染组件，减少整个页面的初始渲染开销。 组件中 data 什么时候可以使用对象 这道题目其实更多考的是 JS 功底。 组件复用时所有组件实例都会共享 data，如果 data 是对象的话，就会造成一个组件修改 data 以后会影响到其他所有组件，所以需要将 data 写成函数，每次用到就调用一次函数获得新的数据。 当我们使用 new Vue() 的方式的时候，无论我们将 data 设置为对象还是函数都是可以的，因为 new Vue() 的方式是生成一个根组件，该组件不会复用，也就不存在共享 data 的情况了。 小结 总的来说这一章节的内容更多的偏向于 Vue 的基础，下一章节我们将来了解一些原理性方面的知识。 "},"前端面试之道/21.Vue常考进阶知识点.html":{"url":"前端面试之道/21.Vue常考进阶知识点.html","title":"21.Vue常考进阶知识点","keywords":"","body":"Vue 常考进阶知识点 这一章节我们将来学习 Vue 的一些经常考到的进阶知识点。这些知识点相对而言理解起来会很有难度，可能需要多次阅读才能理解。 响应式原理 Vue 内部使用了 Object.defineProperty() 来实现数据响应式，通过这个函数可以监听到 set 和 get 的事件。 var data = { name: 'yck' } observe(data) let name = data.name // -> get value data.name = 'yyy' // -> change value function observe(obj) { // 判断类型 if (!obj || typeof obj !== 'object') { return } Object.keys(obj).forEach(key => { defineReactive(obj, key, obj[key]) }) } function defineReactive(obj, key, val) { // 递归子属性 observe(val) Object.defineProperty(obj, key, { // 可枚举 enumerable: true, // 可配置 configurable: true, // 自定义函数 get: function reactiveGetter() { console.log('get value') return val }, set: function reactiveSetter(newVal) { console.log('change value') val = newVal } }) } 以上代码简单的实现了如何监听数据的 set 和 get 的事件，但是仅仅如此是不够的，因为自定义的函数一开始是不会执行的。只有先执行了依赖收集，才能在属性更新的时候派发更新，所以接下来我们需要先触发依赖收集。 {{name}} 在解析如上模板代码时，遇到 {{name}} 就会进行依赖收集。 接下来我们先来实现一个 Dep 类，用于解耦属性的依赖收集和派发更新操作。 // 通过 Dep 解耦属性的依赖和更新操作 class Dep { constructor() { this.subs = [] } // 添加依赖 addSub(sub) { this.subs.push(sub) } // 更新 notify() { this.subs.forEach(sub => { sub.update() }) } } // 全局属性，通过该属性配置 Watcher Dep.target = null 以上的代码实现很简单，当需要依赖收集的时候调用 addSub，当需要派发更新的时候调用 notify。 接下来我们先来简单的了解下 Vue 组件挂载时添加响应式的过程。在组件挂载时，会先对所有需要的属性调用 Object.defineProperty()，然后实例化 Watcher，传入组件更新的回调。在实例化过程中，会对模板中的属性进行求值，触发依赖收集。 因为这一小节主要目的是学习响应式原理的细节，所以接下来的代码会简略的表达触发依赖收集时的操作。 class Watcher { constructor(obj, key, cb) { // 将 Dep.target 指向自己 // 然后触发属性的 getter 添加监听 // 最后将 Dep.target 置空 Dep.target = this this.cb = cb this.obj = obj this.key = key this.value = obj[key] Dep.target = null } update() { // 获得新值 this.value = this.obj[this.key] // 调用 update 方法更新 Dom this.cb(this.value) } } 以上就是 Watcher 的简单实现，在执行构造函数的时候将 Dep.target 指向自身，从而使得收集到了对应的 Watcher，在派发更新的时候取出对应的 Watcher 然后执行 update 函数。 接下来，需要对 defineReactive 函数进行改造，在自定义函数中添加依赖收集和派发更新相关的代码。 function defineReactive(obj, key, val) { // 递归子属性 observe(val) let dp = new Dep() Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter() { console.log('get value') // 将 Watcher 添加到订阅 if (Dep.target) { dp.addSub(Dep.target) } return val }, set: function reactiveSetter(newVal) { console.log('change value') val = newVal // 执行 watcher 的 update 方法 dp.notify() } }) } 以上所有代码实现了一个简易的数据响应式，核心思路就是手动触发一次属性的 getter 来实现依赖收集。 现在我们就来测试下代码的效果，只需要把所有的代码复制到浏览器中执行，就会发现页面的内容全部被替换了。 var data = { name: 'yck' } observe(data) function update(value) { document.querySelector('div').innerText = value } // 模拟解析到 `{{name}}` 触发的操作 new Watcher(data, 'name', update) // update Dom innerText data.name = 'yyy' Object.defineProperty 的缺陷 以上已经分析完了 Vue 的响应式原理，接下来说一点 Object.defineProperty 中的缺陷。 如果通过下标方式修改数组数据或者给对象新增属性并不会触发组件的重新渲染，因为 Object.defineProperty 不能拦截到这些操作，更精确的来说，对于数组而言，大部分操作都是拦截不到的，只是 Vue 内部通过重写函数的方式解决了这个问题。 对于第一个问题，Vue 提供了一个 API 解决 export function set (target: Array | Object, key: any, val: any): any { // 判断是否为数组且下标是否有效 if (Array.isArray(target) && isValidArrayIndex(key)) { // 调用 splice 函数触发派发更新 // 该函数已被重写 target.length = Math.max(target.length, key) target.splice(key, 1, val) return val } // 判断 key 是否已经存在 if (key in target && !(key in Object.prototype)) { target[key] = val return val } const ob = (target: any).__ob__ // 如果对象不是响应式对象，就赋值返回 if (!ob) { target[key] = val return val } // 进行双向绑定 defineReactive(ob.value, key, val) // 手动派发更新 ob.dep.notify() return val } 对于数组而言，Vue 内部重写了以下函数实现派发更新 // 获得数组原型 const arrayProto = Array.prototype export const arrayMethods = Object.create(arrayProto) // 重写以下函数 const methodsToPatch = [ 'push', 'pop', 'shift', 'unshift', 'splice', 'sort', 'reverse' ] methodsToPatch.forEach(function (method) { // 缓存原生函数 const original = arrayProto[method] // 重写函数 def(arrayMethods, method, function mutator (...args) { // 先调用原生函数获得结果 const result = original.apply(this, args) const ob = this.__ob__ let inserted // 调用以下几个函数时，监听新数据 switch (method) { case 'push': case 'unshift': inserted = args break case 'splice': inserted = args.slice(2) break } if (inserted) ob.observeArray(inserted) // 手动派发更新 ob.dep.notify() return result }) }) 编译过程 想必大家在使用 Vue 开发的过程中，基本都是使用模板的方式。那么你有过「模板是怎么在浏览器中运行的」这种疑虑嘛？ 首先直接把模板丢到浏览器中肯定是不能运行的，模板只是为了方便开发者进行开发。Vue 会通过编译器将模板通过几个阶段最终编译为 render 函数，然后通过执行 render 函数生成 Virtual DOM 最终映射为真实 DOM。 接下来我们就来学习这个编译的过程，了解这个过程中大概发生了什么事情。这个过程其中又分为三个阶段，分别为： 将模板解析为 AST 优化 AST 将 AST 转换为 render 函数 在第一个阶段中，最主要的事情还是通过各种各样的正则表达式去匹配模板中的内容，然后将内容提取出来做各种逻辑操作，接下来会生成一个最基本的 AST 对象 { // 类型 type: 1, // 标签 tag, // 属性列表 attrsList: attrs, // 属性映射 attrsMap: makeAttrsMap(attrs), // 父节点 parent, // 子节点 children: [] } 然后会根据这个最基本的 AST 对象中的属性，进一步扩展 AST。 当然在这一阶段中，还会进行其他的一些判断逻辑。比如说对比前后开闭标签是否一致，判断根组件是否只存在一个，判断是否符合 HTML5 Content Model 规范等等问题。 接下来就是优化 AST 的阶段。在当前版本下，Vue 进行的优化内容其实还是不多的。只是对节点进行了静态内容提取，也就是将永远不会变动的节点提取了出来，实现复用 Virtual DOM，跳过对比算法的功能。在下一个大版本中，Vue 会在优化 AST 的阶段继续发力，实现更多的优化功能，尽可能的在编译阶段压榨更多的性能，比如说提取静态的属性等等优化行为。 最后一个阶段就是通过 AST 生成 render 函数了。其实这一阶段虽然分支有很多，但是最主要的目的就是遍历整个 AST，根据不同的条件生成不同的代码罢了。 NextTick 原理分析 nextTick 可以让我们在下次 DOM 更新循环结束之后执行延迟回调，用于获得更新后的 DOM。 在 Vue 2.4 之前都是使用的 microtasks，但是 microtasks 的优先级过高，在某些情况下可能会出现比事件冒泡更快的情况，但如果都使用 macrotasks 又可能会出现渲染的性能问题。所以在新版本中，会默认使用 microtasks，但在特殊情况下会使用 macrotasks，比如 v-on。 对于实现 macrotasks ，会先判断是否能使用 setImmediate ，不能的话降级为 MessageChannel ，以上都不行的话就使用 setTimeout if (typeof setImmediate !== 'undefined' && isNative(setImmediate)) { macroTimerFunc = () => { setImmediate(flushCallbacks) } } else if ( typeof MessageChannel !== 'undefined' && (isNative(MessageChannel) || // PhantomJS MessageChannel.toString() === '[object MessageChannelConstructor]') ) { const channel = new MessageChannel() const port = channel.port2 channel.port1.onmessage = flushCallbacks macroTimerFunc = () => { port.postMessage(1) } } else { macroTimerFunc = () => { setTimeout(flushCallbacks, 0) } } 以上代码很简单，就是判断能不能使用相应的 API。 小结 以上就是 Vue 的几个高频核心问题了，如果你还想了解更多的源码相关的细节，强烈推荐黄老师的 Vue 技术揭秘。 "},"前端面试之道/22.React常考基础知识点.html":{"url":"前端面试之道/22.React常考基础知识点.html","title":"22.React常考基础知识点","keywords":"","body":"React 常考基础知识点 这一章节我们将来学习 React 的一些经常考到的基础知识点。 生命周期 在 V16 版本中引入了 Fiber 机制。这个机制一定程度上的影响了部分生命周期的调用，并且也引入了新的 2 个 API 来解决问题，关于 Fiber 的内容将会在下一章节中讲到。 在之前的版本中，如果你拥有一个很复杂的复合组件，然后改动了最上层组件的 state，那么调用栈可能会很长 调用栈过长，再加上中间进行了复杂的操作，就可能导致长时间阻塞主线程，带来不好的用户体验。Fiber 就是为了解决该问题而生。 Fiber 本质上是一个虚拟的堆栈帧，新的调度器会按照优先级自由调度这些帧，从而将之前的同步渲染改成了异步渲染，在不影响体验的情况下去分段计算更新。 对于如何区别优先级，React 有自己的一套逻辑。对于动画这种实时性很高的东西，也就是 16 ms 必须渲染一次保证不卡顿的情况下，React 会每 16 ms（以内） 暂停一下更新，返回来继续渲染动画。 对于异步渲染，现在渲染有两个阶段：reconciliation 和 commit 。前者过程是可以打断的，后者不能暂停，会一直更新界面直到完成。 Reconciliation 阶段 componentWillMount componentWillReceiveProps shouldComponentUpdate componentWillUpdate Commit 阶段 componentDidMount componentDidUpdate componentWillUnmount 因为 Reconciliation 阶段是可以被打断的，所以 Reconciliation 阶段会执行的生命周期函数就可能会出现调用多次的情况，从而引起 Bug。由此对于 Reconciliation 阶段调用的几个函数，除了 shouldComponentUpdate 以外，其他都应该避免去使用，并且 V16 中也引入了新的 API 来解决这个问题。 getDerivedStateFromProps 用于替换 componentWillReceiveProps ，该函数会在初始化和 update 时被调用 class ExampleComponent extends React.Component { // Initialize state in constructor, // Or with a property initializer. state = {}; static getDerivedStateFromProps(nextProps, prevState) { if (prevState.someMirroredValue !== nextProps.someValue) { return { derivedData: computeDerivedState(nextProps), someMirroredValue: nextProps.someValue }; } // Return null to indicate no change to state. return null; } } getSnapshotBeforeUpdate 用于替换 componentWillUpdate ，该函数会在 update 后 DOM 更新前被调用，用于读取最新的 DOM 数据。 setState setState 在 React 中是经常使用的一个 API，但是它存在一些的问题经常会导致初学者出错，核心原因就是因为这个 API 是异步的。 首先 setState 的调用并不会马上引起 state 的改变，并且如果你一次调用了多个 setState ，那么结果可能并不如你期待的一样。 handle() { // 初始化 `count` 为 0 console.log(this.state.count) // -> 0 this.setState({ count: this.state.count + 1 }) this.setState({ count: this.state.count + 1 }) this.setState({ count: this.state.count + 1 }) console.log(this.state.count) // -> 0 } 第一，两次的打印都为 0，因为 setState 是个异步 API，只有同步代码运行完毕才会执行。setState 异步的原因我认为在于，setState 可能会导致 DOM 的重绘，如果调用一次就马上去进行重绘，那么调用多次就会造成不必要的性能损失。设计成异步的话，就可以将多次调用放入一个队列中，在恰当的时候统一进行更新过程。 第二，虽然调用了三次 setState ，但是 count 的值还是为 1。因为多次调用会合并为一次，只有当更新结束后 state 才会改变，三次调用等同于如下代码 Object.assign( {}, { count: this.state.count + 1 }, { count: this.state.count + 1 }, { count: this.state.count + 1 }, )w 当然你也可以通过以下方式来实现调用三次 setState 使得 count 为 3 handle() { this.setState((prevState) => ({ count: prevState.count + 1 })) this.setState((prevState) => ({ count: prevState.count + 1 })) this.setState((prevState) => ({ count: prevState.count + 1 })) } 如果你想在每次调用 setState 后获得正确的 state ，可以通过如下代码实现 handle() { this.setState((prevState) => ({ count: prevState.count + 1 }), () => { console.log(this.state) }) } 性能优化 这小节内容集中在组件的性能优化上，这一方面的性能优化也基本集中在 shouldComponentUpdate 这个钩子函数上做文章。 PS：下文中的 state 指代了 state 及 props 在 shouldComponentUpdate 函数中我们可以通过返回布尔值来决定当前组件是否需要更新。这层代码逻辑可以是简单地浅比较一下当前 state 和之前的 state 是否相同，也可以是判断某个值更新了才触发组件更新。一般来说不推荐完整地对比当前 state 和之前的 state 是否相同，因为组件更新触发可能会很频繁，这样的完整对比性能开销会有点大，可能会造成得不偿失的情况。 当然如果真的想完整对比当前 state 和之前的 state 是否相同，并且不影响性能也是行得通的，可以通过 immutable 或者 immer 这些库来生成不可变对象。这类库对于操作大规模的数据来说会提升不错的性能，并且一旦改变数据就会生成一个新的对象，对比前后 state 是否一致也就方便多了，同时也很推荐阅读下 immer 的源码实现。 另外如果只是单纯的浅比较一下，可以直接使用 PureComponent，底层就是实现了浅比较 state。 class Test extends React.PureComponent { render() { return ( PureComponent ) } } 这时候你可能会考虑到函数组件就不能使用这种方式了，如果你使用 16.6.0 之后的版本的话，可以使用 React.memo 来实现相同的功能。 const Test = React.memo(() => ( PureComponent )) 通过这种方式我们就可以既实现了 shouldComponentUpdate 的浅比较，又能够使用函数组件。 通信 其实 React 中的组件通信基本和 Vue 中的一致。同样也分为以下三种情况： 父子组件通信 兄弟组件通信 跨多层级组件通信 任意组件 父子通信 父组件通过 props 传递数据给子组件，子组件通过调用父组件传来的函数传递数据给父组件，这两种方式是最常用的父子通信实现办法。 这种父子通信方式也就是典型的单向数据流，父组件通过 props 传递数据，子组件不能直接修改 props， 而是必须通过调用父组件函数的方式告知父组件修改数据。 兄弟组件通信 对于这种情况可以通过共同的父组件来管理状态和事件函数。比如说其中一个兄弟组件调用父组件传递过来的事件函数修改父组件中的状态，然后父组件将状态传递给另一个兄弟组件。 跨多层次组件通信 如果你使用 16.3 以上版本的话，对于这种情况可以使用 Context API。 // 创建 Context，可以在开始就传入值 const StateContext = React.createContext() class Parent extends React.Component { render () { return ( // value 就是传入 Context 中的值 ) } } class Child extends React.Component { render () { return ( // 取出值 {context => ( name is { context } )} ); } } 任意组件 这种方式可以通过 Redux 或者 Event Bus 解决，另外如果你不怕麻烦的话，可以使用这种方式解决上述所有的通信情况 小结 总的来说这一章节的内容更多的偏向于 React 的基础，另外 React 的面试题还会经常考到 Virtual DOM 中的内容，所以这块内容大家也需要好好准备。 下一章节我们将来了解一些 React 的进阶知识内容。 "},"前端面试之道/23.React常考进阶知识点.html":{"url":"前端面试之道/23.React常考进阶知识点.html","title":"23.React常考进阶知识点","keywords":"","body":"React 常考进阶知识点 这一章节我们将来学习 React 的一些经常考到的进阶知识点，并且这章节还需要配合第十九章阅读，其中的内容经常会考到。 HOC 是什么？相比 mixins 有什么优点？ 很多人看到高阶组件（HOC）这个概念就被吓到了，认为这东西很难，其实这东西概念真的很简单，我们先来看一个例子。 function add(a, b) { return a + b } 现在如果我想给这个 add 函数添加一个输出结果的功能，那么你可能会考虑我直接使用 console.log 不就实现了么。说的没错，但是如果我们想做的更加优雅并且容易复用和扩展，我们可以这样去做： function withLog (fn) { function wrapper(a, b) { const result = fn(a, b) console.log(result) return result } return wrapper } const withLogAdd = withLog(add) withLogAdd(1, 2) 其实这个做法在函数式编程里称之为高阶函数，大家都知道 React 的思想中是存在函数式编程的，高阶组件和高阶函数就是同一个东西。我们实现一个函数，传入一个组件，然后在函数内部再实现一个函数去扩展传入的组件，最后返回一个新的组件，这就是高阶组件的概念，作用就是为了更好的复用代码。 其实 HOC 和 Vue 中的 mixins 作用是一致的，并且在早期 React 也是使用 mixins 的方式。但是在使用 class 的方式创建组件以后，mixins 的方式就不能使用了，并且其实 mixins 也是存在一些问题的，比如： 隐含了一些依赖，比如我在组件中写了某个 state 并且在 mixin 中使用了，就这存在了一个依赖关系。万一下次别人要移除它，就得去 mixin 中查找依赖 多个 mixin 中可能存在相同命名的函数，同时代码组件中也不能出现相同命名的函数，否则就是重写了，其实我一直觉得命名真的是一件麻烦事。。 雪球效应，虽然我一个组件还是使用着同一个 mixin，但是一个 mixin 会被多个组件使用，可能会存在需求使得 mixin 修改原本的函数或者新增更多的函数，这样可能就会产生一个维护成本 HOC 解决了这些问题，并且它们达成的效果也是一致的，同时也更加的政治正确（毕竟更加函数式了）。 事件机制 React 其实自己实现了一套事件机制，首先我们考虑一下以下代码： const Test = ({ list, handleClick }) => ({ list.map((item, index) => ( {index} )) }) 以上类似代码想必大家经常会写到，但是你是否考虑过点击事件是否绑定在了每一个标签上？事实当然不是，JSX 上写的事件并没有绑定在对应的真实 DOM 上，而是通过事件代理的方式，将所有的事件都统一绑定在了 document 上。这样的方式不仅减少了内存消耗，还能在组件挂载销毁时统一订阅和移除事件。 另外冒泡到 document 上的事件也不是原生浏览器事件，而是 React 自己实现的合成事件（SyntheticEvent）。因此我们如果不想要事件冒泡的话，调用 event.stopPropagation 是无效的，而应该调用 event.preventDefault。 那么实现合成事件的目的是什么呢？总的来说在我看来好处有两点，分别是： 合成事件首先抹平了浏览器之间的兼容问题，另外这是一个跨浏览器原生事件包装器，赋予了跨浏览器开发的能力 对于原生浏览器事件来说，浏览器会给监听器创建一个事件对象。如果你有很多的事件监听，那么就需要分配很多的事件对象，造成高额的内存分配问题。但是对于合成事件来说，有一个事件池专门来管理它们的创建和销毁，当事件需要被使用时，就会从池子中复用对象，事件回调结束后，就会销毁事件对象上的属性，从而便于下次复用事件对象。 更新内容 React 进阶系列：Hooks 该怎么用 小结 你可能会惊讶于这一章节的内容并不多的情况，其实你如果将两章 React 以及第十九章的内容全部学习完后，基本上 React 的大部分面试问题都可以解决。 当然你可能会觉得看的还不过瘾，这不需要担心。我已经决定写一个免费专栏「React 进阶」，专门讲解有难度的问题。比如组件的设计模式、新特性、部分源码解析等等内容。当然这些内容都是需要好好打磨的，所以更新的不会很快，有兴趣的可以持续关注，都会更新链接在这一章节中。 "},"前端面试之道/24.监控.html":{"url":"前端面试之道/24.监控.html","title":"24.监控","keywords":"","body":"监控 前端监控一般分为三种，分别为页面埋点、性能监控以及异常监控。 这一章节我们将来学习这些监控相关的内容，但是基本不会涉及到代码，只是让大家了解下前端监控该用什么方式实现。毕竟大部分公司都只是使用到了第三方的监控工具，而不是选择自己造轮子。 页面埋点 页面埋点应该是大家最常写的监控了，一般起码会监控以下几个数据： PV / UV 停留时长 流量来源 用户交互 对于这几类统计，一般的实现思路大致可以分为两种，分别为手写埋点和无埋点的方式。 相信第一种方式也是大家最常用的方式，可以自主选择需要监控的数据然后在相应的地方写入代码。这种方式的灵活性很大，但是唯一的缺点就是工作量较大，每个需要监控的地方都得插入代码。 另一种无埋点的方式基本不需要开发者手写埋点了，而是统计所有的事件并且定时上报。这种方式虽然没有前一种方式繁琐了，但是因为统计的是所有事件，所以还需要后期过滤出需要的数据。 性能监控 性能监控可以很好的帮助开发者了解在各种真实环境下，页面的性能情况是如何的。 对于性能监控来说，我们可以直接使用浏览器自带的 Performance API 来实现这个功能。 对于性能监控来说，其实我们只需要调用 performance.getEntriesByType('navigation') 这行代码就行了。对，你没看错，一行代码我们就可以获得页面中各种详细的性能相关信息。 我们可以发现这行代码返回了一个数组，内部包含了相当多的信息，从数据开始在网络中传输到页面加载完成都提供了相应的数据。 异常监控 对于异常监控来说，以下两种监控是必不可少的，分别是代码报错以及接口异常上报。 对于代码运行错误，通常的办法是使用 window.onerror 拦截报错。该方法能拦截到大部分的详细报错信息，但是也有例外 对于跨域的代码运行错误会显示 Script error. 对于这种情况我们需要给 script 标签添加 crossorigin 属性 对于某些浏览器可能不会显示调用栈信息，这种情况可以通过 arguments.callee.caller 来做栈递归 对于异步代码来说，可以使用 catch 的方式捕获错误。比如 Promise 可以直接使用 catch 函数，async await 可以使用 try catch。 但是要注意线上运行的代码都是压缩过的，需要在打包时生成 sourceMap 文件便于 debug。 对于捕获的错误需要上传给服务器，通常可以通过 img 标签的 src 发起一个请求。 另外接口异常就相对来说简单了，可以列举出出错的状态码。一旦出现此类的状态码就可以立即上报出错。接口异常上报可以让开发人员迅速知道有哪些接口出现了大面积的报错，以便迅速修复问题。 小结 这一章节内容虽然不多，但是这类监控的知识网上的资料确实不多，相信能给大家一个不错的思路。 "},"前端面试之道/25.UDP.html":{"url":"前端面试之道/25.UDP.html","title":"25.UDP","keywords":"","body":"UDP 网络协议是每个前端工程师都必须要掌握的知识，我们将先来学习传输层中的两个协议：UDP 以及 TCP。对于大部分工程师来说最常用的协议也就是这两个了，并且面试中经常会提问的也是关于这两个协议的区别。 我们先来解答这个常考面试题关于 UDP 部分的内容，然后再详细去学习这个协议。 常考面试题：UDP 与 TCP 的区别是什么？ 首先 UDP 协议是面向无连接的，也就是说不需要在正式传递数据之前先连接起双方。然后 UDP 协议只是数据报文的搬运工，不保证有序且不丢失的传递到对端，并且UDP 协议也没有任何控制流量的算法，总的来说 UDP 相较于 TCP 更加的轻便。 面向无连接 首先 UDP 是不需要和 TCP 一样在发送数据前进行三次握手建立连接的，想发数据就可以开始发送了。 并且也只是数据报文的搬运工，不会对数据报文进行任何拆分和拼接操作。 具体来说就是： 在发送端，应用层将数据传递给传输层的 UDP 协议，UDP 只会给数据增加一个 UDP 头标识下是 UDP 协议，然后就传递给网络层了 在接收端，网络层将数据传递给传输层，UDP 只去除 IP 报文头就传递给应用层，不会任何拼接操作 不可靠性 首先不可靠性体现在无连接上，通信都不需要建立连接，想发就发，这样的情况肯定不可靠。 并且收到什么数据就传递什么数据，并且也不会备份数据，发送数据也不会关心对方是否已经正确接收到数据了。 再者网络环境时好时坏，但是 UDP 因为没有拥塞控制，一直会以恒定的速度发送数据。即使网络条件不好，也不会对发送速率进行调整。这样实现的弊端就是在网络条件不好的情况下可能会导致丢包，但是优点也很明显，在某些实时性要求高的场景（比如电话会议）就需要使用 UDP 而不是 TCP。 高效 虽然 UDP 协议不是那么的可靠，但是正是因为它不是那么的可靠，所以也就没有 TCP 那么复杂了，需要保证数据不丢失且有序到达。 因此 UDP 的头部开销小，只有八字节，相比 TCP 的至少二十字节要少得多，在传输数据报文时是很高效的。 UDP 头部包含了以下几个数据 两个十六位的端口号，分别为源端口（可选字段）和目标端口 整个数据报文的长度 整个数据报文的检验和（IPv4 可选 字段），该字段用于发现头部信息和数据中的错误 传输方式 UDP 不止支持一对一的传输方式，同样支持一对多，多对多，多对一的方式，也就是说 UDP 提供了单播，多播，广播的功能。 适合使用的场景 UDP 虽然对比 TCP 有很多缺点，但是正是因为这些缺点造就了它高效的特性，在很多实时性要求高的地方都可以看到 UDP 的身影。 直播 想必大家都看过直播吧，大家可以考虑下如果直播使用了基于 TCP 的协议会发生什么事情？ TCP 会严格控制传输的正确性，一旦有某一个数据对端没有收到，就会停止下来直到对端收到这个数据。这种问题在网络条件不错的情况下可能并不会发生什么事情，但是在网络情况差的时候就会变成画面卡住，然后再继续播放下一帧的情况。 但是对于直播来说，用户肯定关注的是最新的画面，而不是因为网络条件差而丢失的老旧画面，所以 TCP 在这种情况下无用武之地，只会降低用户体验。 王者荣耀 虽然我具体不知道王者荣耀底层使用了什么协议，但是对于这类实时性要求很高的游戏来说，UDP 是跑不了的。 为什么这样说呢？首先对于王者荣耀来说，用户体量是相当大的，如果使用 TCP 连接的话，就可能会出现服务器不够用的情况，因为每台服务器可供支撑的 TCP 连接数量是有限制的。 再者，因为 TCP 会严格控制传输的正确性，如果因为用户网络条件不好就造成页面卡顿然后再传输旧的游戏画面是肯定不能接受的，毕竟对于这类实时性要求很高的游戏来说，最新的游戏画面才是最需要的，而不是老旧的画面，否则角色都不知道死多少次了。 小结 这一章节的内容就到这里，因为 UDP 协议相对简单，所以内容并不是很多，但是下一章节会呈现很多关于 TCP 相关的内容，请大家做好准备。 最后总结一下这一章节的内容： UDP 相比 TCP 简单的多，不需要建立连接，不需要验证数据报文，不需要流量控制，只会把想发的数据报文一股脑的丢给对端 虽然 UDP 并没有 TCP 传输来的准确，但是也能在很多实时性要求高的地方有所作为 "},"前端面试之道/26.TCP.html":{"url":"前端面试之道/26.TCP.html","title":"26.TCP","keywords":"","body":"TCP 首先还是先来解答这个常考面试题关于 TCP 部分的内容，然后再详细去学习这个协议。 常考面试题：UDP 与 TCP 的区别是什么？ TCP 基本是和 UDP 反着来，建立连接断开连接都需要先需要进行握手。在传输数据的过程中，通过各种算法保证数据的可靠性，当然带来的问题就是相比 UDP 来说不那么的高效。 头部 从这个图上我们就可以发现 TCP 头部比 UDP 头部复杂的多。 对于 TCP 头部来说，以下几个字段是很重要的 Sequence number，这个序号保证了 TCP 传输的报文都是有序的，对端可以通过序号顺序的拼接报文 Acknowledgement Number，这个序号表示数据接收端期望接收的下一个字节的编号是多少，同时也表示上一个序号的数据已经收到 Window Size，窗口大小，表示还能接收多少字节的数据，用于流量控制 标识符 URG=1：该字段为一表示本数据报的数据部分包含紧急信息，是一个高优先级数据报文，此时紧急指针有效。紧急数据一定位于当前数据包数据部分的最前面，紧急指针标明了紧急数据的尾部。 ACK=1：该字段为一表示确认号字段有效。此外，TCP 还规定在连接建立后传送的所有报文段都必须把 ACK 置为一。 PSH=1：该字段为一表示接收端应该立即将数据 push 给应用层，而不是等到缓冲区满后再提交。 RST=1：该字段为一表示当前 TCP 连接出现严重问题，可能需要重新建立 TCP 连接，也可以用于拒绝非法的报文段和拒绝连接请求。 SYN=1：当SYN=1，ACK=0时，表示当前报文段是一个连接请求报文。当SYN=1，ACK=1时，表示当前报文段是一个同意建立连接的应答报文。 FIN=1：该字段为一表示此报文段是一个释放连接的请求报文。 状态机 TCP 的状态机是很复杂的，并且与建立断开连接时的握手息息相关，接下来就来详细描述下两种握手。 在这之前需要了解一个重要的性能指标 RTT。该指标表示发送端发送数据到接收到对端数据所需的往返时间。 建立连接三次握手 首先假设主动发起请求的一端称为客户端，被动连接的一端称为服务端。不管是客户端还是服务端，TCP 连接建立完后都能发送和接收数据，所以 TCP 是一个全双工的协议。 起初，两端都为 CLOSED 状态。在通信开始前，双方都会创建 TCB。 服务器创建完 TCB 后便进入 LISTEN 状态，此时开始等待客户端发送数据。 第一次握手 客户端向服务端发送连接请求报文段。该报文段中包含自身的数据通讯初始序号。请求发送后，客户端便进入 SYN-SENT 状态。 第二次握手 服务端收到连接请求报文段后，如果同意连接，则会发送一个应答，该应答中也会包含自身的数据通讯初始序号，发送完成后便进入 SYN-RECEIVED 状态。 第三次握手 当客户端收到连接同意的应答后，还要向服务端发送一个确认报文。客户端发完这个报文段后便进入 ESTABLISHED 状态，服务端收到这个应答后也进入 ESTABLISHED 状态，此时连接建立成功。 PS：第三次握手中可以包含数据，通过快速打开（TFO）技术就可以实现这一功能。其实只要涉及到握手的协议，都可以使用类似 TFO 的方式，客户端和服务端存储相同的 cookie，下次握手时发出 cookie 达到减少 RTT 的目的。 常考面试题：为什么 TCP 建立连接需要三次握手，明明两次就可以建立起连接 因为这是为了防止出现失效的连接请求报文段被服务端接收的情况，从而产生错误。 可以想象如下场景。客户端发送了一个连接请求 A，但是因为网络原因造成了超时，这时 TCP 会启动超时重传的机制再次发送一个连接请求 B。此时请求顺利到达服务端，服务端应答完就建立了请求，然后接收数据后释放了连接。 假设这时候连接请求 A 在两端关闭后终于抵达了服务端，那么此时服务端会认为客户端又需要建立 TCP 连接，从而应答了该请求并进入 ESTABLISHED 状态。但是客户端其实是 CLOSED 的状态，那么就会导致服务端一直等待，造成资源的浪费。 PS：在建立连接中，任意一端掉线，TCP 都会重发 SYN 包，一般会重试五次，在建立连接中可能会遇到 SYN Flood 攻击。遇到这种情况你可以选择调低重试次数或者干脆在不能处理的情况下拒绝请求。 断开链接四次握手 TCP 是全双工的，在断开连接时两端都需要发送 FIN 和 ACK。 第一次握手 若客户端 A 认为数据发送完成，则它需要向服务端 B 发送连接释放请求。 第二次握手 B 收到连接释放请求后，会告诉应用层要释放 TCP 链接。然后会发送 ACK 包，并进入 CLOSE_WAIT 状态，此时表明 A 到 B 的连接已经释放，不再接收 A 发的数据了。但是因为 TCP 连接是双向的，所以 B 仍旧可以发送数据给 A。 第三次握手 B 如果此时还有没发完的数据会继续发送，完毕后会向 A 发送连接释放请求，然后 B 便进入 LAST-ACK 状态。 PS：通过延迟确认的技术（通常有时间限制，否则对方会误认为需要重传），可以将第二次和第三次握手合并，延迟 ACK 包的发送。 第四次握手 A 收到释放请求后，向 B 发送确认应答，此时 A 进入 TIME-WAIT 状态。该状态会持续 2MSL（最大段生存期，指报文段在网络中生存的时间，超时会被抛弃） 时间，若该时间段内没有 B 的重发请求的话，就进入 CLOSED 状态。当 B 收到确认应答后，也便进入 CLOSED 状态。 为什么 A 要进入 TIME-WAIT 状态，等待 2MSL 时间后才进入 CLOSED 状态？ 为了保证 B 能收到 A 的确认应答。若 A 发完确认应答后直接进入 CLOSED 状态，如果确认应答因为网络问题一直没有到达，那么会造成 B 不能正常关闭。 ARQ 协议 ARQ 协议也就是超时重传机制。通过确认和超时机制保证了数据的正确送达，ARQ 协议包含停止等待 ARQ 和连续 ARQ 两种协议。 停止等待 ARQ 正常传输过程 只要 A 向 B 发送一段报文，都要停止发送并启动一个定时器，等待对端回应，在定时器时间内接收到对端应答就取消定时器并发送下一段报文。 报文丢失或出错 在报文传输的过程中可能会出现丢包。这时候超过定时器设定的时间就会再次发送丢失的数据直到对端响应，所以需要每次都备份发送的数据。 即使报文正常的传输到对端，也可能出现在传输过程中报文出错的问题。这时候对端会抛弃该报文并等待 A 端重传。 PS：一般定时器设定的时间都会大于一个 RTT 的平均时间。 ACK 超时或丢失 对端传输的应答也可能出现丢失或超时的情况。那么超过定时器时间 A 端照样会重传报文。这时候 B 端收到相同序号的报文会丢弃该报文并重传应答，直到 A 端发送下一个序号的报文。 在超时的情况下也可能出现应答很迟到达，这时 A 端会判断该序号是否已经接收过，如果接收过只需要丢弃应答即可。 从上面的描述中大家肯定可以发现这肯定不是一个高效的方式。假设在良好的网络环境中，每次发送数据都需要等待片刻肯定是不能接受的。那么既然我们不能接受这个不那么高效的协议，就来继续学习相对高效的协议吧。 连续 ARQ 在连续 ARQ 中，发送端拥有一个发送窗口，可以在没有收到应答的情况下持续发送窗口内的数据，这样相比停止等待 ARQ 协议来说减少了等待时间，提高了效率。 累计确认 连续 ARQ 中，接收端会持续不断收到报文。如果和停止等待 ARQ 中接收一个报文就发送一个应答一样，就太浪费资源了。通过累计确认，可以在收到多个报文以后统一回复一个应答报文。报文中的 ACK 标志位可以用来告诉发送端这个序号之前的数据已经全部接收到了，下次请发送这个序号后的数据。 但是累计确认也有一个弊端。在连续接收报文时，可能会遇到接收到序号 5 的报文后，并未接收到序号 6 的报文，然而序号 7 以后的报文已经接收。遇到这种情况时，ACK 只能回复 6，这样就会造成发送端重复发送数据的情况。 滑动窗口 在上面小节中讲到了发送窗口。在 TCP 中，两端其实都维护着窗口：分别为发送端窗口和接收端窗口。 发送端窗口包含已发送但未收到应答的数据和可以发送但是未发送的数据。 发送端窗口是由接收窗口剩余大小决定的。接收方会把当前接收窗口的剩余大小写入应答报文，发送端收到应答后根据该值和当前网络拥塞情况设置发送窗口的大小，所以发送窗口的大小是不断变化的。 当发送端接收到应答报文后，会随之将窗口进行滑动 滑动窗口是一个很重要的概念，它帮助 TCP 实现了流量控制的功能。接收方通过报文告知发送方还可以发送多少数据，从而保证接收方能够来得及接收数据，防止出现接收方带宽已满，但是发送方还一直发送数据的情况。 Zero 窗口 在发送报文的过程中，可能会遇到对端出现零窗口的情况。在该情况下，发送端会停止发送数据，并启动 persistent timer 。该定时器会定时发送请求给对端，让对端告知窗口大小。在重试次数超过一定次数后，可能会中断 TCP 链接。 拥塞处理 拥塞处理和流量控制不同，后者是作用于接收方，保证接收方来得及接受数据。而前者是作用于网络，防止过多的数据拥塞网络，避免出现网络负载过大的情况。 拥塞处理包括了四个算法，分别为：慢开始，拥塞避免，快速重传，快速恢复。 慢开始算法 慢开始算法，顾名思义，就是在传输开始时将发送窗口慢慢指数级扩大，从而避免一开始就传输大量数据导致网络拥塞。想必大家都下载过资源，每当我们开始下载的时候都会发现下载速度是慢慢提升的，而不是一蹴而就直接拉满带宽。 慢开始算法步骤具体如下 连接初始设置拥塞窗口（Congestion Window） 为 1 MSS（一个分段的最大数据量） 每过一个 RTT 就将窗口大小乘二 指数级增长肯定不能没有限制的，所以有一个阈值限制，当窗口大小大于阈值时就会启动拥塞避免算法。 拥塞避免算法 拥塞避免算法相比简单点，每过一个 RTT 窗口大小只加一，这样能够避免指数级增长导致网络拥塞，慢慢将大小调整到最佳值。 在传输过程中可能定时器超时的情况，这时候 TCP 会认为网络拥塞了，会马上进行以下步骤： 将阈值设为当前拥塞窗口的一半 将拥塞窗口设为 1 MSS 启动拥塞避免算法 快速重传 快速重传一般和快恢复一起出现。一旦接收端收到的报文出现失序的情况，接收端只会回复最后一个顺序正确的报文序号。如果发送端收到三个重复的 ACK，无需等待定时器超时而是直接启动快速重传算法。具体算法分为两种： TCP Taho 实现如下 将阈值设为当前拥塞窗口的一半 将拥塞窗口设为 1 MSS 重新开始慢开始算法 TCP Reno 实现如下 拥塞窗口减半 将阈值设为当前拥塞窗口 进入快恢复阶段（重发对端需要的包，一旦收到一个新的 ACK 答复就退出该阶段），这种方式在丢失多个包的情况下就不那么好了 使用拥塞避免算法 TCP New Ren 改进后的快恢复 TCP New Reno 算法改进了之前 TCP Reno 算法的缺陷。在之前，快恢复中只要收到一个新的 ACK 包，就会退出快恢复。 在 TCP New Reno 中，TCP 发送方先记下三个重复 ACK 的分段的最大序号。 假如我有一个分段数据是 1 ~ 10 这十个序号的报文，其中丢失了序号为 3 和 7 的报文，那么该分段的最大序号就是 10。发送端只会收到 ACK 序号为 3 的应答。这时候重发序号为 3 的报文，接收方顺利接收的话就会发送 ACK 序号为 7 的应答。这时候 TCP 知道对端是有多个包未收到，会继续发送序号为 7 的报文，接收方顺利接收并会发送 ACK 序号为 11 的应答，这时发送端认为这个分段接收端已经顺利接收，接下来会退出快恢复阶段。 小结 这一章节内容很多，充斥了大量的术语，适合大家反复研读，已经把 TCP 中最核心最需要掌握的内容全盘托出了，如有哪里不明白的欢迎提问。 总结一下这一章节的内容： 建立连接需要三次握手，断开连接需要四次握手 滑动窗口解决了数据的丢包、顺序不对和流量控制问题 拥塞窗口实现了对流量的控制，保证在全天候环境下最优的传递数据 "},"前端面试之道/27.HTTP及TLS.html":{"url":"前端面试之道/27.HTTP及TLS.html","title":"27.HTTP及TLS","keywords":"","body":"HTTP 及 TLS 这一章节我们将来学习 HTTP 及 TLS 协议中的内容。 HTTP 请求中的内容 HTTP 请求由三部分构成，分别为： 请求行 首部 实体 请求行大概长这样 GET /images/logo.gif HTTP/1.1，基本由请求方法、URL、协议版本组成，这其中值得一说的就是请求方法了。 请求方法分为很多种，最常用的也就是 Get 和 Post 了。虽然请求方法有很多，但是更多的是传达一个语义，而不是说 Post 能做的事情 Get 就不能做了。如果你愿意，都使用 Get 请求或者 Post 请求都是可以的。更多请求方法的语义描述可以阅读 文档。 常考面试题：Post 和 Get 的区别？ 首先先引入副作用和幂等的概念。 副作用指对服务器上的资源做改变，搜索是无副作用的，注册是副作用的。 幂等指发送 M 和 N 次请求（两者不相同且都大于 1），服务器上资源的状态一致，比如注册 10 个和 11 个帐号是不幂等的，对文章进行更改 10 次和 11 次是幂等的。因为前者是多了一个账号（资源），后者只是更新同一个资源。 在规范的应用场景上说，Get 多用于无副作用，幂等的场景，例如搜索关键字。Post 多用于副作用，不幂等的场景，例如注册。 在技术上说： Get 请求能缓存，Post 不能 Post 相对 Get 安全一点点，因为Get 请求都包含在 URL 里（当然你想写到 body 里也是可以的），且会被浏览器保存历史纪录。Post 不会，但是在抓包的情况下都是一样的。 URL有长度限制，会影响 Get 请求，但是这个长度限制是浏览器规定的，不是 RFC 规定的 Post 支持更多的编码类型且不对数据类型限制 首部 首部分为请求首部和响应首部，并且部分首部两种通用，接下来我们就来学习一部分的常用首部。 通用首部 通用字段 作用 Cache-Control 控制缓存的行为 Connection 浏览器想要优先使用的连接类型，比如 keep-alive Date 创建报文时间 Pragma 报文指令 Via 代理服务器相关信息 Transfer-Encoding 传输编码方式 Upgrade 要求客户端升级协议 Warning 在内容中可能存在错误 请求首部 请求首部 作用 Accept 能正确接收的媒体类型 Accept-Charset 能正确接收的字符集 Accept-Encoding 能正确接收的编码格式列表 Accept-Language 能正确接收的语言列表 Expect 期待服务端的指定行为 From 请求方邮箱地址 Host 服务器的域名 If-Match 两端资源标记比较 If-Modified-Since 本地资源未修改返回 304（比较时间） If-None-Match 本地资源未修改返回 304（比较标记） User-Agent 客户端信息 Max-Forwards 限制可被代理及网关转发的次数 Proxy-Authorization 向代理服务器发送验证信息 Range 请求某个内容的一部分 Referer 表示浏览器所访问的前一个页面 TE 传输编码方式 响应首部 响应首部 作用 Accept-Ranges 是否支持某些种类的范围 Age 资源在代理缓存中存在的时间 ETag 资源标识 Location 客户端重定向到某个 URL Proxy-Authenticate 向代理服务器发送验证信息 Server 服务器名字 WWW-Authenticate 获取资源需要的验证信息 实体首部 实体首部 作用 Allow 资源的正确请求方式 Content-Encoding 内容的编码格式 Content-Language 内容使用的语言 Content-Length request body 长度 Content-Location 返回数据的备用地址 Content-MD5 Base64加密格式的内容 MD5检验值 Content-Range 内容的位置范围 Content-Type 内容的媒体类型 Expires 内容的过期时间 Last_modified 内容的最后修改时间 常见状态码 状态码表示了响应的一个状态，可以让我们清晰的了解到这一次请求是成功还是失败，如果失败的话，是什么原因导致的，当然状态码也是用于传达语义的。如果胡乱使用状态码，那么它存在的意义就没有了。 状态码通常也是一道常考题。 2XX 成功 200 OK，表示从客户端发来的请求在服务器端被正确处理 204 No content，表示请求成功，但响应报文不含实体的主体部分 205 Reset Content，表示请求成功，但响应报文不含实体的主体部分，但是与 204 响应不同在于要求请求方重置内容 206 Partial Content，进行范围请求 3XX 重定向 301 moved permanently，永久性重定向，表示资源已被分配了新的 URL 302 found，临时性重定向，表示资源临时被分配了新的 URL 303 see other，表示资源存在着另一个 URL，应使用 GET 方法获取资源 304 not modified，表示服务器允许访问资源，但因发生请求未满足条件的情况 307 temporary redirect，临时重定向，和302含义类似，但是期望客户端保持请求方法不变向新的地址发出请求 4XX 客户端错误 400 bad request，请求报文存在语法错误 401 unauthorized，表示发送的请求需要有通过 HTTP 认证的认证信息 403 forbidden，表示对请求资源的访问被服务器拒绝 404 not found，表示在服务器上没有找到请求的资源 5XX 服务器错误 500 internal sever error，表示服务器端在执行请求时发生了错误 501 Not Implemented，表示服务器不支持当前请求所需要的某个功能 503 service unavailable，表明服务器暂时处于超负载或正在停机维护，无法处理请求 TLS HTTPS 还是通过了 HTTP 来传输信息，但是信息通过 TLS 协议进行了加密。 TLS 协议位于传输层之上，应用层之下。首次进行 TLS 协议传输需要两个 RTT ，接下来可以通过 Session Resumption 减少到一个 RTT。 在 TLS 中使用了两种加密技术，分别为：对称加密和非对称加密。 对称加密： 对称加密就是两边拥有相同的秘钥，两边都知道如何将密文加密解密。 这种加密方式固然很好，但是问题就在于如何让双方知道秘钥。因为传输数据都是走的网络，如果将秘钥通过网络的方式传递的话，一旦秘钥被截获就没有加密的意义的。 非对称加密： 有公钥私钥之分，公钥所有人都可以知道，可以将数据用公钥加密，但是将数据解密必须使用私钥解密，私钥只有分发公钥的一方才知道。 这种加密方式就可以完美解决对称加密存在的问题。假设现在两端需要使用对称加密，那么在这之前，可以先使用非对称加密交换秘钥。 简单流程如下：首先服务端将公钥公布出去，那么客户端也就知道公钥了。接下来客户端创建一个秘钥，然后通过公钥加密并发送给服务端，服务端接收到密文以后通过私钥解密出正确的秘钥，这时候两端就都知道秘钥是什么了。 TLS 握手过程如下图： 客户端发送一个随机值以及需要的协议和加密方式。 服务端收到客户端的随机值，自己也产生一个随机值，并根据客户端需求的协议和加密方式来使用对应的方式，并且发送自己的证书（如果需要验证客户端证书需要说明） 客户端收到服务端的证书并验证是否有效，验证通过会再生成一个随机值，通过服务端证书的公钥去加密这个随机值并发送给服务端，如果服务端需要验证客户端证书的话会附带证书 服务端收到加密过的随机值并使用私钥解密获得第三个随机值，这时候两端都拥有了三个随机值，可以通过这三个随机值按照之前约定的加密方式生成密钥，接下来的通信就可以通过该密钥来加密解密 通过以上步骤可知，在 TLS 握手阶段，两端使用非对称加密的方式来通信，但是因为非对称加密损耗的性能比对称加密大，所以在正式传输数据时，两端使用对称加密的方式通信。 PS：以上说明的都是 TLS 1.2 协议的握手情况，在 1.3 协议中，首次建立连接只需要一个 RTT，后面恢复连接不需要 RTT 了。 小结 总结一下内容： HTTP 经常考到的内容包括：请求方法、首部的作用以及状态码的含义 TLS 中经常考到的内容包括：两种加密方式以及握手的流程 "},"前端面试之道/28.HTTP2及HTTP3.html":{"url":"前端面试之道/28.HTTP2及HTTP3.html","title":"28.HTTP2及HTTP3","keywords":"","body":"HTTP/2 及 HTTP/3 这一章节我们将来学习 HTTP/2 及 HTTP/3 的内容。 HTTP/2 很好的解决了当下最常用的 HTTP/1 所存在的一些性能问题，只需要升级到该协议就可以减少很多之前需要做的性能优化工作，当然兼容问题以及如何优雅降级应该是国内还不普遍使用的原因之一。 虽然 HTTP/2 已经解决了很多问题，但是并不代表它已经是完美的了，HTTP/3 就是为了解决 HTTP/2 所存在的一些问题而被推出来的。 HTTP/2 HTTP/2 相比于 HTTP/1，可以说是大幅度提高了网页的性能。 在 HTTP/1 中，为了性能考虑，我们会引入雪碧图、将小图内联、使用多个域名等等的方式。这一切都是因为浏览器限制了同一个域名下的请求数量（Chrome 下一般是限制六个连接），当页面中需要请求很多资源的时候，队头阻塞（Head of line blocking）会导致在达到最大请求数量时，剩余的资源需要等待其他资源请求完成后才能发起请求。 在 HTTP/2 中引入了多路复用的技术，这个技术可以只通过一个 TCP 连接就可以传输所有的请求数据。多路复用很好的解决了浏览器限制同一个域名下的请求数量的问题，同时也间接更容易实现全速传输，毕竟新开一个 TCP 连接都需要慢慢提升传输速度。 大家可以通过 该链接 感受下 HTTP/2 比 HTTP/1 到底快了多少。 在 HTTP/1 中，因为队头阻塞的原因，你会发现发送请求是长这样的 在 HTTP/2 中，因为可以复用同一个 TCP 连接，你会发现发送请求是长这样的 二进制传输 HTTP/2 中所有加强性能的核心点在于此。在之前的 HTTP 版本中，我们是通过文本的方式传输数据。在 HTTP/2 中引入了新的编码机制，所有传输的数据都会被分割，并采用二进制格式编码。 多路复用 在 HTTP/2 中，有两个非常重要的概念，分别是帧（frame）和流（stream）。 帧代表着最小的数据单位，每个帧会标识出该帧属于哪个流，流也就是多个帧组成的数据流。 多路复用，就是在一个 TCP 连接中可以存在多条流。换句话说，也就是可以发送多个请求，对端可以通过帧中的标识知道属于哪个请求。通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。 Header 压缩 在 HTTP/1 中，我们使用文本的形式传输 header，在 header 携带 cookie 的情况下，可能每次都需要重复传输几百到几千的字节。 在 HTTP /2 中，使用了 HPACK 压缩格式对传输的 header 进行编码，减少了 header 的大小。并在两端维护了索引表，用于记录出现过的 header ，后面在传输过程中就可以传输已经记录过的 header 的键名，对端收到数据后就可以通过键名找到对应的值。 服务端 Push 在 HTTP/2 中，服务端可以在客户端某个请求后，主动推送其他资源。 可以想象以下情况，某些资源客户端是一定会请求的，这时就可以采取服务端 push 的技术，提前给客户端推送必要的资源，这样就可以相对减少一点延迟时间。当然在浏览器兼容的情况下你也可以使用 prefetch 。 HTTP/3 虽然 HTTP/2 解决了很多之前旧版本的问题，但是它还是存在一个巨大的问题，虽然这个问题并不是它本身造成的，而是底层支撑的 TCP 协议的问题。 因为 HTTP/2 使用了多路复用，一般来说同一域名下只需要使用一个 TCP 连接。当这个连接中出现了丢包的情况，那就会导致 HTTP/2 的表现情况反倒不如 HTTP/1 了。 因为在出现丢包的情况下，整个 TCP 都要开始等待重传，也就导致了后面的所有数据都被阻塞了。但是对于 HTTP/1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。 那么可能就会有人考虑到去修改 TCP 协议，其实这已经是一件不可能完成的任务了。因为 TCP 存在的时间实在太长，已经充斥在各种设备中，并且这个协议是由操作系统实现的，更新起来不大现实。 基于这个原因，Google 就更起炉灶搞了一个基于 UDP 协议的 QUIC 协议，并且使用在了 HTTP/3 上，当然 HTTP/3 之前名为 HTTP-over-QUIC，从这个名字中我们也可以发现，HTTP/3 最大的改造就是使用了 QUIC，接下来我们就来学习关于这个协议的内容。 QUIC 之前我们学习过 UDP 协议的内容，知道这个协议虽然效率很高，但是并不是那么的可靠。QUIC 虽然基于 UDP，但是在原本的基础上新增了很多功能，比如多路复用、0-RTT、使用 TLS1.3 加密、流量控制、有序交付、重传等等功能。这里我们就挑选几个重要的功能学习下这个协议的内容。 多路复用 虽然 HTTP/2 支持了多路复用，但是 TCP 协议终究是没有这个功能的。QUIC 原生就实现了这个功能，并且传输的单个数据流可以保证有序交付且不会影响其他的数据流，这样的技术就解决了之前 TCP 存在的问题。 并且 QUIC 在移动端的表现也会比 TCP 好。因为 TCP 是基于 IP 和端口去识别连接的，这种方式在多变的移动端网络环境下是很脆弱的。但是 QUIC 是通过 ID 的方式去识别一个连接，不管你网络环境如何变化，只要 ID 不变，就能迅速重连上。 0-RTT 通过使用类似 TCP 快速打开的技术，缓存当前会话的上下文，在下次恢复会话的时候，只需要将之前的缓存传递给服务端验证通过就可以进行传输了。 纠错机制 假如说这次我要发送三个包，那么协议会算出这三个包的异或值并单独发出一个校验包，也就是总共发出了四个包。 当出现其中的非校验包丢包的情况时，可以通过另外三个包计算出丢失的数据包的内容。 当然这种技术只能使用在丢失一个包的情况下，如果出现丢失多个包就不能使用纠错机制了，只能使用重传的方式了。 小结 总结一下内容： HTTP/2 通过多路复用、二进制流、Header 压缩等等技术，极大地提高了性能，但是还是存在着问题的 QUIC 基于 UDP 实现，是 HTTP/3 中的底层支撑协议，该协议基于 UDP，又取了 TCP 中的精华，实现了即快又可靠的协议 "},"前端面试之道/29.输入URL到页面渲染的整个流程.html":{"url":"前端面试之道/29.输入URL到页面渲染的整个流程.html","title":"29.输入URL到页面渲染的整个流程","keywords":"","body":"输入 URL 到页面渲染的整个流程 之前我们学了那么多章节的内容，是时候找个时间将它们再次复习消化了。就借用这道经典面试题，将之前学习到的浏览器以及网络几章节的知识联系起来。 首先是 DNS 查询，如果这一步做了智能 DNS 解析的话，会提供访问速度最快的 IP 地址回来，这部分的内容之前没有写过，所以就在这里讲解下。 DNS DNS 的作用就是通过域名查询到具体的 IP。 因为 IP 存在数字和英文的组合（IPv6），很不利于人类记忆，所以就出现了域名。你可以把域名看成是某个 IP 的别名，DNS 就是去查询这个别名的真正名称是什么。 在 TCP 握手之前就已经进行了 DNS 查询，这个查询是操作系统自己做的。当你在浏览器中想访问 www.google.com 时，会进行一下操作： 操作系统会首先在本地缓存中查询 IP 没有的话会去系统配置的 DNS 服务器中查询 如果这时候还没得话，会直接去 DNS 根服务器查询，这一步查询会找出负责 com 这个一级域名的服务器 然后去该服务器查询 google 这个二级域名 接下来三级域名的查询其实是我们配置的，你可以给 www 这个域名配置一个 IP，然后还可以给别的三级域名配置一个 IP 以上介绍的是 DNS 迭代查询，还有种是递归查询，区别就是前者是由客户端去做请求，后者是由系统配置的 DNS 服务器做请求，得到结果后将数据返回给客户端。 PS：DNS 是基于 UDP 做的查询，大家也可以考虑下为什么之前不考虑使用 TCP 去实现。 接下来是 TCP 握手，应用层会下发数据给传输层，这里 TCP 协议会指明两端的端口号，然后下发给网络层。网络层中的 IP 协议会确定 IP 地址，并且指示了数据传输中如何跳转路由器。然后包会再被封装到数据链路层的数据帧结构中，最后就是物理层面的传输了。 在这一部分中，可以详细说下 TCP 的握手情况以及 TCP 的一些特性。 当 TCP 握手结束后就会进行 TLS 握手，然后就开始正式的传输数据。 在这一部分中，可以详细说下 TLS 的握手情况以及两种加密方式的内容。 数据在进入服务端之前，可能还会先经过负责负载均衡的服务器，它的作用就是将请求合理的分发到多台服务器上，这时假设服务端会响应一个 HTML 文件。 首先浏览器会判断状态码是什么，如果是 200 那就继续解析，如果 400 或 500 的话就会报错，如果 300 的话会进行重定向，这里会有个重定向计数器，避免过多次的重定向，超过次数也会报错。 浏览器开始解析文件，如果是 gzip 格式的话会先解压一下，然后通过文件的编码格式知道该如何去解码文件。 文件解码成功后会正式开始渲染流程，先会根据 HTML 构建 DOM 树，有 CSS 的话会去构建 CSSOM 树。如果遇到 script 标签的话，会判断是否存在 async 或者 defer ，前者会并行进行下载并执行 JS，后者会先下载文件，然后等待 HTML 解析完成后顺序执行。 如果以上都没有，就会阻塞住渲染流程直到 JS 执行完毕。遇到文件下载的会去下载文件，这里如果使用 HTTP/2 协议的话会极大的提高多图的下载效率。 CSSOM 树和 DOM 树构建完成后会开始生成 Render 树，这一步就是确定页面元素的布局、样式等等诸多方面的东西 在生成 Render 树的过程中，浏览器就开始调用 GPU 绘制，合成图层，将内容显示在屏幕上了。 这一部分就是渲染原理中讲解到的内容，可以详细的说明下这一过程。并且在下载文件时，也可以说下通过 HTTP/2 协议可以解决队头阻塞的问题。 总的来说这一章节就是带着大家从 DNS 查询开始到渲染出画面完整的了解一遍过程，将之前学习到的内容连接起来。 当来这一过程远远不止这些内容，但是对于大部分人能答出这些内容已经很不错了，你如果想了解更加详细的过程，可以阅读这篇文章。 "},"前端面试之道/30.设计模式.html":{"url":"前端面试之道/30.设计模式.html","title":"30.设计模式","keywords":"","body":"设计模式 设计模式总的来说是一个抽象的概念，前人通过无数次的实践总结出的一套写代码的方式，通过这种方式写的代码可以让别人更加容易阅读、维护以及复用。 这一章节我们将来学习几种最常用的设计模式。 工厂模式 工厂模式分为好几种，这里就不一一讲解了，以下是一个简单工厂模式的例子 class Man { constructor(name) { this.name = name } alertName() { alert(this.name) } } class Factory { static create(name) { return new Man(name) } } Factory.create('yck').alertName() 当然工厂模式并不仅仅是用来 new 出实例。 可以想象一个场景。假设有一份很复杂的代码需要用户去调用，但是用户并不关心这些复杂的代码，只需要你提供给我一个接口去调用，用户只负责传递需要的参数，至于这些参数怎么使用，内部有什么逻辑是不关心的，只需要你最后返回我一个实例。这个构造过程就是工厂。 工厂起到的作用就是隐藏了创建实例的复杂度，只需要提供一个接口，简单清晰。 在 Vue 源码中，你也可以看到工厂模式的使用，比如创建异步组件 export function createComponent ( Ctor: Class | Function | Object | void, data: ?VNodeData, context: Component, children: ?Array, tag?: string ): VNode | Array | void { // 逻辑处理... const vnode = new VNode( `vue-component-${Ctor.cid}${name ? `-${name}` : ''}`, data, undefined, undefined, undefined, context, { Ctor, propsData, listeners, tag, children }, asyncFactory ) return vnode } 在上述代码中，我们可以看到我们只需要调用 createComponent 传入参数就能创建一个组件实例，但是创建这个实例是很复杂的一个过程，工厂帮助我们隐藏了这个复杂的过程，只需要一句代码调用就能实现功能。 单例模式 单例模式很常用，比如全局缓存、全局状态管理等等这些只需要一个对象，就可以使用单例模式。 单例模式的核心就是保证全局只有一个对象可以访问。因为 JS 是门无类的语言，所以别的语言实现单例的方式并不能套入 JS 中，我们只需要用一个变量确保实例只创建一次就行，以下是如何实现单例模式的例子 class Singleton { constructor() {} } Singleton.getInstance = (function() { let instance return function() { if (!instance) { instance = new Singleton() } return instance } })() let s1 = Singleton.getInstance() let s2 = Singleton.getInstance() console.log(s1 === s2) // true 在 Vuex 源码中，你也可以看到单例模式的使用，虽然它的实现方式不大一样，通过一个外部变量来控制只安装一次 Vuex let Vue // bind on install export function install (_Vue) { if (Vue && _Vue === Vue) { // 如果发现 Vue 有值，就不重新创建实例了 return } Vue = _Vue applyMixin(Vue) } 适配器模式 适配器用来解决两个接口不兼容的情况，不需要改变已有的接口，通过包装一层的方式实现两个接口的正常协作。 以下是如何实现适配器模式的例子 class Plug { getName() { return '港版插头' } } class Target { constructor() { this.plug = new Plug() } getName() { return this.plug.getName() + ' 适配器转二脚插头' } } let target = new Target() target.getName() // 港版插头 适配器转二脚插头 在 Vue 中，我们其实经常使用到适配器模式。比如父组件传递给子组件一个时间戳属性，组件内部需要将时间戳转为正常的日期显示，一般会使用 computed 来做转换这件事情，这个过程就使用到了适配器模式。 装饰模式 装饰模式不需要改变已有的接口，作用是给对象添加功能。就像我们经常需要给手机戴个保护套防摔一样，不改变手机自身，给手机添加了保护套提供防摔功能。 以下是如何实现装饰模式的例子，使用了 ES7 中的装饰器语法 function readonly(target, key, descriptor) { descriptor.writable = false return descriptor } class Test { @readonly name = 'yck' } let t = new Test() t.yck = '111' // 不可修改 在 React 中，装饰模式其实随处可见 import { connect } from 'react-redux' class MyComponent extends React.Component { // ... } export default connect(mapStateToProps)(MyComponent) 代理模式 代理是为了控制对对象的访问，不让外部直接访问到对象。在现实生活中，也有很多代理的场景。比如你需要买一件国外的产品，这时候你可以通过代购来购买产品。 在实际代码中其实代理的场景很多，也就不举框架中的例子了，比如事件代理就用到了代理模式。 1 2 3 4 5 let ul = document.querySelector('#ul') ul.addEventListener('click', (event) => { console.log(event.target); }) 因为存在太多的 li，不可能每个都去绑定事件。这时候可以通过给父节点绑定一个事件，让父节点作为代理去拿到真实点击的节点。 发布-订阅模式 发布-订阅模式也叫做观察者模式。通过一对一或者一对多的依赖关系，当对象发生改变时，订阅方都会收到通知。在现实生活中，也有很多类似场景，比如我需要在购物网站上购买一个产品，但是发现该产品目前处于缺货状态，这时候我可以点击有货通知的按钮，让网站在产品有货的时候通过短信通知我。 在实际代码中其实发布-订阅模式也很常见，比如我们点击一个按钮触发了点击事件就是使用了该模式 let ul = document.querySelector('#ul') ul.addEventListener('click', (event) => { console.log(event.target); }) 在 Vue 中，如何实现响应式也是使用了该模式。对于需要实现响应式的对象来说，在 get 的时候会进行依赖收集，当改变了对象的属性时，就会触发派发更新。 外观模式 外观模式提供了一个接口，隐藏了内部的逻辑，更加方便外部调用。 举个例子来说，我们现在需要实现一个兼容多种浏览器的添加事件方法 function addEvent(elm, evType, fn, useCapture) { if (elm.addEventListener) { elm.addEventListener(evType, fn, useCapture) return true } else if (elm.attachEvent) { var r = elm.attachEvent(\"on\" + evType, fn) return r } else { elm[\"on\" + evType] = fn } } 对于不同的浏览器，添加事件的方式可能会存在兼容问题。如果每次都需要去这样写一遍的话肯定是不能接受的，所以我们将这些判断逻辑统一封装在一个接口中，外部需要添加事件只需要调用 addEvent 即可。 小结 这一章节我们学习了几种常用的设计模式。其实设计模式还有很多，有一些内容很简单，我就没有写在章节中了，比如迭代器模式、原型模式，有一些内容也是不经常使用，所以也就不一一列举了。 如果你还想了解更多关于设计模式的内容，可以阅读这本书。 "},"前端面试之道/31.常见数据结构.html":{"url":"前端面试之道/31.常见数据结构.html","title":"31.常见数据结构","keywords":"","body":"常见数据结构 这一章节我们将来学习数据结构的内容。经常会有人提问说：学习数据结构或者算法对于前端工程师有用么？ 总的来说，这些基础学科在短期内收效确实甚微，但是我们首先不要将自己局限在前端工程师这点上。笔者之前是做 iOS 开发的，转做前端以后，只有两个技能还对我有用： 基础学科内容，比如：网络知识、数据结构算法 编程思想 其他 iOS 上积累的经验，转行以后基本就没多大用处了。所以说，当我们把视野放到编程这个角度去说，数据结构算法一定是有用的，并且也是你未来的一个天花板。可以不花费集中的时间去学习这些内容，但是一定需要时常去学习一点，因为这些技能可以实实在在提升你写代码的能力。 这一章节的内容信息量会很大，不适合在非电脑环境下阅读，请各位打开代码编辑器，一行行的敲代码，单纯阅读是学习不了数据结构的。 时间复杂度 在进入正题之前，我们先来了解下什么是时间复杂度。 通常使用最差的时间复杂度来衡量一个算法的好坏。 常数时间 O(1) 代表这个操作和数据量没关系，是一个固定时间的操作，比如说四则运算。 对于一个算法来说，可能会计算出操作次数为 aN + 1，N 代表数据量。那么该算法的时间复杂度就是 O(N)。因为我们在计算时间复杂度的时候，数据量通常是非常大的，这时候低阶项和常数项可以忽略不计。 当然可能会出现两个算法都是 O(N) 的时间复杂度，那么对比两个算法的好坏就要通过对比低阶项和常数项了。 栈 概念 栈是一个线性结构，在计算机中是一个相当常见的数据结构。 栈的特点是只能在某一端添加或删除数据，遵循先进后出的原则 实现 每种数据结构都可以用很多种方式来实现，其实可以把栈看成是数组的一个子集，所以这里使用数组来实现 class Stack { constructor() { this.stack = [] } push(item) { this.stack.push(item) } pop() { this.stack.pop() } peek() { return this.stack[this.getCount() - 1] } getCount() { return this.stack.length } isEmpty() { return this.getCount() === 0 } } 应用 选取了 LeetCode 上序号为 20 的题目 题意是匹配括号，可以通过栈的特性来完成这道题目 var isValid = function (s) { let map = { '(': -1, ')': 1, '[': -2, ']': 2, '{': -3, '}': 3 } let stack = [] for (let i = 0; i 0) return false return true }; 其实在 Vue 中关于模板解析的代码，就有应用到匹配尖括号的内容。 队列 概念 队列是一个线性结构，特点是在某一端添加数据，在另一端删除数据，遵循先进先出的原则。 实现 这里会讲解两种实现队列的方式，分别是单链队列和循环队列。 单链队列 class Queue { constructor() { this.queue = [] } enQueue(item) { this.queue.push(item) } deQueue() { return this.queue.shift() } getHeader() { return this.queue[0] } getLength() { return this.queue.length } isEmpty() { return this.getLength() === 0 } } 因为单链队列在出队操作的时候需要 O(n) 的时间复杂度，所以引入了循环队列。循环队列的出队操作平均是 O(1) 的时间复杂度。 循环队列 class SqQueue { constructor(length) { this.queue = new Array(length + 1) // 队头 this.first = 0 // 队尾 this.last = 0 // 当前队列大小 this.size = 0 } enQueue(item) { // 判断队尾 + 1 是否为队头 // 如果是就代表需要扩容数组 // % this.queue.length 是为了防止数组越界 if (this.first === (this.last + 1) % this.queue.length) { this.resize(this.getLength() * 2 + 1) } this.queue[this.last] = item this.size++ this.last = (this.last + 1) % this.queue.length } deQueue() { if (this.isEmpty()) { throw Error('Queue is empty') } let r = this.queue[this.first] this.queue[this.first] = null this.first = (this.first + 1) % this.queue.length this.size-- // 判断当前队列大小是否过小 // 为了保证不浪费空间，在队列空间等于总长度四分之一时 // 且不为 2 时缩小总长度为当前的一半 if (this.size === this.getLength() / 4 && this.getLength() / 2 !== 0) { this.resize(this.getLength() / 2) } return r } getHeader() { if (this.isEmpty()) { throw Error('Queue is empty') } return this.queue[this.first] } getLength() { return this.queue.length - 1 } isEmpty() { return this.first === this.last } resize(length) { let q = new Array(length) for (let i = 0; i 链表 概念 链表是一个线性结构，同时也是一个天然的递归结构。链表结构可以充分利用计算机内存空间，实现灵活的内存动态管理。但是链表失去了数组随机读取的优点，同时链表由于增加了结点的指针域，空间开销比较大。 实现 单向链表 class Node { constructor(v, next) { this.value = v this.next = next } } class LinkList { constructor() { // 链表长度 this.size = 0 // 虚拟头部 this.dummyNode = new Node(null, null) } find(header, index, currentIndex) { if (index === currentIndex) return header return this.find(header.next, index, currentIndex + 1) } addNode(v, index) { this.checkIndex(index) // 当往链表末尾插入时，prev.next 为空 // 其他情况时，因为要插入节点，所以插入的节点 // 的 next 应该是 prev.next // 然后设置 prev.next 为插入的节点 let prev = this.find(this.dummyNode, index, 0) prev.next = new Node(v, prev.next) this.size++ return prev.next } insertNode(v, index) { return this.addNode(v, index) } addToFirst(v) { return this.addNode(v, 0) } addToLast(v) { return this.addNode(v, this.size) } removeNode(index, isLast) { this.checkIndex(index) index = isLast ? index - 1 : index let prev = this.find(this.dummyNode, index, 0) let node = prev.next prev.next = node.next node.next = null this.size-- return node } removeFirstNode() { return this.removeNode(0) } removeLastNode() { return this.removeNode(this.size, true) } checkIndex(index) { if (index this.size) throw Error('Index error') } getNode(index) { this.checkIndex(index) if (this.isEmpty()) return return this.find(this.dummyNode, index, 0).next } isEmpty() { return this.size === 0 } getSize() { return this.size } } 树 二叉树 树拥有很多种结构，二叉树是树中最常用的结构，同时也是一个天然的递归结构。 二叉树拥有一个根节点，每个节点至多拥有两个子节点，分别为：左节点和右节点。树的最底部节点称之为叶节点，当一颗树的叶数量数量为满时，该树可以称之为满二叉树。 二分搜索树 二分搜索树也是二叉树，拥有二叉树的特性。但是区别在于二分搜索树每个节点的值都比他的左子树的值大，比右子树的值小。 这种存储方式很适合于数据搜索。如下图所示，当需要查找 6 的时候，因为需要查找的值比根节点的值大，所以只需要在根节点的右子树上寻找，大大提高了搜索效率。 实现 class Node { constructor(value) { this.value = value this.left = null this.right = null } } class BST { constructor() { this.root = null this.size = 0 } getSize() { return this.size } isEmpty() { return this.size === 0 } addNode(v) { this.root = this._addChild(this.root, v) } // 添加节点时，需要比较添加的节点值和当前 // 节点值的大小 _addChild(node, v) { if (!node) { this.size++ return new Node(v) } if (node.value > v) { node.left = this._addChild(node.left, v) } else if (node.value 以上是最基本的二分搜索树实现，接下来实现树的遍历。 对于树的遍历来说，有三种遍历方法，分别是先序遍历、中序遍历、后序遍历。三种遍历的区别在于何时访问节点。在遍历树的过程中，每个节点都会遍历三次，分别是遍历到自己，遍历左子树和遍历右子树。如果需要实现先序遍历，那么只需要第一次遍历到节点时进行操作即可。 // 先序遍历可用于打印树的结构 // 先序遍历先访问根节点，然后访问左节点，最后访问右节点。 preTraversal() { this._pre(this.root) } _pre(node) { if (node) { console.log(node.value) this._pre(node.left) this._pre(node.right) } } // 中序遍历可用于排序 // 对于 BST 来说，中序遍历可以实现一次遍历就 // 得到有序的值 // 中序遍历表示先访问左节点，然后访问根节点，最后访问右节点。 midTraversal() { this._mid(this.root) } _mid(node) { if (node) { this._mid(node.left) console.log(node.value) this._mid(node.right) } } // 后序遍历可用于先操作子节点 // 再操作父节点的场景 // 后序遍历表示先访问左节点，然后访问右节点，最后访问根节点。 backTraversal() { this._back(this.root) } _back(node) { if (node) { this._back(node.left) this._back(node.right) console.log(node.value) } } 以上的这几种遍历都可以称之为深度遍历，对应的还有种遍历叫做广度遍历，也就是一层层地遍历树。对于广度遍历来说，我们需要利用之前讲过的队列结构来完成。 breadthTraversal() { if (!this.root) return null let q = new Queue() // 将根节点入队 q.enQueue(this.root) // 循环判断队列是否为空，为空 // 代表树遍历完毕 while (!q.isEmpty()) { // 将队首出队，判断是否有左右子树 // 有的话，就先左后右入队 let n = q.deQueue() console.log(n.value) if (n.left) q.enQueue(n.left) if (n.right) q.enQueue(n.right) } } 接下来先介绍如何在树中寻找最小值或最大数。因为二分搜索树的特性，所以最小值一定在根节点的最左边，最大值相反 getMin() { return this._getMin(this.root).value } _getMin(node) { if (!node.left) return node return this._getMin(node.left) } getMax() { return this._getMax(this.root).value } _getMax(node) { if (!node.right) return node return this._getMin(node.right) } 向上取整和向下取整，这两个操作是相反的，所以代码也是类似的，这里只介绍如何向下取整。既然是向下取整，那么根据二分搜索树的特性，值一定在根节点的左侧。只需要一直遍历左子树直到当前节点的值不再大于等于需要的值，然后判断节点是否还拥有右子树。如果有的话，继续上面的递归判断。 floor(v) { let node = this._floor(this.root, v) return node ? node.value : null } _floor(node, v) { if (!node) return null if (node.value === v) return v // 如果当前节点值还比需要的值大，就继续递归 if (node.value > v) { return this._floor(node.left, v) } // 判断当前节点是否拥有右子树 let right = this._floor(node.right, v) if (right) return right return node } 排名，这是用于获取给定值的排名或者排名第几的节点的值，这两个操作也是相反的，所以这个只介绍如何获取排名第几的节点的值。对于这个操作而言，我们需要略微的改造点代码，让每个节点拥有一个 size 属性。该属性表示该节点下有多少子节点（包含自身）。 class Node { constructor(value) { this.value = value this.left = null this.right = null // 修改代码 this.size = 1 } } // 新增代码 _getSize(node) { return node ? node.size : 0 } _addChild(node, v) { if (!node) { return new Node(v) } if (node.value > v) { // 修改代码 node.size++ node.left = this._addChild(node.left, v) } else if (node.value k) return this._select(node.left, k) // 如果小于 k，代表所需要的节点在右节点 // 注意这里需要重新计算 k，减去根节点除了右子树的节点数量 if (size 接下来讲解的是二分搜索树中最难实现的部分：删除节点。因为对于删除节点来说，会存在以下几种情况 需要删除的节点没有子树 需要删除的节点只有一条子树 需要删除的节点有左右两条树 对于前两种情况很好解决，但是第三种情况就有难度了，所以先来实现相对简单的操作：删除最小节点，对于删除最小节点来说，是不存在第三种情况的，删除最大节点操作是和删除最小节点相反的，所以这里也就不再赘述。 delectMin() { this.root = this._delectMin(this.root) console.log(this.root) } _delectMin(node) { // 一直递归左子树 // 如果左子树为空，就判断节点是否拥有右子树 // 有右子树的话就把需要删除的节点替换为右子树 if ((node != null) & !node.left) return node.right node.left = this._delectMin(node.left) // 最后需要重新维护下节点的 `size` node.size = this._getSize(node.left) + this._getSize(node.right) + 1 return node } 最后讲解的就是如何删除任意节点了。对于这个操作，T.Hibbard 在 1962 年提出了解决这个难题的办法，也就是如何解决第三种情况。 当遇到这种情况时，需要取出当前节点的后继节点（也就是当前节点右子树的最小节点）来替换需要删除的节点。然后将需要删除节点的左子树赋值给后继结点，右子树删除后继结点后赋值给他。 你如果对于这个解决办法有疑问的话，可以这样考虑。因为二分搜索树的特性，父节点一定比所有左子节点大，比所有右子节点小。那么当需要删除父节点时，势必需要拿出一个比父节点大的节点来替换父节点。这个节点肯定不存在于左子树，必然存在于右子树。然后又需要保持父节点都是比右子节点小的，那么就可以取出右子树中最小的那个节点来替换父节点。 delect(v) { this.root = this._delect(this.root, v) } _delect(node, v) { if (!node) return null // 寻找的节点比当前节点小，去左子树找 if (node.value v) { // 寻找的节点比当前节点大，去右子树找 node.left = this._delect(node.left, v) } else { // 进入这个条件说明已经找到节点 // 先判断节点是否拥有拥有左右子树中的一个 // 是的话，将子树返回出去，这里和 `_delectMin` 的操作一样 if (!node.left) return node.right if (!node.right) return node.left // 进入这里，代表节点拥有左右子树 // 先取出当前节点的后继结点，也就是取当前节点右子树的最小值 let min = this._getMin(node.right) // 取出最小值后，删除最小值 // 然后把删除节点后的子树赋值给最小值节点 min.right = this._delectMin(node.right) // 左子树不动 min.left = node.left node = min } // 维护 size node.size = this._getSize(node.left) + this._getSize(node.right) + 1 return node } AVL 树 概念 二分搜索树实际在业务中是受到限制的，因为并不是严格的 O(logN)，在极端情况下会退化成链表，比如加入一组升序的数字就会造成这种情况。 AVL 树改进了二分搜索树，在 AVL 树中任意节点的左右子树的高度差都不大于 1，这样保证了时间复杂度是严格的 O(logN)。基于此，对 AVL 树增加或删除节点时可能需要旋转树来达到高度的平衡。 实现 因为 AVL 树是改进了二分搜索树，所以部分代码是于二分搜索树重复的，对于重复内容不作再次解析。 对于 AVL 树来说，添加节点会有四种情况 对于左左情况来说，新增加的节点位于节点 2 的左侧，这时树已经不平衡，需要旋转。因为搜索树的特性，节点比左节点大，比右节点小，所以旋转以后也要实现这个特性。 旋转之前：new 对于右右情况来说，相反于左左情况，所以不再赘述。 对于左右情况来说，新增加的节点位于节点 4 的右侧。对于这种情况，需要通过两次旋转来达到目的。 首先对节点的左节点左旋，这时树满足左左的情况，再对节点进行一次右旋就可以达到目的。 class Node { constructor(value) { this.value = value this.left = null this.right = null this.height = 1 } } class AVL { constructor() { this.root = null } addNode(v) { this.root = this._addChild(this.root, v) } _addChild(node, v) { if (!node) { return new Node(v) } if (node.value > v) { node.left = this._addChild(node.left, v) } else if (node.value 1 && this._getBalanceFactor(node.left) >= 0) { return this._rightRotate(node) } // 当需要左旋时，根节点的左树一定比右树高度矮 if (factor 1 && this._getBalanceFactor(node.left) 0) { node.right = this._rightRotate(node.right) return this._leftRotate(node) } return node } _getHeight(node) { if (!node) return 0 return node.height } _getBalanceFactor(node) { return this._getHeight(node.left) - this._getHeight(node.right) } // 节点右旋 // 5 2 // / \\ / \\ // 2 6 ==> 1 5 // / \\ / / \\ // 1 3 new 3 6 // / // new _rightRotate(node) { // 旋转后新根节点 let newRoot = node.left // 需要移动的节点 let moveNode = newRoot.right // 节点 2 的右节点改为节点 5 newRoot.right = node // 节点 5 左节点改为节点 3 node.left = moveNode // 更新树的高度 node.height = 1 + Math.max(this._getHeight(node.left), this._getHeight(node.right)) newRoot.height = 1 + Math.max(this._getHeight(newRoot.left), this._getHeight(newRoot.right)) return newRoot } // 节点左旋 // 4 6 // / \\ / \\ // 2 6 ==> 4 7 // / \\ / \\ \\ // 5 7 2 5 new // \\ // new _leftRotate(node) { // 旋转后新根节点 let newRoot = node.right // 需要移动的节点 let moveNode = newRoot.left // 节点 6 的左节点改为节点 4 newRoot.left = node // 节点 4 右节点改为节点 5 node.right = moveNode // 更新树的高度 node.height = 1 + Math.max(this._getHeight(node.left), this._getHeight(node.right)) newRoot.height = 1 + Math.max(this._getHeight(newRoot.left), this._getHeight(newRoot.right)) return newRoot } } Trie 概念 在计算机科学，trie，又称前缀树或字典树，是一种有序树，用于保存关联数组，其中的键通常是字符串。 简单点来说，这个结构的作用大多是为了方便搜索字符串，该树有以下几个特点 根节点代表空字符串，每个节点都有 N（假如搜索英文字符，就有 26 条） 条链接，每条链接代表一个字符 节点不存储字符，只有路径才存储，这点和其他的树结构不同 从根节点开始到任意一个节点，将沿途经过的字符连接起来就是该节点对应的字符串 、 实现 总得来说 Trie 的实现相比别的树结构来说简单的很多，实现就以搜索英文字符为例。 class TrieNode { constructor() { // 代表每个字符经过节点的次数 this.path = 0 // 代表到该节点的字符串有几个 this.end = 0 // 链接 this.next = new Array(26).fill(null) } } class Trie { constructor() { // 根节点，代表空字符 this.root = new TrieNode() } // 插入字符串 insert(str) { if (!str) return let node = this.root for (let i = 0; i 并查集 概念 并查集是一种特殊的树结构，用于处理一些不交集的合并及查询问题。该结构中每个节点都有一个父节点，如果只有当前一个节点，那么该节点的父节点指向自己。 这个结构中有两个重要的操作，分别是： Find：确定元素属于哪一个子集。它可以被用来确定两个元素是否属于同一子集。 Union：将两个子集合并成同一个集合。 实现 class DisjointSet { // 初始化样本 constructor(count) { // 初始化时，每个节点的父节点都是自己 this.parent = new Array(count) // 用于记录树的深度，优化搜索复杂度 this.rank = new Array(count) for (let i = 0; i this.rank[j]) { this.parent[j] = i } else { this.parent[i] = j this.rank[j] += 1 } } } 堆 概念 堆通常是一个可以被看做一棵树的数组对象。 堆的实现通过构造二叉堆，实为二叉树的一种。这种数据结构具有以下性质。 任意节点小于（或大于）它的所有子节点 堆总是一棵完全树。即除了最底层，其他层的节点都被元素填满，且最底层从左到右填入。 将根节点最大的堆叫做最大堆或大根堆，根节点最小的堆叫做最小堆或小根堆。 优先队列也完全可以用堆来实现，操作是一模一样的。 实现大根堆 堆的每个节点的左边子节点索引是 i * 2 + 1，右边是 i * 2 + 2，父节点是 (i - 1) /2。 堆有两个核心的操作，分别是 shiftUp 和 shiftDown 。前者用于添加元素，后者用于删除根节点。 shiftUp 的核心思路是一路将节点与父节点对比大小，如果比父节点大，就和父节点交换位置。 shiftDown 的核心思路是先将根节点和末尾交换位置，然后移除末尾元素。接下来循环判断父节点和两个子节点的大小，如果子节点大，就把最大的子节点和父节点交换。 class MaxHeap { constructor() { this.heap = [] } size() { return this.heap.length } empty() { return this.size() == 0 } add(item) { this.heap.push(item) this._shiftUp(this.size() - 1) } removeMax() { this._shiftDown(0) } getParentIndex(k) { return parseInt((k - 1) / 2) } getLeftIndex(k) { return k * 2 + 1 } _shiftUp(k) { // 如果当前节点比父节点大，就交换 while (this.heap[k] > this.heap[this.getParentIndex(k)]) { this._swap(k, this.getParentIndex(k)) // 将索引变成父节点 k = this.getParentIndex(k) } } _shiftDown(k) { // 交换首位并删除末尾 this._swap(k, this.size() - 1) this.heap.splice(this.size() - 1, 1) // 判断节点是否有左孩子，因为二叉堆的特性，有右必有左 while (this.getLeftIndex(k) this.heap[j]) j++ // 判断父节点是否已经比子节点都大 if (this.heap[k] >= this.heap[j]) break this._swap(k, j) k = j } } _swap(left, right) { let rightValue = this.heap[right] this.heap[right] = this.heap[left] this.heap[left] = rightValue } } 小结 这一章节我们学习了一些常见的数据结构，当然我没有将其他更难的数据结构也放进来，能够掌握这些常见的内容已经足够解决大部分的问题了。当然你如果还想继续深入学习数据结构，可以阅读 算法第四版 以及在 leetcode 中实践。 "},"前端面试之道/32.常考算法题解析.html":{"url":"前端面试之道/32.常考算法题解析.html","title":"32.常考算法题解析","keywords":"","body":"常考算法题解析 这一章节依托于上一章节的内容，毕竟了解了数据结构我们才能写出更好的算法。 对于大部分公司的面试来说，排序的内容已经足以应付了，由此为了更好的符合大众需求，排序的内容是最多的。当然如果你还想冲击更好的公司，那么整一个章节的内容都是需要掌握的。对于字节跳动这类十分看重算法的公司来说，这一章节是远远不够的，剑指Offer应该是你更好的选择。 这一章节的内容信息量会很大，不适合在非电脑环境下阅读，请各位打开代码编辑器，一行行的敲代码，单纯阅读是学习不了算法的。 另外学习算法的时候，有一个可视化界面会相对减少点学习的难度，具体可以阅读 algorithm-visualizer 这个仓库。 位运算 在进入正题之前，我们先来学习一下位运算的内容。因为位运算在算法中很有用，速度可以比四则运算快很多。 在学习位运算之前应该知道十进制如何转二进制，二进制如何转十进制。这里说明下简单的计算方式 十进制 33 可以看成是 32 + 1 ，并且 33 应该是六位二进制的（因为 33 近似 32，而 32 是 2 的五次方，所以是六位），那么 十进制 33 就是 100001 ，只要是 2 的次方，那么就是 1否则都为 0 那么二进制 100001 同理，首位是 2^5 ，末位是 2^0 ，相加得出 33 左移 10 20 左移就是将二进制全部往左移动，10 在二进制中表示为 1010 ，左移一位后变成 10100 ，转换为十进制也就是 20，所以基本可以把左移看成以下公式 a * (2 ^ b) 算数右移 >> 10 >> 1 // -> 5 算数右移就是将二进制全部往右移动并去除多余的右边，10 在二进制中表示为 1010 ，右移一位后变成 101 ，转换为十进制也就是 5，所以基本可以把右移看成以下公式 int v = a / (2 ^ b) 右移很好用，比如可以用在二分算法中取中间值 13 >> 1 // -> 6 按位操作 按位与 每一位都为 1，结果才为 1 8 & 7 // -> 0 // 1000 & 0111 -> 0000 -> 0 按位或 其中一位为 1，结果就是 1 8 | 7 // -> 15 // 1000 | 0111 -> 1111 -> 15 按位异或 每一位都不同，结果才为 1 8 ^ 7 // -> 15 8 ^ 8 // -> 0 // 1000 ^ 0111 -> 1111 -> 15 // 1000 ^ 1000 -> 0000 -> 0 从以上代码中可以发现按位异或就是不进位加法 面试题：两个数不使用四则运算得出和 这道题中可以按位异或，因为按位异或就是不进位加法，8 ^ 8 = 0 如果进位了，就是 16 了，所以我们只需要将两个数进行异或操作，然后进位。那么也就是说两个二进制都是 1 的位置，左边应该有一个进位 1，所以可以得出以下公式 a + b = (a ^ b) + ((a & b) ，然后通过迭代的方式模拟加法 function sum(a, b) { if (a == 0) return b if (b == 0) return a let newA = a ^ b let newB = (a & b) 排序 以下两个函数是排序中会用到的通用函数，就不一一写了 function checkArray(array) { return Array.isArray(array) } function swap(array, left, right) { let rightValue = array[right] array[right] = array[left] array[left] = rightValue } 冒泡排序 冒泡排序的原理如下，从第一个元素开始，把当前元素和下一个索引元素进行比较。如果当前元素大，那么就交换位置，重复操作直到比较到最后一个元素，那么此时最后一个元素就是该数组中最大的数。下一轮重复以上操作，但是此时最后一个元素已经是最大数了，所以不需要再比较最后一个元素，只需要比较到 length - 2 的位置。 以下是实现该算法的代码 function bubble(array) { checkArray(array); for (let i = array.length - 1; i > 0; i--) { // 从 0 到 `length - 1` 遍历 for (let j = 0; j array[j + 1]) swap(array, j, j + 1) } } return array; } 该算法的操作次数是一个等差数列 n + (n - 1) + (n - 2) + 1 ，去掉常数项以后得出时间复杂度是 O(n * n) 插入排序 插入排序的原理如下。第一个元素默认是已排序元素，取出下一个元素和当前元素比较，如果当前元素大就交换位置。那么此时第一个元素就是当前的最小数，所以下次取出操作从第三个元素开始，向前对比，重复之前的操作。 以下是实现该算法的代码 function insertion(array) { if (!checkArray(array)) return for (let i = 1; i = 0 && array[j] > array[j + 1]; j--) swap(array, j, j + 1); } return array; } 该算法的操作次数是一个等差数列 n + (n - 1) + (n - 2) + 1 ，去掉常数项以后得出时间复杂度是 O(n * n) 选择排序 选择排序的原理如下。遍历数组，设置最小值的索引为 0，如果取出的值比当前最小值小，就替换最小值索引，遍历完成后，将第一个元素和最小值索引上的值交换。如上操作后，第一个元素就是数组中的最小值，下次遍历就可以从索引 1 开始重复上述操作。 以下是实现该算法的代码 function selection(array) { if (!checkArray(array)) return for (let i = 0; i 该算法的操作次数是一个等差数列 n + (n - 1) + (n - 2) + 1 ，去掉常数项以后得出时间复杂度是 O(n * n) 归并排序 归并排序的原理如下。递归的将数组两两分开直到最多包含两个元素，然后将数组排序合并，最终合并为排序好的数组。假设我有一组数组 [3, 1, 2, 8, 9, 7, 6]，中间数索引是 3，先排序数组 [3, 1, 2, 8] 。在这个左边数组上，继续拆分直到变成数组包含两个元素（如果数组长度是奇数的话，会有一个拆分数组只包含一个元素）。然后排序数组 [3, 1] 和 [2, 8] ，然后再排序数组 [1, 3, 2, 8] ，这样左边数组就排序完成，然后按照以上思路排序右边数组，最后将数组 [1, 2, 3, 8] 和 [6, 7, 9] 排序。 以下是实现该算法的代码 function sort(array) { if (!checkArray(array)) return mergeSort(array, 0, array.length - 1); return array; } function mergeSort(array, left, right) { // 左右索引相同说明已经只有一个数 if (left === right) return; // 等同于 `left + (right - left) / 2` // 相比 `(left + right) / 2` 来说更加安全，不会溢出 // 使用位运算是因为位运算比四则运算快 let mid = parseInt(left + ((right - left) >> 1)); mergeSort(array, left, mid); mergeSort(array, mid + 1, right); let help = []; let i = 0; let p1 = left; let p2 = mid + 1; while (p1 以上算法使用了递归的思想。递归的本质就是压栈，每递归执行一次函数，就将该函数的信息（比如参数，内部的变量，执行到的行数）压栈，直到遇到终止条件，然后出栈并继续执行函数。对于以上递归函数的调用轨迹如下 mergeSort(data, 0, 6) // mid = 3 mergeSort(data, 0, 3) // mid = 1 mergeSort(data, 0, 1) // mid = 0 mergeSort(data, 0, 0) // 遇到终止，回退到上一步 mergeSort(data, 1, 1) // 遇到终止，回退到上一步 // 排序 p1 = 0, p2 = mid + 1 = 1 // 回退到 `mergeSort(data, 0, 3)` 执行下一个递归 mergeSort(2, 3) // mid = 2 mergeSort(3, 3) // 遇到终止，回退到上一步 // 排序 p1 = 2, p2 = mid + 1 = 3 // 回退到 `mergeSort(data, 0, 3)` 执行合并逻辑 // 排序 p1 = 0, p2 = mid + 1 = 2 // 执行完毕回退 // 左边数组排序完毕，右边也是如上轨迹 该算法的操作次数是可以这样计算：递归了两次，每次数据量是数组的一半，并且最后把整个数组迭代了一次，所以得出表达式 2T(N / 2) + T(N) （T 代表时间，N 代表数据量）。根据该表达式可以套用 该公式 得出时间复杂度为 O(N * logN) 快排 快排的原理如下。随机选取一个数组中的值作为基准值，从左至右取值与基准值对比大小。比基准值小的放数组左边，大的放右边，对比完成后将基准值和第一个比基准值大的值交换位置。然后将数组以基准值的位置分为两部分，继续递归以上操作。 以下是实现该算法的代码 function sort(array) { if (!checkArray(array)) return quickSort(array, 0, array.length - 1); return array; } function quickSort(array, left, right) { if (left array[right]) { // 当前值比基准值大，将当前值和右边的值交换 // 并且不改变 `left`，因为当前换过来的值还没有判断过大小 swap(array, --more, left); } else { // 和基准值相同，只移动下标 left++; } } // 将基准值和比基准值大的第一个值交换位置 // 这样数组就变成 `[比基准值小, 基准值, 比基准值大]` swap(array, right, more); return [less, more]; } 该算法的复杂度和归并排序是相同的，但是额外空间复杂度比归并排序少，只需 O(logN)，并且相比归并排序来说，所需的常数时间也更少。 面试题 Sort Colors：该题目来自 LeetCode，题目需要我们将 [2,0,2,1,1,0] 排序成 [0,0,1,1,2,2] ，这个问题就可以使用三路快排的思想。 以下是代码实现 var sortColors = function(nums) { let left = -1; let right = nums.length; let i = 0; // 下标如果遇到 right，说明已经排序完成 while (i Kth Largest Element in an Array：该题目来自 LeetCode，题目需要找出数组中第 K 大的元素，这问题也可以使用快排的思路。并且因为是找出第 K 大元素，所以在分离数组的过程中，可以找出需要的元素在哪边，然后只需要排序相应的一边数组就好。 以下是代码实现 var findKthLargest = function(nums, k) { let l = 0 let r = nums.length - 1 // 得出第 K 大元素的索引位置 k = nums.length - k while (l k) { r = index - 1 } else { break } } return nums[k] }; function part(array, left, right) { let less = left - 1; let more = right; while (left array[right]) { swap(array, --more, left); } else { left++; } } swap(array, right, more); return more; } 堆排序 堆排序利用了二叉堆的特性来做，二叉堆通常用数组表示，并且二叉堆是一颗完全二叉树（所有叶节点（最底层的节点）都是从左往右顺序排序，并且其他层的节点都是满的）。二叉堆又分为大根堆与小根堆。 大根堆是某个节点的所有子节点的值都比他小 小根堆是某个节点的所有子节点的值都比他大 堆排序的原理就是组成一个大根堆或者小根堆。以小根堆为例，某个节点的左边子节点索引是 i * 2 + 1，右边是 i * 2 + 2，父节点是 (i - 1) /2。 首先遍历数组，判断该节点的父节点是否比他小，如果小就交换位置并继续判断，直到他的父节点比他大 重新以上操作 1，直到数组首位是最大值 然后将首位和末尾交换位置并将数组长度减一，表示数组末尾已是最大值，不需要再比较大小 对比左右节点哪个大，然后记住大的节点的索引并且和父节点对比大小，如果子节点大就交换位置 重复以上操作 3 - 4 直到整个数组都是大根堆。 以下是实现该算法的代码 function heap(array) { if (!checkArray(array)) return // 将最大值交换到首位 for (let i = 0; i 0) { heapify(array, 0, size); swap(array, 0, --size); } return array; } function heapInsert(array, index) { // 如果当前节点比父节点大，就交换 while (array[index] > array[parseInt((index - 1) / 2)]) { swap(array, index, parseInt((index - 1) / 2)); // 将索引变成父节点 index = parseInt((index - 1) / 2); } } function heapify(array, index, size) { let left = index * 2 + 1; while (left 以上代码实现了小根堆，如果需要实现大根堆，只需要把节点对比反一下就好。 该算法的复杂度是 O(logN) 系统自带排序实现 每个语言的排序内部实现都是不同的。 对于 JS 来说，数组长度大于 10 会采用快排，否则使用插入排序 源码实现 。选择插入排序是因为虽然时间复杂度很差，但是在数据量很小的情况下和 O(N * logN)相差无几，然而插入排序需要的常数时间很小，所以相对别的排序来说更快。 对于 Java 来说，还会考虑内部的元素的类型。对于存储对象的数组来说，会采用稳定性好的算法。稳定性的意思就是对于相同值来说，相对顺序不能改变。 链表 反转单向链表 该题目来自 LeetCode，题目需要将一个单向链表反转。思路很简单，使用三个变量分别表示当前节点和当前节点的前后节点，虽然这题很简单，但是却是一道面试常考题 以下是实现该算法的代码 var reverseList = function(head) { // 判断下变量边界问题 if (!head || !head.next) return head // 初始设置为空，因为第一个节点反转后就是尾部，尾部节点指向 null let pre = null let current = head let next // 判断当前节点是否为空 // 不为空就先获取当前节点的下一节点 // 然后把当前节点的 next 设为上一个节点 // 然后把 current 设为下一个节点，pre 设为当前节点 while(current) { next = current.next current.next = pre pre = current current = next } return pre }; 树 二叉树的先序，中序，后序遍历 先序遍历表示先访问根节点，然后访问左节点，最后访问右节点。 中序遍历表示先访问左节点，然后访问根节点，最后访问右节点。 后序遍历表示先访问左节点，然后访问右节点，最后访问根节点。 递归实现 递归实现相当简单，代码如下 function TreeNode(val) { this.val = val; this.left = this.right = null; } var traversal = function(root) { if (root) { // 先序 console.log(root); traversal(root.left); // 中序 // console.log(root); traversal(root.right); // 后序 // console.log(root); } }; 对于递归的实现来说，只需要理解每个节点都会被访问三次就明白为什么这样实现了。 非递归实现 非递归实现使用了栈的结构，通过栈的先进后出模拟递归实现。 以下是先序遍历代码实现 function pre(root) { if (root) { let stack = []; // 先将根节点 push stack.push(root); // 判断栈中是否为空 while (stack.length > 0) { // 弹出栈顶元素 root = stack.pop(); console.log(root); // 因为先序遍历是先左后右，栈是先进后出结构 // 所以先 push 右边再 push 左边 if (root.right) { stack.push(root.right); } if (root.left) { stack.push(root.left); } } } } 以下是中序遍历代码实现 function mid(root) { if (root) { let stack = []; // 中序遍历是先左再根最后右 // 所以首先应该先把最左边节点遍历到底依次 push 进栈 // 当左边没有节点时，就打印栈顶元素，然后寻找右节点 // 对于最左边的叶节点来说，可以把它看成是两个 null 节点的父节点 // 左边打印不出东西就把父节点拿出来打印，然后再看右节点 while (stack.length > 0 || root) { if (root) { stack.push(root); root = root.left; } else { root = stack.pop(); console.log(root); root = root.right; } } } } 以下是后序遍历代码实现，该代码使用了两个栈来实现遍历，相比一个栈的遍历来说要容易理解很多 function pos(root) { if (root) { let stack1 = []; let stack2 = []; // 后序遍历是先左再右最后根 // 所以对于一个栈来说，应该先 push 根节点 // 然后 push 右节点，最后 push 左节点 stack1.push(root); while (stack1.length > 0) { root = stack1.pop(); stack2.push(root); if (root.left) { stack1.push(root.left); } if (root.right) { stack1.push(root.right); } } while (stack2.length > 0) { console.log(s2.pop()); } } } 中序遍历的前驱后继节点 实现这个算法的前提是节点有一个 parent 的指针指向父节点，根节点指向 null 。 如图所示，该树的中序遍历结果是 4, 2, 5, 1, 6, 3, 7 前驱节点 对于节点 2 来说，他的前驱节点就是 4 ，按照中序遍历原则，可以得出以下结论 如果选取的节点的左节点不为空，就找该左节点最右的节点。对于节点 1 来说，他有左节点 2 ，那么节点 2 的最右节点就是 5 如果左节点为空，且目标节点是父节点的右节点，那么前驱节点为父节点。对于节点 5 来说，没有左节点，且是节点 2 的右节点，所以节点 2 是前驱节点 如果左节点为空，且目标节点是父节点的左节点，向上寻找到第一个是父节点的右节点的节点。对于节点 6 来说，没有左节点，且是节点 3 的左节点，所以向上寻找到节点 1 ，发现节点 3 是节点 1 的右节点，所以节点 1 是节点 6 的前驱节点 以下是算法实现 function predecessor(node) { if (!node) return // 结论 1 if (node.left) { return getRight(node.left) } else { let parent = node.parent // 结论 2 3 的判断 while(parent && parent.right === node) { node = parent parent = node.parent } return parent } } function getRight(node) { if (!node) return node = node.right while(node) node = node.right return node } 后继节点 对于节点 2 来说，他的后继节点就是 5 ，按照中序遍历原则，可以得出以下结论 如果有右节点，就找到该右节点的最左节点。对于节点 1 来说，他有右节点 3 ，那么节点 3 的最左节点就是 6 如果没有右节点，就向上遍历直到找到一个节点是父节点的左节点。对于节点 5 来说，没有右节点，就向上寻找到节点 2 ，该节点是父节点 1 的左节点，所以节点 1 是后继节点 以下是算法实现 function successor(node) { if (!node) return // 结论 1 if (node.right) { return getLeft(node.right) } else { // 结论 2 let parent = node.parent // 判断 parent 为空 while(parent && parent.left === node) { node = parent parent = node.parent } return parent } } function getLeft(node) { if (!node) return node = node.left while(node) node = node.left return node } 树的深度 树的最大深度：该题目来自 Leetcode，题目需要求出一颗二叉树的最大深度 以下是算法实现 var maxDepth = function(root) { if (!root) return 0 return Math.max(maxDepth(root.left), maxDepth(root.right)) + 1 }; 对于该递归函数可以这样理解：一旦没有找到节点就会返回 0，每弹出一次递归函数就会加一，树有三层就会得到3。 动态规划 动态规划背后的基本思想非常简单。就是将一个问题拆分为子问题，一般来说这些子问题都是非常相似的，那么我们可以通过只解决一次每个子问题来达到减少计算量的目的。 一旦得出每个子问题的解，就存储该结果以便下次使用。 斐波那契数列 斐波那契数列就是从 0 和 1 开始，后面的数都是前两个数之和 0，1，1，2，3，5，8，13，21，34，55，89.... 那么显然易见，我们可以通过递归的方式来完成求解斐波那契数列 function fib(n) { if (n = 0) return n return fib(n - 1) + fib(n - 2) } fib(10) 以上代码已经可以完美的解决问题。但是以上解法却存在很严重的性能问题，当 n 越大的时候，需要的时间是指数增长的，这时候就可以通过动态规划来解决这个问题。 动态规划的本质其实就是两点 自底向上分解子问题 通过变量存储已经计算过的解 根据上面两点，我们的斐波那契数列的动态规划思路也就出来了 斐波那契数列从 0 和 1 开始，那么这就是这个子问题的最底层 通过数组来存储每一位所对应的斐波那契数列的值 function fib(n) { let array = new Array(n + 1).fill(null) array[0] = 0 array[1] = 1 for (let i = 2; i 0 - 1背包问题 该问题可以描述为：给定一组物品，每种物品都有自己的重量和价格，在限定的总重量内，我们如何选择，才能使得物品的总价格最高。每个问题只能放入至多一次。 假设我们有以下物品 物品 ID / 重量 价值 1 3 2 7 3 12 对于一个总容量为 5 的背包来说，我们可以放入重量 2 和 3 的物品来达到背包内的物品总价值最高。 对于这个问题来说，子问题就两个，分别是放物品和不放物品，可以通过以下表格来理解子问题 物品 ID / 剩余容量 0 1 2 3 4 5 1 0 3 3 3 3 3 2 0 3 7 10 10 10 3 0 3 7 12 15 19 直接来分析能放三种物品的情况，也就是最后一行 当容量少于 3 时，只取上一行对应的数据，因为当前容量不能容纳物品 3 当容量 为 3 时，考虑两种情况，分别为放入物品 3 和不放物品 3 不放物品 3 的情况下，总价值为 10 放入物品 3 的情况下，总价值为 12，所以应该放入物品 3 当容量 为 4 时，考虑两种情况，分别为放入物品 3 和不放物品 3 不放物品 3 的情况下，总价值为 10 放入物品 3 的情况下，和放入物品 1 的价值相加，得出总价值为 15，所以应该放入物品 3 当容量 为 5 时，考虑两种情况，分别为放入物品 3 和不放物品 3 不放物品 3 的情况下，总价值为 10 放入物品 3 的情况下，和放入物品 2 的价值相加，得出总价值为 19，所以应该放入物品 3 以下代码对照上表更容易理解 /** * @param {*} w 物品重量 * @param {*} v 物品价值 * @param {*} C 总容量 * @returns */ function knapsack(w, v, C) { let length = w.length if (length === 0) return 0 // 对照表格，生成的二维数组，第一维代表物品，第二维代表背包剩余容量 // 第二维中的元素代表背包物品总价值 let array = new Array(length).fill(new Array(C + 1).fill(null)) // 完成底部子问题的解 for (let i = 0; i = w[0] ? v[0] : 0 } // 自底向上开始解决子问题，从物品 2 开始 for (let i = 1; i = w[i]) { // 可以放入的话，就比大小 // 放入当前物品和不放入当前物品，哪个背包总价值大 array[i][j] = Math.max(array[i][j], v[i] + array[i - 1][j - w[i]]) } } } return array[length - 1][C] } 最长递增子序列 最长递增子序列意思是在一组数字中，找出最长一串递增的数字，比如 0, 3, 4, 17, 2, 8, 6, 10 对于以上这串数字来说，最长递增子序列就是 0, 3, 4, 8, 10，可以通过以下表格更清晰的理解 数字 0 3 4 17 2 8 6 10 长度 1 2 3 4 2 4 4 5 通过以上表格可以很清晰的发现一个规律，找出刚好比当前数字小的数，并且在小的数组成的长度基础上加一。 这个问题的动态思路解法很简单，直接上代码 function lis(n) { if (n.length === 0) return 0 // 创建一个和参数相同大小的数组，并填充值为 1 let array = new Array(n.length).fill(1) // 从索引 1 开始遍历，因为数组已经所有都填充为 1 了 for (let i = 1; i n[j]) { array[i] = Math.max(array[i], 1 + array[j]) } } } let res = 1 for (let i = 0; i "},"前端面试之道/33.CSS常考面试题资料.html":{"url":"前端面试之道/33.CSS常考面试题资料.html","title":"33.CSS常考面试题资料","keywords":"","body":"CSS 常考面试题资料 其实笔者在面试的时候这方面的内容完全没有被问到，并且自己也基本没有准备这一部分的内容。 但是鉴于小册面向的群体是大众，肯定会有人被问到这方面的内容，因此我在这一章节会总结一些面试资料给大家，我就不班门弄斧了。 50道CSS基础面试题（附答案） 《50道CSS基础面试题（附答案）》中的答案真的就只是答案吗？ CSS 面试题总结 front-end-interview-handbook "},"前端面试之道/34.如何写好一封简历.html":{"url":"前端面试之道/34.如何写好一封简历.html","title":"34.如何写好一封简历","keywords":"","body":"如何写好一封简历 简历不是一份记流水账的东西，而是让用人方了解你的亮点的。 平时有在做修改简历的收费服务，也算看过蛮多简历了。很多简历都有以下几个特征： 喜欢说自己的特长、优点，用人方真的不关注你的性格是否阳光等等 喜欢列举一大堆个人技能，生怕用人方不知道你会些什么，造成的结果就是好多简历的技能都是差不多 项目经验流水账，比如使用了什么框架，什么 API 做了什么业务 简历页数过多 以上类似简历可以说用人方也看了无数份，完全抓不到你的亮点。 简历其实就是推销自己，如果你的简历和别人千篇一律，没有亮点，用人方就不会对你产生兴趣。 以下是我经常给别人修改简历的意见： 简历页数控制在 2 页以下 技术名词注意大小写 突出个人亮点。比如在项目中如何找到 Bug，解决 Bug 的过程；比如如何发现的性能问题，如何解决性能问题，最终提升了多少性能；比如为何如此选型，目的是什么，较其他有什么优点等等。总体思路就是不写流水账，突出你在项目中具有不错的解决问题的能力和独立思考的能力 斟酌熟悉、精通等字眼，不要给自己挖坑 确保每一个写上去的技术点自己都能说出点什么，杜绝面试官问你一个技术点，你只能答出会用 API 这种减分的情况 拿事实说话。你说你学习能力强，那么请列举你能力强的事实；你说你成绩好，那么请写出你专业的排名 做到以上内容，然后在投递简历的过程中加上一份求职信，对你的求职之路相信能帮上很多忙，当然了，一般来说我推荐尽量走内推通道投递简历。在网上多花点心思就能找到很多内推，比如 V2EX、脉脉等等。 说了这么多，我们还是实战来修改一封简历吧，该简历的作者是一名两年经验的前端开发，关键信息已经全部隐去。 这算是简历最先被别人看到的地方，最黄金的广告位必然要放自己最闪亮的东西。 比如你是 985、211 毕业的，有不错的成绩、专业排名都可以在这个位置暴露出来。但是如果你学历并不怎么好，可以考虑把教育经历移到简历的最后，尽量把这块黄金位置让出来。 然后个人优势这块，一般来说就是个人技能。首先杜绝任何精通的字眼，因为百分之 99 的人都做不到精通，如果你真的精通了，就是一堆工作找你了。一般来说在个人技能这个区域我推荐写上几个前端必备的技能就可以了，然后根据投递的公司可以选择性的添加几个对方需求且自己也会的技能栈，最后个人技能这块内容同样也可以调整到简历的后半部分，没有必要占据一大块的简历第一页内容。 这封简历的工作经历这块写的基本没有什么问题，大家在写这一部分的时候需要注意以下几点： 在工作中有什么不错的结果都可以在这一块表现出来，比如文中的绩效前端小组 7 人最好等等 在工作中解决过什么很困难的问题也可以在这里提一下 最后需要注意一点，以上划红线的内容可能会被面试官问到，要做到心中有数，知道该如何回答，否则还不如不写。就比如说简历中写到了使用了新的架构节省了开发时间，那么这个架构是怎么样的，你对这个架构有什么看法等等这些问题都可能会被问到，要准备好一个通用的回答。 这封简历的工作经历这块写的就触及到很多我之前提到过的问题了。 首先两个项目的经验介绍都很流水账，都是属于使用了某某技术实现了某某功能。如果写简历的时候实在想不出平时工作中有遇到什么困难或者解决了什么问题的话，就要确保以上写到的技术栈都能很好的回答出来。 以上划红线的地方可能都会是面试官会重点提问的技术栈。 其实一封简历写的好，一般需要做到以下两点： 你让用人方了解到你比其他候选者强 不过分夸大，确保简历里写的每一个技术点都心中有数 毕竟简历写的很华丽，只是敲开了公司的第一扇门，如果过分夸大了事实，那么其实就是浪费双方的时间了。 大家在写简历的时候可以多多注意以上我提到的几个点，然后在写完以后找出简历中涉及到的所有技术点，并且确保自己能够说个所以然，这样简历这关就没什么问题了。 "},"前端面试之道/35.面试常用技巧.html":{"url":"前端面试之道/35.面试常用技巧.html","title":"35.面试常用技巧","keywords":"","body":"面试常用技巧 这一章节我会介绍一些面试中常用的一些技巧，这些技巧可以帮助大家更好的准备面试，提高面试成功率。 尽早准备简历 找工作的第一个重要问题就是写简历了，简历就是一个人的门面。简历写的不好，用人方也没有多大兴趣再深入了解你，毕竟行业人太多了。 很多人都会有一个问题就是：不知道简历该写啥。其实我很不推荐当要面试的时候才去写简历，因为很多人没有记录的习惯，当去写简历的时候才会发现，在公司呆了那么久好像记不得自己做了哪些东西了。 所以简历应该是经常去更新的，隔几个月去更新一次简历，了解自己这几个月以来的成长在哪里，结果是什么。 分批投递简历 当我们准备投递简历的时候，应该先把想投递的几个公司分出几个档次。先投递档次最低的，就算失败了，也就当在攒经验。这样多面几次，把握大了就可以开始投递更加心仪的公司了，增加成功几率。 如何粗略判断公司是否靠谱 毕竟不是每个人都能去大公司的，所以分辨一个公司是否靠谱是相当重要的，这关系到过来几个月甚至几年的职业道路。 首先一家公司所涉足的行业是很重要的，如果你去一家做社交的公司，很大程度上会以失败而告终。我个人认为目前教育、新能源、生鲜、医疗、数据这几个行业前景不错，当然这只是个人观点仅做参考。 然后我们还得了解一家公司的情况，这里我推荐使用「天眼查」去查询一家公司的信息。在这里我们可以查询到一家公司的几个重要指标 具体的一个融资情况，一家公司好不好，拥有的资本肯定是重要的一块。一家不错的公司，往往前期融到的金额就很高 核心团队的介绍，通过介绍我们可以了解到高管的一个教育背景，行业的经验等等 公司涉及到了哪些司法、经营上的风险 然后还可以在网上查询一下这家公司是否有拖欠工资等等负面的消息。 如何回答问题 尽量不要止步于问题，也就是面试官问什么你答什么，而是把回答的点发散出去，引导面试官提问，展示自己的水平。 比如说面试官提问了一个通过 DNS 查找 IP 过程的一个问题。那么在回答好这个问题的同时，可以指出获得 IP 以后就会发生 TCP 三次握手等等的情况，然后就可以引导面试官提问网络协议相关的问题了。 当然引导面试官的前提是你确实熟悉这一块的内容，否则就是给自己挖坑了。 很推荐大家在准备面试的过程中，挖掘出自己擅长的技术内容，然后在面试的过程中，寻找机会引导面试官提问你擅长的技术点。 最后需要注意一点，如果你不能很好的理解面试官的提问，最好先弄明白面试官到底想问什么，而不是直接回答问题导致出现文不对题的情况。 如何应对可能答不好的题目 假如你遇到了一道不会的题目，但是稍微有一点想法，你可以先坦白说这道题目不怎么会，但是愿意尝试回答一下，这样即使回答错了，也不会有什么问题。 但是千万不要不懂装懂，弄巧成拙。 多反思 一场面试结束以后，尽快的将面试中遇到的问题记录下来，然后复盘整个面试。 对于涉及到的题目，可以查询下资料验证自己是否答错了，如果答错了，就应该把这个知识漏洞补起来。 如果知识点答对了，但是语言组织的不好，那么就需要重新组织下措辞和表达方式。 谈钱 我一直认为到手的才是真的，当然老板的大饼有时候也会梦想成真，但是这个更多的就是看个人机遇了，可遇不可求，大部分人还是应该追求到手的这一部分，在薪资满意的情况下，再去追求期权这类东西。 在面试之前应该想好自己想要的薪资，然后在和 HR 谈论工资的时候提高百分之 10 - 15的样子，便于别人压价，因为大部分人是没有谈判能力的。然后跳槽的薪资涨幅应该是你当下的百分之 15 以上，这样才能对冲跳槽带来的一个风险，当然如果你实在很想去这家公司的话，那么薪资就另谈了。 在和 HR 讨论待遇的时候，应该问清楚以下几点 具体的工资（也就是合同上签订的工资），不要杂七杂八什么绩效加起来的那种 五险一金缴纳的比例 加班是否有加班工资或者调休 是否是 996，我个人很不推荐 996 的公司 加薪升职的情况 其他各种福利，比如餐补、房补、交通补、节假日福利、另外的保险等等 "},"前端面试之道/36.前方的路，让我们结伴同行.html":{"url":"前端面试之道/36.前方的路，让我们结伴同行.html","title":"36.前方的路，让我们结伴同行","keywords":"","body":"前方的路，让我们结伴同行 总结 首先感谢各位购买这本小册。这是我的第一本小册，内容可能会存在瑕疵，感谢大家选择这本小册，选择相信我这个作者。 相信大家都看过一句话：面试造火箭工作拧螺丝。诚然，现在大公司的门槛确实高，但这也是因为僧多粥少，供大于求的问题，因此大公司需要择优而录。那么为了进入大公司（我相信大部分人都有这个想法），我们势必需要驱动自己去不断学习，探索更深入的领域。而不是故步自封，原地踏步，认为会使用框架 API 能干活就行了。 面试时的信心源自于我们面试前的充分准备和平时的积累。有了信心，才能在面试中披荆斩棘，无往不胜。而不是毫无依据的自我感觉良好，面试失败就怪考官刁难、考题太难，责怪于外部因素而不是寻找个人的不足。 我也不说互联网寒不寒冬，毕竟物价、房价摆在那里，想做的好，赚的钱多，只能好好学，好好干，无论春夏秋冬。很感谢看到最后一章节的各位，相信这本小册能给大家带来一份不小的收获。 展望未来 小册不是我们学习的终点，为了减少大家找寻学习资料的时间，接下来我会提供一些我认为不错的学习资料供大家参考。 当然了资料是一部分，其实我更推荐在工作中学习。深入学习工作中用到的技术栈并且储备一些未来可能用到的技能，这样对个人职业发展是很有帮助的。 JS You-Dont-Know-JS，这套书深入的讲解很多 JS 的内容，英文版是开源免费阅读的，如果你英文不好的话，国内这套书已经有出版了，可以选择购买。 Functional-Light-JS，这本书是讲解函数式编程的，函数式编程也是一种编程范式，轻量级的函数式可以很方便的解决很多问题，有兴趣的可以一读。 33-js-concepts，这份资料讲解了 33 个前端开发必须知道的 JS 概念，内容是英文的，如果你英文不好的话，可以寻找这份资料的中文版。 前端精读周刊，这是一份前端好文集合，每周都会更新，目前已经更新了 84 篇文章。 前端性能清单，这是一份前端性能清单，如果你需要优化一个项目的话，可以根据这份清单一个个来检查优化项。 30-seconds-of-code，30 秒系列，很短的代码片段让你了解一个知识点。 must-watch-javascript，这份资料包含了很多高质量的前端相关视频，值得一看。 CSS css-protips，通过这份资料你可以学习到很多 tips 来提高你的 CSS 技能。 30-seconds-of-css，30 秒系列，很短的代码片段让你了解一个知识点 CSS 世界，张鑫旭出版的书籍，没什么好说的了，看就是了。 一些有趣的 CSS 话题，CSS 奇技淫巧，在这里，都有。 框架 框架这里其实我不想推荐任何的资料，如果你单纯想学习一个框架的话，我只推荐阅读官方文档学习，没有任何的必要去学习其他的入门资料，因为基本上都是照搬文档的。 如果你想进一步学习框架的内容的话，我推荐去阅读框架核心团队成员的博客。比如 React 核心团队成员 Dan Abramov 的 blog。 Node Node.js 几乎是资深前端工程师躲不过去的一道坎，也是一个团队的通用底层能力，学习 Node 可以更好的使用工具，建立起一套数据中间层服务于整个团队。 Node.js 调试指南，这是一本专注于讲解 Node 调试的书籍，已经出版了，但是可以开源免费阅读。 Node.js：来一打 C++ 扩展，死月出版的书籍，没什么好说的，看就是了。 Node.js 最佳实践，这是对 Node.js 最佳实践中排名最高的内容的总结和分享 安全 the-book-of-secret-knowledge，这是一份安全领域的资料，如果你对安全感兴趣的话，可以阅读一下内容。 周报 奇舞周刊，每周都会整理一份不错的中文文章合集。 TechBridge Weekly，这是一份台湾地区整理的一份多个技术领域的周报。 JavaScript Weekly，这是一份相当有名气的英文周报，整理的文章质量都很高，如果你只想订阅一份周报，那就是它了。 Pony Foo Weekly，这也是一份不错的英文周报，文章质量也很高，并且和上一份周报重叠的内容不多。 Medium Medium 上我并没有怎么固定阅读，更多的是订阅它的日报或者从别的周报上看到的 Medium 的文章，但是如果一定要推荐两个组织的话，我只推荐这两个，毕竟他们的文章质量都很高。 freecodecamp hackernoon Youtube Youtube 有很多高质量的视频，但是门槛大家都知道，这里我推荐一些值得订阅的频道。 JSConf，很多会议的视频你都可以在这里找到。 Google Chrome Developers，Google 金字招牌，没啥好说的。 Computerphile，内容偏向于计算机领域。 Coding Tech，内容偏向于入门。 Fun Fun Function，如果你想学习函数式编程的一些内容，这是一个值得订阅的频道。 DevTips，每周更新一个视频，能够学习到不少开发中的 Tips。 其他 互联网公司技术架构，这份资料介绍了当下互联网公司的一个技术架构。 javascript-algorithms，这份资料作者使用了 JS 来实现了大部分的数据结构和算法。 小型编译器，这份资料告诉了我们该如何去实现一个小型的编译器，很适合前端开发者阅读。 every-programmer-should-know，这份资料列举了很多每个开发者都应该知道的知识点。 最后 你可能发现我推荐的很多内容都是英文的或者你并不能打开，这里我只能说一声抱歉。因为我获取学习资料更多的来源于国外，可能不能很好照顾到英文不好的同学。但是说一句肺腑之言吧，技术需求的英文真的要求不高，花点时间静下心去阅读英文资料，坚持个几个月，从此技术的大门就完完整整的打开了。 如果大家也有不错的资料想要分享，欢迎在留言区留言。 在小册的最后一章，打一个自己公众号的广告，如果你想了解到一些前端的热点、新知识、我的学习感悟等等，你可以关注我的公众号「前端真好玩」。 最后的最后，真的很感谢购买我小册的朋友，同时也感谢一些业内的大佬花时间阅读我的小册，并给我提出了修改意见，是你们促使我一直写作下去的。我们，下本小册见！ "},"剖析Vue.js内部运行机制/1.Vue.js运行机制全局概览.html":{"url":"剖析Vue.js内部运行机制/1.Vue.js运行机制全局概览.html","title":"1.Vue.js运行机制全局概览","keywords":"","body":"Vue.js 运行机制全局概览 全局概览 这一节笔者将为大家介绍一下 Vue.js 内部的整个流程，希望能让大家对全局有一个整体的印象，然后我们再来逐个模块进行讲解。从来没有了解过 Vue.js 实现的同学可能会对一些内容感到疑惑，这是很正常的，这一节的目的主要是为了让大家对整个流程有一个大概的认识，算是一个概览预备的过程，当把整本小册认真读完以后，再来阅读这一节，相信会有收获的。 首先我们来看一下笔者画的内部流程图。 大家第一次看到这个图一定是一头雾水的，没有关系，我们来逐个讲一下这些模块的作用以及调用关系。相信讲完之后大家对Vue.js内部运行机制会有一个大概的认识。 初始化及挂载 在 new Vue() 之后。 Vue 会调用 _init 函数进行初始化，也就是这里的 init 过程，它会初始化生命周期、事件、 props、 methods、 data、 computed 与 watch 等。其中最重要的是通过 Object.defineProperty 设置 setter 与 getter 函数，用来实现「响应式」以及「依赖收集」，后面会详细讲到，这里只要有一个印象即可。 初始化之后调用 $mount 会挂载组件，如果是运行时编译，即不存在 render function 但是存在 template 的情况，需要进行「编译」步骤。 编译 compile编译可以分成 parse、optimize 与 generate 三个阶段，最终需要得到 render function。 parse parse 会用正则等方式解析 template 模板中的指令、class、style等数据，形成AST。 optimize optimize 的主要作用是标记 static 静态节点，这是 Vue 在编译过程中的一处优化，后面当 update 更新界面时，会有一个 patch 的过程， diff 算法会直接跳过静态节点，从而减少了比较的过程，优化了 patch 的性能。 generate generate 是将 AST 转化成 render function 字符串的过程，得到结果是 render 的字符串以及 staticRenderFns 字符串。 在经历过 parse、optimize 与 generate 这三个阶段以后，组件中就会存在渲染 VNode 所需的 render function 了。 响应式 接下来也就是 Vue.js 响应式核心部分。 这里的 getter 跟 setter 已经在之前介绍过了，在 init 的时候通过 Object.defineProperty 进行了绑定，它使得当被设置的对象被读取的时候会执行 getter 函数，而在当被赋值的时候会执行 setter 函数。 当 render function 被渲染的时候，因为会读取所需对象的值，所以会触发 getter 函数进行「依赖收集」，「依赖收集」的目的是将观察者 Watcher 对象存放到当前闭包中的订阅者 Dep 的 subs 中。形成如下所示的这样一个关系。 在修改对象的值的时候，会触发对应的 setter， setter 通知之前「依赖收集」得到的 Dep 中的每一个 Watcher，告诉它们自己的值改变了，需要重新渲染视图。这时候这些 Watcher 就会开始调用 update 来更新视图，当然这中间还有一个 patch 的过程以及使用队列来异步更新的策略，这个我们后面再讲。 Virtual DOM 我们知道，render function 会被转化成 VNode 节点。Virtual DOM 其实就是一棵以 JavaScript 对象（ VNode 节点）作为基础的树，用对象属性来描述节点，实际上它只是一层对真实 DOM 的抽象。最终可以通过一系列操作使这棵树映射到真实环境上。由于 Virtual DOM 是以 JavaScript 对象为基础而不依赖真实平台环境，所以使它具有了跨平台的能力，比如说浏览器平台、Weex、Node 等。 比如说下面这样一个例子： { tag: 'div', /*说明这是一个div标签*/ children: [ /*存放该标签的子节点*/ { tag: 'a', /*说明这是一个a标签*/ text: 'click me' /*标签的内容*/ } ] } 渲染后可以得到 click me 这只是一个简单的例子，实际上的节点有更多的属性来标志节点，比如 isStatic （代表是否为静态节点）、 isComment （代表是否为注释节点）等。 更新视图 前面我们说到，在修改一个对象值的时候，会通过 setter -> Watcher -> update 的流程来修改对应的视图，那么最终是如何更新视图的呢？ 当数据变化后，执行 render function 就可以得到一个新的 VNode 节点，我们如果想要得到新的视图，最简单粗暴的方法就是直接解析这个新的 VNode 节点，然后用 innerHTML 直接全部渲染到真实 DOM 中。但是其实我们只对其中的一小块内容进行了修改，这样做似乎有些「浪费」。 那么我们为什么不能只修改那些「改变了的地方」呢？这个时候就要介绍我们的「patch」了。我们会将新的 VNode 与旧的 VNode 一起传入 patch 进行比较，经过 diff 算法得出它们的「差异」。最后我们只需要将这些「差异」的对应 DOM 进行修改即可。 再看全局 回过头再来看看这张图，是不是大脑中已经有一个大概的脉络了呢？ 那么，让我们继续学习每一个模块吧! "},"剖析Vue.js内部运行机制/2.响应式系统的基本原理.html":{"url":"剖析Vue.js内部运行机制/2.响应式系统的基本原理.html","title":"2.响应式系统的基本原理","keywords":"","body":"响应式系统的基本原理 响应式系统 Vue.js 是一款 MVVM 框架，数据模型仅仅是普通的 JavaScript 对象，但是对这些对象进行操作时，却能影响对应视图，它的核心实现就是「响应式系统」。尽管我们在使用 Vue.js 进行开发时不会直接修改「响应式系统」，但是理解它的实现有助于避开一些常见的「坑」，也有助于在遇见一些琢磨不透的问题时可以深入其原理来解决它。 Object.defineProperty 首先我们来介绍一下 Object.defineProperty，Vue.js就是基于它实现「响应式系统」的。 首先是使用方法： /* obj: 目标对象 prop: 需要操作的目标对象的属性名 descriptor: 描述符 return value 传入对象 */ Object.defineProperty(obj, prop, descriptor) descriptor的一些属性，简单介绍几个属性，具体可以参考 MDN 文档。 enumerable，属性是否可枚举，默认 false。 configurable，属性是否可以被修改或者删除，默认 false。 get，获取属性的方法。 set，设置属性的方法。 实现 observer（可观察的） 知道了 Object.defineProperty 以后，我们来用它使对象变成可观察的。 这一部分的内容我们在第二小节中已经初步介绍过，在 init 的阶段会进行初始化，对数据进行「响应式化」。 为了便于理解，我们不考虑数组等复杂的情况，只对对象进行处理。 首先我们定义一个 cb 函数，这个函数用来模拟视图更新，调用它即代表更新视图，内部可以是一些更新视图的方法。 function cb (val) { /* 渲染视图 */ console.log(\"视图更新啦～\"); } 然后我们定义一个 defineReactive ，这个方法通过 Object.defineProperty 来实现对对象的「响应式」化，入参是一个 obj（需要绑定的对象）、key（obj的某一个属性），val（具体的值）。经过 defineReactive 处理以后，我们的 obj 的 key 属性在「读」的时候会触发 reactiveGetter 方法，而在该属性被「写」的时候则会触发 reactiveSetter 方法。 function defineReactive (obj, key, val) { Object.defineProperty(obj, key, { enumerable: true, /* 属性可枚举 */ configurable: true, /* 属性可被修改或删除 */ get: function reactiveGetter () { return val; /* 实际上会依赖收集，下一小节会讲 */ }, set: function reactiveSetter (newVal) { if (newVal === val) return; cb(newVal); } }); } 当然这是不够的，我们需要在上面再封装一层 observer 。这个函数传入一个 value（需要「响应式」化的对象），通过遍历所有属性的方式对该对象的每一个属性都通过 defineReactive 处理。（注：实际上 observer 会进行递归调用，为了便于理解去掉了递归的过程） function observer (value) { if (!value || (typeof value !== 'object')) { return; } Object.keys(value).forEach((key) => { defineReactive(value, key, value[key]); }); } 最后，让我们用 observer 来封装一个 Vue 吧！ 在 Vue 的构造函数中，对 options 的 data 进行处理，这里的 data 想必大家很熟悉，就是平时我们在写 Vue 项目时组件中的 data 属性（实际上是一个函数，这里当作一个对象来简单处理）。 class Vue { /* Vue构造类 */ constructor(options) { this._data = options.data; observer(this._data); } } 这样我们只要 new 一个 Vue 对象，就会将 data 中的数据进行「响应式」化。如果我们对 data 的属性进行下面的操作，就会触发 cb 方法更新视图。 let o = new Vue({ data: { test: \"I am test.\" } }); o._data.test = \"hello,world.\"; /* 视图更新啦～ */ 至此，响应式原理已经介绍完了，接下来让我们学习「响应式系统」的另一部分 ——「依赖收集」。 注：本节代码参考《响应式系统的基本原理》。 "},"剖析Vue.js内部运行机制/3.响应式系统的依赖收集追踪原理.html":{"url":"剖析Vue.js内部运行机制/3.响应式系统的依赖收集追踪原理.html","title":"3.响应式系统的依赖收集追踪原理","keywords":"","body":"响应式系统的依赖收集追踪原理 为什么要依赖收集？ 先举个栗子🌰 我们现在有这么一个 Vue 对象。 new Vue({ template: ` {{text1}} {{text2}} `, data: { text1: 'text1', text2: 'text2', text3: 'text3' } }); 然后我们做了这么一个操作。 this.text3 = 'modify text3'; 我们修改了 data 中 text3 的数据，但是因为视图中并不需要用到 text3 ，所以我们并不需要触发上一章所讲的 cb 函数来更新视图，调用 cb 显然是不正确的。 再来一个栗子🌰 假设我们现在有一个全局的对象，我们可能会在多个 Vue 对象中用到它进行展示。 let globalObj = { text1: 'text1' }; let o1 = new Vue({ template: ` {{text1}} `, data: globalObj }); let o2 = new Vue({ template: ` {{text1}} `, data: globalObj }); 这个时候，我们执行了如下操作。 globalObj.text1 = 'hello,text1'; 我们应该需要通知 o1 以及 o2 两个vm实例进行视图的更新，「依赖收集」会让 text1 这个数据知道“哦～有两个地方依赖我的数据，我变化的时候需要通知它们～”。 最终会形成数据与视图的一种对应关系，如下图。 接下来我们来介绍一下「依赖收集」是如何实现的。 订阅者 Dep 首先我们来实现一个订阅者 Dep ，它的主要作用是用来存放 Watcher 观察者对象。 class Dep { constructor () { /* 用来存放Watcher对象的数组 */ this.subs = []; } /* 在subs中添加一个Watcher对象 */ addSub (sub) { this.subs.push(sub); } /* 通知所有Watcher对象更新视图 */ notify () { this.subs.forEach((sub) => { sub.update(); }) } } 为了便于理解我们只实现了添加的部分代码，主要是两件事情： 用 addSub 方法可以在目前的 Dep 对象中增加一个 Watcher 的订阅操作； 用 notify 方法通知目前 Dep 对象的 subs 中的所有 Watcher 对象触发更新操作。 观察者 Watcher class Watcher { constructor () { /* 在new一个Watcher对象时将该对象赋值给Dep.target，在get中会用到 */ Dep.target = this; } /* 更新视图的方法 */ update () { console.log(\"视图更新啦～\"); } } Dep.target = null; 依赖收集 接下来我们修改一下 defineReactive 以及 Vue 的构造函数，来完成依赖收集。 我们在闭包中增加了一个 Dep 类的对象，用来收集 Watcher 对象。在对象被「读」的时候，会触发 reactiveGetter 函数把当前的 Watcher 对象（存放在 Dep.target 中）收集到 Dep 类中去。之后如果当该对象被「写」的时候，则会触发 reactiveSetter 方法，通知 Dep 类调用 notify 来触发所有 Watcher 对象的 update 方法更新对应视图。 function defineReactive (obj, key, val) { /* 一个Dep类对象 */ const dep = new Dep(); Object.defineProperty(obj, key, { enumerable: true, configurable: true, get: function reactiveGetter () { /* 将Dep.target（即当前的Watcher对象存入dep的subs中） */ dep.addSub(Dep.target); return val; }, set: function reactiveSetter (newVal) { if (newVal === val) return; /* 在set的时候触发dep的notify来通知所有的Watcher对象更新视图 */ dep.notify(); } }); } class Vue { constructor(options) { this._data = options.data; observer(this._data); /* 新建一个Watcher观察者对象，这时候Dep.target会指向这个Watcher对象 */ new Watcher(); /* 在这里模拟render的过程，为了触发test属性的get函数 */ console.log('render~', this._data.test); } } 小结 总结一下。 首先在 observer 的过程中会注册 get 方法，该方法用来进行「依赖收集」。在它的闭包中会有一个 Dep 对象，这个对象用来存放 Watcher 对象的实例。其实「依赖收集」的过程就是把 Watcher 实例存放到对应的 Dep 对象中去。get 方法可以让当前的 Watcher 对象（Dep.target）存放到它的 subs 中（addSub）方法，在数据变化时，set 会调用 Dep 对象的 notify 方法通知它内部所有的 Watcher 对象进行视图更新。 这是 Object.defineProperty 的 set/get 方法处理的事情，那么「依赖收集」的前提条件还有两个： 触发 get 方法； 新建一个 Watcher 对象。 这个我们在 Vue 的构造类中处理。新建一个 Watcher 对象只需要 new 出来，这时候 Dep.target 已经指向了这个 new 出来的 Watcher 对象来。而触发 get 方法也很简单，实际上只要把 render function 进行渲染，那么其中的依赖的对象都会被「读取」，这里我们通过打印来模拟这个过程，读取 test 来触发 get 进行「依赖收集」。 本章我们介绍了「依赖收集」的过程，配合之前的响应式原理，已经把整个「响应式系统」介绍完毕了。其主要就是 get 进行「依赖收集」。set 通过观察者来更新视图，配合下图仔细捋一捋，相信一定能搞懂它！ 注：本节代码参考《响应式系统的依赖收集追踪原理》。 "},"剖析Vue.js内部运行机制/4.实现Virtual_DOM下的一个VNode节点.html":{"url":"剖析Vue.js内部运行机制/4.实现Virtual_DOM下的一个VNode节点.html","title":"4.实现Virtual_DOM下的一个VNode节点","keywords":"","body":"实现 Virtual DOM 下的一个 VNode 节点 什么是VNode 我们知道，render function 会被转化成 VNode 节点。Virtual DOM 其实就是一棵以 JavaScript 对象（VNode 节点）作为基础的树，用对象属性来描述节点，实际上它只是一层对真实 DOM 的抽象。最终可以通过一系列操作使这棵树映射到真实环境上。由于 Virtual DOM 是以 JavaScript 对象为基础而不依赖真实平台环境，所以使它具有了跨平台的能力，比如说浏览器平台、Weex、Node 等。 实现一个VNode VNode 归根结底就是一个 JavaScript 对象，只要这个类的一些属性可以正确直观地描述清楚当前节点的信息即可。我们来实现一个简单的 VNode 类，加入一些基本属性，为了便于理解，我们先不考虑复杂的情况。 class VNode { constructor (tag, data, children, text, elm) { /*当前节点的标签名*/ this.tag = tag; /*当前节点的一些数据信息，比如props、attrs等数据*/ this.data = data; /*当前节点的子节点，是一个数组*/ this.children = children; /*当前节点的文本*/ this.text = text; /*当前虚拟节点对应的真实dom节点*/ this.elm = elm; } } 比如我目前有这么一个 Vue 组件。 This is a span. 用 JavaScript 代码形式就是这样的。 function render () { return new VNode( 'span', { /* 指令集合数组 */ directives: [ { /* v-show指令 */ rawName: 'v-show', expression: 'isShow', name: 'show', value: true } ], /* 静态class */ staticClass: 'demo' }, [ new VNode(undefined, undefined, undefined, 'This is a span.') ] ); } 看看转换成 VNode 以后的情况。 { tag: 'span', data: { /* 指令集合数组 */ directives: [ { /* v-show指令 */ rawName: 'v-show', expression: 'isShow', name: 'show', value: true } ], /* 静态class */ staticClass: 'demo' }, text: undefined, children: [ /* 子节点是一个文本VNode节点 */ { tag: undefined, data: undefined, text: 'This is a span.', children: undefined } ] } 然后我们可以将 VNode 进一步封装一下，可以实现一些产生常用 VNode 的方法。 创建一个空节点 function createEmptyVNode () { const node = new VNode(); node.text = ''; return node; } 创建一个文本节点 function createTextVNode (val) { return new VNode(undefined, undefined, undefined, String(val)); } 克隆一个 VNode 节点 function cloneVNode (node) { const cloneVnode = new VNode( node.tag, node.data, node.children, node.text, node.elm ); return cloneVnode; } 总的来说，VNode 就是一个 JavaScript 对象，用 JavaScript 对象的属性来描述当前节点的一些状态，用 VNode 节点的形式来模拟一棵 Virtual DOM 树。 注：本节代码参考《实现 Virtual DOM 下的一个 VNode 节点》。 "},"剖析Vue.js内部运行机制/5.template模板是怎样通过Compile编译的.html":{"url":"剖析Vue.js内部运行机制/5.template模板是怎样通过Compile编译的.html","title":"5.template模板是怎样通过Compile编译的","keywords":"","body":"template 模板是怎样通过 Compile 编译的 Compile compile 编译可以分成 parse、optimize 与 generate 三个阶段，最终需要得到 render function。这部分内容不算 Vue.js 的响应式核心，只是用来编译的，笔者认为在精力有限的情况下不需要追究其全部的实现细节，能够把握如何解析的大致流程即可。 由于解析过程比较复杂，直接上代码可能会导致不了解这部分内容的同学一头雾水。所以笔者准备提供一个 template 的示例，通过这个示例的变化来看解析的过程。但是解析的过程及结果都是将最重要的部分抽离出来展示，希望能让读者更好地了解其核心部分的实现。 {{item}} var html = '{{item}}'; 接下来的过程都会依赖这个示例来进行。 parse 首先是 parse，parse 会用正则等方式将 template 模板中进行字符串解析，得到指令、class、style等数据，形成 AST（在计算机科学中，抽象语法树（abstract syntax tree或者缩写为AST），或者语法树（syntax tree），是源代码的抽象语法结构的树状表现形式，这里特指编程语言的源代码。）。 这个过程比较复杂，会涉及到比较多的正则进行字符串解析，我们来看一下得到的 AST 的样子。 { /* 标签属性的map，记录了标签上属性 */ 'attrsMap': { ':class': 'c', 'class': 'demo', 'v-if': 'isShow' }, /* 解析得到的:class */ 'classBinding': 'c', /* 标签属性v-if */ 'if': 'isShow', /* v-if的条件 */ 'ifConditions': [ { 'exp': 'isShow' } ], /* 标签属性class */ 'staticClass': 'demo', /* 标签的tag */ 'tag': 'div', /* 子标签数组 */ 'children': [ { 'attrsMap': { 'v-for': \"item in sz\" }, /* for循环的参数 */ 'alias': \"item\", /* for循环的对象 */ 'for': 'sz', /* for循环是否已经被处理的标记位 */ 'forProcessed': true, 'tag': 'span', 'children': [ { /* 表达式，_s是一个转字符串的函数 */ 'expression': '_s(item)', 'text': '{{item}}' } ] } ] } 最终得到的 AST 通过一些特定的属性，能够比较清晰地描述出标签的属性以及依赖关系。 接下来我们用代码来讲解一下如何使用正则来把 template 编译成我们需要的 AST 的。 正则 首先我们定义一下接下来我们会用到的正则。 const ncname = '[a-zA-Z_][\\\\w\\\\-\\\\.]*'; const singleAttrIdentifier = /([^\\s\"'<>/=]+)/ const singleAttrAssign = /(?:=)/ const singleAttrValues = [ /\"([^\"]*)\"+/.source, /'([^']*)'+/.source, /([^\\s\"'=<>`]+)/.source ] const attribute = new RegExp( '^\\\\s*' + singleAttrIdentifier.source + '(?:\\\\s*(' + singleAttrAssign.source + ')' + '\\\\s*(?:' + singleAttrValues.join('|') + '))?' ) const qnameCapture = '((?:' + ncname + '\\\\:)?' + ncname + ')' const startTagOpen = new RegExp('^/ const endTag = new RegExp('^]*>') const defaultTagRE = /\\{\\{((?:.|\\n)+?)\\}\\}/g const forAliasRE = /(.*?)\\s+(?:in|of)\\s+(.*)/ advance 因为我们解析 template 采用循环进行字符串匹配的方式，所以每匹配解析完一段我们需要将已经匹配掉的去掉，头部的指针指向接下来需要匹配的部分。 function advance (n) { index += n html = html.substring(n) } 举个例子，当我们把第一个 div 的头标签全部匹配完毕以后，我们需要将这部分除去，也就是向右移动 43 个字符。 调用 advance 函数 advance(43); 得到结果 parseHTML 首先我们需要定义个 parseHTML 函数，在里面我们循环解析 template 字符串。 function parseHTML () { while(html) { let textEnd = html.indexOf('parseHTML 会用 while 来循环解析 template ，用正则在匹配到标签头、标签尾以及文本的时候分别进行不同的处理。直到整个 template 被解析完毕。 parseStartTag 我们来写一个 parseStartTag 函数，用来解析起始标签（\"\"部分的内容）。 function parseStartTag () { const start = html.match(startTagOpen); if (start) { const match = { tagName: start[1], attrs: [], start: index } advance(start[0].length); let end, attr while (!(end = html.match(startTagClose)) && (attr = html.match(attribute))) { advance(attr[0].length) match.attrs.push({ name: attr[1], value: attr[3] }); } if (end) { match.unarySlash = end[1]; advance(end[0].length); match.end = index; return match } } } 首先用 startTagOpen 正则得到标签的头部，可以得到 tagName（标签名称），同时我们需要一个数组 attrs 用来存放标签内的属性。 const start = html.match(startTagOpen); const match = { tagName: start[1], attrs: [], start: index } advance(start[0].length); 接下来使用 startTagClose 与 attribute 两个正则分别用来解析标签结束以及标签内的属性。这段代码用 while 循环一直到匹配到 startTagClose 为止，解析内部所有的属性。 let end, attr while (!(end = html.match(startTagClose)) && (attr = html.match(attribute))) { advance(attr[0].length) match.attrs.push({ name: attr[1], value: attr[3] }); } if (end) { match.unarySlash = end[1]; advance(end[0].length); match.end = index; return match } stack 此外，我们需要维护一个 stack 栈来保存已经解析好的标签头，这样我们可以根据在解析尾部标签的时候得到所属的层级关系以及父标签。同时我们定义一个 currentParent 变量用来存放当前标签的父标签节点的引用， root 变量用来指向根标签节点。 const stack = []; let currentParent, root; 知道这个以后，我们优化一下 parseHTML ，在 startTagOpen 的 if 逻辑中加上新的处理。 if (html.match(startTagOpen)) { const startTagMatch = parseStartTag(); const element = { type: 1, tag: startTagMatch.tagName, lowerCasedTag: startTagMatch.tagName.toLowerCase(), attrsList: startTagMatch.attrs, attrsMap: makeAttrsMap(startTagMatch.attrs), parent: currentParent, children: [] } if(!root){ root = element } if(currentParent){ currentParent.children.push(element); } stack.push(element); currentParent = element; continue; } 我们将 startTagMatch 得到的结果首先封装成 element ，这个就是最终形成的 AST 的节点，标签节点的 type 为 1。 const startTagMatch = parseStartTag(); const element = { type: 1, tag: startTagMatch.tagName, attrsList: startTagMatch.attrs, attrsMap: makeAttrsMap(startTagMatch.attrs), parent: currentParent, children: [] } 然后让 root 指向根节点的引用。 if(!root){ root = element } 接着我们将当前节点的 element 放入父节点 currentParent 的 children 数组中。 if(currentParent){ currentParent.children.push(element); } 最后将当前节点 element 压入 stack 栈中，并将 currentParent 指向当前节点，因为接下去下一个解析如果还是头标签或者是文本的话，会成为当前节点的子节点，如果是尾标签的话，那么将会从栈中取出当前节点，这种情况我们接下来要讲。 stack.push(element); currentParent = element; continue; 其中的 makeAttrsMap 是将 attrs 转换成 map 格式的一个方法。 function makeAttrsMap (attrs) { const map = {} for (let i = 0, l = attrs.length; i parseEndTag 同样，我们在 parseHTML 中加入对尾标签的解析函数，为了匹配如“”。 const endTagMatch = html.match(endTag) if (endTagMatch) { advance(endTagMatch[0].length); parseEndTag(endTagMatch[1]); continue; } 用 parseEndTag 来解析尾标签，它会从 stack 栈中取出最近的跟自己标签名一致的那个元素，将 currentParent 指向那个元素，并将该元素之前的元素都从 stack 中出栈。 这里可能有同学会问，难道解析的尾元素不应该对应 stack 栈的最上面的一个元素才对吗？ 其实不然，比如说可能会存在自闭合的标签，如“”，或者是写了“”但是没有加上“”的情况，这时候就要找到 stack 中的第二个位置才能找到同名标签。 function parseEndTag (tagName) { let pos; for (pos = stack.length - 1; pos >= 0; pos--) { if (stack[pos].lowerCasedTag === tagName.toLowerCase()) { break; } } if (pos >= 0) { stack.length = pos; currentParent = stack[pos]; } } parseText 最后是解析文本，这个比较简单，只需要将文本取出，然后有两种情况，一种是普通的文本，直接构建一个节点 push 进当前 currentParent 的 children 中即可。还有一种情况是文本是如“”这样的 Vue.js 的表达式，这时候我们需要用 parseText 来将表达式转化成代码。 text = html.substring(0, textEnd) advance(textEnd) let expression; if (expression = parseText(text)) { currentParent.children.push({ type: 2, text, expression }); } else { currentParent.children.push({ type: 3, text, }); } continue; 我们会用到一个 parseText 函数。 function parseText (text) { if (!defaultTagRE.test(text)) return; const tokens = []; let lastIndex = defaultTagRE.lastIndex = 0 let match, index while ((match = defaultTagRE.exec(text))) { index = match.index if (index > lastIndex) { tokens.push(JSON.stringify(text.slice(lastIndex, index))) } const exp = match[1].trim() tokens.push(`_s(${exp})`) lastIndex = index + match[0].length } if (lastIndex 我们使用一个 tokens 数组来存放解析结果，通过 defaultTagRE 来循环匹配该文本，如果是普通文本直接 push 到 tokens 数组中去，如果是表达式（），则转化成“_s(${exp})”的形式。 举个例子，如果我们有这样一个文本。 hello,{{name}}. 最终得到 tokens。 tokens = ['hello,', _s(name), '.']; 最终通过 join 返回表达式。 'hello' + _s(name) + '.'; processIf与processFor 最后介绍一下如何处理“v-if”以及“v-for”这样的 Vue.js 的表达式的，这里我们只简单介绍两个示例中用到的表达式解析。 我们只需要在解析头标签的内容中加入这两个表达式的解析函数即可，在这时“v-for”之类指令已经在属性解析时存入了 attrsMap 中了。 if (html.match(startTagOpen)) { const startTagMatch = parseStartTag(); const element = { type: 1, tag: startTagMatch.tagName, attrsList: startTagMatch.attrs, attrsMap: makeAttrsMap(startTagMatch.attrs), parent: currentParent, children: [] } processIf(element); processFor(element); if(!root){ root = element } if(currentParent){ currentParent.children.push(element); } stack.push(element); currentParent = element; continue; } 首先我们需要定义一个 getAndRemoveAttr 函数，用来从 el 的 attrsMap 属性或是 attrsList 属性中取出 name 对应值。 function getAndRemoveAttr (el, name) { let val if ((val = el.attrsMap[name]) != null) { const list = el.attrsList for (let i = 0, l = list.length; i 比如说解析示例的 div 标签属性。 getAndRemoveAttr(el, 'v-for'); 可有得到“item in sz”。 有了这个函数这样我们就可以开始实现 processFor 与 processIf 了。 “v-for”会将指令解析成 for 属性以及 alias 属性，而“v-if”会将条件都存入 ifConditions 数组中。 function processFor (el) { let exp; if ((exp = getAndRemoveAttr(el, 'v-for'))) { const inMatch = exp.match(forAliasRE); el.for = inMatch[2].trim(); el.alias = inMatch[1].trim(); } } function processIf (el) { const exp = getAndRemoveAttr(el, 'v-if'); if (exp) { el.if = exp; if (!el.ifConditions) { el.ifConditions = []; } el.ifConditions.push({ exp: exp, block: el }); } } 到这里，我们已经把 parse 的过程介绍完了，接下来看一下 optimize。 optimize optimize 主要作用就跟它的名字一样，用作「优化」。 这个涉及到后面要讲 patch 的过程，因为 patch 的过程实际上是将 VNode 节点进行一层一层的比对，然后将「差异」更新到视图上。那么一些静态节点是不会根据数据变化而产生变化的，这些节点我们没有比对的需求，是不是可以跳过这些静态节点的比对，从而节省一些性能呢？ 那么我们就需要为静态的节点做上一些「标记」，在 patch 的时候我们就可以直接跳过这些被标记的节点的比对，从而达到「优化」的目的。 经过 optimize 这层的处理，每个节点会加上 static 属性，用来标记是否是静态的。 得到如下结果。 { 'attrsMap': { ':class': 'c', 'class': 'demo', 'v-if': 'isShow' }, 'classBinding': 'c', 'if': 'isShow', 'ifConditions': [ 'exp': 'isShow' ], 'staticClass': 'demo', 'tag': 'div', /* 静态标志 */ 'static': false, 'children': [ { 'attrsMap': { 'v-for': \"item in sz\" }, 'static': false, 'alias': \"item\", 'for': 'sz', 'forProcessed': true, 'tag': 'span', 'children': [ { 'expression': '_s(item)', 'text': '{{item}}', 'static': false } ] } ] } 我们用代码实现一下 optimize 函数。 isStatic 首先实现一个 isStatic 函数，传入一个 node 判断该 node 是否是静态节点。判断的标准是当 type 为 2（表达式节点）则是非静态节点，当 type 为 3（文本节点）的时候则是静态节点，当然，如果存在 if 或者 for这样的条件的时候（表达式节点），也是非静态节点。 function isStatic (node) { if (node.type === 2) { return false } if (node.type === 3) { return true } return (!node.if && !node.for); } markStatic markStatic 为所有的节点标记上 static，遍历所有节点通过 isStatic 来判断当前节点是否是静态节点，此外，会遍历当前节点的所有子节点，如果子节点是非静态节点，那么当前节点也是非静态节点。 function markStatic (node) { node.static = isStatic(node); if (node.type === 1) { for (let i = 0, l = node.children.length; i markStaticRoots 接下来是 markStaticRoots 函数，用来标记 staticRoot（静态根）。这个函数实现比较简单，简单来将就是如果当前节点是静态节点，同时满足该节点并不是只有一个文本节点左右子节点（作者认为这种情况的优化消耗会大于收益）时，标记 staticRoot 为 true，否则为 false。 function markStaticRoots (node) { if (node.type === 1) { if (node.static && node.children.length && !( node.children.length === 1 && node.children[0].type === 3 )) { node.staticRoot = true; return; } else { node.staticRoot = false; } } } optimize 有了以上的函数，就可以实现 optimize 了。 function optimize (rootAst) { markStatic(rootAst); markStaticRoots(rootAst); } generate generate 会将 AST 转化成 render funtion 字符串，最终得到 render 的字符串以及 staticRenderFns 字符串。 首先带大家感受一下真实的 Vue.js 编译得到的结果。 with(this){ return (isShow) ? _c( 'div', { staticClass: \"demo\", class: c }, _l( (sz), function(item){ return _c('span',[_v(_s(item))]) } ) ) : _e() } 看到这里可能会纳闷了，这些 _c，_l 到底是什么？其实他们是 Vue.js 对一些函数的简写，比如说 _c 对应的是 createElement 这个函数。没关系，我们把它用 VNode 的形式写出来就会明白了，这个对接上一章写的 VNode 函数。 首先是第一层 div 节点。 render () { return isShow ? (new VNode('div', { 'staticClass': 'demo', 'class': c }, [ /*这里还有子节点*/ ])) : createEmptyVNode(); } 然后我们在 children 中加上第二层 span 及其子文本节点节点。 /* 渲染v-for列表 */ function renderList (val, render) { let ret = new Array(val.length); for (i = 0, l = val.length; i { return new VNode('span', {}, [ createTextVNode(item); ]); }) /* end */ )) : createEmptyVNode(); } 那我们如何来实现一个 generate 呢？ genIf 首先实现一个处理 if 条件的 genIf 函数。 function genIf (el) { el.ifProcessed = true; if (!el.ifConditions.length) { return '_e()'; } return `(${el.ifConditions[0].exp})?${genElement(el.ifConditions[0].block)}: _e()` } genFor 然后是处理 for 循环的函数。 function genFor (el) { el.forProcessed = true; const exp = el.for; const alias = el.alias; const iterator1 = el.iterator1 ? `,${el.iterator1}` : ''; const iterator2 = el.iterator2 ? `,${el.iterator2}` : ''; return `_l((${exp}),` + `function(${alias}${iterator1}${iterator2}){` + `return ${genElement(el)}` + '})'; } genText 处理文本节点的函数。 function genText (el) { return `_v(${el.expression})`; } genElement 接下来实现一下 genElement，这是一个处理节点的函数，因为它依赖 genChildren 以及g enNode ，所以这三个函数放在一起讲。 genElement会根据当前节点是否有 if 或者 for 标记然后判断是否要用 genIf 或者 genFor 处理，否则通过 genChildren 处理子节点，同时得到 staticClass、class 等属性。 genChildren 比较简单，遍历所有子节点，通过 genNode 处理后用“，”隔开拼接成字符串。 genNode 则是根据 type 来判断该节点是用文本节点 genText 还是标签节点 genElement 来处理。 function genNode (el) { if (el.type === 1) { return genElement(el); } else { return genText(el); } } function genChildren (el) { const children = el.children; if (children && children.length > 0) { return `${children.map(genNode).join(',')}`; } } function genElement (el) { if (el.if && !el.ifProcessed) { return genIf(el); } else if (el.for && !el.forProcessed) { return genFor(el); } else { const children = genChildren(el); let code; code = `_c('${el.tag},'{ staticClass: ${el.attrsMap && el.attrsMap[':class']}, class: ${el.attrsMap && el.attrsMap['class']}, }${ children ? `,${children}` : '' })` return code; } } generate 最后我们使用上面的函数来实现 generate，其实很简单，我们只需要将整个 AST 传入后判断是否为空，为空则返回一个 div 标签，否则通过 generate 来处理。 function generate (rootAst) { const code = rootAst ? genElement(rootAst) : '_c(\"div\")' return { render: `with(this){return ${code}}`, } } 经历过这些过程以后，我们已经把 template 顺利转成了 render function 了，接下来我们将介绍 patch 的过程，来看一下具体 VNode 节点如何进行差异的比对。 注：本节代码参考《template 模板是怎样通过 Compile 编译的》。 "},"剖析Vue.js内部运行机制/6.数据状态更新时的差异diff及patch机制.html":{"url":"剖析Vue.js内部运行机制/6.数据状态更新时的差异diff及patch机制.html","title":"6.数据状态更新时的差异diff及patch机制","keywords":"","body":"数据状态更新时的差异 diff 及 patch 机制 数据更新视图 之前讲到，在对 model 进行操作对时候，会触发对应 Dep 中的 Watcher 对象。Watcher 对象会调用对应的 update 来修改视图。最终是将新产生的 VNode 节点与老 VNode 进行一个 patch 的过程，比对得出「差异」，最终将这些「差异」更新到视图上。 这一章就来介绍一下这个 patch 的过程，因为 patch 过程本身比较复杂，这一章的内容会比较多，但是不要害怕，我们逐块代码去看，一定可以理解。 跨平台 因为使用了 Virtual DOM 的原因，Vue.js具有了跨平台的能力，Virtual DOM 终归只是一些 JavaScript 对象罢了，那么最终是如何调用不同平台的 API 的呢？ 这就需要依赖一层适配层了，将不同平台的 API 封装在内，以同样的接口对外提供。 const nodeOps = { setTextContent (text) { if (platform === 'weex') { node.parentNode.setAttr('value', text); } else if (platform === 'web') { node.textContent = text; } }, parentNode () { //...... }, removeChild () { //...... }, nextSibling () { //...... }, insertBefore () { //...... } } 举个例子，现在我们有上述一个 nodeOps 对象做适配，根据 platform 区分不同平台来执行当前平台对应的API，而对外则是提供了一致的接口，供 Virtual DOM 来调用。 一些API 接下来我们来介绍其他的一些 API，这些API在下面 patch 的过程中会被用到，他们最终都会调用 nodeOps 中的相应函数来操作平台。 insert 用来在 parent 这个父节点下插入一个子节点，如果指定了 ref 则插入到 ref 这个子节点前面。 function insert (parent, elm, ref) { if (parent) { if (ref) { if (ref.parentNode === parent) { nodeOps.insertBefore(parent, elm, ref); } } else { nodeOps.appendChild(parent, elm) } } } createElm 用来新建一个节点， tag 存在创建一个标签节点，否则创建一个文本节点。 function createElm (vnode, parentElm, refElm) { if (vnode.tag) { insert(parentElm, nodeOps.createElement(vnode.tag), refElm); } else { insert(parentElm, nodeOps.createTextNode(vnode.text), refElm); } } addVnodes 用来批量调用 createElm 新建节点。 function addVnodes (parentElm, refElm, vnodes, startIdx, endIdx) { for (; startIdx removeNode 用来移除一个节点。 function removeNode (el) { const parent = nodeOps.parentNode(el); if (parent) { nodeOps.removeChild(parent, el); } } removeVnodes 会批量调用 removeNode 移除节点。 function removeVnodes (parentElm, vnodes, startIdx, endIdx) { for (; startIdx patch 首先说一下 patch 的核心 diff 算法，我们用 diff 算法可以比对出两颗树的「差异」，我们来看一下，假设我们现在有如下两颗树，它们分别是新老 VNode 节点，这时候到了 patch 的过程，我们需要将他们进行比对。 diff 算法是通过同层的树节点进行比较而非对树进行逐层搜索遍历的方式，所以时间复杂度只有 O(n)，是一种相当高效的算法，如下图。 。 这张图中的相同颜色的方块中的节点会进行比对，比对得到「差异」后将这些「差异」更新到视图上。因为只进行同层级的比对，所以十分高效。 patch 的过程相当复杂，我们先用简单的代码来看一下。 function patch (oldVnode, vnode, parentElm) { if (!oldVnode) { addVnodes(parentElm, null, vnode, 0, vnode.length - 1); } else if (!vnode) { removeVnodes(parentElm, oldVnode, 0, oldVnode.length - 1); } else { if (sameVnode(oldVNode, vnode)) { patchVnode(oldVNode, vnode); } else { removeVnodes(parentElm, oldVnode, 0, oldVnode.length - 1); addVnodes(parentElm, null, vnode, 0, vnode.length - 1); } } } 因为 patch 的主要功能是比对两个 VNode 节点，将「差异」更新到视图上，所以入参有新老两个 VNode 以及父节点的 element 。我们来逐步捋一下逻辑， addVnodes 、 removeVnodes 等函数后面会讲。 首先在 oldVnode（老 VNode 节点）不存在的时候，相当于新的 VNode 替代原本没有的节点，所以直接用 addVnodes 将这些节点批量添加到 parentElm 上。 if (!oldVnode) { addVnodes(parentElm, null, vnode, 0, vnode.length - 1); } 然后同理，在 vnode（新 VNode 节点）不存在的时候，相当于要把老的节点删除，所以直接使用 removeVnodes 进行批量的节点删除即可。 else if (!vnode) { removeVnodes(parentElm, oldVnode, 0, oldVnode.length - 1); } 最后一种情况，当 oldVNode 与 vnode 都存在的时候，需要判断它们是否属于 sameVnode（相同的节点）。如果是则进行patchVnode（比对 VNode ）操作，否则删除老节点，增加新节点。 if (sameVnode(oldVNode, vnode)) { patchVnode(oldVNode, vnode); } else { removeVnodes(parentElm, oldVnode, 0, oldVnode.length - 1); addVnodes(parentElm, null, vnode, 0, vnode.length - 1); } sameVnode 上面这些比较好理解，下面我们来看看什么情况下两个 VNode 会属于 sameVnode （相同的节点）呢？ function sameVnode () { return ( a.key === b.key && a.tag === b.tag && a.isComment === b.isComment && (!!a.data) === (!!b.data) && sameInputType(a, b) ) } function sameInputType (a, b) { if (a.tag !== 'input') return true let i const typeA = (i = a.data) && (i = i.attrs) && i.type const typeB = (i = b.data) && (i = i.attrs) && i.type return typeA === typeB } sameVnode 其实很简单，只有当 key、 tag、 isComment（是否为注释节点）、 data同时定义（或不定义），同时满足当标签类型为 input 的时候 type 相同（某些浏览器不支持动态修改类型，所以他们被视为不同类型）即可。 patchVnode 之前patch的过程还剩下 patchVnode 这个函数没有讲，这也是最复杂的一个，我们现在来看一下。因为这个函数是在符合 sameVnode 的条件下触发的，所以会进行「比对」。 function patchVnode (oldVnode, vnode) { if (oldVnode === vnode) { return; } if (vnode.isStatic && oldVnode.isStatic && vnode.key === oldVnode.key) { vnode.elm = oldVnode.elm; vnode.componentInstance = oldVnode.componentInstance; return; } const elm = vnode.elm = oldVnode.elm; const oldCh = oldVnode.children; const ch = vnode.children; if (vnode.text) { nodeOps.setTextContent(elm, vnode.text); } else { if (oldCh && ch && (oldCh !== ch)) { updateChildren(elm, oldCh, ch); } else if (ch) { if (oldVnode.text) nodeOps.setTextContent(elm, ''); addVnodes(elm, null, ch, 0, ch.length - 1); } else if (oldCh) { removeVnodes(elm, oldCh, 0, oldCh.length - 1) } else if (oldVnode.text) { nodeOps.setTextContent(elm, '') } } } 首先在新老 VNode 节点相同的情况下，就不需要做任何改变了，直接 return 掉。 if (oldVnode === vnode) { return; } 下面的这种情况也比较简单，在当新老 VNode 节点都是 isStatic（静态的），并且 key 相同时，只要将 componentInstance 与 elm 从老 VNode 节点“拿过来”即可。这里的 isStatic 也就是前面提到过的「编译」的时候会将静态节点标记出来，这样就可以跳过比对的过程。 if (vnode.isStatic && oldVnode.isStatic && vnode.key === oldVnode.key) { vnode.elm = oldVnode.elm; vnode.componentInstance = oldVnode.componentInstance; return; } 接下来，当新 VNode 节点是文本节点的时候，直接用 setTextContent 来设置 text，这里的 nodeOps 是一个适配层，根据不同平台提供不同的操作平台 DOM 的方法，实现跨平台。 if (vnode.text) { nodeOps.setTextContent(elm, vnode.text); } 当新 VNode 节点是非文本节点当时候，需要分几种情况。 oldCh 与 ch 都存在且不相同时，使用 updateChildren 函数来更新子节点，这个后面重点讲。 如果只有 ch 存在的时候，如果老节点是文本节点则先将节点的文本清除，然后将 ch 批量插入插入到节点elm下。 同理当只有 oldch 存在时，说明需要将老节点通过 removeVnodes 全部清除。 最后一种情况是当只有老节点是文本节点的时候，清除其节点文本内容。 if (oldCh && ch && (oldCh !== ch)) { updateChildren(elm, oldCh, ch); } else if (ch) { if (oldVnode.text) nodeOps.setTextContent(elm, ''); addVnodes(elm, null, ch, 0, ch.length - 1); } else if (oldCh) { removeVnodes(elm, oldCh, 0, oldCh.length - 1) } else if (oldVnode.text) { nodeOps.setTextContent(elm, '') } updateChildren 接下来就要讲一下 updateChildren 函数了。 function updateChildren (parentElm, oldCh, newCh) { let oldStartIdx = 0; let newStartIdx = 0; let oldEndIdx = oldCh.length - 1; let oldStartVnode = oldCh[0]; let oldEndVnode = oldCh[oldEndIdx]; let newEndIdx = newCh.length - 1; let newStartVnode = newCh[0]; let newEndVnode = newCh[newEndIdx]; let oldKeyToIdx, idxInOld, elmToMove, refElm; while (oldStartIdx oldEndIdx) { refElm = (newCh[newEndIdx + 1]) ? newCh[newEndIdx + 1].elm : null; addVnodes(parentElm, refElm, newCh, newStartIdx, newEndIdx); } else if (newStartIdx > newEndIdx) { removeVnodes(parentElm, oldCh, oldStartIdx, oldEndIdx); } } 看到代码那么多先不要着急，我们还是一点一点地讲解。 首先我们定义 oldStartIdx、newStartIdx、oldEndIdx 以及 newEndIdx 分别是新老两个 VNode 的两边的索引，同时 oldStartVnode、newStartVnode、oldEndVnode 以及 newEndVnode 分别指向这几个索引对应的 VNode 节点。 接下来是一个 while 循环，在这过程中，oldStartIdx、newStartIdx、oldEndIdx 以及 newEndIdx 会逐渐向中间靠拢。 while (oldStartIdx 首先当 oldStartVnode 或者 oldEndVnode 不存在的时候，oldStartIdx 与 oldEndIdx 继续向中间靠拢，并更新对应的 oldStartVnode 与 oldEndVnode 的指向（注：下面讲到的 oldStartIdx、newStartIdx、oldEndIdx 以及 newEndIdx 移动都会伴随着 oldStartVnode、newStartVnode、oldEndVnode 以及 newEndVnode 的指向的变化，之后的部分只会讲 Idx 的移动）。 if (!oldStartVnode) { oldStartVnode = oldCh[++oldStartIdx]; } else if (!oldEndVnode) { oldEndVnode = oldCh[--oldEndIdx]; } 接下来这一块，是将 oldStartIdx、newStartIdx、oldEndIdx 以及 newEndIdx 两两比对的过程，一共会出现 2*2=4 种情况。 else if (sameVnode(oldStartVnode, newStartVnode)) { patchVnode(oldStartVnode, newStartVnode); oldStartVnode = oldCh[++oldStartIdx]; newStartVnode = newCh[++newStartIdx]; } else if (sameVnode(oldEndVnode, newEndVnode)) { patchVnode(oldEndVnode, newEndVnode); oldEndVnode = oldCh[--oldEndIdx]; newEndVnode = newCh[--newEndIdx]; } else if (sameVnode(oldStartVnode, newEndVnode)) { patchVnode(oldStartVnode, newEndVnode); nodeOps.insertBefore(parentElm, oldStartVnode.elm, nodeOps.nextSibling(oldEndVnode.elm)); oldStartVnode = oldCh[++oldStartIdx]; newEndVnode = newCh[--newEndIdx]; } else if (sameVnode(oldEndVnode, newStartVnode)) { patchVnode(oldEndVnode, newStartVnode); nodeOps.insertBefore(parentElm, oldEndVnode.elm, oldStartVnode.elm); oldEndVnode = oldCh[--oldEndIdx]; newStartVnode = newCh[++newStartIdx]; } 首先是 oldStartVnode 与 newStartVnode 符合 sameVnode 时，说明老 VNode 节点的头部与新 VNode 节点的头部是相同的 VNode 节点，直接进行 patchVnode，同时 oldStartIdx 与 newStartIdx 向后移动一位。 其次是 oldEndVnode 与 newEndVnode 符合 sameVnode，也就是两个 VNode 的结尾是相同的 VNode，同样进行 patchVnode 操作并将 oldEndVnode 与 newEndVnode 向前移动一位。 接下来是两种交叉的情况。 先是 oldStartVnode 与 newEndVnode 符合 sameVnode 的时候，也就是老 VNode 节点的头部与新 VNode 节点的尾部是同一节点的时候，将 oldStartVnode.elm 这个节点直接移动到 oldEndVnode.elm 这个节点的后面即可。然后 oldStartIdx 向后移动一位，newEndIdx 向前移动一位。 同理，oldEndVnode 与 newStartVnode 符合 sameVnode 时，也就是老 VNode 节点的尾部与新 VNode 节点的头部是同一节点的时候，将 oldEndVnode.elm 插入到 oldStartVnode.elm 前面。同样的，oldEndIdx 向前移动一位，newStartIdx 向后移动一位。 最后是当以上情况都不符合的时候，这种情况怎么处理呢？ else { let elmToMove = oldCh[idxInOld]; if (!oldKeyToIdx) oldKeyToIdx = createKeyToOldIdx(oldCh, oldStartIdx, oldEndIdx); idxInOld = newStartVnode.key ? oldKeyToIdx[newStartVnode.key] : null; if (!idxInOld) { createElm(newStartVnode, parentElm); newStartVnode = newCh[++newStartIdx]; } else { elmToMove = oldCh[idxInOld]; if (sameVnode(elmToMove, newStartVnode)) { patchVnode(elmToMove, newStartVnode); oldCh[idxInOld] = undefined; nodeOps.insertBefore(parentElm, newStartVnode.elm, oldStartVnode.elm); newStartVnode = newCh[++newStartIdx]; } else { createElm(newStartVnode, parentElm); newStartVnode = newCh[++newStartIdx]; } } } function createKeyToOldIdx (children, beginIdx, endIdx) { let i, key const map = {} for (i = beginIdx; i createKeyToOldIdx 的作用是产生 key 与 index 索引对应的一个 map 表。比如说： [ {xx: xx, key: 'key0'}, {xx: xx, key: 'key1'}, {xx: xx, key: 'key2'} ] 在经过 createKeyToOldIdx 转化以后会变成： { key0: 0, key1: 1, key2: 2 } 我们可以根据某一个 key 的值，快速地从 oldKeyToIdx（createKeyToOldIdx 的返回值）中获取相同 key 的节点的索引 idxInOld，然后找到相同的节点。 如果没有找到相同的节点，则通过 createElm 创建一个新节点，并将 newStartIdx 向后移动一位。 if (!idxInOld) { createElm(newStartVnode, parentElm); newStartVnode = newCh[++newStartIdx]; } 否则如果找到了节点，同时它符合 sameVnode，则将这两个节点进行 patchVnode，将该位置的老节点赋值 undefined（之后如果还有新节点与该节点key相同可以检测出来提示已有重复的 key ），同时将 newStartVnode.elm 插入到 oldStartVnode.elm 的前面。同理，newStartIdx 往后移动一位。 else { elmToMove = oldCh[idxInOld]; if (sameVnode(elmToMove, newStartVnode)) { patchVnode(elmToMove, newStartVnode); oldCh[idxInOld] = undefined; nodeOps.insertBefore(parentElm, newStartVnode.elm, oldStartVnode.elm); newStartVnode = newCh[++newStartIdx]; } } 如果不符合 sameVnode，只能创建一个新节点插入到 parentElm 的子节点中，newStartIdx 往后移动一位。 else { createElm(newStartVnode, parentElm); newStartVnode = newCh[++newStartIdx]; } 最后一步就很容易啦，当 while 循环结束以后，如果 oldStartIdx > oldEndIdx，说明老节点比对完了，但是新节点还有多的，需要将新节点插入到真实 DOM 中去，调用 addVnodes 将这些节点插入即可。 同理，如果满足 newStartIdx > newEndIdx 条件，说明新节点比对完了，老节点还有多，将这些无用的老节点通过 removeVnodes 批量删除即可。 if (oldStartIdx > oldEndIdx) { refElm = (newCh[newEndIdx + 1]) ? newCh[newEndIdx + 1].elm : null; addVnodes(parentElm, refElm, newCh, newStartIdx, newEndIdx); } else if (newStartIdx > newEndIdx) { removeVnodes(parentElm, oldCh, oldStartIdx, oldEndIdx); } 到这里，比对的核心实现已经讲完了，这部分比较复杂，不过仔细地梳理一下比对的过程，相信一定能够理解得更加透彻的。 注：本节代码参考《数据状态更新时的差异 diff 及 patch 机制》。 "},"剖析Vue.js内部运行机制/7.批量异步更新策略及nextTick原理.html":{"url":"剖析Vue.js内部运行机制/7.批量异步更新策略及nextTick原理.html","title":"7.批量异步更新策略及nextTick原理","keywords":"","body":"批量异步更新策略及 nextTick 原理 为什么要异步更新 通过前面几个章节我们介绍，相信大家已经明白了 Vue.js 是如何在我们修改 data 中的数据后修改视图了。简单回顾一下，这里面其实就是一个“setter -> Dep -> Watcher -> patch -> 视图”的过程。 假设我们有如下这么一种情况。 {{number}} click export default { data () { return { number: 0 }; }, methods: { handleClick () { for(let i = 0; i 当我们按下 click 按钮的时候，number 会被循环增加1000次。 那么按照之前的理解，每次 number 被 +1 的时候，都会触发 number 的 setter 方法，从而根据上面的流程一直跑下来最后修改真实 DOM。那么在这个过程中，DOM 会被更新 1000 次！太可怕了。 Vue.js 肯定不会以如此低效的方法来处理。Vue.js在默认情况下，每次触发某个数据的 setter 方法后，对应的 Watcher 对象其实会被 push 进一个队列 queue 中，在下一个 tick 的时候将这个队列 queue 全部拿出来 run（ Watcher 对象的一个方法，用来触发 patch 操作） 一遍。 那么什么是下一个 tick 呢？ nextTick Vue.js 实现了一个 nextTick 函数，传入一个 cb ，这个 cb 会被存储到一个队列中，在下一个 tick 时触发队列中的所有 cb 事件。 因为目前浏览器平台并没有实现 nextTick 方法，所以 Vue.js 源码中分别用 Promise、setTimeout、setImmediate 等方式在 microtask（或是task）中创建一个事件，目的是在当前调用栈执行完毕以后（不一定立即）才会去执行这个事件。 笔者用 setTimeout 来模拟这个方法，当然，真实的源码中会更加复杂，笔者在小册中只讲原理，有兴趣了解源码中 nextTick 的具体实现的同学可以参考next-tick。 首先定义一个 callbacks 数组用来存储 nextTick，在下一个 tick 处理这些回调函数之前，所有的 cb 都会被存在这个 callbacks 数组中。pending 是一个标记位，代表一个等待的状态。 setTimeout 会在 task 中创建一个事件 flushCallbacks ，flushCallbacks 则会在执行时将 callbacks 中的所有 cb 依次执行。 let callbacks = []; let pending = false; function nextTick (cb) { callbacks.push(cb); if (!pending) { pending = true; setTimeout(flushCallbacks, 0); } } function flushCallbacks () { pending = false; const copies = callbacks.slice(0); callbacks.length = 0; for (let i = 0; i 再写 Watcher 第一个例子中，当我们将 number 增加 1000 次时，先将对应的 Watcher 对象给 push 进一个队列 queue 中去，等下一个 tick 的时候再去执行，这样做是对的。但是有没有发现，另一个问题出现了？ 因为 number 执行 ++ 操作以后对应的 Watcher 对象都是同一个，我们并不需要在下一个 tick 的时候执行 1000 个同样的 Watcher 对象去修改界面，而是只需要执行一个 Watcher 对象，使其将界面上的 0 变成 1000 即可。 那么，我们就需要执行一个过滤的操作，同一个的 Watcher 在同一个 tick 的时候应该只被执行一次，也就是说队列 queue 中不应该出现重复的 Watcher 对象。 那么我们给 Watcher 对象起个名字吧～用 id 来标记每一个 Watcher 对象，让他们看起来“不太一样”。 实现 update 方法，在修改数据后由 Dep 来调用， 而 run 方法才是真正的触发 patch 更新视图的方法。 let uid = 0; class Watcher { constructor () { this.id = ++uid; } update () { console.log('watch' + this.id + ' update'); queueWatcher(this); } run () { console.log('watch' + this.id + '视图更新啦～'); } } queueWatcher 不知道大家注意到了没有？笔者已经将 Watcher 的 update 中的实现改成了 queueWatcher(this); 将 Watcher 对象自身传递给 queueWatcher 方法。 我们来实现一下 queueWatcher 方法。 let has = {}; let queue = []; let waiting = false; function queueWatcher(watcher) { const id = watcher.id; if (has[id] == null) { has[id] = true; queue.push(watcher); if (!waiting) { waiting = true; nextTick(flushSchedulerQueue); } } } 我们使用一个叫做 has 的 map，里面存放 id -> true ( false ) 的形式，用来判断是否已经存在相同的 Watcher 对象 （这样比每次都去遍历 queue 效率上会高很多）。 如果目前队列 queue 中还没有这个 Watcher 对象，则该对象会被 push 进队列 queue 中去。 waiting 是一个标记位，标记是否已经向 nextTick 传递了 flushSchedulerQueue 方法，在下一个 tick 的时候执行 flushSchedulerQueue 方法来 flush 队列 queue，执行它里面的所有 Watcher 对象的 run 方法。 flushSchedulerQueue function flushSchedulerQueue () { let watcher, id; for (index = 0; index 举个例子 let watch1 = new Watcher(); let watch2 = new Watcher(); watch1.update(); watch1.update(); watch2.update(); 我们现在 new 了两个 Watcher 对象，因为修改了 data 的数据，所以我们模拟触发了两次 watch1 的 update 以及 一次 watch2 的 update。 假设没有批量异步更新策略的话，理论上应该执行 Watcher 对象的 run，那么会打印。 watch1 update watch1视图更新啦～ watch1 update watch1视图更新啦～ watch2 update watch2视图更新啦～ 实际上则执行 watch1 update watch1 update watch2 update watch1视图更新啦～ watch2视图更新啦～ 这就是异步更新策略的效果，相同的 Watcher 对象会在这个过程中被剔除，在下一个 tick 的时候去更新视图，从而达到对我们第一个例子的优化。 我们再回过头聊一下第一个例子， number 会被不停地进行 ++ 操作，不断地触发它对应的 Dep 中的 Watcher 对象的 update 方法。然后最终 queue 中因为对相同 id 的 Watcher 对象进行了筛选，从而 queue 中实际上只会存在一个 number 对应的 Watcher 对象。在下一个 tick 的时候（此时 number 已经变成了 1000），触发 Watcher 对象的 run 方法来更新视图，将视图上的 number 从 0 直接变成 1000。 到这里，批量异步更新策略及 nextTick 原理已经讲完了，接下来让我们学习一下 Vuex 状态管理的工作原理。 注：本节代码参考《批量异步更新策略及 nextTick 原理》。 "},"剖析Vue.js内部运行机制/8.Vuex状态管理的工作原理.html":{"url":"剖析Vue.js内部运行机制/8.Vuex状态管理的工作原理.html","title":"8.Vuex状态管理的工作原理","keywords":"","body":"Vuex 状态管理的工作原理 为什么要使用 Vuex 当我们使用 Vue.js 来开发一个单页应用时，经常会遇到一些组件间共享的数据或状态，或是需要通过 props 深层传递的一些数据。在应用规模较小的时候，我们会使用 props、事件等常用的父子组件的组件间通信方法，或者是通过事件总线来进行任意两个组件的通信。但是当应用逐渐复杂后，问题就开始出现了，这样的通信方式会导致数据流异常地混乱。 这个时候，我们就需要用到我们的状态管理工具 Vuex 了。Vuex 是一个专门为 Vue.js 框架设计的、专门用来对于 Vue.js 应用进行状态管理的库。它借鉴了 Flux、redux 的基本思想，将状态抽离到全局，形成一个 Store。因为 Vuex 内部采用了 new Vue 来将 Store 内的数据进行「响应式化」，所以 Vuex 是一款利用 Vue 内部机制的库，与 Vue 高度契合，与 Vue 搭配使用显得更加简单高效，但缺点是不能与其他的框架（如 react）配合使用。 本节将简单介绍 Vuex 最核心的内部机制，起个抛砖引玉的作用，想了解更多细节可以参考笔者 Github 上的另一篇文章 《Vuex源码解析》或者直接阅读 Vuex源码。 安装 Vue.js 提供了一个 Vue.use 的方法来安装插件，内部会调用插件提供的 install 方法。 Vue.use(Vuex); 所以我们的插件需要提供一个 install 方法来安装。 let Vue; export default install (_Vue) { Vue.mixin({ beforeCreate: vuexInit }); Vue = _Vue; } 我们采用 Vue.mixin 方法将 vuexInit 方法混淆进 beforeCreate 钩子中，并用 Vue 保存 Vue 对象。那么 vuexInit 究竟实现了什么呢？ 我们知道，在使用 Vuex 的时候，我们需要将 store 传入到 Vue 实例中去。 /*将store放入Vue创建时的option中*/ new Vue({ el: '#app', store }); 但是我们却在每一个 vm 中都可以访问该 store，这个就需要靠 vuexInit 了。 function vuexInit () { const options = this.$options; if (options.store) { this.$store = options.store; } else { this.$store = options.parent.$store; } } 因为之前已经用Vue.mixin 方法将 vuexInit 方法混淆进 beforeCreate 钩子中，所以每一个 vm 实例都会调用 vuexInit 方法。 如果是根节点（$options中存在 store 说明是根节点），则直接将 options.store 赋值给 this.$store。否则则说明不是根节点，从父节点的 $store 中获取。 通过这步的操作，我们已经可以在任意一个 vm 中通过 this.$store 来访问 Store 的实例啦～ Store 数据的响应式化 首先我们需要在 Store 的构造函数中对 state 进行「响应式化」。 constructor () { this._vm = new Vue({ data: { $$state: this.state } }) } 熟悉「响应式」的同学肯定知道，这个步骤以后，state 会将需要的依赖收集在 Dep 中，在被修改时更新对应视图。我们来看一个小例子。 let globalData = { d: 'hello world' }; new Vue({ data () { return { $$state: { globalData } } } }); /* modify */ setTimeout(() => { globalData.d = 'hi~'; }, 1000); Vue.prototype.globalData = globalData; 任意模板中 {{globalData.d}} 上述代码在全局有一个 globalData，它被传入一个 Vue 对象的 data 中，之后在任意 Vue 模板中对该变量进行展示，因为此时 globalData 已经在 Vue 的 prototype 上了所以直接通过 this.prototype 访问，也就是在模板中的 {{globalData.d}}。此时，setTimeout 在 1s 之后将 globalData.d 进行修改，我们发现模板中的 globalData.d 发生了变化。其实上述部分就是 Vuex 依赖 Vue 核心实现数据的“响应式化”。 讲完了 Vuex 最核心的通过 Vue 进行数据的「响应式化」，接下来我们再来介绍两个 Store 的 API。 commit 首先是 commit 方法，我们知道 commit 方法是用来触发 mutation 的。 commit (type, payload, _options) { const entry = this._mutations[type]; entry.forEach(function commitIterator (handler) { handler(payload); }); } 从 _mutations 中取出对应的 mutation，循环执行其中的每一个 mutation。 dispatch dispatch 同样道理，用于触发 action，可以包含异步状态。 dispatch (type, payload) { const entry = this._actions[type]; return entry.length > 1 ? Promise.all(entry.map(handler => handler(payload))) : entry[0](payload); } 同样的，取出 _actions 中的所有对应 action，将其执行，如果有多个则用 Promise.all 进行包装。 最后 理解 Vuex 的核心在于理解其如何与 Vue 本身结合，如何利用 Vue 的响应式机制来实现核心 Store 的「响应式化」。 Vuex 本身代码不多且设计优雅，非常值得一读，想阅读源码的同学请看Vuex源码。 注：本节代码参考《Vuex状态管理的工作原理》。 "},"剖析Vue.js内部运行机制/9.总结&常见问题解答.html":{"url":"剖析Vue.js内部运行机制/9.总结&常见问题解答.html","title":"9.总结&常见问题解答","keywords":"","body":"总结 & 常见问题解答 总结 在本小册的第一节中，笔者对 Vue.js 内部运行机制做了一个全局的概览，当时通过下面这张图把 Vue.js 拆分成一个一个小模块来介绍，之后通过这一系列小节的学习，相信大家已经对 Vue.js 内部的原理有了一个更进一步的了解，对这张图也再也不会感觉到那么陌生。 每个小节中的代码都是笔者根据 Vue.js 原理单独抽离出来写成的 Demo，大家可以在我的 Gtihub 上查看完整的代码 (见 VueDemo 项目)。 本小册对 Vue.js 原理进行了初步的介绍，希望能够起到一个抛砖引玉的作用，读者读完以后，可以利用这些基础对 Vue.js 进行一个更加深入的探索，相信会有更大的收获。 常见问题 怎么实现 this._test 改变而不是 this._data.test 改变触发更新？ 答：其实这中间有一个代理的过程。 _proxy(options.data); function _proxy (data) { const that = this; Object.keys(data).forEach(key => { Object.defineProperty(that, key, { configurable: true, enumerable: true, get: function proxyGetter () { return that._data[key]; }, set: function proxySetter (val) { that._data[key] = val; } }) }); } 本质就是通过 Object.defineProperty 使在访问 this 上的某属性时从 this._data 中读取（写入）。 能不能将依赖收集中讲到的 dep.addSub(Dep.target) 改成 dep.addSub(new Watcher())呢？ 为了便于读者理解这部分内容，我将代码做了简化，实际上一个 Watcher 对象可能会在多个 Dep 中，并不是每次 addSub 都是一个新的 Watcher 对象，需依赖 Dep.target 进行收集（实际上 Dep.target 也是通过 Watcher 对象的 get 方法调用 pushTarget 将自身赋值给 Dep.target）。 最后 从 2017 年 12 月开始写这本小册到现在差不多 2 个月的时间，虽说之前写过类似的内容，但是将 Vue.js 源码抽离成一个一个 Demo 还是花了很多时间，对于这本小册也是前前后后改了好几次才让自己满意。 因为读者的基础不一致，而小册的定位是偏向于对新手读者更加友好，所以我尽量用更加浅显易懂的方式去写这本小册的内容。希望大家可以通过这本小册初步掌握 Vue.js 的原理，掌握这些原理以后再去尝试阅读 Vue.js 源码，相信会事半功倍，也会对 Vue.js 有更深一层的理解。 如果想获取更多优质的前端技术内容资讯，欢迎大家关注笔者的公众号。 End "},"基于JavaScript开发灵活的数据应用/00.基于JavaScript的数据应用开发概述.html":{"url":"基于JavaScript开发灵活的数据应用/00.基于JavaScript的数据应用开发概述.html","title":"00.基于JavaScript的数据应用开发概述","keywords":"","body":"第 1 节 基于 JavaScript 的数据应用开发概述 这本小册的主要目的是让前端工程师和希望能快速实现动态数据应用的数据工作者，学习如何使用 JavaScript 和前端技能来开发具有可用性的数据应用。 1.1 你会学到什么？ 基于前端技术来开发一个复杂的动态数据应用，需要用到最基本的 JavaScript 常量变量控制、JavaScript 基本数据处理方法、可视化工具、动态数据控制方法等。所以本小册会先从最基本的 JavaScript 数据类型、处理方法讲起，到较为复杂的数据结构，再到逐渐复杂的数据可视化，最后我们将重新定义数据处理，使用前端技能让你的可视化数据应用变得更加灵活。 总体来说，你将会从本小册中学到以下技能点。 JavaScript 对基本数据类型的操作 JavaScript 对复杂数据结构的操作 复杂数据结构的处理技巧 基于 ECharts 可视化工具库对简单数据和复杂数据进行图表绘制 结合 Vue.js 为数据流添加动态处理功能 对于有 JavaScript 基础的读者来说，可能前面数节你会觉得稍稍有些无趣，但笔者还是希望你能认真地跟着一起学习，因为这些内容可能会改变你对 JavaScript 数据处理的一些既有印象。 1.2 在一切开始之前 本小册的全部知识都建立在 JavaScript 语言之上，所以在学习本小册之前，你首先需要准备好 JavaScript 开发环境。虽然说在进行数据可视化和动态数据应用开发的时候，我们必须使用浏览器和网页作为 JavaScript 的运行载体，但是在这之前你也可以选择 Node.js 作为学习 JavaScript 开发的平台。 1.2.1 CodePen 当然你也可以选择一些基于网页的即时运行 JavaScript 结果工具来进行学习，这里笔者推荐使用 CodePen。你可以直接在这上面编辑 JavaScript 代码，并实时查看运行结果，也可以将其分享给你的小伙伴。 在 CodePen 中可以添加一些第三方 JavaScript 库，点击右上角的 “Settings” 按钮，选择 “JavaScript” 标签页，在下方的 “Add External Scripts/Pens” 你就可以使用第三方 JavaScript 库的地址进行引入。CodePen 也提供了一些比较常用的库以供便捷地引入，比如在本小册中将会使用到的 Lodash 工具库。 当然 CodePen 并不只能运行 JavaScript，它也允许我们直接在上面进行 HTML 和 CSS 的开发，还能实时看到所生成网页的结果。这在我们学习如何进行数据可视化时同样可以派上用场。 1.2.2 单页应用 如果你觉得需要一步到位到进行页面应用开发，那么请跟着笔者一步一步准备你的开发环境。 首先请选择一个你最喜欢的编辑器或 IDE，创建一个空的文件夹并将其命名为 js-learning。在这个文件夹中创建一个 HTML 文件并将其命名为 index.html。将以下内容写入到 index.html 文件中。 Build a data app 然后在这个文件夹中再创建一个 main.js 文件并输入以下内容。 console.log('Hello World') 保存后，双击 index.html 并使用你最喜欢的浏览器打开（笔者推荐使用 Google Chrome），按下键盘上的 F12 功能键，在弹出的开发者工具中你就能看到刚才在 main.js 文件中输出的 Hello World。 此后在本小册的学习中，你就可以通过修改 main.js 中的代码来动手自己尝试了。 1.3 还是在一切开始之前 本小册的内容比较多且非常需要你一步一步跟着动手尝试，所以笔者建议你最好在空闲时间进行学习，并随时准备好开发环境，而不是单纯地阅读本小册。 Learn by doing，你将会事半功倍。 "},"基于JavaScript开发灵活的数据应用/01.字符串和数字.html":{"url":"基于JavaScript开发灵活的数据应用/01.字符串和数字.html","title":"01.字符串和数字","keywords":"","body":"第 2 节 基本数据处理 · 字符串和数字 无论在任何的现代编程语言中，最基本的数据格式都会是字符串和数字。字符串用于表达人类文明的自然语言，数字用于表达量化世界的各种数值。 2.1 字符串 字符串在自然世界中充当着非常重要的角色，所有的自然语言（比如汉语、英语等）都由多个字符组成，比如经典的 “Hello World” 这句话则由 11 个字符组成：H,e,l,l,o,,W,o,r,l,d。 而当我们在希望使用计算机程序来理解我们平常所说的自然语言时，我们则需要对包含了目标自然语言的字符串进行拆分，如分词算法；同时当我们需要使用计算机程序来自动化地完成一些自然语言表达时，如自动组成“今天你有 3 个待办事务”，则需要对多段字符串进行组合而变成一个字符串；当我们想要从寻找字符串中符合“XXX 你好，我是 XXX”句式的文字时，我们又应该如何进行检索呢？别着急，我们一步一步来。 2.1.1 创建字符串 在 JavaScript 中创建一个字符串跟其他语言并没有较大的区别，可以分别使用 '、\" 和 ` 作为边界标识。 const str1 = 'string 1' const str2 = \"string 2\" const str3 = `string 3` 从 JavaScript 的语法定义上 ' 和 \" 并没有太大的差别，但是 ` 的用途较为特殊。虽然 ` 同样可以以与 ' 和 \" 一样的使用方式使用，但也可以有更高级的用法。 const target = 'World' const word = `Hello ${target}` //=> Hello World 同时 ` 也可以用于创建一个“多行字符串”，即字符串内容中包含多行文本。 const str = ` Hello World ` //=> // Hello // World 2.1.2 分割字符串 当我们在学习任何一门编程语言时，书本或者老师教我们的第一行代码往往是“如何输出 Hello World”，如上一小节中。而在数据科学领域中，又应该以什么来充当这个 \"Hello World\" 的例子呢？ 一般来说人们都会使用词频统计作为数据科学的 \"Hello World\"，简单来说就是对一段英语内容中的单词进行频次（出现次数）统计。 我们在这里选取 MIT 开源协议中的一部分内容： Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. 我们在进行词频统计之前，我们首先需要对源内容进行预处理。首先我们要了解的是，我们可以看到这段内容中有小写字母、大写字母以及标点符号（包括逗号、句号、括号、双引号、斜杠和冒号）。 而从语言角度，HELLO、hello 和 Hello 都是一样的，所以我们需要先完成以下预处理任务： 去除文本中的标点符号、数字 将所有大写字母转换为小写字母 假设原文为 \"Hey dude, how is it going?\"，则需要首先转换为 \"hey dude how is it going\"。 去除文本中的标点符号 在做任何需求之前，都需要先对需求的上下文进行多方位理解，比如去除标点符号、数字这个需求在全英语的语境下可以说是约等于只保留英文字母。这样我们就可以从文本中直接筛选出英文字母和空格即可，这里可以使用 ASCII 码进行甄别。大写字母的 ASCII 码范围为 65 到 90，即 A 到 Z，而小写字母则为 97 到 122，空格的 ASCII 码为 32，换行符的 ASCII 码为 10。在 JavaScript 可以用 string.charCodeAt() 方法获取字符的 ASCII 码。 const originalText = 'Hey dude, how is it going?' let wordOnlyText = '' for (let i = 0; i = 65 && asciiCode = 97 && asciiCode \"Hey dude how is it going\" 数值变量 i 使用表达式 ++i 的意义为将其数值加 1，并将其结果作为该表达式的值；而表达式 i++ 则为将其数值加 1，但返回 i 的原值。 将所有大写字母转换为小写字母 上面我们用到了 string.charCodeAt() 方法来获取字符的 ASCII 码，那么自然也有对应的方法用于将 ASCII 码转换为对应字符 String.fromCharCode(code)。 而从字母的 ASCII 码范围可以看到，将大写字母的 ASCII 码数值加上 32 便是其对应小写字母的 ASCII 码数值。 let lowerCaseText = '' for (let i = 0; i = 65 && asciiCode \"hey dude how is it going\" 幸运的是，在 JavaScript 中早就已经内置了将文本中的大写字母转换为小写字母的 API 了 —— string.toLowerCase()。 const lowerCaseText = wordOnlyText.toLowerCase() 完成了文本的预处理之后，就可以将文本数据进行分割了。而最主要用到的方法便是 string.split(separator)，其中这个 separator 则是定义了用于分割字符串内容的“分割符”。比如在该需求中，我们已经将文本内容进行了预处理，单词与单词之间的分割符则是空格。 const originalText = ` Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE. ` let wordOnlyText = '' for (let i = 0; i = 65 && asciiCode = 97 && asciiCode 163 而如何实现词频统计，我们先稍作休息，后面的章节继续来学习。 2.1.3 组装字符串 除了对字符串进行拆分以外，我们也常常需要将不同的信息通过各种方式拼装成一个完整的字符串信息。最常见的例子便是我们几乎每天都能遇见的，由程序自动发送的自动短信、自动邮件等。要学习如何在 JavaScript 中进行字符串组装，我们需要一步一步来。 字符串之间的连接可以直接使用 + 运算符完成。 const str1 = 'Hello' const str2 = 'World' console.log(str1 + ' ' + str2) //=> \"Hello World\" 这是最基本的字符串连接方式，这适用于数据量较小的字符串信息拼接。若当数据量比较大时，需要将多个数据量“嵌入”到一个文本模板中。一般情况下，开发工程师会选择一个较为顺手的模板引擎来实现这个功能，但在这里我们一切从简，使用 JavaScript 中的字符串模板特性 ` 来完成这个需求。 const name = 'Will Wen Gunn' const level = 'Gold' const message = ` Hello, ${name}. Here is Turing Airline, you are the ${level} member of our Privilege Club. ` console.log(message) //=> // Hello, Will Wen Gunn. // Here is Turing Airline, you are the Gold member of our Privilege Club. 2.1.4 正则表达式 我们回过头来看看我们在进行字符串分割的时候，需要剔除文本中非英文字母的内容。而前面我们所使用的方法为判定每一个字符的 ASCII 码是否符合英文字母的范围。这种方法虽然容易理解，但很显然这并非最好的办法。而正则表达式的使用可以让这个需求的实现变得非常简单。 const originalText = 'Hey dude, how is it going?' const words = originalText.toLowerCase().match(/\\w+/g) console.log(words.length) //=> 6 当然，因为正则表达式这一个知识点单独拿出来就可以写一本书了，所以这里我们不再详细阐述。 2.2 数字 除了自然语言以外，当我们需要准确地表达世界上任何事物时，我们还需要有数字的帮助。 我今年 18 岁 我有 3 个孩子 2.2.1 四则运算 四则运算是所有数学运算的基础，懂得如何对数字做四则运算是进行后续更高深运算的首要前提。 const a = 3 const b = 4 a + b //=> 7 b - a //=> 1 a * b //=> 12 a / b //=> 0.75 2.2.2 优先级 我们在计算数学式子的时候经常会碰到这样的情况： %5C%5C%0A(2%20%2B%203)%20*%204%20%3D%2020%20%5Cquad%20(2)) 由于在四则运算中乘法和除法拥有比加法和减法更高的优先级，若当我们要计算 与 的和再乘以 的结果时就需要像 ) 式这样写，否则由于优先级的原因会导致错误的结果，如式子 )。 在 JavaScript 中也同样存在这样的问题，当然我们也是可以使用括号来解决。 console.log(2 + 3 * 4) //=> 14 console.log((2 + 3) * 4) //=> 20 2.2.3 幂运算 问：设有一个边长为 3 厘米的正方体，求该正方体的体积为多少？ 答： 问：设一个正方体的边长为 ，求该正方体的体积为多少？ 答： 幂运算，又称指数运算，是数学中非常重要的一种运算方式，具体定义便是同一个数值的多次自乘结果。有了幂运算才有后面更为深入的对数运算、导数运算、方差运算等等。在 JavaScript 中，使用 Math.pow(base, exponent) 来进行幂运算，其中 base 为底数即上式中的 ，而 exponent 则为指数即右上角的 。 const V1 = 3 * 3 * 3 console.log(V1) //=> 27 const V2 = Math.pow(3, 3) console.log(V2) //=> 27 const calcCubeVolume = function(sideLength) { return Math.pow(sideLength, 3) } console.log(calcCubeVolume(3)) //=> 27 2.2.4 对数运算 当人类发明了幂运算之后，为了能够知道一个数究竟是由什么数进行了幂运算所得的，所以有幂运算的逆转运算——对数运算。 27 是 3 的多少次方？ 1024 是 2 的多少次方？ 在数学中这就涉及了对数运算，比如求“27 是 3 的多少次方”则为 而在数学中有一个神奇的数值自然对数 ，关于这个数值的传奇故事你可以搜索到非常多的文章甚至视频。在 JavaScript 中的 Math.log(x) 函数只接受一个参数，而这个函数的直接作用便是计算以自然对数 为底 的对数。 那么就很奇怪了，我们要如何在 JavaScript 中计算并非以 为底的对数结果呢？这得先回到数学推导上来。对数中有一个经典公式为换底公式，定义如下： 具体推导可以参考维基百科页面 · 对数。那么代入我们前面公式中就可以用这样的方式解决了。 换成使用 JavaScript 实现便是： function getBaseLog(base, x) { return Math.log(x) / Math.log(base) } console.log(getBaseLog(2, 1024)) //=> 10 2.2.5 求和 当两个数值相加时用一个加号可以完成，当三个数值相加时用两个加号可以完成，但若需要求 1000 个数值甚至更多的数值相加的时候，数学表达式要怎么表达呢？ 假设数列 为有 个元素的自然数数列，其中 ) 为数列 的第 个元素。那么求数列 的元素总和 可以用以下公式表达： 比较可惜的是，在 JavaScript 中并没有直接等同于这个 的 API。但是我们可以手动使用循环的方式来实现这个需求。 let S = 0 const L = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 ] const n = L.length for (let i = 0; i 55 2.2.6 求余 求余可能是在数学中比较少见的一种运算，但是计算机领域中却会经常使用，比如进制之间的转换等等。 5 % 2 == 1 4 % 2 == 0 小结 在本节学习中，你学会了如何使用 JavaScript 创建一个字符串以及一个数字，并且学会了如何对它们进行计算、转换、拼接以及拆分。那么为了能够更好地理解和吸收本节的知识，动动手完成以下的习题吧。 习题 尝试使用 JavaScript 将字符串 \"Hello World\" 中的小写字母全部转为大写字母。 尝试筛选出章节 2.1.2 中 MIT 开源协议的文本中的大写英文字母。 使用 JavaScript 完成以下式子的计算。 %20*%204%20%5Cdiv%205%20-%20(6%20%2B%207)) 定义函数 ，接受唯一参数长度为 的数列 。使用 JavaScript 实现该函数。 %20%3D%20L_1%20%20L_2%20%20%5Ccdots%20*%20L_i) "},"基于JavaScript开发灵活的数据应用/02.对象字面量.html":{"url":"基于JavaScript开发灵活的数据应用/02.对象字面量.html","title":"02.对象字面量","keywords":"","body":"第 3 节 基本数据处理 · 对象字面量 “都这么大了，还找不到对象吗？”“不用找，我可以 new 一个。” 对象是 JavaScript 中的基础，它可以用于表达具象的事物，可以表达抽象的事物，也可以将具象事物抽象表达，反之亦然。 3.1 描述万物的对象 我是小问，多领域开发者，主要为 Web 开发与大数据、机器学习领域。 若要根据这段个人介绍，将笔者使用 JavaScript 进行抽象化表达，便可以使用对象字面量来实现。 const author = { name: '小问', title: '多领域开发者', domains: [ 'Web 开发', '大数据', '机器学习' ] } const someone = { name: 'Ben', age: 25, title: 'Web Developer', skills: [ 'JavaScript', 'TypeScript', 'HTML', 'CSS', 'React', 'MobX' ] } 对象字面量可以将一个具象的事物在计算机程序中抽象化表达，但同时也可以将一个抽象的事物变得更为具象，就好比这一篇文章原本是一个抽象的事物，而在程序中却可以将其具象化表达。 const post = { title: '基本数据处理 · 对象字面量', serialNo: 2, parentBook: { title: '基于 JavaScript 开发灵活的数据应用', author: { name: '小问', title: '多领域开发者', domains: [ 'Web 开发', '大数据', '机器学习' ] } }, content: '......' } 当然对象的属性键（Key）也并非只能用这样的方式定义，如果说需要为一个数值定义一些数学特征值，包括底数为 2 的对数、底数为自然对数 的对数以及底数为 10 的对数。 const x = 1024 function getBaseLog(base, x) { return Math.log(x) / Math.log(base) } const baseLog = { 2: getBaseLog(2, x), e: getBaseLog(Math.E, x), 10: getBaseLog(10, x) } console.log(baseLog) //=> {2: 10, 10: 3.0102999566398116, e: 6.931471805599453} 当需要描述的事物更加抽象时，可能连属性键都会是动态生成的，那么这时候就需要更高级的语法来实现这样的需求了。 const prefix = 'MK' const sourceVersion = 1 const latestVersion = 47 const ironMan = { [prefix + sourceVersion]: '2008', [prefix + latestVersion]: '2017' } console.log(ironMan.MK47) //=> 2017 在 { []: value } 中的 expression 为一个表达式，即可以计算出结果的代码，如上面一段代码的 prefix + sourceVersion。 3.2 对象内容操作 对象被定义以后，自然就是对其的使用，而最直接的便是对对象内容的读取和写入。 3.2.1 对象内容读取 JavaScript 中对象内容读取十分的简单，如果属性键为字符串，且该字符串中只包含英文字母和下划线的话，可以直接用 . 来读取属性值。 const post = { title: '基本数据处理 · 对象字面量', serialNo: 2, parentBook: { title: '基于 JavaScript 开发灵活的数据应用', author: { name: '小问', title: '多领域开发者', domains: [ 'Web 开发', '大数据', '机器学习' ] } }, content: '......' } console.log(post.title) //=> 基本数据处理 · 对象字面量 console.log(post.parentBook.author.name) //=> 小问 而当对象中所需要读取的目标属性键为数字、包含英文字母和下划线以外的字符串甚至是 Symbol 对象的时候，就需要使用 obj[key] 的形式来读取属性值了。 const obj = { 1: 2, 'a b c': 'd e f', [Symbol.for('foo')]: 'bar' } console.log(obj[1]) //=> 2 console.log(obj['a b c']) //=> d e f console.log(obj[Symbol.for('foo')]) //=> bar 3.2.2 修改对象内容 虽然使用 const 语句所定义的对象是不能直接被替换的，但是其中的内容依然能被修改。 关于 const、let 和 var 的故事，可以自行搜索，也可以参考笔者的《实战 ES2015》，其中有很详细的讲解。 在 JavaScript 中存在着“引用”和“值”的概念区别，当然这同样不是本书的讨论范围。简单地解释，就是对对象内容进行修改跟进行读取类似，只是在读取语句后面加上 = 即可。 const obj = { foo: 'bar', 1: 2, 'a b c': 'd e f', [Symbol.for('foo')]: 'bar' } obj.foo = 'rab' obj[1] = 3 console.log(obj.foo) //=> rab console.log(obj[1]) //=> 3 当然，当你需要为一个对象添加新的属性时，也是通过同样的方式添加属性。 const obj = {} obj.foo = 'bar' obj[1] = 2 但要非常注意的是，在一般情况下，无论是对对象进行添加、读取还是修改属性，都遵循着嵌套链完整的原则，具体如下例所示。 const outer = { inner: {} } outer.inner.foo = 'bar' // OK outer.something.bar = 1 // Error! 小结 对象可以说是在 JavaScript 编程开发中最最重要的概念，懂得如何在最基础的知识上学会灵活使用，在后面的学习和开发中你会变得事半功倍。 习题 请用对象字面量描述自己，尽可能多地丰富对象属性内容，并注意其中的层级嵌套关系。 "},"基于JavaScript开发灵活的数据应用/03.数组.html":{"url":"基于JavaScript开发灵活的数据应用/03.数组.html","title":"03.数组","keywords":"","body":"第 4 节 基本数据处理 · 数组 让我们再次把目光放回我们在第 2 节中提出的大数据中的 “Hello World” 词频统计上。在前面的章节中，我们将 MIT 开源协议中的一部分文本进行了预处理，并将这个文本切割成以字符串为元素的数组。 那么我们就可以开始学习如何处理数组、更强的数组以及使用数组完成我们的案例。 4.1 数组 数组在数学中也可以称为“数列”，也就是以数字或其他类型内容为元素的有序集合。 // 整型数字数组 const intArray = [ 1, 2, 3, 4, 5 ] // 浮点型数字数组 const floatArray = [ 1.1, 1.2, 1.3, 1.4, 1.5 ] // 字符串数组 const strArray = [ 'a', 'b', 'c', 'd', 'e' ] 在第 2 节中我们完成的将文本预处理便是将一段较长的文本变成了这种字符串数组。在数据科学领域中，数组可以说是承载了绝大部分数据的表达任务，无论是规整的数据表，还是随时间排序的时间序列，或是复杂多变的非结构化数据，都可以使用数组或类数组的形式表达。 4.1.1 长度 我们前面讲到数组是一个有序集合，那么就意味着它包含了若干个元素。当然了，数组可空。因为它是一个包含了若干元素的集合，所以它就肯定天然地包含了一个属性，那便是元素的数量。 const array = [ 1, 2, 3, 4, 5 ] console.log(array.length) //=> 5 4.1.2 修改内容 因为在计算机中的可用内存是有限的，所以大部分程序在创建数据（比如数组）的时候，都需要先设定好该数据的所占长度。但在 JavaScript 中这并不需要，因为实际在 JavaScript 中数组就是一个特殊的对象，但这并不在讨论范围内。 所以在 JavaScript 中，对数组内容的修改会比较方便。“增查改删”是数据库应用领域中最常见的操作，这在数组中也是一样的。 增加内容 一般来说向数组增加内容是在数组的末端新增内容（Append），当然也可能存在将新内容添加到数组首端或是插入到中间的某一个部分的需求。 添加到末端 Append Append 操作在 JavaScript 中使用 array.push(element1[, ...[, elementN]]) 方法直接实现。 const array = [] array.push(1) console.log(array) //=> [1] array.push(2, 3) console.log(array) //=> [1, 2, 3] console.log(array.length) //=> 3 添加到首端 Prepend 添加到首端的操作在 JavaScript 中可以使用 array.unshift(element1[, ...[, elementN]]) 方法。 const array = [ 4, 5 ] array.unshift(3) console.log(array) //=> [3, 4, 5] array.unshift(1, 2) console.log(array) //=> [1, 2, 3, 4, 5] 插入到中间某位置 Insert 有的时候我们还需要往数组中的某一个位置添加元素。但需要注意的是，在 JavaScript 中数组元素的位置是从 0 开始的，也就是数组的第一个元素的下标为 0，第二个为 1。 假设我们需要在数组 [ 1, 2, 4, 5 ] 中的第三个位置，即下标为 2 的位置上添加元素 3。这需要用到 array.splice(start, deleteCount, element1[, ...[, elementN]]) 方法。你可以注意到该方法第二个参数是 deleteCount，因为这个方法也可以用来删除数组中某一个位置开始的若干个元素，而当我们将这个参数设置为 0 的时候，该方法第三个以及后面的参数便会插入到下标为 start 的位置，后面的元素自动往后推导。 const array = [ 1, 2, 6, 7 ] array.splice(2, 0, 3) console.log(array) //=> [1, 2, 3, 6, 7] array.splice(3, 0, 4, 5) console.log(array) //=> [1, 2, 3, 4, 5, 6, 7] 查找内容 因为我们说数组是一个有序集合，所以我们在对数组中的元素进行查找的时候也是一个有序进行的过程，而最常用的内容查找方法便是 filter 过滤器。 过滤器的逻辑便是定义一个过滤函数，该函数会有序地被传入数组中当前下标的元素，而它则需要返回该函数是否符合其过滤要求，即结果为 true 或 false。 假设我们需要在数组 [1, 2, 3, 4, 5, 6, 7, 8] 中找出偶数项，即对元素进行对 2 求余结果为 0 时即为偶数。 const array = [ 1, 2, 3, 4, 5, 6, 7, 8 ] const evenNumbers = array.filter(function(x) { return x % 2 == 0 }) console.log(evenNumbers) //=> [2, 4, 6, 8] 删除内容 删除内容在实际应用中有非常多的含义，有可能是删除不符合某一种条件的元素，那么使用过滤器即可实现；有可能是需要删除某一个位置上的元素，那么就需要使用上面提到的 array.splice(start, deleteCount) 方法。 比如我们要删除数组 [1, 2, 3, 10, 4, 5] 中下标为 3 的元素 10，就可以这样使用，删除从位置 3 开始的 1 个元素。 const array = [1, 2, 3, 10, 4, 5] array.splice(3, 1) console.log(array) //=> [1, 2, 3, 4, 5] 更新内容 对数组中的某一个元素进行修改，这种操作与对象中的修改对象属性内容是一样的，因为数组就是一个特殊的对象（属性键为自增长自然数）。 const array = [ 1, 2, 3, 4, 5 ] array[0] = 10 console.log(array) //=> [10, 2, 3, 4, 5] “题外话”：封装数组操作工具 虽然绝大多数操作都可以直接使用 JavaScript 中自带的 API 来实现，但是如 array.splice() 这种方法看上去就很容易产生操作错误。那么为了避免开发中的失误，我们可以通过定义一个抽象对象来封装一个用于操作数组的工具库。 const arrayUtils = { // methods } 添加内容 前面我们说道了为数组添加内容有三种模式：末端添加、首端添加和中间插入，那么我们就可以分别为它们封装好 append、prepend 和 insert 函数。 const arrayUtils = { // ... append(array, ...elements) { array.push(...elements) return array }, prepend(array, ...elements) { array.unshift(...elements) return array }, insert(array, index, ...elements) { array.splice(index, 0, ...elements) return array } } // 使用 const array = [] arrayUtils.append(array, 3) // 末端添加元素 3 arrayUtils.prepend(array, 1) // 首端添加元素 1 arrayUtils.insert(array, 1, 2) // 在位置 1 添加元素 2 console.log(array) //=> [1, 2, 3] 删除内容 因为要删除数组中的某一个元素同样需要用到 array.splice() 方法，为了避免歧义我们也可以将其封装到工具库中。 const arrayUtils = { // ... remove(array, index) { array.splice(index, 1) return array } } // 使用 const array = [ 1, 2, 3 ] arrayUtils.remove(array, 1) console.log(array) //=> [1, 3] 4.1.3 以数组为单位的基本处理方法 我们前面对数组的介绍，全部都是以元素为单位的操作。但是在大多数情况下，我们都需要以整个数组为单位进行运算，比如进行平均数计算等等。那么我们就需要有一些方法来对整个数组进行处理和计算。 一般来说对数组的总体进行处理可以归类为两个操作：转换和聚合。 转换 转换便是将一个数组中的内容，以一定的方式规律地转换为另一个数组内容。为什么要进行数据转换？因为有时候并不是天生就是可计算的，比如视频、图像、声音和文本等等，而当我们讨论运算的时候，都是以数字为运算的基础。那么为了方便进行运算，就需要先将这些“不可计算”的数据转换为数字，就比如我们前面学习字符串处理的时候就使用过了将英文字母转换为 ASCII 码的过程。 在 JavaScript 中对数组进行“扫描”有不少方法，如前面提到过的 filter、只进行循环的 forEach、与 filter 类似的但只返回第一个匹配值的 find，以及接下来我们需要用到的用于进行数据转换的 map 和用于聚合数据的 reduce。 假设我们需要将数组 [ 1, 2, 3, 4, 5 ] 中的每一个元素都转换为较其增 2 的数值，也就是说要给每一个元素做 + 2 的操作，那么我们就可以使用 array.map(callback) 方法来实现。 const array = [ 1, 2, 3, 4, 5 ] const addedArray = array.map(function(x) { return x + 2 }) console.log(addedArray) //=> [3,4,5,6,7] 当然我们也可以用来做不同数据类型之间的转换，比如由 ASCII 码组成的数组 [ 72, 101, 108, 108, 111, 32, 87, 111, 114, 108, 100 ]，我们需要把它转化为对应的字符串数组就可以这样做。 const asciiArray = [ 72, 101, 108, 108, 111, 87, 111, 114, 108, 100 ] const charArray = asciiArray.map(function(ascii) { return String.fromCharCode(ascii) }) console.log(charArray) //=> [\"H\", \"e\", \"l\", \"l\", \"o\", \"W\", \"o\", \"r\", \"l\", \"d\"] 聚合 什么是聚合？或许我们刚开始听到这个词的时候会“一脸懵逼”，而看到 reduce 这个方法名的时候则更是头疼了。其实不用担心，这个方法在我们很多年前学习加法运算的时候就已经使用过了。不相信吗？我们来接着看。 我们来回忆一下当年我们是怎么一步一步做 1 + 2 + 3 + 4 这道加法运算题的。根据从左到右的运算法则，我们需要首先计算 1 + 2 等于 3；然后将这个和再与 3 相加得到 6，并且以此类推最终得到了这个式子的结果为 10。 而其实这个过程就是 reduce 方法的过程。我们换做使用 JavaScript 来实现便是这样的。 const array = [ 1, 2, 3, 4 ] const sumResult = array.reduce(function(left, right) { return left + right }) console.log(sumResult) //=> 10 为此我们就可以对这个聚合结果做一个小封装，比如求数组中数值相加的和与相乘的积。 const array = [ 1, 2, 3, 4 ] function sum(array) { return array.reduce(function(left, right) { return left + right }) } function multi(array) { return array.reduce(function(left, right) { return left * right }) } console.log(sum(array)) //=> 10 console.log(multi(array)) //=> 24 甚至我们还可以将这个封装的程度再往抽象的方向进一步发展，这其中涉及了一些函数式编程的概念。 const array = [ 1, 2, 3, 4 ] function reduceFn(callback) { return function(array) { return array.reduce(callback) } } const sum = reduceFn(function(left, right) { return left + right }) const multi = reduceFn(function(left, right) { return left * right }) console.log(sum(array)) //=> 10 console.log(multi(array)) //=> 24 又一个“题外话”：Lodash 工具库 Lodash 是一个包含了非常多实用工具函数的 JavaScript 工具库，其中也包括了非常多我们在对对象型、数组型数据进行处理时需要用到的函数。我们在实际开发中可以借助 Lodash 以大大提高我们的开发效率。 安装 Lodash 工具库的方法有很多，如果你目前正在浏览器环境中使用 JavaScript 进行开发，那么就可以在 HTML 文件的 head 部分中加入以下代码以加载 Lodash 工具库。 使用 Lodash 实现数组相加 正好我们可以使用 Lodash 来实现我们前面所用到的数组相加。 const array = [ 1, 2, 3, 4 ] const sumResult = _.sum(array) console.log(sumResult) //=> 20 是的！Lodash 早就已经为我们提供了这个用于计算数值数组中所有元素相加的函数了。当然，Lodash 的实用性可不止如此，后面我们可以继续来学习。 4.1.4 “更强”的数组 我们前面接触到的数组基本都是只包含了像数值、字符串这样的简单元素。那么如果说数组所包含的元素是更为复杂的对象，甚至是数组呢？实际开发经验告诉我们，除了包含数值、字符串这样的简单数据外，我们还需要“更强”的数组以对付更复杂的需求。 比如我们需要使用一个数组来存储某个部门的人员数据，那么该数组中的元素就应该代表了该部门中的每一个人的抽象映射。而为了能够表达一个人的各种属性，我们需要用对象来完成这样的需求，也就是说我们需要让对象成为数组的元素内容。 const crew = [ { name: 'Peter', gender: 'male', level: 'Product Manager', age: 32 }, { name: 'Ben', gender: 'male', level: 'Senior Developer', age: 28 }, { name: 'Jean', gender: 'female', level: 'Senior Developer', age: 26 }, { name: 'Chang', gender: 'male', level: 'Developer', age: 23 }, { name: 'Siva', gender: 'female', level: 'Quality Assurance', age: 25 } ] 而当我们需要表达一个抽象的二维空间（比如数学中的直角坐标系）甚至更高维度空间中的许多点的集合时，每一个点都可以使用一个向量来表示其在对应空间中的位置，比如 [ 3, 5 ]。那么自然地，用于表达这些点的集合的数组就是一个以数组为元素的数组了。 const points = [ [ 1, 1 ], [ 2, 3 ], [ 3, 5 ], [ 4, 7 ], [ 5, 10 ], [ 6, 15 ] ] 甚至我们有的时候还需要一个数组中有着不同类型的元素，比如混杂着字符串和数值。 const array = [ [ 'Hello', 1 ], [ 'World', 1 ] ] 这些更复杂的数组有什么实际的用途，我们下一节见分晓。 小结 数组是现实世界中绝大部分数据的主要呈现形式，学会如何灵活地使用数组类型的数据，对数组本身进行测量、对数组中的元素进行操作，那么你就已经可以非常自豪地大声说：我已经踏入了数据科学的大门了！ 习题 将数组 [ 1, 2, 3, 4, 5 ] 转换为 [ 'a1', 'a2', 'a3', 'a4', 'a5' ]； 将数组 [ 1, 2, 3, 4, 5 ] 转换为 [ 'a1', 'b2', 'c3', 'd4', 'e5' ]； 将数组 [ 1, 2, 3, 4, 5 ] 转换为 [ 1, 4, 9, 16, 25 ]； 查询 JavaScript 中 Array.prototype.map 方法的详细文档，并将数组 [ 0, 0, 0, 0, 0 ] 转换为 [ 'A', 'B', 'C', 'D', 'E' ]； 提取数组 [ 1, 2, 3, 4, 5 ] 中的 [ 2, 3, 4 ]。 "},"基于JavaScript开发灵活的数据应用/04.基本统计.html":{"url":"基于JavaScript开发灵活的数据应用/04.基本统计.html","title":"04.基本统计","keywords":"","body":"第 5 节 基本数据处理 · 基本统计 学习了如何对 JavaScript 中的数组数据进行操作之后，我们就要回到刚开始选择购买这本小册的目的了：使用 JavaScript 开发灵活的数据应用。既然说是数据应用，那么便离不开统计计算，而数组就可以说是统计计算中的“第一要素”。 5.1 基本统计方法 我们经常能在各种地方听到这样的词语“平均”、“绝大部分”、“百分之三十”，这些都可以在统计学中找到对应的东西。比如“平均”就是平均值，或更专业的“数学期望值”，而“绝大部分”对应的就是“众数”。这些我们都可以将它们统称为数列的数学特征值。 5.1.1 平均值 如果没有学习过概率论的话，就可能会对平均值和数学期望值之间的关系和区别有所疑惑，那么我们这里就可以先简单地补一课。 数学期望值指的是在概率论中，一个数值集合总体中各种可能性的结合。举一个“栗子”，一个袋子中装有若干来自我国北方的板栗，以及若干来自我国南方的锥栗。那么经过无限次取出、记录并放回之后，我们可以假设计板栗为 -1，计锥栗为 1，经过简单的统计计算得出取出样本中板栗的概率 为 ，而锥栗的概率 为 。 值 板栗（-1） 锥栗（1） 概率 根据数学期望的计算公式可得，该袋子中栗子的期望值为 。 那么如果说我们假设这“无限次”的取出就是 5 次的话，就可以用这样的一个数组来表达记录的结果：[ -1, 1, -1, -1, 1 ]，其中板栗 3 次，锥栗 2 次。使用我们以往学习平均数的计算方法来计算的话就是。 可以发现其实数学期望值的计算方法和平均值的计算方法是非常相似的。不过从数学概念上，平均数是指在有限的样本空间内对样本的平均数值，而数学期望值是指总体空间中各种可能性（比如在这个“栗子”中的板栗和锥栗）的可能性结合。 扯了那么远，其实我们会发现在 JavaScript 中，我们使用 Lodash 来实现平均值的计算是那么的简单。 const array = [ 1, 2, 3, 4, 5 ] const mean = _.mean(array) console.log(mean) //=> 3 结合转换聚合的概念，我们来计算前面 4.1.4 节中部门人员数据的人员平均年龄。 const crew = [ { name: 'Peter', gender: 'male', level: 'Product Manager', age: 32 }, { name: 'Ben', gender: 'male', level: 'Senior Developer', age: 28 }, { name: 'Jean', gender: 'female', level: 'Senior Developer', age: 26 }, { name: 'Chang', gender: 'male', level: 'Developer', age: 23 }, { name: 'Siva', gender: 'female', level: 'Quality Assurance', age: 25 } ] const ages = _.map(crew, function(person) { return person.age }) const meanAge = _.mean(ages) console.log(meanAge) //=> 26.8 当然 Lodash 还提供了更为简单的函数来应对这样的数组计算。 const meanAge = _.meanBy(crew, 'age') // 或者 const meanAge = _.meanBy(crew, function(person) { return person.age }) 5.1.2 众数 除了平均数以外，我们最常用到的数学特征值恐怕就要数众数了，因为我们常常希望知道在一个群体中的最大多数是什么。而这就意味着众数并不代表只能用在数值数列上，也可以用于其他可以对比相同的元素上，比如字符串。 虽然说在众数计算中，除了先计算出所有可能性的频次以外，还可以使用摩尔投票算法（Boyer–Moore majority vote algorithm）。而摩尔投票算法的前提是数列中绝对存在一个频次最高的元素，即主要元素（Majority Element）。摩尔投票算法的好处是相比于使用哈希（Hash、Map、Object等）进行频次统计经典方法的非线性时空复杂度，摩尔投票算法有非常良好的 O(n) 时间复杂度和 O(1) 的空间复杂度。但由于在很多情况下我们并不仅仅是想要单一的一个众数，而是想要“频次出现最多的若干个情况”，所以我们这里暂不会对这种算法进行介绍。 而既然我们需要使用最经典的逐一计算每种可能性的频次，那么就让我们再次回到第 2 节中我们提出的词频统计吧。 5.1.3 词频统计 一般来对数组中的各种可能性进行频次统计，是先创建一个用于记录频次的对象，然后通过遍历数组中的每一个元素，并将其一个一个放入到前面创建的对象中以记录频次。但是自从我们学会了使用 Map 和 Reduce 开始我们就可以使用更直观的方式进行统计。 首先把每一个词使用变换函数将其变成一个以单词为第一元素，以 1 为第二元素的数组，我们可以将其称为 Tuple，相当于对象中的一个键值对。 \"hello\" -> [ \"hello\", 1 ] 既然我们将单词转换成了多个 Tuple 键值对的键，那么我们是不是可以使用这个特性更方便地进行 Reduce 呢？是的，我们可以将其称为 reduceByKey。在一般情况下的 Reduce 函数是用于遍历整个数组的，而 reduceByKey 则是根据 Tuple 集中的键首先进行一次分类组合，将具有相同键的值进行组合，然后对每一个组合集进行单独遍历。 不幸的是，无论是原生 JavaScript 中还是 Lodash 中并没有这样的 API。但是我们却可以使用 Lodash 的函数进行组合，对 Lodash 进行拓展。 _.reduceByKey = function(tuples, reduceCallback) { const grouped = _.groupBy(tuples, function(tuple) { return tuple[0] }) return _.toPairs(_.mapValues(grouped, function(tuples) { return _.chain(tuples) .map(function(tuple) { return tuple[1] }) .reduce(reduceCallback) .value() })) } 我们在第 2 节中通过使用正则表达式将 MIT 开源协议中的一部分内容进行了数据清洗和分割。 const originalText = 'Permission is hereby granted, ...' const words = originalText.toLowerCase().match(/\\w+/g) 那么我们按照 Map 和 Reduce 的思路进行一下词频统计，首先将单词字符串转换为 Tuple，然后再使用 reduceByKey 进行聚合统计。 const tuples = words.map(function(word) { return [ word, 1 ] }) const wordCountResult = _.reduceByKey(tuples, function(left, right) { return left + right }) console.log(wordCountResult) //=> [[\"permission\", 2], [\"is\", 4], [\"hereby\", 1], [\"granted\", 1], [\"free\", 1], …] 现在我们有了一个统计了不同单词在 MIT 开源协议中频次的统计结果，接下来让我们继续进行下一步操作。 5.1.4 排序 既然我们已经对不同的单词频次进行了统计，那么我们应该要知道哪些单词出现次数最多，哪些出现最少吧？所以我们需要对上面的统计结果按照频次从大到小或从小到大排序。 排序算法有非常多种，但是这并不在我们的讨论范围内，如果感兴趣的话，可以参考 Wikipedia 中的排序算法页面。 我们可以直接使用 JavaScript 中的 array.sort 方法进行简单的排序。 array.sort 方法需要传入一个回调函数，这个回调函数是用于比对两个元素，以确定两者之间的排序。而在这过程中也可以将元素中真正需要用于排序的“元素”取出，也可以先将元素进行转换。比如本小册 4.1.4 小节中的 crew 数组中的 age 是用于排序部门人员年龄大小的元素。而这里则是每一个 Tuple 中的值，也就是数组的第二元素。 const sorted = wordCountResult.sort(function(leftTuple, rightTuple) { return rightTuple[1] - leftTuple[1] }) console.log(sorted) //=> [[\"the\", 14], [\"or\", 9], [\"software\", 9], [\"of\", 8], [\"to\", 8], …] 5.1.5 裁剪 有了排序之后的统计结果，我们就可以从中取出一部分用于展示统计结果了，比如“频次最多的 5 个单词”和“频次最少的 5 个单词”等。 这里我们可以用到 JavaScript 原生的 array.slice，正如这个方法的字面意思那样，这个方法的用途就是对数组进行切片，比如前 5 个元素的切片、后 5 个元素的切片和中间某个范围的切片等。 比如我们需要知道词频统计结果中，频次最多的 5个单词是哪些。那么我们就可以对已经经过从大到小排序的统计结果中，选取前 5 个元素的切片。 const top5 = sorted.slice(0, 5) array.slice 方法传入两个参数，一个是目标切片的起始位置，一个是结束位置。选取前 5 个元素也就是选取从下边为 0 的元素开始到下标为 5 的前一个元素结束。是不是觉得很复杂？那我们可以选择使用 Lodash 提供的 _.take 函数。 _.take 函数除了第一个参数为被处理数组外，还接受一个参数为个数 n，也就是该函数会返回数组中前 n 个元素的切片。 const top5 = _.take(sorted, 5).map(function(tuple) { return tuple[0] }) console.log(top5) //=> [\"the\", \"software\", \"or\", \"to\", \"of\"] 而如果需要知道出现频次最少的 5 个单词，那就取统计结果的后 5 个元素即可。而 Lodash 同样提供了一个 _.takeRight 函数，用于从数组的右端（也就是末端）开始选取元素。 const minimal5 = _.takeRight(sorted, 5) console.log(minimal5) //=> [[\"from\", 1], [\"out\", 1], [\"connection\", 1], [\"with\", 1], [\"above\", 1]] 小结 在学会了如何使用数组存储和操作数据之后，在本节中我们学会了如何使用一些基本的数学和统计知识来对数组中的元素进行基本的运算。非常好，我们要保持好这样的学习节奏。 到此我们已经完成了 JavaScript 中基本数据结构及其基本处理方法的学习，接下来我们正式要开始学习较为复杂的数据处理、数据可视化以及动态数据应用的开发了，你准备好了吗？ 习题 设某次投票结果为如下 [ 1, 2, 3, 2, 2, 3, 1, 4, 4, 1, 2, 1, 1, 3, 4 ]，请统计投票结果并找出票数最多的选项； 假设某一时间记录软件记录下一个人一天 24 小时中每一个小时的工作状态，其中分别以范围为 1 ~ 8 的自然数标识，1 为生产力最差的程度，而 8 则为生产力最佳的状态。而该软件记录了某人一天的数据为 [ 1, 1, 1, 1, 1, 1, 1, 1, 6, 7, 8, 4, 3, 7, 8, 8, 6, 6, 4, 3, 3, 3, 1, 1 ]。假设区间 1 ~ 3 为生产力较低，4 ~ 5 为生产力一般，6 ~ 8 为生产力较高。请统计并分析这份数据中一天的工作状态。 "},"基于JavaScript开发灵活的数据应用/05.使用序列.html":{"url":"基于JavaScript开发灵活的数据应用/05.使用序列.html","title":"05.使用序列","keywords":"","body":"第 6 节 复杂数据处理 · 使用序列 我们常使用数组作为存储一系列数据的方式，而在 JavaScript 中数组是非常强调顺序的一种数据结构。但我们在日常使用的时候，并不是所有的数据都是完全遵守等间距的。可能每两个数据之间从特定的维度上观察是呈现的间断性，而非连续性。 其中最为典型的就是时间序列，从物理传感器传来的数据、智能穿戴设备的记录数据等等都是经常会出现不连续的现象，这些数据从时间维度上观测会发现基本上是无规律间隙性的。那么我们就不能简单地使用数组进行记录。 为了更为准确地记录和表达这些数据，我们需要使用到第 4 节中我们所提到的“更强”的数组。将用于表达顺序的标签从 JavaScript 数组中的下标，改变为对象元素中的某一个标签。 6.1 时间序列 时间序列一般用于表达一组建立在时间轴上的数据，比如工业生产设备中传感器所定时记录的数据，但由于传感器设备同样存在误差，而且由于实际应用中也有可能出现不工作的情况，所以真正所记录下来的数据很有可能是断断续续的。 在这图中你会看到并不是每一秒钟都会记录有数据，这种数据集我们可以将其称为稀疏序列，虽然我们可以使用插值、拟合等方式将这些空缺的数据补上，但是这涉及更为复杂的数学运算所以不会在本小册的讨论范围之内，感兴趣的同学可以查询“数值计算”相关的文献和书籍进行学习。 回到正题上，我们需要使用“更强”的数组来进行对时间序列的存储，那么自然就意味着数组元素中必定包含用于存储每一个数据点所对应的时间戳（Timestamp）。在 JavaScript 中，一般使用毫秒级 Unix 时间戳作为时间的基本表达方式。毫秒级 Unix 时间戳即以格林尼治时间 1970 年 1 月 1 日 0 点 0 分开始，每经过一毫秒（ 秒）即记数 1。如 2018 年 1 月 1 日 0 时 0 分整点使用毫秒级 Unix 时间戳则为 1514736000000。 在 JavaScript 中我们可以使用 Date.now() 方法来获取当前设备中所记录的当前毫秒级 Unix 时间戳。同样的也可以使用 new Date(timestamp) 的方式将以数值为表达方式的时间戳转换为以 JavaScript 中用于表达时间（包括日期和时间）的 Date 类型。 假设我们有以下记账数据，并以时间序列的形式存储。 时间 类型 价格 Thu Mar 01 2018 08:31:32 餐饮 6.00 Thu Mar 01 2018 11:27:52 餐饮 12.00 Thu Mar 01 2018 18:24:09 餐饮 52.50 Fri Mar 02 2018 09:14:09 餐饮 4.50 Fri Mar 02 2018 11:58:22 餐饮 13.50 Fri Mar 02 2018 22:10:49 餐饮 104.25 这是某人两天的一日三餐记账记录，假设我们使用 JavaScript 的形式进行存储的话就可以使用以带有时间戳 timestamp 属性的对象作为数组的元素。 let transactions = [ { timestamp: 1519864292535, category: '餐饮', price: 6.00 }, { timestamp: 1519874872261, category: '餐饮', price: 12.00 }, { timestamp: 1519899849526, category: '餐饮', price: 52.50 }, { timestamp: 1519953249020, category: '餐饮', price: 4.50 }, { timestamp: 1519963102270, category: '餐饮', price: 13.50 }, { timestamp: 1519999849526, category: '餐饮', price: 104.25 } ] 如果我们将这些数据放到时间轴上，就可以发现这些记录值间歇性地分布在时间轴上，中间的间隔也并非一定。 6.1.1 处理时间 在时间序列中，顾名思义其最重要的参数便是序列元素中的时间戳。但由于在实际研究和应用中，我们大多并不需要将统计分析的精度精确到毫秒级或是秒级，更多的情况是以每天、每周、每月和每年的方式进行统计。 所以我们在处理时间序列的时候，首先需要做的是如何将时间序列中的高精确度记录数据进行整合，首先聚合出一定时间范围内的平均、总体记录结果。 在 JavaScript 中处理时间，我们可以首先使用 Date 类型将以整型为存储介质的时间戳转换为 Date 类型。 transactions = transactions.map(function(data) { data.timestamp = new Date(data.timestamp) return data }) 这样我们就已经将现有数据中的时间戳变成了可以用于进行详细操作的 Date 类型对象，接下来就可以将其进行时间范围的分组操作。 但是跟 JavaScript 中的数组一样，JavaScript 中的 Date 对象虽然本身也已经提供了非常多很实用的方法，但是这远远不足以满足我们的实际需求。所以我们这里再次引入一个第三方工具库 Moment.js。 引入 Moment.js Moment.js 是一个专门用于处理 JavaScript 中 Date 类型数据的工具库，它除了提供用于设置和提取时间对象中的各种参数（时、分、秒、日期等）外，还可以根据不同的表达格式进行字符串渲染，得到需要的时间格式。 将以下 HTML 标签直接加入到 head 头部中，或者在 CodePen 的设置中加入 Moment.js 的链接即可。 在使用 Moment.js 之前，我们同样需要将时间戳转换为 Moment 类的对象，支持直接将以整型的时间戳或 Date 类型转换为 Moment 对象。 transactions = transactions.map(function(data) { data.moment = moment(data.timestamp) return data }) 按天分组 对于记账数据来说，一般来说我们需要进行最小颗粒统计便是以天为单位的计算。那么我们首先就需要对记录数据中的时间戳进行处理，得到对应的日期。 使用 Moment.js 进行日期提取非常简单，Moment.js 允许对时间对象进行格式化。比如我们若需要将时间转换为以 年-月-日 为格式的字符串，就可以使用 moment.format('YYYY-MM-DD') 进行格式化。 结合前面我们学习过的 LoDash 工具库，我们可以使用 _.groupBy 函数进行分组。 const transactionsGroupedByDate = _.groupBy(transactions, function(transaction) { return transaction.moment.format('YYYY-MM-DD') }) console.log(transactionsGroupedByDate) // => { // \"2018-03-01\": [{...}, {...}], // \"2018-03-02\": [{...}, {...}] // } 按周分组 除了按天计算以外，我们对于我们的记账数据往往对每周的开销更为看重。然而实际上如何把时间按周分组确实是一个“技术活”，因为我们往往不能保证每年 1 月 1 日和每个月的第一天都是周日（每周的第一天）。 一般情况下一年有 365 天（闰年有 366 天），以一周 7 天为标准，所以一年就有 周，也就是一年有 52 个星期多一到两天。 如果严格使用周日为一周的第一天原则，就需要精确到天来确定某一天处在于某一年的第几个星期。当然我们不需要太过于纠结于这个，因为 Moment.js 已经帮我们封装好这样的转换工具了。 在调用 moment.format(pattern) 方法时使用 \"WW\" 可以获取两位数的周数（01 ~ 53），为了根据周分组我们可以按 \"YYYY-WW\" 作为分组标签。 const transactionsGroupedByWeek = _.groupBy(transactions, function(transaction) { return transaction.moment.format('YYYY-WW') }) console.log(transactionsGroupedByWeek) // => { // \"2018-09\": [{…}, {…}, {…}, {…}, {…}, {…}] // } 按月、年分组 除了按星期作为分组以外，我们也需要看看我们一个月内我们究竟花了多少钱，而且对于个体户来说一个月的收支更是重要。按月分组跟按周分组非常相似，只是在调用 moment.format(pattern) 时，将 \"WW\" 改成 \"MM\" 即可。 const transactionsGroupedByMonth = _.groupBy(transactions, function(transaction) { return transaction.moment.format('YYYY-MM') }) console.log(transactionsGroupedByMonth) // => { // \"2018-03\": [{…}, {…}, {…}, {…}, {…}, {…}] // } 按照年来分组则同理，对格式化方式进行更改就可以了。 const transactionsGroupedByYear = _.groupBy(transactions, function(transaction) { return transaction.moment.format('YYYY') }) console.log(transactionsGroupedByYear) // => { // \"2018\": [{…}, {…}, {…}, {…}, {…}, {…}] // } 分组整合 是否觉得我们一个一个时间单位地分别进行分组太麻烦了？不用担心，回想一下我们在进行数组操作的时候，我们曾为数组的操作封装过一个工具，那么我们也同样可以为时间序列封装一个工具来方便我们使用时间序列。 function createTimeSeries(timeSeriesArray) { const timeSeriesObj = { array: timeSeriesArray.map(function(data) { data.moment = moment(data.timestamp) return data }), groupByFormat(formatPattern) { return _.groupBy(timeSeriesObj.array, function(data) { return data.moment.format(formatPattern) }) }, groupByDate() { return timeSeriesObj.groupByFormat('YYYY-MM-DD') }, groupByWeek() { return timeSeriesObj.groupByFormat('YYYY-WW') }, groupByMonth() { return timeSeriesObj.groupByFormat('YYYY-MM') }, groupByYear() { return timeSeriesObj.groupByFormat('YYYY') } // ... } return timeSeriesObj } const timeSeries = createTimeSeries(transactions) console.log(timeSeries.groupByMonth()) 6.1.2 时间序列统计计算 我们已经将账单数据按照时间进行了分组，但是当我们打开一个记账软件的时候难道只会看某一天我花了哪些钱吗？我自然希望能够知道这一天我花了多少钱、一周内花了多少钱、一个月内花了多少钱、一般是周几的时候花钱最多、一周平均每天花多少钱等等计算结果。 而我们前面已经将数据按周、月进行分组，但是我们同样需要在按周、月分组之后再进行按天分组，因为我们需要看到一个星期、一个月内每天的开销统计。 计算每天开销情况 要计算每天的开销情况，不一定是需要先将数据分组好以后再进行处理，而我们在进行分组的时候就可以直接完成我们需要的统计计算。 首先我们第一步就是需要从知道每天花了哪些钱，变成知道每天花了多少钱，那么我们就需要进行求和计算。在第 4 节中我们介绍过 LoDash 工具库中的 _.sum 函数，而 LoDash 工具库同时还提供了一个 _.sumBy 函数以用于处理我们较为复杂的多维数组。 我们前面定义了一个 timeSeriesObj.groupByFormat 方法，该方法返回的结果是一个以 { [date]: array } 为格式的对象（或叫映射集）。为了避免数据产生的大量冗余（重复、不必要的数据），我们可以再定义一个结果对象，将前面的日期集对象以 map 属性值存储，并且定义 dates() 以返回日期字符串集以便我们后面的使用。 再回到正题上，我们需要得到当前日期集中每一天的开销总和。但是让我们再次思考一个问题，是否一定要让每一天的统计值以实体数据（即内存变量）的方式存储呢？其实不必，我们可以以一种虚拟映射的方式表达这样的数据，即定义一个计算函数 sum(date)，只有当传入某一日期的时候才会返回该日期的统计结果，以节省内存空间。这些日期字符串我们就可以通过调用 dates 取得。 function createTimeSeries(timeSeriesArray) { const timeSeriesObj = { // ... groupByDate() { const groupedResult = { map: timeSeriesObj.groupByFormat('YYYY-MM-DD'), dates() { return _.keys(groupedResult.map) }, sum(date) { return _.sumBy(groupedResult.map[date], 'price') } } return groupedResult }, // ... } return timeSeriesObj } const timeSeries = createTimeSeries(transactions) const groupedByDateSeries = timeSeries.groupByDate() console.log(groupedByDateSeries.dates()) //=> [\"2018-03-01\", \"2018-03-02\"] const firstDate = groupedByDateSeries.dates()[0] console.log(groupedByDateSeries.sum(firstDate)) //=> 70.5 如果我们需要一次性打出所有日期的统计结果，我们可以简单地灵活使用 Array.map 方法即可。 groupedByDateSeries.dates().map(function(date) { return { date: date, sum: groupedByDateSeries.sum(date) } }) //=> [ // { date: \"2018-03-01\", sum: 70.5 }, // { date: \"2018-03-02\", sum: 122.25 } // ] 计算每周开销情况 完成了对每天开销情况的统计以后，我们就可以对更大时间范围的数据进行进一步的统计了，比如我们需要知道一周内的使用情况。那就可以在前面按天计算的前提下完成这个需求。 事实上 Moment.js 库非常的“聪明”，它可以自动检测我们传入的时间参数的格式（整数时间戳、时间字符串、日期字符串等等），并转化为标准的 Moment 时间对象。那么这就意味着可以直接传入前面使用 groupByDate.dates() 方法所得到的日期集合来进行聚合。 相比于 groupedByDate 直接建立从日期到数据集的直接映射，出于避免数据过度冗余的原则，在进行对星期聚合的时候我们选择从星期到日期的映射，再使用前面 groupedByDate 所建立的虚拟映射来完成新的虚拟映射需求。 const timeSeriesObj = { // ... groupByWeek() { const groupedByDate = timeSeriesObj.groupByDate() const groupedResult = { map: _.groupBy(groupedByDate.dates(), function(date) { return moment(date).format('YYYY-WW') }), weeks() { return _.keys(groupedResult.map) }, sum(week) { const dates = groupedResult.map[week] return _.sumBy(dates, function(date) { return groupedByDate.sum(date) }) }, average(week) { const dates = groupedResult.map[week] const sum = groupedResult.sum(week) return sum / dates.length } } return groupedResult }, // ... } 相比前面的 groupByDate，groupByWeek 还多了一个 average 虚拟映射以得到某一星期内每天开销的平均值。学会对星期进行分组聚合以后，对月和对年的实现就由你们来完成哦😃。 更为简单的组合接口 是否觉得目前对于获取每一个范围内的开销总和以及平均日开销太过于复杂？不用担心，经过了前面几节的学习之后，我们已经知道了如何使用函数和对象进行一些逻辑的封装，那么我们自然可以再继续将封装的程度往上堆叠，将 sum 和 average 从聚合结果中抽出。 function createTimeSeries(timeSeriesArray) { const timeSeriesObj = { // ... dates() { return timeSeriesObj.groupByDate().dates() }, weeks() { return timeSeriesObj.groupByWeek().weeks() }, months() { return timeSeriesObj.groupByMonth().months() }, years() { return timeSeriesObj.groupByYear().years() }, sum(unit, point) { switch (unit) { case 'date': return timeSeriesObj.groupByDate().sum(point) case 'week': return timeSeriesObj.groupByWeek().sum(point) case 'month': return timeSeriesObj.groupByMonth().sum(point) case 'year': return timeSeriesObj.groupByYear().sum(point) } }, average(unit, point) { switch (unit) { case 'week': return timeSeriesObj.groupByWeek().average(point) case 'month': return timeSeriesObj.groupByMonth().average(point) case 'year': return timeSeriesObj.groupByYear().average(point) } } } return timeSeriesObj } const timeSeries = createTimeSeries(transactions) console.log(timeSeries.sum('month', '2018-03')) //=> 192.75 console.log(timeSeries.average('month', '2018-03')) //=> 96.375 题外话：聚合缓存 经过了三层的封装之后，各种的聚合、提取的调用次数变得比较多。而为了能够让程序运行更加顺畅，内存调度更为节约，可以使用懒加载的方式缓存一些经常使用的聚合结果。 一般来说，缓存的存储位置是在封装层级较底层的位置，来进行存储和读取。而我们这里最为底层的封装位置则是最开始的 groupByFormat 函数。 我们可以在 createTimeSeries 函数中、创建 timeSeries 对象之前定义一个 caches 对象。然后在 groupByFormat 中首先检查 caches 对象中是否存在当前 formatPattern 的结果缓存，若存在则将其作为当前结果返回；在完成计算后就将其存储到 caches 对象中。 function createTimeSeries(timeSeriesArray) { const caches = {} const timeSeriesObj = { // ... groupByFormat(formatPattern) { if (caches[formatPattern]) { return caches[formatPattern] } const result = _.groupBy(timeSeriesObj.array, function(data) { return data.moment.format(formatPattern) }) caches[formatPattern] = result return result }, // ... } return timeSeriesObj } 小结 在现代社会中，几乎所有的大小单位团体都已经离不开账本系统，无论大至国家公司，还是小至家庭个人，都需要账本来记录和分析收支情况。而你已经在本节中学会了如何使用数组类型来存储这些收支数据，非常棒。 习题 请根据已有代码，完成以月聚合和以年聚合的处理方法。 在实际情况中，我们同样需要根据不同的支出分类（category）进行分组计算，请完成按分类计算的同时，支持按天、周、月、年进行分拣范围的统计。 "},"基于JavaScript开发灵活的数据应用/06.树形.html":{"url":"基于JavaScript开发灵活的数据应用/06.树形.html","title":"06.树形","keywords":"","body":"第 7 节 复杂数据处理 · 树形 什么是树形结构？树形结构无论是在计算机环境中，还是在我们的日常生活中都非常的常见，比如我们电脑中的文件夹结构、比如公司内部的人员结构，都是呈上一级元素和若干下一级元素组成的高维度结构。 为了能够在计算机程序中实现对树形结构的操作处理，工程师们发明了非常多不同种类的树形结构以及适合于它们的各种算法。但是我们这里不需要太深入地了解这些各式各样的结构和算法，我们只需要学习最朴素的简单树形即可。 当然如果有兴趣的话，您也可以通过《算法》、《算法导论》、《编程珠玑》等等经典的算法教材来学习更多树形结构及其相关算法。 7.1 创建节点 树形结构是由多个包含子节点内容的节点（Node）所组成的，也就是说树形结构由根节点开始至每一个叶节点为止，都是由同一种数据结构组成的。 一般来说，普通树形结构的节点由一个用于存储节点内容的空间，以及一个用于存储子节点的引用（在其他语言中也可以为指针）的数组所组成。 7.1.1 JavaScript 中的类（Class） 在学习如何创建一个树形结构的节点之前，我们需要首先来学习下如何使用 JavaScript 中的类语法，因为接下来非常多的数据应用开发中都离不开对类的使用。 类（Class）可以比喻为生物学中的物种，自然界中生物种类多得数不清，但是生物学家们却可以将它们逐一使用生物分类法进行分类，就好比威猛凶悍的狮子、老虎再到惹人喜爱的花猫、橘猫无论从体型、毛色上都有着天差地别，但都同属猫科动物。也好比我们智人这一种族也有非常多的“亲戚”，而哪怕是我们智人本身也有黄种人、黑种人、白种人，人与人之间也有着千差万别的多样性。 而在计算机中也同样有着这样的多样性，有着若干个相同性质的对象，但各自却有着不同的特性、内容、参数等等。这就需要类来进行表示和实现这种特性。 我们再次将具体事物抽象化，我们每一个人都有各自的名字，我们都能表达自己的欢迎之词，那么就用一个 Person 类来表达我们共同的物种——智人。 class Person { constructor(name) { this.name = name } hello() { return 'Hello, my name is ' + this.name } } const me = new Person('Will') console.log(me.hello()) //=> Hello, my name is Will constructor 为构建函数，定义包含一个 name 参数以将其赋予这个人实例本身以作为其名字；hello 方法用于表达作为智人的友好欢迎之词。 脱离动物世界，回到人类社会文明中来，我们不仅拥有名字，还有着更为复杂的家族关系，我们都有一个家族名（Family Name）也就是我们的姓氏，以组成我们完整的姓名。 class Person { constructor(givenName, familyName) { this.givenName = givenName this.familyName = familyName } hello() { return `Hello, my name is ${this.givenName} ${this.familyName}` } } const me = new Person('Will', 'Gunn') console.log(me.hello()) //=> Hello, my name is Will Gunn 在这个 Person 类中，我们定义了 givenName 和 familyName 两个属性，而在 JavaScript 的类中同时还允许定义虚拟属性，也就是 Getter。比如我们可以将姓与名结合在一起以组成我们的全名。 class Person { constructor(givenName, familyName) { this.givenName = givenName this.familyName = familyName } get fullName() { return `${this.givenName} ${this.familyName}` } hello() { return `Hello, my name is ${this.fullName}` } } const me = new Person('Will', 'Gunn') console.log(me.hello()) //=> Hello, my name is Will Gunn 类所产生的实例都是一个对象，所以我们在第 3 节中时就已经说明了，对象是一种可以表达万物的技术。非常好，你已经学会了如何使用 JavaScript 的类来表达一种事物了，那么就让我们开始回到正题上，创建一个树形结构中的节点吧。 7.1.2 定义节点类型 一般情况下每一个节点都包含一个用于存储内容的容器，我们可以使用一个简单的 value 属性来表达；而对于子节点的引用则可以使用一个数组属性 children 来承载。 class Node { constructor(value) { this.value = value this.children = [] } } const node = new Node('node value') 有了节点以后，就需要将多个节点组合起来了，比如将两个节点加入到另外一个节点中以作为其子节点。那么我们可以先为这个 Node 类添加一个 addChild 方法。 class Node { // ... addChild(node) { this.children.push(node) return this } } 你可能会问，为什么不直接使用 node.children.push(childNode)，而非要在外面包一层 addChild 方法？别着急，事情远没有那么简单，我们后面会慢慢讲解。 const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') const node3 = new Node('node 3') root.addChild(node1).addChild(node2) node1.addChild(node3) 这段代码中我们定义了四个节点，其中一个包含内容 root 的节点作为根节点，而节点 node 1 和 node 2 作为根节点的子节点，节点 node 3 作为节点 node 1 的子节点。从而形成了一棵非常简单的树形结构。 非常好，一个简单的树形已经构建出来了，那么接下来我们应该如何使用这棵树呢？一般来说每一种数据结构被发明出来就肯定会有其使用的方法和特征，就如数组结构有其长度特征 length，包含数字的数组则有平均值等等数学特征值。那么对于树形结构及其节点来说又有哪些特征值呢？ 结构 树（Tree） 名称 翻译 解析 root 根 一棵树的根节点 结构 节点（Node） 名称 翻译 解析 parent 父节点 一个节点的父节点 children 子节点（复数） 一个节点的子节点集合 siblings 兄弟节点 与某一个节点拥有相同父节点的其他节点 degree 度 以某一节点为根节点的子树的个数，也可以简单地理解为子节点数目 depth 深度 一个节点的深度被定义为该节点到根节点之间边*数 height 高度 一个节点到距离它最远的叶节点**中间的边数 [ * ] 边：Edge，节点与节点直接的连接被定义为边[ ** ] 叶节点：没有子节点的节点 在这份表格中你发现其实每一个节点还可以包含其父节点的信息，所以在之前的 Node 类中我们可以加入一个 parent 属性，以存储该节点的父节点。 而在前面定义的 addChild 方法中，我们就可以将定义父节点这个任务放在这里了。 class Node { constructor(name) { this.name = name this.parent = null // 默认一个节点在产生时为一个无父节点的根节点 this.children = [] } addChild(node) { node.parent = this this.children.push(node) return this } } 7.1.3 扩展节点类型 Siblings 兄弟节点 当每一个节点有了其父节点的信息之后，就可以去尝试访问它的兄弟节点了，通过查询 node.parent.children 中的节点排除掉自己后便是它的兄弟节点。 class Node { // ... siblings() { const self = this if (this.parent) { return this.parent.children.filter(function(node) { return node !== self }) } else { return [] } } } const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') const node3 = new Node('node 3') root.addChild(node1).addChild(node2) node1.addChild(node3) console.log(node1.siblings()) //=> [Node{'node 2'}] Degree 度 这个特征值的定义比较简单，在树形结构中，每一个节点的 degree 值就等于直接与它相连的子节点数。这里我们就可以用到前面学习到的“虚拟属性”了。 class Node { // ... get degree() { return this.children.length } } const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') root.addChild(node1) root.addChild(node2) console.log(root.degree) //=> 2 Depth & Height 深度与高度 深度（Depth）和高度（Height）可以说是树形结构中比较抽象且很有意思的特征值了。深度的定义为从某一个节点到其所在的树形结构中的根节点所经过边的数目。 就好比上面的例子中，从节点 node 3 到节点 node 1 最后到根节点 root 中间经过了两个边，所以节点 node 3 的深度则为 2。这个在 JavaScript 中也是非常好实现的，只需不断检查经过的每一个父节点是否存在继续往根部走的父节点，并记录循环次数即可。当找到了没有父节点的节点时，则该节点就是这棵树的根节点，而循环次数便是目标节点的深度值。 class Node { // ... get depth() { let depth = 0 let currNode = this while (currNode.parent != null) { depth++ currNode = currNode.parent } return depth } } const root = new Node('root') const node1 = new Node('node 1') const node3 = new Node('node 3') root.addChild(node1) node1.addChild(node3) console.log(node3.depth) //=> 2 而高度的定义则是以某一个节点为根所形成的树形结构（该树形结构可能是一棵更大的树形结构中的一部分，即子树）中，这个节点到最深的子节点中间经过的边的数目。 而深度和高度的关系，可以用一张图非常清晰的解释。 我们可以发现每一个节点的高度其实就是等于以该节点为根的的子树中，最深的一个子节点的深度。也就是说只要找到最深的一个子节点，并计算当前子树的深度即可。 但是我们前面在计算深度的时候是直接计算整棵树的深度，那么为了能够让每一个子节点都能够计算指定子树的深度，我们需要对前面的代码进行一些修改。 我们可以首先假设每一棵树的根目录都有一个虚拟的父节点 null，那么就直接在计算深度时候，将 currNode.parent != null 改成 currNode.parent != root，当 root 为 null 的时候将最后的结果加上 1 便是该节点到整棵树根节点的深度。 而为了能够将计算深度的算法使用在计算高度上，我们同时还需要将原本计算深度的算法提取出来，单独作为一个用于计算子树深度的方法。 class Node { // ... getDepthByRoot(root) { let depth = 0 let currNode = this while (currNode.parent !== root) { depth++ currNode = currNode.parent } return depth + 1 } get depth() { return this.getDepthByRoot(null) } } 那么问题来了，该如何找到一棵子树中的最深子节点呢？一般来说有两种方式，BFS（Breadth-first Search，广度优先搜索）和 DFS（Depth-first Search，深度优先搜索），而因为 DFS 的宗旨就是“不撞南墙不回头”，为了算法实现的简易性，我们这里选择 BFS 作为实现的方式。 如何使用 BFS 找到最深的子节点？那便是逐层给节点编号，直到最后一个就是最深的节点。当然我们也没有必要真的为它们编号，只需按层级顺序找到最深的一个即可。 定义一个 FIFO（First In First Out，先进的先出）的队列，将每一个层的节点不断地推入到这个队列中，并不断取出前面被推入的节点，并检查是否有子节点，直到最后一个节点便是最深子节点。 class Node { // ... get height() { const queue = [ this ] let deepestNode = this while (queue.length > 0) { const len = queue.length for (let i = 0; i 0) { queue.push(...currNode.children) } } } return deepestNode.getDepthByRoot(this) } } const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') const node3 = new Node('node 3') const node4 = new Node('node 4') const node5 = new Node('node 5') const node6 = new Node('node 6') root.addChild(node1) root.addChild(node2) node1.addChild(node3) node1.addChild(node4) node2.addChild(node5) node5.addChild(node6) console.log(root.height) //=> 3 console.log(node1.height) //=> 1 console.log(node2.height) //=> 2 7.1.4 树形节点代码清单 最后我们便得到了一个完整的树形结构节点类，以用于完成一些我们需要的需求实现。 class Node { constructor(name) { this.name = name this.parent = null this.children = [] } addChild(node) { node.parent = this this.children.push(node) return this } siblings() { const self = this if (this.parent) { return this.parent.children.filter(function(node) { return node !== self }) } else { return [] } } get degree() { return this.children.length } getDepthByRoot(root) { let depth = 0 let currNode = this while (currNode.parent !== root) { depth++ currNode = currNode.parent } return depth + 1 } get depth() { return this.getDepthByRoot(null) } get height() { const queue = [ this ] let deepestNode = this while (queue.length > 0) { const len = queue.length for (let i = 0; i 0) { queue.push(...currNode.children) } } } return deepestNode.getDepthByRoot(this) } toString(join = true) { let parts = [ this.name ] if (this.children.length > 0) { parts = parts.concat(this.children .map(function(node) { return node.toString(false) }) .reduce(function(left, right) { return left.concat(right) }) .map(function(line) { return ' ' + line }) ) } if (join) { return parts.join('\\n') } else { return parts } } } 7.2 定义树形结构 完成了节点的定义后，事实上我们已经可以实现树形结构的定义，并将数据存储在节点上了。但就如数组和序列之类的数据结构那样，除了对单个元素的操作以外，还需要对整个数据结构进行处理和计算。 所以我们需要定义一个专用的树形类，命名为 Tree，以完成一些需要对整棵树进行的计算。 class Tree { constructor(root) { this.root = root } addNode(node, parent = this.root) { parent.addChild(node) } } 创建一棵树时首先要传入一个根节点对象，还可以使用 tree.addNode 代替直接调用 node.addChild，并默认将传入的节点作为根节点的子节点，以便进行管理。 7.2.1 查询节点 当一个树形结构被其他程序创建好以后，通过各种方式传入到你的程序中。而你需要知道这棵树中是否包含某一节点时，就需要使用一些算法来实现这个需求了。 我们前面在实现寻找一棵树中最深子节点的时候用到了 BFS 搜索算法来实现为每一层的子节点进行编号，BFS 的好处是可以搜索到树形结构中的大部分分支。但如果说要找到树形结构中的特定的某一个节点，BFS 显然不是最优的方案。 那么从拓扑学的角度上看一棵树形结构，BFS 的概念便是横向搜索，而 DFS 则是纵向搜索，“不撞南墙不回头”。这种搜索方式的好处是在一棵广度非常大的树形结构中，一旦能找到符合的节点，就能结束对其他分支的搜索。 DFS 在实现上也并不困难，从根节点开始，不断往下搜索第一个子节点（因为在本小册中所使用的树形结构节点都只会使用数组来存储子节点，所以自带顺序结构）。如果符合要求则返回该节点，如果不符合则先检查是否存在下一层或检查下一个兄弟节点。这里我们配合使用第 4 节中所封装的 arrayUtils 进行实现。 class Tree { // ... search(validator) { const queue = [ this.root ] const result = [] while (queue.length > 0) { const currNode = queue.shift() if (validator(currNode)) { result.push(currNode) continue } if (currNode.children.length > 0) { arrayUtils.prepend(queue, ...currNode.children) } } return result } } const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') const node3 = new Node('node 3') const node4 = new Node('node 4') const node5 = new Node('node 5') const node6 = new Node('node 6') const tree = new Tree(root) tree.addNode(node1) tree.addNode(node2) tree.addNode(node3, node1) tree.addNode(node4, node1) tree.addNode(node5, node2) tree.addNode(node6, node5) console.log(tree.search(function(node) { return node.name == 'node 4') })) //=> [ Node{node 4} ] 7.2.2 统计树形大小 当我们使用各种程序来创建和扩展一棵树形结构之后，我们并不一定知道这棵树中究竟有多少节点，因为这些节点很有可能是由多个相互独立的程序所创建和插入的。那么我们就需要有一个方法来统计一棵树内究竟有多少节点（包括根节点）。 既然需要统计所有的节点，那必定要遍历整棵树以进行计数。而我们已经学会了使用 BFS 和 DFS 两种搜索方式了，那么我们可以使用其中的一种来进行遍历，并去掉其中的判断逻辑以遍历整棵树。这里我们先用我们刚刚学会的 DFS 来进行遍历统计。 class Tree { // ... get size() { let size = 0 const bag = [ this.root ] while (bag.length > 0) { const currNode = bag.shift() size++ if (currNode.children.length > 0) { arrayUtils.prepend(bag, ...currNode.children) } } return size } } const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') const node3 = new Node('node 3') const node4 = new Node('node 4') const node5 = new Node('node 5') const node6 = new Node('node 6') const tree = new Tree(root) tree.addNode(node1) tree.addNode(node2) tree.addNode(node3, node1) tree.addNode(node4, node1) tree.addNode(node5, node2) tree.addNode(node6, node5) console.log(tree.size) //=> 7 7.2.3 树形结构代码清单 class Tree { constructor(root) { this.root = root } addNode(node, parent = this.root) { parent.addChild(node) } search(validator) { const queue = [ this.root ] while (queue.length > 0) { const currNode = queue.shift() if (validator(currNode)) { return currNode } if (currNode.children.length > 0) { arrayUtils.prepend(queue, ...currNode.children) } } } get size() { let size = 0 const bag = [ this.root ] while (bag.length > 0) { const currNode = bag.shift() size++ if (currNode.children.length > 0) { arrayUtils.prepend(bag, ...currNode.children) } } return size } get height() { return this.root.height } toString() { return this.root.toString() } } 小结 我们已经学会了创建一个树形结构并且如何对其进行操作和检索，虽然现在看来你可能还会对树形结构究竟能完成些什么实际需求感到疑惑。但是别着急，我们接下来会接触更多的数据结构，我们需要通过接触不同的数据结构来进行组合学习，才能更好地理解每一种数据结构的特点和使用场景。 习题 请使用 BFS 方法来实现统计树形结构中节点的数量。 "},"基于JavaScript开发灵活的数据应用/07.关系图谱.html":{"url":"基于JavaScript开发灵活的数据应用/07.关系图谱.html","title":"07.关系图谱","keywords":"","body":"第 14 节 复杂数据图表 · 关系图谱 关系图谱可以说是笔者我最喜欢的一种数据图表了，因为从很多年前的好莱坞科幻电影开始，主人公都会在一个悬浮在半空中的操作界面中进行操作。其中最具酷炫感的便是不同的球形之间通过一条线进行连接，操作者点击其中一个球体便会带动其他相连的球体，这简直太酷了。 还记得我们在第 8 节中所学习过的关系图谱数据结构吗？我们可以将其应用起来，变成一个非常酷炫的关系图谱。 14.1 准备数据 我们再次使用在第 8 节中准备好的关系图谱数据，一个简单却能够包含大部分情况的图谱数据。 const vertices = [ new Vertex(1, 'A'), new Vertex(2, 'B'), new Vertex(3, 'C'), new Vertex(4, 'D'), new Vertex(5, 'E') ] const edges = [ new DirectedEdge(1, 2, 1), new DirectedEdge(1, 3, 2), new DirectedEdge(2, 4, 1), new DirectedEdge(3, 4, 1), new DirectedEdge(1, 1, 3), new DirectedEdge(3, 5, 4), new DirectedEdge(4, 5, 5) ] 虽然我们在第 8 节中创建了如 Vertex、Edge 和 DirectedEdge 这样的类以方便进行关系图谱算法实现以及代码的理解，但 ECharts 的关系图谱图表则相对简单许多，并不需要使用到特定的类进行内容的标识，只需准备好符合规则结构的数据即可。 对应上面的关系图谱数据，我们可以编写出以下数据集。 const vertices = [ { name: 'A' }, { name: 'B' }, { name: 'C' }, { name: 'D' }, { name: 'E' } ] const edges = [ { source: 'A', target: 'B' }, { source: 'A', target: 'C' }, { source: 'B', target: 'D' }, { source: 'C', target: 'D' }, { source: 'A', target: 'A' }, { source: 'C', target: 'E' }, { source: 'D', target: 'E' } ] 比较特殊的是，因为关系图谱数据系列同时需要使用到两个数据集，所以没办法使用前面学习到的 dataset 和 encode 来进行数据绑定。 14.2 关系图谱数据系列 在将数据集应用到数据图表中之前，首先我们需要了解的是虽然 ECharts 中的关系图谱图表也是建立在二维空间中的，但其与前面学习过的饼图类似，默认情况下并不需要使用到直角坐标系。 所以关系图谱中的每一个节点在二维空间中的位置是需要特定标明的，也就是每一个节点（Node）都需要带有二维空间的坐标信息（x 和 y）。但显然这个任务由我们来完成并不现实，所以 ECharts 提供了几个比较实用的“模板”（Layout），以便于将关系图谱以比较好的形式展示在图表上。 Circular 环形，整个关系图谱的节点会围绕成一个环形结构，并根据实际节点之间的关系进行排列； Force 力引导，关系图谱的分布会根据节点之间连接的“能量”来尽可能保持边长的一致和尽可能少地出现交叉。 从这两张图我们可以看出同一份关系图谱数据分别使用两种不同的展示方式，便有着区别非常大的展示效果。环形井然有序中透露着不少的科技感，而力引导虽然看似杂乱无章却处处透露着数学的魅力。两种不同的模板可以根据实际的需要进行合理的选择，以达到更好的展示效果。 当然 ECharts 也同样支持在数据集中录入每一个节点的位置参数，通常用于展示由其他软件生成的关系图谱数据。 14.2.1 编写配置 因为关系图谱在一般情况下都不需要使用到坐标系来进行辅助，所以我们只需要直接指定数据系列的类别为 graph 即可，并将我们的数据传入到数据系列中。 const option = { series: { type: 'graph', // Dataset data: vertices, links: edges } } 然后我们以环形模板为例子，以展示一个较为简单的关系图谱，只需要添加一个 layout 配置即可。 const option = { series: { // ... layout: 'circular' } } 14.2.2 润色图表 看完前面章节的同学肯定都知道我们在绘制图表的时候都是采用循序渐进的形式进行绘制的，在完成了最基础的图表绘制以后，需要逐步地根据实际需求对图表进行优化润色。 在这个关系图谱中我们可以总结出以下需要优化的地方： 节点图标大小需要调整，目前的节点图标过小而导致画面空洞，当然这也跟节点数量有关； 有向边没有直观的标识，我们在准备节点之间的边时便已经标明了这些边均为有向边，而目前在图表上边的有向性并没有表现出来； 节点的名称没有标明。 节点大小 我们也是逐个将上面的问题进行解决，首先就是需要调整节点的大小，一般情况下只需要填写一个合适的大小即可。 const option = { series: { // ... symbolSize: 50 } } 展示标签 回想一下我们前面学习过的数据图表，当我们需要在数据系列上进行标签展示的时候需要添加什么配置？ const option = { series: { // ... label: { normal: { show: true } } } } 展示有向边 因为在进行图表展示的时候，有向图的意义与无向图有着非常大的差别，而准确地表达数据集所包含的内容则是可视化工程的首要原则。 const option = { series: { type: 'graph', layout: 'circular', symbolSize: 50, // Dataset data: vertices, links: edges, label: { normal: { show: true } }, edgeSymbol: [ 'circle', 'arrow' ], edgeSymbolSize: [ 4, 10 ] } } 14.2.3 力引导关系图谱 前面我们使用了环形模板来展示我们的关系图谱数据，而 ECharts 还提供了力引导模板以供使用。力引导模板运用了一系列的数学原则以及算法来计算每一个节点的位置和节点之间的距离，综合得到最终的完整关系图谱。 将前面的环形配置更换为力引导 force。 const option = { series: { // ... layout: 'force' } } 咦？为什么更换了力引导模板以后整个关系图谱的节点都挤在了一起？因为我们前面设置的节点图标大小与力引导模板默认的大小相差太大，而在距离的计算上也并没有自动地进行适应，所以就出现了全部节点挤在了一起的现象。 为了修复这一问题，我们还需要对力引导模板进行配置，比如力引导中模板中节点之间的斥力大小以及边长的取值范围。 const option = { series: { // ... force: { repulsion: 100, edgeLength: [ 100, 500 ] } } } 小结 这一节我们学习到了，如何将我们在第 8 节中学习到的关系图谱数据使用直观的图表展示出来，虽然图表并不能像图论算法一样通过计算节点之间的关系以进行动态调整，但却能更直观地将数据表达出来。 "},"基于JavaScript开发灵活的数据应用/08.结构转换（上）.html":{"url":"基于JavaScript开发灵活的数据应用/08.结构转换（上）.html","title":"08.结构转换（上）","keywords":"","body":"第 9 节 复杂数据处理 · 结构转换（上） 前面我们相继介绍了多种数据结构，它们各自都承担着不同类型数据的承载功能。不同的数据之间有着不同的表现方式，而在实际工作中我们却常常需要将不同的数据类型进行相互转换，以满足不同的需求。 9.1 Any ↔ 字符串 在开发数据应用的时候，有大部分的数据都不会是由 JavaScript 或用户的操作实时生成的，更多的是直接从服务端的数据存储设施中提取出来，然后通过网络协议传输到客户端以用于展示。 这样的话我们可以首先引入一个题外话，既然我们知道前端使用的数据大部分都需要通过网络协议从服务端传往前端，那这样一个传输过程就是抽象内容的编码和解编码的过程。而且在计算机科学中，通信协议基本上都是以字符串（或二进制）为基础承载数据结构，也就是说在一个服务端与客户端的通信架构中，会需要将各种数据结构首先转换为字符串，经过了网络的传输过程而达到另一端之后，再以相同的方式转换为原本的数据结构。 9.1.1 JSON JSON，全称为 JavaScript Object Notation，是目前最流行的网络数据传输格式之一。相比于 CSV（Comma-Separated Values，逗号分隔值）、XML（Extensible Markup Language，可扩展标记语言）等历史更为悠久的格式化数据传输格式，JSON 同时拥有着易读性强（完全符合 JavaScript 标准）、格式不敏感和轻量化的特点。 { \"name\": \"Chaoyang Gan\", \"nickname\": \"iwillwen\" } JSON 是一个 JavaScript 语言标准的子集，它完全可以直接运行在 JavaScript 引擎中。当然因为 JavaScript 语言本身是具有可被攻击的可能性的，所以在解析 JSON 数据内容的时候，并不能直接作为一段 JavaScript 代码运行。 JavaScript 引擎中提供了一个 eval 函数以用于运行一段 JavaScript 代码，所以假如一段 JSON 数据内容是绝对安全的，确实可以使用 eval 函数当做是 JSON 解析器。 const jsonStr = `{ \"name\": \"Chaoyang Gan\", \"nickname\": \"iwillwen\" }` eval('var me = ' + jsonStr) console.log(me.name) //=> Chaoyang Gan 但如果需要解析的 JSON 数据并不能保证安全甚至可以被恶意篡改（通过中间人劫持、XSS 攻击等方式），就会出现非常不安全的情况，严重者会导致用户私密信息被盗取。 const somethingImportant = 'some secret' const jsonStr = `{ \"attack\": (function(){ alert(somethingImportant) })() }` eval('var me = ' + jsonStr) //=> some secret 为了避免这种情况的出现，我们必须使用现代 JavaScript 引擎中提供的或其他可信任的 JSON.parse 函数进行解码和 JSON.stringify 函数进行编码。 JSON.parse(`{ \"attack\": (function(){ alert(somethingImportant) })() }`) //=> SyntaxError: Unexpected token ( in JSON 言归正传，通常来说，我们可以把将非字符串类型的数据通过某种算法转换为字符串的过程称为序列化（字符串也是一种有序序列），而利用 JSON 格式便是目前最流行的序列化方法之一。 const jsonStr = JSON.stringify({ name: 'Chaoyang Gan', nickname: 'iwillwen' }) console.log(jsonStr) //=> {\"name\":\"Chaoyang Gan\",\"nickname\":\"iwillwen\"} 9.1.2 直接转换 JSON 格式的好处是将结构不确定的数据转换为字符串格式，但同时也会强行带来可能不必要的内容，比如 JSON 的边界字符（如 \"、{} 等）。在需要转换的目标数据类型是确定的，而且将序列化后的字符串数据进行解析的接收方也是可控的的情况下，可以选择直接对数据进行类型转换。 数值类型 在 JavaScript 中所有的对象都会默认带有一个 toString 方法，而对于数值类型来说，可以直接使用这个方法来进行向字符串类型的转换。 const n1 = 1 const n2 = 1.2 const s1 = n1.toString() const s2 = n2.toString() console.log(s1, typeof s1) //=> 1 string console.log(s2, typeof s2) //=> 1.2 string 除了将数值直接转换为字符串之外，我们常常需要实现一个将数据类型的小数点后的值固定在一个长度范围内，比如 5 -> 5.00 和 3.1415 -> 3.14，这个主要用于表格和图表的展示上。3.1415 可以通过数值计算得到需要的 3.14，但是 5 没办法直接通过计算得到 5.00。因为 JavaScript 并不像其他语言那样区分开整型和非整型的数值，所以它提供了一个用于实现这个需求的方法 Number.toFixed。这个方法接受一个数值参数，即小数点后的保留位数，一般来说这个参数需要是非负整型数值，当然如果传入一个非整型数值，该方法也会自动取整进行计算。 const int = 5 const pi = Math.PI //=> 3.141592653589793 (约等于) console.log(int.toFixed(2)) //=> '5.00' console.log(pi.toFixed(2)) //=> '3.14' console.log(int.toFixed(pi)) //=> '5.000' 转换成字符串之后还可以通过 parseInt 和 parseFloat 将以字符串形式存储的数值转换为整型或浮点型。 console.log(parseInt('5.00')) //=> 5 console.log(parseFloat('3.14')) //=> 3.14 布尔型（逻辑型） 布尔型也就是真与假（幸亏 JavaScript 并不存在中间态），在 JavaScript 中表现为 true 与 false。显而易见，这两个值各自都有一个以英文单词来表示的意义，那么我们自然可以非常简单地对其进行转换了。 console.log(true.toString()) //=> 'true' console.log(false.toString()) //=> 'false' 但是要将其再转换成布尔型就没那么简单了，因为 JavaScript 中并没有直接提供 parseBoolean 这样的函数，而且作为弱类型语言，JavaScript 在进行一些判断时也有不少让人非常费解的“操作”。 true == 'true' //=> false false == 'false' //=> false true == 1 //=> true false == 0 //=> true 所以一般来说我们可以使用强类型判断 === 分别判断一个字符串是否是 \"true\"，不是则为 false。 function parseBoolean(string) { return string === 'true' } console.log(parseBoolean('true')) //=> true console.log(parseBoolean('false')) //=> false 数组 事实上，我们在第 2 节中就已经接触过字符串中的 split 方法，它用于将一个字符串以指定字符串为分隔符分割成一个数组。 const str = '1,2,3,4,5' const arr = str.split(',') console.log(arr) //=> [ 1, 2, 3, 4, 5 ] 对应地，数组也可以进行组合变成一个字符串，使用的是 Array.join 方法。 const arr = [ 1, 2, 3, 4, 5 ] console.log(arr.join()) //=> 1,2,3,4,5 console.log(arr.join('#')) //=> 1#2#3#4#5 9.2 对象 ↔ 数组 我们在第 5 节中介绍对象字面量的时候曾经介绍过，在 JavaScript 中的数组实际上是一个特殊的对象字面量，那么在从属关系上看数组应该是对象字面量的一个子集 。 但为什么我们这里还是要提到对象和数组之间的互相转换呢？假设我们需要将一个对象字面量中的属性以列表的形式展示出来： 虽然各种框架都有相关的函数或者工具来完成这个需求，但是为了更好地理解数据结构之间的差异及对其的应用，我们还是需要了解其中如何进行数据格式的转换。 JavaScript 中提供了一个 Object.keys() 函数，可以提取出对象的所有属性键，并以数组的形式表示。 const object = { \"name\": \"Chaoyang Gan\", \"title\": \"Engineer\", \"subject\": \"Maths\" } const keys = Object.keys(object) console.log(keys) //=> [\"name\", \"title\", \"subject\"] 得到了目标对象的属性键数组后，配合数组的 .map 方法便可以将每一个属性键对应的值提取出来。 const list = keys.map(key => { return { key, value: object[key] } }) console.log(list) //=> [ // {key: \"name\", value: \"Chaoyang Gan\"}, // {key: \"title\", value: \"Engineer\"}, // {key: \"subject\", value: \"Maths\"} // ] 当然我们可以将第二层中的对象也使用数组表示。 const pairs = keys.map(key => { return [ key, object[key] ] }) console.log(pairs) // => [ // [\"name\", \"Chaoyang Gan\"], // [\"title\", \"Engineer\"], // [\"subject\", \"Maths\"] // ] 同样，我们也可以使用 Lodash 中提供的 _.toPairs 方法将对象转换为以双元素为键值对表达方式的数组。 const pairs = _.toPairs(object) 完成了从对象到数组的转换后自然需要一个将其进行逆转换的方法，可以直接使用 Lodash 中提供的 _.fromPairs。 const object = _.fromPairs(pairs) console.log(object) // => { // name: \"Chaoyang Gan\", // title: \"Engineer\", // subject: \"Maths\" // } 事实上，我们在第 5 节中用过的 _.groupBy 函数也是一种将数组转换为对象的方法，但它更多的是为了将数组根据其中的某一个字段或某一种变换结果来进行字典化，而不是单纯地将其进行转换。 我们需要明确的原则是，数据转换的出发点和目的都是为了服务需求，而不是单纯地将其进行数据结构上的转换，在思考如何对数据进行处理之前，首先要明确目标需求究竟需要怎样的数据形式。 究竟是需要一个以数值作为元素的数组（如人工神经网络的输入和输出值），还是以对象作为元素类型的数组以用于表格的展示（每一个对象元素代表表格中的一行），或是以列为单位存储的数据框对象（如 ECharts 框架中常用）。 // Input data for ANN const xorArray = [ 1, 0, 0, 1, 1, 0, 1 ] // Row-base dataset const rDataset = [ { name: \"iwillwen\", gender: \"male\" }, { name: \"rrrruu\", gender: \"female\" } ] // Column-base dataset const cDataset = { name: [ \"iwillwen\", \"rrrruu\" ], gender: [ \"male\", \"female\" ] } 小结 我们在这一节中学习了字符串、对象以及数组间的相互转化，这些都是比较常见也比较简单的数据转换需求和方法，一般用于数据的预处理和使用过程中的转换步骤。 习题 我们分别介绍了两种可以存储一个对象信息的数组格式，请分别实现它们的逆转换过程 fromList（用于以 { key: \"key\", value: \"value\" } 为元素的数组）和 fromPairs。 请分别实现 Row-base dataset 和 Column-base dataset 之间的转换过程。 "},"基于JavaScript开发灵活的数据应用/09.结构转换（下）.html":{"url":"基于JavaScript开发灵活的数据应用/09.结构转换（下）.html","title":"09.结构转换（下）","keywords":"","body":"第 10 节 复杂数据处理 · 结构转换（下） 在上一节中，我们学习了如何实现一些简单数据结构的转换，在这一节中我们将继续学习更为复杂的数据格式之间的转换。 10.1 数据集 在上一节的最后，我们提到了两种用于存储表格数据的结构：行式数据集（Row-oriented Dataset）和列式数据集（Column-oriented Dataset）。这两种数据集在二维空间中都同样标识了一个矩阵式数据集，但它们存储的方式和适用的范围不一样。 例如，以下这个数据集存储了某公司的一部分人员信息。该数据集包含了五个数据列和五个数据行，其中每一行代表了一个员工的信息，而每一列对应的则是不同的信息维度。 RowId EmpId Lastname Firstname Salary 001 10 Smith Joe 40000 002 12 Jones Mary 50000 003 11 Johnson Cathy 44000 004 22 Jones Bob 55000 005 24 Steve Mike 62000 如果将这个数据集分别使用行式数据集和列式数据集两种数据结构进行存储的话，则将会是以下形式的实际结构。 行式数据集 // Row-oriented Dataset const empsRows = [ { RowId: '001', EmpId: '10', Lastname: 'Smith', Firstname: 'Joe', Salary: 40000 }, { RowId: '002', EmpId: '12', Lastname: 'Jones', Firstname: 'Mary', Salary: 50000 }, { RowId: '003', EmpId: '11', Lastname: 'Johnson', Firstname: 'Cathy', Salary: 44000 }, { RowId: '004', EmpId: '22', Lastname: 'Jones', Firstname: 'Bob', Salary: 55000 }, { RowId: '005', EmpId: '24', Lastname: 'Steve', Firstname: 'Mike', Salary: 62000 } ] 列式数据集 // Column-oriented Dataset const empsColumns = { RowId: [ '001', '002', '003', '004', '005' ], EmpId: [ '10', '12', '11', '22', '24' ], Lastname: [ 'Smith', 'Jones', 'Johnson', 'Jones', 'Steve' ], Firstname: [ 'Joe', 'Mary', 'Cathy', 'Bob', 'Mike' ], Salary: [ 40000, 50000, 44000, 55000, 62000 ] } 这两种数据集存储结构各有其不同的优势和优化方式，在数据库领域中有分别基于这两种结构实现的不同数据库软件，如基于行式的 MySQL 以及基于列式的 Apache HBase。行式数据集有直观、单一行内的数据结构稳定、利于行式切分存储等优点，而列式数据集的好处是可以通过忽略非必要列以加速数据读取、查询等操作。甚至有些框架或者语言中的数据集就是以列式进行存储的，比如在广泛用于统计领域的 R 语言中的数据框 data.frame，其中的每一列都是以一个向量 vector 进行存储的。 当然讨论数据库和其他语言并不在本小册的范围，所以还是让我们回到正题上来。事实上我们在很多的数据 API 中都会发现，API 所提供的数据结构基本上都是以行式数据提供的。这是因为后端服务所使用的大部分都是行式数据库，再者行式数据在后端程序的处理中也更为方便直接。 10.1.1 为什么要使用列式数据集 为什么在前端我们还要使用到这两种数据结构呢，或者说在前端开发中，列式数据集又有哪些应用场景呢？我们再次将目光放回到上面这张员工数据集上，如果要统计数据集中各员工的收入水平，我们可以选用最大公约数（）再乘以 10 作为约数，然后进行取整的结果作为统计区间。 然而这里我们只需要用到数据集中的 Salary 这一个字段，如果该数据集的尺寸远比 大的话，使用整个数据集进行计算显然会浪费非常多的计算资源（CPU 时间、内存空间、IO 等）。这时候列式数据集的优势便体现出来了，只取该一列的数据进行计算即可。 function gcd(a, b) { if (b === 0) { return a } return gcd(b, a % b) } const w = empsColumns.Salary.reduce(gcd) * 10 const W = empsColumns.Salary .map(function(s) { return Math.floor(s / w) }) console.log(W) //=> [4, 5, 4, 5, 6] 得到了各数据所落到的区间后，再进行统计，最后得到的结果便可用于图表绘制了。同样，我们可以使用前面编写的 _.reduceByKey 进行统计计算。 const salaryAnalysis = _.reduceByKey( W.map(function(W_i) { return [ W_i, 1 ] }), function(a, b) { return a + b } ) console.log(salaryAnalysis) //=> [ // [\"4\", 2], // [\"5\", 2], // [\"6\", 1] // ] 如果要找出不同收入层次的人的名字，需要使用到其他列的数据，那么在列式数据集中该如何使用呢？其实非常简单，无论是在 JavaScript 中的列式数据集还是基于列式的数据库，当需要使用到其他列的时候使用相同的下标即可。 const groupedNames = _.mapValues( _.groupBy( empsColumns.Salary .map(function(s) { return Math.floor(s / w) }) .map(function(W_i, i) { return { w: W_i, name:`${empsColumns.Firstname[i]} ${empsColumns.Lastname[i]}` } }), 'w' ), function(items) { return items.map(_.iteratee('name')) } ) console.log(groupedNames) //=> { // 4: [ \"Joe Smith\", \"Cathy Johnson\" ], // 5: [ \"Mary Jones\", \"Bob Jones\" ], // 6: [ \"Mike Steve\" ] // } 10.1.2 行式数据集 → 列式数据集 了解完列式数据集的好处和实际使用方式之后，我们来学习下如何将前端生成或者从后端服务中取得的行式数据集转换为列式数据集。 首先我们要了解数据集并不一定是完全密集的，也就是说某些字段是允许为空的，在以对象字面量作为一行的行式数据集中便有某一个字段不存在或为 null/undefined。同样，在列式数据集中也可以使用 null 或 undefined 来表示空字段。 假设我们并不知道某个行式数据集究竟有哪些字段列，因为很有可能前面所有的数据行中都不存在的某个字段，在最后一行出现了。而且在实际业务开发中很有可能数据并非一次性加载完成，而是通过数据流的形式不断添加的。因此我们需要能够随时检查是否有新字段列产生，如果有，将其添加到目标列式数据集中。 首先定义一个用于初始化列式数据集中新字段的函数，逻辑很简单，检查目标数据集中是否已经存在目标字段，如果不存在将其初始化为一个空数组。 function applyColumn(colDataset, columnName) { if (!_.has(colDataset, columnName)) { colDataset[columnName] = [] } return colDataset } 然后将行式数据集中的每一个对象字面量所包含的字段都插入到对应行列位置上即可。 function rowOriented2ColOriented(rowDataset) { let colDataset = {} rowDataset.forEach(function(row, i) { const columnNames = _.keys(row) columnNames.forEach(function(columnName) { colDataset = applyColumn(colDataset, columnName) colDataset[columnName][i] = row[columnName] }) }) return colDataset } const transformedDataset = rowOriented2ColOriented(empsRows) console.log(transformedDataset) //=> { // RowId: [ '001', '002', '003', '004', '005' ], // EmpId: [ '10', '12', '11', '22', '24' ], // Lastname: [ 'Smith', 'Jones', 'Johnson', 'Jones', 'Steve' ], // Firstname: [ 'Joe', 'Mary', 'Cathy', 'Bob', 'Mike' ], // Salary: [ 40000, 50000, 44000, 55000, 62000 ] // } 10.1.3 列式数据集 → 行式数据集 当需求变成将列式数据集转换为行式数据集时，需要考虑的技术点也会相应地发生改变。在行式转列式的过程中需要注意的是未知字段列的添加，而列式转行式时则需要注意跳过空字段。 而且因为列式数据集是必须带有顺序的，所以很有可能会出现当前最后一行数据并不是完整的数据，即所有的字段列的长度并不一定相等。 因此在开始遍历每一个字段列之前，需要先检查该数据集究竟有多少个数据行，方法也很简单，就是找出最长的那个字段列。 function rowOriented2ColOriented(colDataset) { const columnNames = _.keys(colDataset) const n = _.max(columnNames.map(function(colName) { return colDataset[colName].length })) const rowDataset = [] for (let i = 0; i [ // { RowId: '001', EmpId: '10', Lastname: 'Smith', Firstname: 'Joe', Salary: 40000 }, // { RowId: '002', EmpId: '12', Lastname: 'Jones', Firstname: 'Mary', Salary: 50000 }, // { RowId: '003', EmpId: '11', Lastname: 'Johnson', Firstname: 'Cathy', Salary: 44000 }, // { RowId: '004', EmpId: '22', Lastname: 'Jones', Firstname: 'Bob', Salary: 55000 }, // { RowId: '005', EmpId: '24', Lastname: 'Steve', Firstname: 'Mike', Salary: 62000 } // ] 10.2 序列集 & 树形结构 & 关系图谱 假设我们有这样一个数据表，它存储着一些有序序列，比如像下面这种的。 使用 JavaScript 中的数组进行表达的话，它可能会是这样的。 const sequences = [ [ 'A', 'B', 'C' ], [ 'B', 'C', 'D' ], [ 'B', 'D', 'E' ], [ 'B', 'F', 'G' ], [ 'F', 'G', 'H' ], [ 'F', 'G', 'H', 'I' ], [ 'J', 'G' ], [ 'J', 'G', 'H' ], [ 'J', 'G', 'H', 'I' ] ] 这种数据结构常用于一些事件流程、关系网络等，因为在后端数据库中通常只能用这种形式存储事物之间的联系，而很难直接存储一张关系图谱或者树形结构，但实际业务开发中又需要使用真正的关系图谱或树形结构，所以我们需要懂得如何将离散存储的关系对或关系序列转换为所需要的数据结构。 10.2.1 序列集 → 树形结构 当我们将一系列有序序列整合成一个或多个树形结构时，需要注意以下几点： 每个序列的不同首端是否都为独立的根节点； 节点是否可重复； 序列中是否允许存在回环； 每个序列的末端是否都为独立的叶节点。 每个序列的不同首端是否都为独立的根节点 每个序列的不同首端是否都为独立的根节点，会直接影响到转换所得的树形结构的数量，我们以下图来理解每个互不相同的首端是与不是独立根节点的区别。 节点是否可重复 节点是否可重复决定了，转换的目标数据结构究竟是树形结构还是一个关系图谱，当多个序列中出现相同的节点时，因为顺序的关系它们并不处于同一个分支中，就会变成多个分支中有着相同的节点。 序列中是否允许存在回环 当序列集中允许出现重复节点时，很可能会出现同一个序列中有着重复的节点，从而形成回环。而在树形结构中，一旦出现回环树形结构便会变为更为立体的关系图谱结构。 每个序列的末端是否都为独立的叶节点 在树形结构中叶节点的定义为树形结构中没有子节点的节点，但是在序列集转换为树形结构时会产生特殊的情况。当序列 的节点为序列 的前半部分，序列 较序列 的后端多出一个或多个节点时，如果序列 的末端节点被定义为一个独立的叶节点，那么在构建树形结构时如何界定，一个分支中的中间节点（如序列 的末端节点）是原本序列集中的一个叶节点呢？这也是后面我们将要讨论的内容。 1. 各首端为独立根节点 当我们所需要转换的序列集中，每一个不同的首端都为独立的根节点时，就意味着不同的首端会成为一个独立的树形结构，从而转换为一个包含多个树形结构的“森林”。 比如本节开头的有序序列集，其中就包含了 4 个不同的首端：A、B、F 和 J。那么这个序列集就可以转换为这样的一个“森林”。 这种情况下，我们可以使用一个虚拟的根节点来完成每一个序列的转换： 创建一个虚拟的根节点，所有的实际根节点都以它为父节点； 遍历序列中的每一个节点； 从虚拟的根节点作为父节点开始，检查父节点是否包含序列中当前的节点，若不存在则往父节点中添加当前节点； 以最新的节点作为父节点，遍历到序列中的下一个节点并重复步骤 3，直至当前序列的末端。 我们可以利用下面这张图来更好地理解这个转换算法。 配合第 7 节中我们所使用的树形结构代码，来完成这个转换算法，然后使用 Node.toString() 将其展示出来以确认是否成功并正确地完成转换。 // 虚拟一个根节点 const root = new Node('*') sequences.forEach(function(sequence) { let lastNode = root sequence.forEach(function(nodeName, i) { // 寻找已存在的节点 const index = lastNode.children.findIndex(function(child) { return child.name === nodeName }) if (index >= 0) { lastNode = lastNode.children[index] } else { // 创建节点 const node = new Node(nodeName) lastNode.addChild(node) lastNode = node } }) }) console.log(root.toString()) //=> // * // A // B // C // B // C // D // D // E // F // G // F // G // H // I // J // G // H // I 2. 各首端不为独立根节点 当序列集中的各首端并不为独立根节点时，整个序列集所转换成的树形结构数量会大大减少，甚至整个序列集都会以一棵树形结构呈现。 可以看到，在这个转换得到了两个树形结构，分别为以节点 A 和节点 J 为根节点。进行转换之前我们需要知道的是，序列集很有可能是无序的，也就是说，并非序列集中第一个序列的第一个节点必定是一个根节点。 因此，在转换的过程中需要完成的第一步便是寻找序列集中，既定存在的若干个根节点。回想一下我们在第 7 节和第 8 节中学过的内容，一般来说，如何辨别树形结构和关系图谱中的节点究竟是根节点、中间节点还是叶节点的？ 根节点的定义是：没有父节点的节点。那么换过来说，如果要寻找序列集中的根节点，第一步便是对其中的所有节点进行整理统计，最直观的办法是将每个序列拆分成多个节点对，即父节点和子节点的配对关系。 针对上面 sequences 这种形式的序列集，我们可以通过遍历序列中除了最后一个节点以外的所有节点，并返回与其下一个元素所组成的元组，以表达树形结构中的父子节点关系。 ) function isLast(i, length) { return (i + 1) === length } function seq2Pairs(seq) { return seq .map(function(node, i) { if (isLast(i, seq.length)) { return false } return [ node, seq[i + 1] ] }) .filter(function(pair) { return pair && pair.length === 2 }) } const pairs = seq2Pairs([ 'A', 'B', 'C' ]) console.log(pairs) //=> [ // [\"A\", \"B\"], // [\"B\", \"C\"] // ] 得到了一系列的父子对之后，我们便可以分别统计每一个出现的节点各自的入度和出度，以找出根节点集并提前向虚拟根节点插入这些根节点。 // 统计节点的度 function analyzeDegrees(pairs) { const analysis = {} for (const pair of pairs) { const [ left, right ] = pair if (!analysis[left]) { analysis[left] = { in: 0, out: 0 } } if (!analysis[right]) { analysis[right] = { in: 0, out: 0 } } analysis[left].out += 1 analysis[right].in += 1 } return _.toPairs(analysis) .map(function([ node, degrees ]) { return { node, ...degrees } }) } // 通过判断入度找出根节点 function findRootNodes(analysis) { return analysis.filter(function({ in: inDegree }) { return inDegree === 0 }) } const analysis = analyzeDegrees(pairs) const rootNodes = findRootNodes(analysis).map(function(result) { return result.node }) console.log(rootNodes) //=> [ 'A' ] const root = new Node('*') for (const nodeName of rootNodes) { const node = new Node(nodeName) root.addChild(node) } 接下来的处理其实跟序列各首端为独立根节点时很相似，不过有一点区别：在前面的情况中，每一个序列的首端都必定会出现在虚拟根节点的子节点中，因此可以直接从根节点开始操作，而在现在的条件下，每个序列的首端节点并不一定是虚拟根节点的子节点，因此除了一个虚拟根节点以外还需要建立使用第 7 节中的树型结构，并使用 Tree.search() 方法来完成上层节点的搜索。 const tree = new Tree(root) // 任务队列 const penddingSeqs = sequences.slice() while (penddingSeqs.length > 0) { const currentSeq = penddingSeqs.shift() // 搜索首端节点 const hit = tree.search(function(node) { return node.name === currentSeq[0] }).shift() // 如果不存在，则将当前序列重新加入任务队列 if (!hit) { penddingSeqs.push(currentSeq) continue } let lastNode = hit currentSeq.shift() while (currentSeq.length > 0) { const currentNodeName = currentSeq.shift() const currentNode = lastNode.children.find(function(node) { return node.name === currentNodeName }) if (currentNode) { lastNode = currentNode } else { const node = new Node(currentNodeName) lastNode.addChild(node) lastNode = node } } } console.log(root.toString()) //=> // * // A // B // C // D // D // E // F // G // H // I // J // G // H // I 10.2.2 序列集 → 关系图谱 与树形结构相比，将序列集转换为关系图谱的方法要简单许多。在第 8 节中我们曾说到，关系图谱的存储方式一般会由一个顶点集和一个边集组成，而序列集从数据结构上可以看做是一个更高维度的边集。因此，我们如果需要将序列集转换为关系图谱，只需要将序列集中的所有独立节点提取出来，然后将序列拆分成有向边或无向边并完成去重即可。 可以参考上面提取序列集中父子对的过程，此处不再演示代码，这个任务由你来完成。 小结 本节中我们学习了多种复杂数据结构之间的转换，其中也包括了上一节中我们所留下的两种数据集结构之间的转换。 这些数据结构在我们日常的开发中都是非常常见的，而且由于数据存储格式的限制或数据传输的约束，我们往往需要通过另一种方式来存储难以表达的数据结构，如序列集与树形结构、关系图谱的关系。 习题 参考 10.2.1 节中第 2 小节里的转换算法，完成序列集到关系图谱的转换。 思考：树形结构作为特殊的关系图谱，我们如何将其一般化，转换为关系图谱呢？ "},"基于JavaScript开发灵活的数据应用/10.散点图与折线图.html":{"url":"基于JavaScript开发灵活的数据应用/10.散点图与折线图.html","title":"10.散点图与折线图","keywords":"","body":"第 11 节 基于 ECharts 的基础表达性统计图表 · 散点图与折线图 经过了对 JavaScript 中各种数据结构的学习和应用，我们已经掌握了绝大部分在实际开发中所需要使用到的数据操作技能。而接下来，我们便可以开始将这些技能应用到我们所收集到的数据上，并将经过处理的数据使用可视化数据图表进行展示。 11.1 散点图 Scatter 在数据统计处理开发中，最主要的数据类型通常是离散型单值数值类型，比如学校班级中的每一个学生的身高体重信息、记账本中的每一次支出的价格等等。 而就比如班级中的身高体重信息，因为严格意义上人与人之间并没有一定的顺序，所以要展示每一个个体的数据应该选用散点图来展示离散的数值数据。 我们首先假设男生的一般身高范围在 155 厘米到 180 厘米之间，而女生的身高范围在 145 厘米到 170 厘米之间。一般来说两者身高在这两个范围会呈正态分布，但为了方便学习，我们假设性地将其看作是均匀分布。我们可以利用这两个范围随机生成一些学生的身高数据，此处假设男女比例相等即各占 50%。 const students = [] const n = 50 const heightRanges = { male: [ 155, 180 ], female: [ 145, 170 ] } function getRandomInt(min, max) { return Math.round(min + Math.random() * (max - min)) } for (let i = 0; i 0.5 ? 'male' : 'female' const [ min, max ] = heightRanges[gender] const student = { id: i + 1, gender: gender, height: getRandomInt(min, max) } students.push(student) } console.log(students) //=> // [ // { id: 1, gender: \"male\", height: 157 }, // { id: 2, gender: \"male\", height: 165 }, // { id: 3, gender: \"female\", height: 157 }, // { id: 4, gender: \"female\", height: 169 }, // ... // ] 11.2 ECharts 简单入门 ECharts 是由百度开发并开源的一个基于 JavaScript 和 Canvas（在 4.0 中支持了 SVG 渲染）数据可视化图表工具库，而且目前已经被捐赠与 Apache 基金会，更名为 Apache ECharts。它并不需要开发者有非常丰富的数据可视化经验，便可以利用所提供的参考实例开发出美观、实用、性能优秀的可视化图表。 11.2.1 可视化图表基本元素 使用 ECharts 绘制可视化图表需要提供以下几种元素（对应不同的图表组件），以组成一个完整的数据图表。 数据（必需） 数据系列（必需） 坐标轴 除此之外还有如辅助线、标记文本、图例等等元素。ECharts 以图表配置为主要使用方式，使用的时候将所需要展示在图表上的元素加入到图表配置中即可。 11.2.2 数据集 dataset 从 ECharts 4.0 版本开始，它提供了一个非常适合我们学习和使用的数据集配置方法 dataset，它的主要用法是使用我们在第 10 节中所学习过的行式数据集以及列式数据集。 行式数据集 // Row-oriented Dataset const empsRows = [ { RowId: '001', EmpId: '10', Lastname: 'Smith', Firstname: 'Joe', Salary: 40000 }, { RowId: '002', EmpId: '12', Lastname: 'Jones', Firstname: 'Mary', Salary: 50000 }, { RowId: '003', EmpId: '11', Lastname: 'Johnson', Firstname: 'Cathy', Salary: 44000 }, { RowId: '004', EmpId: '22', Lastname: 'Jones', Firstname: 'Bob', Salary: 55000 }, { RowId: '005', EmpId: '24', Lastname: 'Steve', Firstname: 'Mike', Salary: 62000 } ] const option = { dataset: { source: empsRows } } 列式数据集 // Column-oriented Dataset const empsColumns = { RowId: [ '001', '002', '003', '004', '005' ], EmpId: [ '10', '12', '11', '22', '24' ], Lastname: [ 'Smith', 'Jones', 'Johnson', 'Jones', 'Steve' ], Firstname: [ 'Joe', 'Mary', 'Cathy', 'Bob', 'Mike' ], Salary: [ 40000, 50000, 44000, 55000, 62000 ] } const option = { dataset: { source: empsColumns } } 11.2.3 数据系列 series 准备好数据集以后，便需要将其与所需要的数据系列（如本节将会介绍的散点图和折线图）进行绑定，使数据可以真正地展示在数据图表上。 // 散点图 Scatter const option = { { type: 'scatter', encode: { x: 'Firstname', y: 'Salary' } } } 在这个数据系列中，我们指定了数据系列的类型为 scatter，即我们需要的散点图。然后通过 encode 绑定前面在 dataset 中数据的维度，如 x 坐标轴绑定到 Firstname，y 坐标轴绑定到 Salary 上。 11.2.4 坐标轴 axis 准备好了数据集和用于展示的数据系列之后，因为我们所需要展示的数据图表类型为散点图，所以至少需要一个坐标轴来作为数据的载体，而在一般情况下我们所使用的坐标轴为直角坐标轴（即一个 X 坐标轴和一个 Y 坐标轴）。 const option = { xAxis: { type: 'category' // X 坐标轴数据为名义数据（分类数据） }, yAxis: { type: 'value' // Y 坐标轴为计量数据（数值数据） } } 11.2.5 组合图表元素 我们将上面准备好的三个图表元素组合在一起，然后将得到的图表配置传到 ECharts 的实例中，这里以行式数据集为例。 const empsRows = [ { RowId: '001', EmpId: '10', Lastname: 'Smith', Firstname: 'Joe', Salary: 40000 }, { RowId: '002', EmpId: '12', Lastname: 'Jones', Firstname: 'Mary', Salary: 50000 }, { RowId: '003', EmpId: '11', Lastname: 'Johnson', Firstname: 'Cathy', Salary: 44000 }, { RowId: '004', EmpId: '22', Lastname: 'Jones', Firstname: 'Bob', Salary: 55000 }, { RowId: '005', EmpId: '24', Lastname: 'Steve', Firstname: 'Mike', Salary: 62000 } ] const option = { dataset: { source: empsRows }, xAxis: { type: 'category' }, yAxis: { type: 'value' }, series: { type: 'scatter', encode: { x: 'Firstname', y: 'Salary' } } } 在 CodePen 中我们创建一个新的 Pen，然后加入一个新的 JavaScript 依赖，详细方法请见第 1 节。 https://cdn.staticfile.org/echarts/4.1.0/echarts.min.js 要让数据图表展现在页面上，首先得有一个用于承载图表的容器元素，我们在 CodePen 的 HTML 代码框中创建一个简单的 div 元素，并在 CSS 代码框中为其定义合适的尺寸样式。 /* CSS */ #chart { width: 600px; height: 400px; } 然后在 JavaScript 代码框中我们使用 ECharts 工具库的 API 将该元素进行 ECharts 图表的初始化。 const chartEl = document.querySelector('#chart') const myChart = echarts.init(chartEl) 最后，将前面准备好的图表配置应用到该 ECharts 实例上，我们便可以在预览框中看到可视化图表的效果了。 const option = { dataset: { source: empsRows }, xAxis: { type: 'category' }, yAxis: { type: 'value' }, series: { type: 'scatter', encode: { x: 'Firstname', y: 'Salary' } } } myChart.setOption(option) 11.3 使用 ECharts 实现散点图绘制 学会了 ECharts 的基本使用方式后，让我们回到正题，学习如何使用 ECharts 绘制一个用于展示班级内各同学身高的散点图。 实际上我们只需要将上面这个图表配置中的数据集换成所需要展示的 students，然后将数据系列中的 encode 维度绑定更改为学生 ID 和身高信息。 { type: 'scatter', encode: { x: 'id', y: 'height' } } 于是便可以得到一个初步的可视化图表。 11.3.1 优化图表 虽然我们确实使用了 ECharts 来将我们所生成的数据进行了可视化，但我们也同样发现这个图表并不尽如人意： 图表中数据点都分布在图表的上方，图表的下半部分有一大片的空白区域； 坐标轴上没有任何的提示信息，单从图表数据无法判断数据的语义信息； 除了身高数据以外，数据中还提供了每一位学生的性别信息 gender（分别为 male 和 female），希望能够在图表中有所表示。 我们可以一步一步地来对既有图表进行优化，首先便是解决图表空白区域太多的问题。产生这个问题的原因是因为数据普遍分布在 145 ~ 180 之间，所以 0 ~ 145 这个区间便完全空白。 拉伸数轴 要解决这个问题只需要在 Y 坐标轴上让 ECharts 对数轴进行拉伸，去掉空白区域。 const option = { yAxis: { type: 'value', scale: true } } 非常好！接下来让我们继续对图表进行优化，因为我们前面并没有在图表中加入任何提示信息，所以在图表上并没有显示任何关于数据内容的文本说明。 添加数据信息 这显然不是一个优秀的可视化图表所应该有的问题，所以我们需要为我们的图表数据加上一些提示信息。我们可以分别在 X 轴和 Y 轴上加入对应数据的名称，并让它们显示在指定的位置。 const option = { xAxis: { type: 'category', name: '学号', nameLocation: 'middle', nameGap: 25 }, yAxis: { type: 'value', scale: true, name: '身高', nameLocation: 'end' } } name 属性对应的是指定坐标轴所需要显示的名字（即数据名称），nameLocation 为名字的显示方位。详细请参考 ECharts 配置项文档。 最后一个需要优化的东西便是我们希望能够在图表上体现出男生和女生之间的身高差异，这个需要将图表中的数据散点体现出性别的差异。一般来说我们会使用 ECharts 中的图例组件（legend）来表示不同的数据分组，但比较遗憾的是目前 ECharts 并不支持直接使用 dataset 中的某一个数据进行直接分组（截至 ECharts 版本 4.1.0）。 数据分组 要实现这个需求，目前需要将男生的数据和女生的数据分别使用各自的数据系列进行表示，但是因为使用了 dataset 来统一集中数据配置，而通过 encode 也并不支持对 dataset 中的数据维度进行筛选。 所以我们可以另辟蹊径，使用 ECharts 中的另外一个组件视觉映射（visualMap）来实现这个功能。一般来说这个组件主要用于表示不同范围或不同程度的数据所对应的不同表现方式（如不同的颜色），比如 0 ~ 10、10 ~ 20、20 ~ 30 等。 但 ECharts 的 VisualMap 组件除了支持区间范围之外，还支持完全匹配某一个值来作为一个区间。那么我们便可以利用这个特性来匹配不同的性别参数，只需要在将其匹配目标指定为我们的性别维度 gender 即可。更详尽的关于 VisualMap 使用方法请参考官方文档。 const option = { visualMap: { type: 'piecewise', // piecewise 表示的是分段式，continuous 则为连续式 dimension: 'gender', pieces: [ { value: 'male', label: '男生', color: '#1890ff' }, { value: 'female', label: '女生', color: '#f5222d' } ], orient: 'horizontal' } } 11.4 折线图 Lines 折线图与散点图相比，虽然都是用于表示一个或多个计量数据，但折线图因为其视觉效果的设计使其更适合用于表示计量数据随时间或某种特定有序排列的数值变化趋势。 就好比我们经常能在电视新闻中看到国家统计局会公布国内 GDP 值的环比、同比变化率以及呈现 GDP 值变化的折线图。而在企业中也非常喜欢使用折线图来表示企业的增长，如企业市值的变化等等。 同样是为了方便学习，我们可以假设性地设定一个会随时间年份变化的计量数据，即每一年的数据都有一点差别。而因为折线图所表示的是变化趋势，所以为了迎合该特性，我们在生成随机数据的时候，也可以采用随机生成变化率，而不是直接生成每一个点的数据。 11.4.1 生成随机时间序列 假设我们限定每一个单位时间内，当前值较前一个值的变化率绝对值不会超过 )。 那么我们便可以使用 JavaScript 中用于生成均匀分布在开区间 )（不包含 0 与 1）随机数的 Math.random() 生成需要的随机数 ，然后通过以下公式得到一个均匀分布在区间 ) 的随机系数。 ) 该公式的推演过程如下。 使用 JavaScript 实现便为如下代码。 function randomCoefficient(r) { const rand = Math.random() const coefficient = (rand - 0.5) * 2 * r return coefficient } 这样每一项数据便为上一项数据加上该变化率。 %20%5Cquad%20(i%3D1%2C2%2C%5Ccdots%2C%20n)) 我们假设数据集的第一项为 100，数据项总数目为 50，得到以下数据生成代码。 const X = [ 100 ] const n = 50 - 1 const r = 0.1 function randomCoefficient(r) { const rand = Math.random() const coefficient = (rand - 0.5) * 2 * r return coefficient } for (let i = 0; i [ 100, 95.23, ... ] const data = X.map(function(x, i) { return { time: i + 1, value: x } }) 11.4.2 绘制折线图 得到了绘制所需要的数据集后，我们便可以将其应用到我们上面所使用到的数据图表中，替换掉原本的散点图数据。当然你也可以直接重新创建一个图表配置，以加深对知识的印象。 const option = { dataset: { source: data }, xAxis: { type: 'value', name: 'i', nameLocation: 'middle', nameGap: 25 }, yAxis: { type: 'value', scale: true, name: 'x', nameLocation: 'end' }, series: { type: 'line', encode: { x: 'time', y: 'value' } } } 11.4.3 优化折线图 我们已经得到了一个看着还不错的折线图，但是“图”如其名，数据图表中的线条都是以直线相连的折线。 受数据采集、图表规模等因素的限制和影响，数据点之间的区间有的时候并不是完全空白的。就好比某空气质量传感器每小时整时记录当前的空气质量，那么就在这个时间区间两端的两个空气质量值是否能代表这中间的 58 分钟呢？这在数学上需要使用到插值的方法进行数据的填充，当然这也不在本小册的范围之内，感兴趣的同学可以自行参考《数值分析》相关的教材。 在 ECharts 中折线图直接提供了一个使用方法非常简单的功能，能将原本的折线变成光滑的曲线图，我们只需要在类型为 line 的数据系列中加入一项 smooth 即可。 { type: 'line', smooth: true, encode: { x: 'time', y: 'value' } } 小结 我们在这一节中学习了如何使用 ECharts 创建简单的散点图和折线图，并知道了如何根据实际的需求选择合适的可视化类型。同时我们还学会了如何创建简单的随机数据以满足我们绘制图表的需要。最后还学会了如何对我们所创建的图表一步一步地进行优化，以更好地满足我们的可视化需求。 习题 请阅读 ECharts 配置项文档，研究如何将 11.3 中创建的散点图中的数据点根据数值的大小变化点的大小； 请创建两个具有相同时间范围的不同随机时间序列数据，并展示在同一个图表中，其中都采用折线图的方式展示； 请对上一题中你所创建的图表进行优化。 "},"基于JavaScript开发灵活的数据应用/11.柱状图与饼图.html":{"url":"基于JavaScript开发灵活的数据应用/11.柱状图与饼图.html","title":"11.柱状图与饼图","keywords":"","body":"第 12 节 · 基于ECharts 的基础表达性统计图表 · 柱状图与饼图 在上一节中我们学习了 ECharts 的基本使用方法以及如何使用 ECharts 绘制散点图与折线图。散点图主要用于表示多个数据点在一维或二维特征空间中的分布情况，而折线图主要用于表示某一个计量数据在一定的顺序范围内的变化情况。 学习了这两种数据可视化图表之后，相信你已经对数据可视化的原理有了一定的认识。数据可视化的出发点永远是数据本身，图表绘制过程中需要通过理解数据所包含的实际意义，并根据需求选择合适的可视化图表。那么，我相信你已经准备好学习接下来更多的数据可视化图表了。 12.1 柱状图 Bar 在我们日常生活中能看到的数据可视化图表中，柱状图可能会占据着大多数，因为它非常适合用于展示同一量纲下不同计量数据值的区别。比如需要对比某年某市多所高中的本科录取人数、本科率等，柱状图绝对是最适合的选择。 12.1.1 准备数据 柱状图所需要的数据集非常简单，每一个类目对应着一个柱状数据，柱状的高度对应着该类目的计量数据。假设某年某市 4 所高中的本科录取人数以及本科率如下表所示。 学校 高中 A 高中 B 高中 C 高中 D 本科录取人数 本科率 其中，我们假设数列 中的每一个元素都为大于 1000 小于 1500 的随机数，而数列 中的元素则为大于 0.85 小于 1 的随机数。同样，我们使用 JavaScript 生成一个符合这些约束的数据集，以便于学习。 const N = [] const P = [] const n = 4 function getRandomInt(min, max) { return Math.round(min + Math.random() * (max - min)) } for (let i = 0; i [ 1395, 1318, 1447, 1437 ] console.log(P) //=> [ 0.96, 0.89, 0.98, 0.99 ] 得到了两个数列之后，还需要将它们整合起来成为一个 ECharts 可用的行式数据集。 const schools = [] for (let i = 0; i [ { name: 'A', N: 1395, P: 0.96 }, ... ] 12.1.2 绘制柱状图 我们还是继续使用上一节中设计好的图表配置进行修改，首先将 dataset.source 改成我们现在需要用的 schools 学校数据集。 const option = { dataset: { source: schools } } 然后将 series 中的 type 改成目前我们需要使用的柱状图 bar，并同时修改 encode 中的维度绑定以符合我们新的数据集。 const option = { series: { type: 'bar', encode: { x: 'name', y: 'N' } } } 最后得到完整的图表配置项，将其应用到 ECharts 实例中查看效果。 const option = { dataset: { source: schools }, xAxis: { type: 'category' }, yAxis: { type: 'value' }, series: [ { type: 'bar', encode: { x: 'id', y: 'N' } } ] } myChart.setOption(option) 由此可见，我们在使用 ECharts 的时候，只需要关注如何组织数据、如何选择可视化图表类型便可以在一定程度上得到所需要的数据图表。 12.1.3 优化图表 在日常生活中柱状图应该会是我们使用频率最多的一种数据可视化图表类型，而在平常所看到的柱状图中除了柱状图本身以外，还有很多辅助元素供图表阅读者更好地理解数据。接下来就来为我们所创建的柱状图表添加一些元素来进行优化，使得这个图表更加完善和直观。 添加数据标签 在上面的图表中，虽然左侧有 Y 坐标轴提供数值指示的功能，但因为 Y 坐标轴所能标识的数值有限，而柱状图本身也并不具备标明精确数值的功能，所以我们需要添加数据标签以准确指明数值。 在 bar 数据系列中添加一个 label 配置，以显示一个数值标签。 const option = { series: [ { type: 'bar', encode: { x: 'id', y: 'N' }, label: { normal: { show: true, position: 'top' } } } ] } 添加平均值辅助线 除了对数值进行标识之外，对于标识不同分类数值的柱状图来说，通常还需要向读者传递一些统计信息，比如该数值的平均值等。在 ECharts 中为图表添加这些信息可以用到 markLine 组件来添加带数值的辅助线。 比如我们需要为某一个柱状图数据系列添加一个表示均值的辅助线，可以如下修改配置项。 const option = { series: [ { type: 'bar', encode: { x: 'id', y: 'N' }, label: { normal: { show: true, position: 'top' } }, markLine: { data: [ { type: 'average', name: '平均值' } ] } } ] } 可以看到已经有一条横向的虚线表示了该柱状图数据序列的平均值，但因为这条线的颜色与柱状图的颜色相同，视觉效果上并不如意。所以我们可以为这条线加一些样式，使其与柱状图相区分开来。 const option = { series: [ { type: 'bar', encode: { x: 'id', y: 'N' }, label: { normal: { show: true, position: 'top' } }, markLine: { data: [ { type: 'average', name: '平均值', lineStyle: { color: '#ffa39e' } } ] } } ] } 12.1.4 绘制多个数据系列 我们在准备数据的时候，除了每一个学校的本科录取人数以外，还有该学校的本科率。而上面我们所绘制的图表中只使用到了一个数据系列来表示本科录取人数，所以我们接下来为了让可视化图表更好地表达我们所准备的数据内容，需要将本科率也展示在图表上。 我们可以首先在 series 配置中添加一个新的 bar 数据系列，并将数据绑定 encode.y 改为 P 即各学校的本科率。 const option = { series: [ { type: 'bar', encode: { x: 'id', y: 'N' }, label: { normal: { show: true, position: 'top' } }, markLine: { data: [ { type: 'average', name: '平均值', lineStyle: { color: '#ffa39e' } } ] } }, { type: 'bar', encode: { x: 'id', y: 'P' }, label: { normal: { show: true, position: 'top' } }, markLine: { data: [ { type: 'average', name: '平均值', lineStyle: { color: '#096dd9' } } ] } } ] } 为什么并没有看到另外一个柱状图？这是因为本科录取人数的数据范围在 1000 到 1500 之间，而本科率的范围则在 0 到 1 之间，而且量纲也相异。所以我们需要借助其他辅助手段对图表进行优化。 虽然说我们比较常用的坐标轴为笛卡尔坐标系也就是直角坐标系，只有一个 X 坐标轴和一个 Y 坐标轴。但若需要将不同量纲的数据在同一个数据图表中展示，就可以使用多个不同的 Y 坐标轴表示。 我们需要在 yAxis 上添加一个新的 Y 坐标轴，然后把本科率的数据系列绑定到这个坐标轴上。 const option = { yAxis: [ { type: 'value', name: '本科录取人数' }, { type: 'value', name: '本科率' } ], series: [ { type: 'bar', encode: { x: 'id', y: 'N' }, label: { normal: { show: true, position: 'top' } }, markLine: { data: [ { type: 'average', name: '平均值', lineStyle: { color: '#ffa39e' } } ] } }, { type: 'bar', yAxisIndex: 1, // 绑定副 Y 坐标轴 encode: { x: 'id', y: 'P' }, label: { normal: { show: true, position: 'top' } }, markLine: { data: [ { type: 'average', name: '平均值', lineStyle: { color: '#096dd9' } } ] } } ] } 12.2 饼图 我们知道柱状图可以用于展示不同组别的数值数据的大小，而饼图的作用则是将不同组别的数值数据合并在同一个数轴上，并以更直观的方式展示不同组别之间的大小关系。 12.2.1 绘制基本饼图 同样是通过修改数据系列的类型为 pie，然后更改数据绑定 encode 中的维度信息。因为饼状图并不需要使用到直角坐标系，所以我们这里可以将前面一直都有使用到的 xAxis 和 yAxis 删除。 const option = { dataset: { source: schools }, series: { type: 'pie', encode: { itemName: 'name', value: 'N' } } } 12.2.2 添加数据标签 与柱状图相同，这个饼图虽然已经能够比较直观地表达出不同组别之间数据的大小关系，但是却无法直观地表达准确的数据值。所以我们也需要为饼图添加数据标签以表明准确的数值数据。 可以通过修改 ECharts 中饼图的 label 也就是标签，来显示每一个组别的组别名、准确数值及其百分比。在 label.formatter 中添加 {@name} 以显示组别名（维度 name），添加 {@N} 以显示每一个学校的本科录取人数，以及内置的变量 {d} 以显示每一个学校的百分比。 const option = { dataset: { source: schools }, series: { type: 'pie', label: { formatter: '{@name}: {@N} ({d}%)' }, encode: { value: 'N', itemName: 'name' } } } 小结 在这一节中我们学习了另外两种简单的数据图表——柱状图和饼图的使用，至此我们已经学习了 4 种基本的数据图表类型，这已经足够我们将它们使用到 90% 以上的数据可视化任务中了。但这其实还不够，我们还需要学习一些更为复杂的数据图表类型，以将它们相互组合完成更多样化的需求。 "},"基于JavaScript开发灵活的数据应用/12.复杂数据图表·箱线图.html":{"url":"基于JavaScript开发灵活的数据应用/12.复杂数据图表·箱线图.html","title":"12.复杂数据图表·箱线图","keywords":"","body":"第 13 节 复杂数据图表 · 箱线图 箱线图是一种结合了散点图和柱状图特性的复合数据图表，它主要用于展示一组或多组离散型数值数据的多个特征值及离散程度。 箱线图可以非常好地表现一组数据中大致的整体状况，从而配合统计学方法对数据进行分析和评价。 13.1 准备数据 13.1.1 箱线图统计量 箱线图是利用离散数据中的 5 个统计量进行绘制的：最小值、第一四分位数 、中位数、第三四分位数 以及最大值，并利用 和 两个四分位数计算得到四分位距 。 是一种用于表示离散数据离散程度的统计量，其定义为一组离散数据中的第一四分位数与第三四分位数的差值。 得到了 之后便可以继续推导出离散数据箱线图的内限 ，超出这个内限的值便为该组数据中的离群值（outlier），需要被单独标记。 虽然在 ECharts 中已经提供了这些数据的计算工具，但是为了能够更好地理解其中的统计学含义，这里将会一步步地计算这些我们需要使用到的数据。 13.1.2 计算统计量 跟前几节不一样的是，使用 Math.random() 所生成的数据在不加以处理的情况下都会呈均匀分布，而像 这些用于表示数据离散程度的统计量在这里便失去了意义。因此，这一节会使用一组真实的数据来作为将要使用的数据。 这份数据来自非常著名的物理实验 —— 迈克耳孙-莫雷实验，它是一项用于验证“以太”物质是否存在的实验。 const data = [ 850, 740, 900, 1070, 930, 850, 950, 980, 980, 880, 1000, 980, 930, 650, 760, 810, 1000, 1000, 960, 960 ] 最小值 & 最大值 最小值和最大值可以说是我们非常熟悉的一对数据统计量，在 JavaScript 中计算这两个值的方法非常多，可以先使用排序然后取头尾两值。当然在 JavaScript 中我们有更好的方法，可以分别使用 Math.min() 和 Math.max() 来进行计算。 const min = Math.min(...data) //=> 650 const max = Math.max(...data) //=> 1070 中位数 中位数的定义为离散数据 在数轴上的中间值： 如果离散数据的个数 为奇数，则中位数就为第 个数值，； 若数据的个数 为偶数，则中位数为最中间两个数值的平均值，)。 let median = 0 const n = data.length const sortedData = data.sort(function(a, b) { return a - b }) if (n % 2 == 1) { median = sortedData[((n + 1) / 2) - 1] } else { median = (sortedData[(n / 2 + 1) - 1] + sortedData[(n / 2) - 1]) / 2 } console.log(median) //=> 940 四分位数 中位数实际上就是一个四分位数，将离散数据画在数轴上，然后以最小值和最大值作为范围，将数轴切分成四份。第一和第二份的边界点为第一四分位数，第二和第三份的边界点为中位数，而第三和第四份的边界点则为第三四分位数。 当中位数的位置上不存在某一个特定的数值时，则取最中间两个数值的平均数。而第一和第三四分位数则除了需要合并两个相邻的数值以外，还需要根据各自的位置进行相应的计算。 比如当第一四分位数的位置上并不是特定的一个数值时，则取前一个数乘以 的乘积加上后一个数乘以 的乘积，而并不是两者的平均数，因为这样才更符合第一四分位数的定义。第三四分位数同理。 %20%5C%5C%0A%20%20%20%20Q1%3D%5Cfrac%7B1%7D%7B4%7DS%7B%5Cleft%20%5Clfloor%20%5Cfrac%7Bn%7D%7B4%7D%20%5Cright%20%5Crfloor%7D%20%2B%20%5Cfrac%7B3%7D%7B4%7DS_%7B%5Cleft%20%5Clfloor%20%5Cfrac%7Bn%7D%7B4%7D%20%5Cright%20%5Crfloor%20%2B%201%7D%20%26%20n%3D2k%2B1(k%20%5Cne%200)%0A%20%20%5Cend%7Barray%7D%0A%5Cright.%0A%5Cend%7Bequation%7D) %20%5C%5C%0A%20%20%20%20Q3%3D%5Cfrac%7B3%7D%7B4%7DS%7B%5Cleft%20%5Clfloor%20%5Cfrac%7B3n%7D%7B4%7D%20%5Cright%20%5Crfloor%7D%20%2B%20%5Cfrac%7B1%7D%7B4%7DS_%7B%5Cleft%20%5Clfloor%20%5Cfrac%7B3n%7D%7B4%7D%20%5Cright%20%5Crfloor%20%2B%201%7D%20%26%20n%3D2k%2B1(k%20%5Cne%200)%0A%20%20%5Cend%7Barray%7D%0A%5Cright.%0A%5Cend%7Bequation%7D) function quantile4(data, pos) { if (pos 3 || pos % 1 !== 0) { throw 'the second argument pos should be an interger and should be 1, 2 or 3' } const sortedData = data.sort(function(a, b) { return a - b }) const n = sortedData.length if ((pos * n / 4) % 1 !== 0) { // pos * n / 4 不为整数时 return sortedData[pos * n / 4 - 1] } else { return (pos / 4) * (sortedData[Math.floor(pos * n / 4) - 1]) + ((4 - pos) / 4) * (sortedData[Math.floor(pos * n / 4)]) } } // 使用中位数作为验证 console.log(quantile4(data, 2)) //=> 940 const Q1 = quantile4(data, 1) const Q3 = quantile4(data, 3) IQR IQR 即四分位距，定义为第一四分位数和第三四分位数的差值。 const IQR = Q3 - Q1 //=> 130 内限 & 离群值 若需要判断一个数据点是否为离群值，就需要先通过四分位数和 IQR 计算出内限，再通过对比该数据点与内限来判断它是否为离群值。 const limit = [ Q1 - 1.5 * IQR, Q3 + 1.5 * IQR ] const outliers = data.filter(function(k) { return k limit[1] }) console.log(outliers) //=> [ 650 ] 13.2 绘制箱线图 凑齐了这些需要用到的数据之后，我们便可以将它们放进图表上了。与前面我们学习使用过的数据图表不一样的是，箱线图一个数据系列就要使用到五个维度的数据。所以我们在做数据绑定的时候也需要分别为这五个维度的数据进行绑定。 13.2.1 准备数据集 跟其他数据图表一样，箱线图的数据同样可以使用 dataset 来提供数据支持。分别需要将 6 个不同的维度数据传入：箱线图标识、最小值、第一四分位数、中位数、第三四分位数、最大值。 const option = { dataset: { source: [ [ 1 /* 第一个箱线图 */, min, Q1, median, Q3, max ] ] } } 13.2.2 准备笛卡尔坐标系 因为箱线图的数据类型是计量数据，所以我们所使用的依然是最熟悉的笛卡尔坐标系。而由于这里暂时只有一个箱线图，为了能够更好地表达数轴的概念，我们将 X 轴作为数据轴，Y 轴作为系列轴。 const option = { xAxis: { type: 'value', scale: true }, yAxis: { type: 'category' }, } 13.2.3 绑定数据系列 绑定数据系列是使用 ECharts 绘制数据图表中最重要的一环，因为这一步直接关系到如何将数据展示在图表上。而箱线图的特殊性在这一步中则显得格外突出，它需要绑定 5 个不同维度的数据。 const option = { series: { type: 'boxplot', encode: { y: 0, x: [ 1, 2, 3, 4, 5 ] } } } 完成了上面的工作以后，我们便可以将图表配置应用到图表实例中查看效果了。 非常好，我们已经在这个图表上看到了一个很好的效果，箱线图非常好地表现了数据的数值范围、离散程度以及中位数特征值。 13.2.4 绘制离群值 除了箱线图以外，我们还知道箱线图有一个内限，用于判断数值是否离群。如果数据中出现了离群值，我们可以将其单绘制到图表上表示出来。离群值可以使用散点 scatter 绘制在图表上。 我们可以多增加一个数据集来存储离群值的数据，以绑定 scatter 数据系列。 const option = { dataset: [ { source: [ [ 1, min, Q1, median, Q3, max ] ] }, { source: outliers.map(function(outlier) { return [ 1, outlier ] }) } ] } 然后我们需要进一步修改数据系列，包括前面的箱线图系列。 const option = { series: [ { type: 'boxplot', datasetIndex: 0, encode: { y: 0, x: [ 1, 2, 3, 4, 5 ] } }, { type: 'scatter', datasetIndex: 1, encode: { y: 0, x: 1 } } ] } 13.3 多系列箱线图 前面我使用一组数据绘制了一个更偏向于一维数轴的箱线图，但是在实际开发和应用中，我们往往需要在一张图表上绘制多组不同数据的箱线图。就比如在进行统计试验的时候，不同的测试水平需要进行多次试验得到数据并进行分析。而多次试验的数据结果需要进行可视化，便可以使用到箱线图进行表达。 比如上面的迈克耳孙-莫雷实验，真正记录的数据肯定不止这一次，我们可以引入多组试验的数据。 const data = [ [850, 740, 900, 1070, 930, 850, 950, 980, 980, 880, 1000, 980, 930, 650, 760, 810, 1000, 1000, 960, 960], [960, 940, 960, 940, 880, 800, 850, 880, 900, 840, 830, 790, 810, 880, 880, 830, 800, 790, 760, 800], [880, 880, 880, 860, 720, 720, 620, 860, 970, 950, 880, 910, 850, 870, 840, 840, 850, 840, 840, 840], [890, 810, 810, 820, 800, 770, 760, 740, 750, 760, 910, 920, 890, 860, 880, 720, 840, 850, 850, 780], [890, 840, 780, 810, 760, 810, 790, 810, 820, 850, 870, 870, 810, 740, 810, 940, 950, 800, 810, 870] ] 13.3.1 整合统计量计算 前面我们为一组数据计算了多个统计量以展示在箱线图上，那么在多组数据中我们可以将前面的计算过程进行封装。 function boxplotDatas(data) { const min = Math.min(...data) const max = Math.max(...data) let median = 0 const n = data.length const sortedData = data.sort(function(a, b) { return a - b }) if (n % 2 == 1) { median = sortedData[((n + 1) / 2) - 1] } else { median = (sortedData[(n / 2 + 1) - 1] + sortedData[(n / 2) - 1]) / 2 } const Q1 = quantile4(data, 1) const Q3 = quantile4(data, 3) const IQR = Q3 - Q1 const limit = [ Q1 - 1.5 * IQR, Q3 + 1.5 * IQR ] const outliers = data.filter(function(k) { return k limit[1] }) return { min, max, median, Q1, Q3, outliers, } } const boxplotData = data.map(function(exprData, i) { return Object.assign({ id: i }, boxplotDatas(exprData)) }) //=> [ // {id: 0, min: 650, max: 1070, median: 940, Q1: 850, …}, // {id: 1, min: 760, max: 960, median: 845, Q1: 800, …}, // ... // ] const outliers = boxplotData .map(function({ id, outliers }) { return outliers.map(function(outlier) { return [ id, outlier ] }) }) .reduce(function(left, right) { return left.concat(right) }) //=> [ // [0, 650], [2, 620], ... // ] 得到数据之后，我们就可以进行数据图表绘制了。 const option = { dataset: [ { source: boxplotData }, { source: outliers } ], xAxis: { type: 'category' }, yAxis: { type: 'value', scale: true }, series: [ { type: 'boxplot', datasetIndex: 0, encode: { x: 'id', y: [ 'min', 'Q1', 'median', 'Q3', 'max' ] } }, { type: 'scatter', datasetIndex: 1, encode: { x: 0, y: 1 } } ] } 小结 这一节中我们学习了一个比较复杂的数据图表，它相较于前面学习和使用过的数据图表使用到了更多维度的数值数据，其自身所具有的统计分析意义也能更直观地表达。 习题 思考箱线图、散点图、折线图、柱状图这几种用于表达计量数据的不同数据图表的异同。 "},"基于JavaScript开发灵活的数据应用/13.复杂数据处理·关系图谱.html":{"url":"基于JavaScript开发灵活的数据应用/13.复杂数据处理·关系图谱.html","title":"13.复杂数据处理·关系图谱","keywords":"","body":"第 8 节 复杂数据处理 · 关系图谱 我们在上一节中用了一个企业中的人员结构作为树形结构的例子，在这棵树中其实节点与节点之间的边（Edge）所表达的是人员之间的上下级关系。而在日常生活中我们还有非常多并不存在上下层次的关系（人际关系、事物关系等等），就好比我们的人际交往中绝大部分都是平等的。而且在树形结构中节点之间的关系严格遵守不形成环的原则，然而在我们的人际交往关系中，环形关系结构则是必然存在的。 当需要使用计算机编程来实现这种结构的时候，就需要用到关系图谱（Graph）。需要注意的是，关系图谱与我们平时所听到的图片是完完全全的两回事。图片是用于表达视觉效果的二维格式（包含点阵图和矢量图），而图形是一种多维的抽象结构，主要用于表达抽象事物之间的关系。 有趣的是我们刚学习完的树形结构其实是一种特殊的关系图谱，树形结构中所规定的是一种节点之间只能有上下级的关系，且不再重复。一棵树形结构中必然存在着根节点和叶节点，但是在关系图谱中却不一定存在明确的头尾节点，它可能是由一群看似杂乱无章的节点相互连接，并且彼此的连接还有一些各式各样的差异，如连接强度不同等。 8.1 无向图 在 7.1.2 节中我们定义了一个用于树形结构的节点，在每一个树形节点中拥有一个来自父节点的引用、存储自身数据的空间和存储子节点引用的数组。 不过与树形结构存在区别的是，树形结构中节点之间的连接是带有方向属性的，即从父节点指向其子节点。而关系图谱存在着两种类型，无向图（Graph）和有向图（Directed Graph，或 Digraph）。其中树形结构正是一种特殊的、每两个顶点之间只有单向边的有向图。但正如上面的图所示，实际应用中同样存在着具有双向关系的有向图。所以在关系图谱中并不存在子节点这一概念，取而代之的则是相邻顶点（Adjacent Vertice）。 8.1.1 定义顶点 一般来说，因为关系图谱具有非常高的复杂性和不确定性，节点与节点之间的关系经常需要发生不同的变化，如果采取像上一节中树形结构中一样，使用引用来表示节点之间的关系，就会产生非常深的引用嵌套。而且 JavaScript 中的引用也无法满足我们表达节点之间关系数据的需求。 所以我们需要另辟蹊径，使用另外一种方式来描述一个关系图谱。我们在上一节的树形结构中，定义一个节点并不需要对其进行编号，因为稳定且单向的层级关系可以使得节点在树形结构中的位置会较为稳定。但这在关系图谱中情况则变得非常的复杂，而导致没办法使用这种简单的方式来完成，那么我们就需要对节点进行编号了。 class Vertex { constructor(id, property) { this.id = id this.property = property } } const me = new Vertex(1, [ 'Will', 'male' ]) 那么问题来了，如果说我们在创建顶点的时候原数据并不带有能够标识每一个个体信息的标识符，就需要有一个能够产生具有唯一性的的标识符。业界通常会使用如 UUID（Universally Unique Identifier，通用唯一识别码）、数据库自增键值等方式。而我们这里可以简单地定义一个用于创建带有标识符的顶点的函数以方便我们使用。 let vertexId = 0 function newVertex(property) { return new Vertex(++vertexId, property) } const me = newVertex([ 'Will', 'male' ]) 8.1.2 定义边 定义好了关系图谱中的顶点之后，就需要开始定义我们用于表达节点之间关系的边了。而因为 JavaScript 中的引用并不能满足稀疏存储和附带信息的需求，所以我们同样需要为边定义一个类型以创建一个边对象。 class Edge { constructor(leftId, rightId, property) { this.leftId = leftId this.rightId = rightId this.property = property } } const will = newVertex({ name: 'Will', gender: 'male' }) const ru = newVertex({ name: 'Rrrruu', gender: 'female' }) const relation = new Edge(will.id, ru.id, 'couple') 现在我们可以通过顶点对象中的 id 属性取得该顶点的标识符，但若需要使用标识符来获取顶点对象本身，就需要别的实体来完成这个需求。而这样的任务我们可以交由关系图谱本身来完成。 8.1.3 图 既然我们对关系图谱中的顶点对象进行编号，以便进行检索，那么我们是不是可以使用同样的方式来对边对象进行编号以便进行检索呢？答案自然是肯定的。 相比于顶点对象只会从自身的 id 被检索，边对象则会从与边相连的两个顶点被检索，所以更需要进行编号以提升检索的速度。通过对边对象的编号和关系的变换，我们可以整理出顶点与边的关系。 整理好这些关系之后，我们就可以通过已经梳理好的逻辑来定义一个关系图谱的 JavaScript 类了。 对顶点进行编号，以优化对顶点的检索； 对边进行编号，并存储好边与顶点的关系。 class Graph { constructor(vertices, edges) { // Vertices this.vertexIds = [] this.vertices = {} for (let i = 0; i 8.1.4 操作图形 完成了关系图谱的建立后，自然需要将其运用起来以配合算法来解决一些我们所面临的问题。但在实现算法之前自然不可能让算法直接涉及图对象中的内部元素，所以我们也需要先为关系图谱定义一些操作方法，如获取某一个顶点、遍历所有顶点、遍历所有边等。 获取某一个顶点 前面在关系图谱类中使用了 vertexIds 存储顶点的标识符和使用 vertices 来存储顶点对象。那么要获取图形中的某一个顶点，保险起见首先要确保在 vertexIds 中存在该节点标识符，否则就直接返回 null。然后再从 vertices 中获取该节点的实例对象以返回。 class Graph { // ... getVertex(vertexId) { if (!_.includes(this.vertexIds, vertexId)) { return null } return this.vertices[vertexId] } } 遍历顶点/边 虽然在 JavaScript 中我们默认所使用的数组都是自带有序特性的，但是在关系图谱的定义中，顶点之间并不存在顺序。所以我们自然也不会允许对图对象中的顶点进行直接的循环操作，而采用回调函数的方式进行循环，以模糊其有序性。 class Graph { // ... eachVertices(callbackFunc) { const self = this return self.vertexIds.forEach(function(vertexId) { return callbackFunc(self.vertices[vertexId]) }) } eachEdges(callbackFunc) { const self = this return self.edgeIds.forEach(function(edgeId) { return callbackFunc(self.edges[edgeId]) }) } } 8.1.5 特征值 我们将关系图谱建立了起来以后，就需要开始对这个图进行一些操作了。首先我们前面就说到树形结构是一种特别的图形结构，那么在树形结构中的一些节点特性在图形结构中也同样适用。 Degree Degree 在树形结构的节点中表示的是某一个节点的子节点数量，而因为在关系图谱中的顶点并不存在“子节点”或“子顶点”的概念，取而代之的则是相邻顶点。而相邻顶点的数量就等于与该顶点相连的边的数量。那么要获取相邻边的数量则首先需要定义一个方法以传入顶点标识符并得到相邻边数组。 class Graph { // ... getEdgesByVertexId(vertexId) { if (!_.includes(this.vertexIds, vertexId)) { return [] } if (!_.has(this.edgeRelations, vertexId)) { return [] } const self = this return self.edgeRelations[vertexId].map(function(edgeId) { return self.edges[edgeId] }) } } 得到相邻边后返回其长度则便是该顶点的度。 class Graph { // ... degree(vertexId) { return this.getEdgesByVertexId(vertexId).length } } 最大的度（Max Degree） 在关系图谱中每一个顶点的度是图论算法中非常重要的计算对象。就好比使用关系图谱描述一个社交群体中人与人的相关关系，每一个人作为一个顶点时，顶点的度则代表了对应的个人社交关系，数量越多则代表该名成员在该群体中的重要性越高。显而易见，如果某一个节点的度最大，则说明他很有可能是这个群体中的核心人物。 寻找一个关系图谱中带有最大度数的顶点并不困难，只需全部先计算出所有顶点的度，然后找出最大数即可。 当然，光是找出最大的度可不能满足算法的需要。除了找出最大的度数以外，自然还需要知道是哪一个顶点具有最大的度数。所以我们需要准备两个函数，一个用于找出带有最大度数的顶点，而另外一个则用于获取其度数。 class Graph { // ... largestVertex() { const self = this const degrees = self.vertexIds.map(function(vertexId) { return { degree: self.degree(vertexId), id: vertexId } }) return self.getVertex(_.maxBy(degrees, 'degree').id) } maxDegree() { return this.degree(this.largestVertex().id) } } const vertices = [ new Vertex(1, 'A'), new Vertex(2, 'B'), new Vertex(3, 'C'), new Vertex(4, 'D'), new Vertex(5, 'E') ] const edges = [ new Edge(1, 2, 1), new Edge(1, 3, 2), new Edge(2, 4, 1), new Edge(3, 4, 1), new Edge(1, 4, 2), new Edge(4, 5, 3) ] const graph = new Graph(vertices, edges) console.log(graph.largestVertex().property) //=> D console.log(graph.maxDegree()) //=> 4 平均度（Average Degree） 在一个关系图谱中，除了最大的顶点度以外，每一个顶点的平均度数也是一个非常重要的数学特征值。在这里我们可以有一个比较巧妙的计算方式，而不需要像上面计算最大度的时候那样子先把所有的顶点度数求出来。这有一个用于计算关系图谱中平均度的公式。 其中 为一个图中的平均度，而 是该图中边的数量， 则是顶点的数量。这个公式还是非常好理解的，因为一条边同时属于左右两个顶点，所以在计算平均度的时候首先需要将边数乘以 ，然后再除以顶点的数量即可得到平均度。 class Graph { // ... avgDegree() { return 2 * this.edgeIds.length / this.vertexIds.length } } const vertices = [ new Vertex(1, 'A'), new Vertex(2, 'B'), new Vertex(3, 'C'), new Vertex(4, 'D'), new Vertex(5, 'E') ] const edges = [ new Edge(1, 2, 1), new Edge(1, 3, 2), new Edge(2, 4, 1), new Edge(3, 4, 1), new Edge(1, 4, 2), new Edge(4, 5, 3) ] const graph = new Graph(vertices, edges) console.log(graph.avgDegree()) //=> 2.4 自环（Self-Loop） 自环是一种十分抽象的概念，其定义是在一个关系图谱内，某一个顶点存在一条边再与自己相连。这种情况我们很难使用一个现实生活中的例子来说明，但是我们可以将一个关系图谱中的每一个顶点看作是事件序列中的某一个事件，顶点间的边则表示多种情况下事件之间的连续关系。那么在这种场景下，顶点的自环就可以被解释为某一个事件的连续发生可能性。 在多种事件顺序发生的可能性中，如果某一个事件的连续发生次数（我们可以使用边的属性值表示）越多，则表示该事件的重要性越强。这种概念在一些对用户行为进行分析的应用中十分重要。 而找到自环的边的方法也非常简单，只需要找到那些左右顶点相同的边即可。 class Graph { // ... loops() { const self = this return self.edgeIds .map(function(edgeId) { return self.edges[edgeId] }) .filter(function(edge) { return edge.leftId === edge.rightId }) } } const vertices = [ new Vertex(1, '1'), new Vertex(2, '2'), new Vertex(3, '3') ] const edges = [ new Edge(1, 1, 3), new Edge(1, 2, 1), new Edge(1, 3, 1), new Edge(2, 3, 2) ] const graph = new Graph(vertices, edges) console.log(graph.loops()) //=> [ Edge{ leftId: 1, rightId: 1, property: 3 } ] 8.1.6 无向图代码清单 class Vertex { constructor(id, property) { this.id = id this.property = property } } class Edge { constructor(leftId, rightId, property) { this.leftId = leftId this.rightId = rightId this.property = property } } let vertexId = 0 function newVertex(property) { return new Vertex(++vertexId, property) } class Graph { constructor(vertices, edges) { // Vertices this.vertexIds = [] this.vertices = {} for (let i = 0; i 8.2 有向图 相比于无向图，有向图则是将无向图中的边加上方向特征，即从原本的一条边即代表两个顶点共同拥有一个平等的关系，变成允许顶点之间存在单向的关系。就好像我们在人际社交中，朋友之间互相认识所以我们是平等的，但是我们也有很多我们只认识他们，他们却不认识我们的人。 8.2.1 有向边 因为我们前面所定义的边是不存在方向特性的，所以我们直接使用了 leftId 和 rightId 来存储与边相连的两个顶点的信息。而有向图的边是带有方向特征的，虽然我们也可以像数学一样定义一个向量的表达方式就是从左到右的（如 ），直接使用前面所定义的边来表示有向边。 但是出于对程序严谨性和语义的考虑，我们还是需要另外定义一个有向边类型以使用。 class DirectedEdge { constructor(originalId, targetId, property) { this.originalId = originalId this.targetId = targetId this.property = property } } 8.2.2 有向图 Digraph 因为使用的边不再是无方向特性的边，所以之前所定义的无向图类型也不能直接当做有向图使用了。有向图和无向图最大的区别就是顶点之间从平行的关系变成了有出或入的单边关系。出代表着某一个顶点存在一个单向的关系指向另外一个顶点，而入则表示某一个顶点被另外一个顶点所指向。 那么前面使用 edgeRelations 来存储顶点与边的关系时则需要加以改动了，我们可以简单地分开 inEdgeRelations 和 outEdgeRelations 来分别存储顶点与入边、出边的关系。 class Digraph { constructor(vertices, edges) { // Vertices this.vertexIds = [] this.vertices = {} for (let i = 0; i 完成了有向图的基本构建后，我们就可以将无向图中的一些数学特征值计算方法应用到有向图中。但其中度的概念在有向图中被分开为入度和出度，所以平均值、最大值等等都需要分别计算。 class Graph { // ... getVertex(vertexId) { if (!_.includes(this.vertexIds, vertexId)) { return null } return this.vertices[vertexId] } eachVertices(callbackFunc) { const self = this return self.vertexIds.forEach(function(vertexId) { return callbackFunc(self.vertices[vertexId]) }) } eachEdges(callbackFunc) { const self = this return self.edgeIds.forEach(function(edgeId) { return callbackFunc(self.edges[edgeId]) }) } getInEdgesByVertexId(vertexId) { if (!_.includes(this.vertexIds, vertexId)) { return [] } if (!_.has(this.inEdgeRelations, vertexId)) { return [] } const self = this return self.inEdgeRelations[vertexId].map(function(edgeId) { return self.edges[edgeId] }) } getOutEdgesByVertexId(vertexId) { if (!_.includes(this.vertexIds, vertexId)) { return [] } if (!_.has(this.outEdgeRelations, vertexId)) { return [] } const self = this return self.outEdgeRelations[vertexId].map(function(edgeId) { return self.edges[edgeId] }) } inDegree(vertexId) { return this.getInEdgesByVertexId(vertexId).length } outDegree(vertexId) { return this.getOutEdgesByVertexId(vertexId).length } largestInDegreeVertex() { const self = this const inDegrees = self.vertexIds.map(function(vertexId) { return { inDegree: self.inDegree(vertexId), id: vertexId } }) return self.getVertex(_.maxBy(inDegrees, 'inDegree').id) } largestOutDegreeVertex() { const self = this const outDegrees = self.vertexIds.map(function(vertexId) { return { outDegree: self.outDegree(vertexId), id: vertexId } }) return self.getVertex(_.maxBy(outDegrees, 'outDegree').id) } maxInDegree() { return this.inDegree(this.largestInDegreeVertex().id) } maxOutDegree() { return this.outDegree(this.largestOutDegreeVertex().id) } avgInDegree() { const self = this const totalInEdgesCount = self.vertexIds .map(function(vertexId) { if (typeof self.inEdgeRelations[vertexId] !== 'undefined') { return self.inEdgeRelations[vertexId] } else { return [] } }) .map(function(edges) { return edges.length }) .reduce(function(a, b) { return a + b }) return totalInEdgesCount / this.vertexIds.length } avgOutDegree() { const self = this const totalOutEdgesCount = self.vertexIds .map(function(vertexId) { if (typeof self.outEdgeRelations[vertexId] !== 'undefined') { return self.outEdgeRelations[vertexId] } else { return [] } }) .map(function(edges) { return edges.length }) .reduce(function(a, b) { return a + b }) return totalOutEdgesCount / this.vertexIds.length } loops() { const self = this return self.edgeIds .map(function(edgeId) { return self.edges[edgeId] }) .filter(function(edge) { return edge.originalId === edge.targetId }) } } 如图所示，我们首先建立一个有向图以备后续使用。 const vertices = [ new Vertex(1, 'A'), new Vertex(2, 'B'), new Vertex(3, 'C'), new Vertex(4, 'D'), new Vertex(5, 'E') ] const edges = [ new DirectedEdge(1, 2, 1), new DirectedEdge(1, 3, 2), new DirectedEdge(2, 4, 1), new DirectedEdge(3, 4, 1), new DirectedEdge(1, 1, 3), new DirectedEdge(3, 5, 4), new DirectedEdge(4, 5, 5) ] const graph = new Digraph(vertices, edges) 8.3 有向图的最短路径 有向图的意义在于能够以抽象的方式表示一些实际生活中的事物，人际关系、地点之间路网关系等等。在心理学中有一个非常重要的理论叫做“六度隔离”（Six Degrees of Separation），而假如我们将一个足够大的人际关系网络使用关系图谱的方式表示出来，那么就可以一探这个理论的究竟了。 而在交通系统中，则可以使用顶点表示地点、交叉路口，用边表示路程，而边的值则可以表示路程的长度。那么这个关系图谱则可以用于计算地点之间的路程，这也是我们所使用的导航系统中的基本原理。 要计算在一个关系图谱中两个顶点之间的最短距离，有非常多的算法用于计算，这里我们介绍一个非常直观和常用的算法——Dijkstra 算法。 Dijkstra 算法是一种适用于有向图的最短路径计算算法，它需要遍历所有的可能性之后，然后返回其中的最短路程。 假设我们使用前面所创建的有向图模型，并将每一条边的距离（边的属性值）作为计算指标，对一整条路径的总距离进行计算。 但由于 Dijkstra 算法涉及的逻辑十分的复杂，有兴趣的同学可以参考掘金上一篇不错的介绍文章进行学习，这里本节仅提供实现代码以供参考学习。 class Digraph { // ... // Dijkstra's algorithm shortestPath(fromVertexId, toVertexId) { const self = this const preferQueue = [] const rootNode = new Node(fromVertexId) const candidateTree = new Tree(rootNode) preferQueue.push(...self.getOutEdgesByVertexId(fromVertexId).map(function(edge) { return [ fromVertexId, edge.targetId ] })) while (preferQueue.length > 0) { const pair = preferQueue.shift() const parentVertexId = pair[0] const currentVertexId = pair[1] // Add the edge to the candidate tree const parentNodes = candidateTree.search(function(node) { return node.name === parentVertexId }) const currentNode = new Node(currentVertexId) parentNodes.forEach(function(parentNode) { candidateTree.addNode(currentNode, parentNode) }) if (currentVertexId === toVertexId) { continue } // Add the next vertex into the prefer queue let outEdges = self.getOutEdgesByVertexId(currentVertexId) if (outEdges.length 0) { const pathsWithDistance = targetNodes .map(function(node) { const vertexId = node.name const path = [ vertexId ] let lastNode = node while (lastNode.parent != null) { path.push(lastNode.parent.name) lastNode = lastNode.parent } return path.reverse() }) .map(function(path) { const distance = path .map(function(vertexId, index) { const nextVertexId = path[index + 1] if (typeof nextVertexId === 'undefined') { return } const edge = self.getOutEdgesByVertexId(vertexId) .find(function(edge) { return edge.targetId === nextVertexId }) return edge }) .filter(function(edge) { return typeof edge !== 'undefined' }) .map(function(edge) { return edge.property }) .reduce(function(distanceA, distanceB) { return distanceA + distanceB }) return { path, distance } }) const shortestPath = _.minBy(pathsWithDistance, 'distance') shortestPath.path = shortestPath.path.map(function(vertexId) { return self.getVertex(vertexId) }) return shortestPath } else { return { path: [], distance: Infinity } } } } const vertices = [ new Vertex(1, 'A'), new Vertex(2, 'B'), new Vertex(3, 'C'), new Vertex(4, 'D'), new Vertex(5, 'E') ] const edges = [ new DirectedEdge(1, 2, 1), new DirectedEdge(1, 3, 2), new DirectedEdge(2, 4, 1), new DirectedEdge(3, 4, 1), new DirectedEdge(1, 1, 3), new DirectedEdge(3, 5, 4), new DirectedEdge(4, 5, 5) ] const graph = new Digraph(vertices, edges) console.log(graph.shortestPath(1, 5)) //=> // { // distance: 6, // path: [ // Vertex{ A }, // Vertex{ C }, // Vertex{ E } // ] // } 小结 在本节中，我们学习了如何构建一个没有方向特征的关系图谱，也就是无向图，来表示一些事物之间的平等关系网络；还学习了在无向图的基础上，为顶点之间的边加上方向特性，构成具有传递性的关系网络，以表示一些更为具体的事物关系；并且对一种最短路径寻路算法 Dijkstra 进行了探索。 习题 请自行并认真地学习 Dijkstra 算法，并思考如何对 Dijkstra 算法进行变化，使其可以应用在无向图中。 使用加权无向图构建一个你身边朋友圈的关系图谱，并使用习题 1 中所得到的 Dijkstra 算法变种，探索“六度隔离”理论在你身边朋友圈中的适用性。并且通过使用度的概念，寻找你身边朋友圈中的“核心人物”。 学习了最短路径计算算法之后，请思考如何寻找一个关系图谱中两个点之间的最长路径。 "},"基于JavaScript开发灵活的数据应用/14.复杂数据图表·树形图.html":{"url":"基于JavaScript开发灵活的数据应用/14.复杂数据图表·树形图.html","title":"14.复杂数据图表·树形图","keywords":"","body":"第 15 节 复杂数据图表 · 树形图 翻过了关系图谱这座小山丘之后，让我们继续回忆一下我们在前面就提到过的一种特殊的关系图谱——树形。树形结构有着非常明确的上下级关系，可以非常直观地表达出事物的因果关系，且其规则复杂却足够灵活，因而能够很好地使用在各种算法和场景中。 使用 ECharts 来对树形结构进行可视化，可以为这种强大的数据结构加上更强的交互性，能让你的用户更好地梳理和理解树形结构中所承载的内容。 15.1 准备数据 在第 7 节中我们介绍了如何利用树形结构及其相关的运算算法来对一系列关系数据进行处理，而本章节我们将要使用 ECharts 进行具有可交互特性的图表可视化。 和在上一节中的关系图谱中所使用的数据集类似，由于 ECharts 对数据集进行应用之前都需要先进行一系列的预处理，而这过程中很有可能会与我们所实现的类中的某些属性或方法相冲突。 所以我们需要准备一个转换函数，将我们第 7 节中所生成的树形结构数据转换为更纯粹的 JavaScript 对象数据，也就是俗称的 JSON 数据。 const root = new Node('root') const node1 = new Node('node 1') const node2 = new Node('node 2') const node3 = new Node('node 3') const node4 = new Node('node 4') const node5 = new Node('node 5') const node6 = new Node('node 6') const tree = new Tree(root) tree.addNode(node1) tree.addNode(node2) tree.addNode(node3, node1) tree.addNode(node4, node1) tree.addNode(node5, node2) tree.addNode(node6, node5) function treeDataHelper(treeNode) { const node = { value: treeNode.value } if (treeNode.children && treeNode.children.length > 0) { node.children = node.children || [] treeNode.children.forEach(function(childNode) { node.children.push(treeDataHelper(childNode)) }) } return node } const pureRoot = treeDataHelper(tree.root) 15.2 编写配置 ECharts 在这种较为复杂的数据图表中有着非常优秀的封装，它可以帮助我们很快地将复杂的数据结构根据图表配置展示出我们所希望看到的可视化图表，这一特点在树形图中尤为明显。 const option = { series: { type: 'tree', data: [ pureRoot ] } } Live DEMO: https://codepen.io/iwillwen/pen/zJXBEV Bravo！极其简单的配置便可以得到样式良好且可交互的树形图表，但我们发现在树形图中节点并没有将节点的名称展示出来，那么接下来我们依然是进入我们非常熟悉的图表优化环节。 图表优化 显示节点名称 事实上 ECharts 的树形图在不需要添加任何配置项的情况下也可以展示节点的名称，不过因为我们在第 7 节中所指定的节点类 Node 中代表节点值或名称的属性为 value 而 ECharts 树形图中则需要使用 name，所以便无法直接展示出节点的名称。 而这一问题也并不是无法解决的，我们可以使用 label.formatter 的方式为节点添加标签。 const option = { series: { // ... label: { formatter: '{@value}' // 绑定到 value 属性上 } } } Live DEMO: https://codepen.io/iwillwen/pen/aaxZEo 但是我们还发现这个配置虽然满足了在图表上显示节点名称的需求，却出现了名称与节点图标重叠的情况。那么我们便需要对这个情况进行调整，以帮助图表的使用者和阅读者更好地使用。 调整节点名称位置 在对数据进行调整之前，我们需要明确调整的思路。因为树形结构中的节点除了根节点都会与上一层的父节点有一条连线以表示节点之间的父子关系，但相对的每一个节点与上一层父节点的关系数量只有一个，但却有可能有很多的子节点与自身有关系，所以如果将节点的名字放在了节点的右方便很有可能会出现严重的与节点的边相重叠。 所以对于叶节点以外的所有节点，我们需要将名字显示在节点的左边，而因为叶节点是没有子节点的，所以叶节点的名称可以显示在节点图标的右边。 const option = { series: { // ... label: { position: 'left' }, leaves: { label: { position: 'right' } } } } Live DEMO: https://codepen.io/iwillwen/pen/qMwNxd 15.3 其他树形图形态 就如上一节中关系图谱的两种模板，除了默认的从左往右伸展的树形图结构以外，ECharts 的树形图表也提供了多种不同的结构模板。 除了最基本的从左往右展开排列以外，还有其他三个方向的模板（如从上往下）。除此以外还有一个十分好看的放射形树形图。 const option = { series: { type: 'tree', layout: 'radial', data: [ treeDataHelper(tree.root) ], label: { formatter: '{@value}' } } } Live DEMO: https://codepen.io/iwillwen/pen/LJvZdG 这里的效果稍微有点差，当然这是因为节点的数量太少了。 小结 这一节中我们学习了另外一种复杂数据结构——树形结构的可视化图表的使用，其中因为 ECharts 对数据的内部处理导致了我们需要利用其他手段将我们原本实现的树形结构转换为更纯净的 JavaScript 对象数据集，那么我们本节的习题也会从这一个点上进行练习。 习题 在上一节中我们并没有为关系图谱数据设计类似 treeDataHelper 这样的函数，而在本节中我们利用了递归的方式进行了逐层的转换来对树形结构进行了转换。 请模仿 treeDataHelper 编写出适用于上一节中关系图谱数据的 graphDataHelper。 "},"基于JavaScript开发灵活的数据应用/15.数据分析师的好帮手·辅助线.html":{"url":"基于JavaScript开发灵活的数据应用/15.数据分析师的好帮手·辅助线.html","title":"15.数据分析师的好帮手·辅助线","keywords":"","body":"第 16 节 数据分析师的好帮手 · 辅助线 经过了一系列的学习，我们已经掌握了多种日常开发中最常用的数据图表，并且可以对各种结构的数据集进行预处理。但是在我们进行可视化图表开发的时候经常会发现如果仅仅将数据使用数据系列展示在图表上的话，是没办法非常直观地展示所有数据信息的。 而这个时候，辅助线便成了帮助开发人员和分析人员更好地利用可视化图表的强有力工具。 16.1 为什么要使用辅助线 我们在第 5 节中学习了如何利用 JavaScript 对数据中的一些数学特征值进行计算，而这些数学特征值往往可以更好、更直观地将数据的基本状况表达出来。 但是这些数学特征值往往只是通过对一组数值进行计算过后得到的另一组数值，那么辅助线便是帮助开发者和数据分析人员更好地使用这些数学特征值的最好工具。 16.2 辅助线基本操作 在 ECharts 中辅助线并不是一种独立的数据类型，它需要依附在某一个数据系列上以表示其与该数据系列的关系。 假设我们有以下数据集，并将其绘制成一个简单的柱状图。 const chartEl = document.querySelector('#chart') const myChart = echarts.init(chartEl) const data = [ 50, 61, 56, 46, 72, 53 ] const option = { dataset: { source: data.map((y, i) => ({ x: i + 1, y })) }, xAxis: { type: 'category' }, yAxis: { type: 'value' }, series: { type: 'bar', encode: { x: 'x', y: 'y' } } } 然后接下来我们通过非常简单的计算，得出这一组数据的平均数。 const mean = data.reduce((left, right) => left + right) / data.length console.log(mean) //=> 56.333333333333336 假如说需要将这个计算结果展示在图表上，那么根据目前所设定的坐标系可知我们需要添加一条横向的水平线，而这条水平线的纵向位置应该为 坐标轴上该数值所对应的位置。 那么在 ECharts 中便需要在对应的数据系列上添加一个 markLine 配置，并在 markLine.data 中添加一个 yAxis 值为对应平均值的配置。 const option = { // ... series: { // ... markLine: { data: [ { name: '平均线', yAxis: mean } ] } } } 16.2.1 ECharts 的自带辅助线 除了我们可以自行计算目标辅助线的数值以外，ECharts 自身也提供了一些比较常用的辅助线，除了前面我们自行计算的平均值外，还有最大值和最小值。 const option = { // ... series: { // ... markLine: { data: [ { name: '平均值', type: 'average' }, { name: '最大值', type: 'max' }, { name: '最小值', type: 'min' } ] } }, } 16.3 辅助线高级用法 是否觉得前面的辅助线都太简单而没有挑战性了？恭喜你已经拥有了成为大牛的一个非常重要的优秀特点，那么我们接下来便需要向更复杂、更具有功能性的辅助线应用进发吧。 16.3.1 SPC 控制图 在传统的统计学领域中，有一种广泛用于工业生产的统计方法——质量管理。在工业生产领域中，企业为了能够稳定且长期地发展产品的质量和销量，必须要对产品生产过程中的各种数据进行监控和分析，比如生产原料、成本、产品特性、质量指标、销量等等。 而其中成本和质量指标直接关系到了企业的长期生存条件，所以对这些数据的监控和分析则显得尤为重要。其中有一种名为 SPC 控制图的数据可视化图表的应用非常广泛，它通过对数据进行计算并将计算结果作为辅助线绘制在图表上。这些辅助线可以帮助数据分析人员非常直观地看到数据中的总体状况和突发的异常情况等。 SPC 控制图事实上是多种控制图表的总称，但其核心都是相似的。SPC 控制图主要通过计算三个控制线：UCL（控制上限）、CL（中心线）和 LCL（控制下限）。在一些情况下还可以将控制图的上下限的中间区域分为 6 等份，并分别标记为控制 A 区、B 区以及 C 区，并通过记录数据点落在这三个控制区域的数量来对数据的稳定性进行直观的判定。 注：图片来源 Wikipedia —— Western Electric rules 16.3.2 建立数据集 假设我们通过随机方法生成一组数值数据（参考第 11 节），并将其绘制到折线图上。 const X = [ 100 ] const n = 50 - 1 const r = 0.1 function randomCoefficient(r) { const rand = Math.random() const coefficient = (rand - 0.5) * 2 * r return coefficient } for (let i = 0; i [ 100, 95.23, ... ] const data = X.map(function(x, i) { return { time: i + 1, value: x } }) const option = { dataset: { source: data }, xAxis: { type: 'value', name: 'i', nameLocation: 'middle', nameGap: 25 }, yAxis: { type: 'value', scale: true, name: 'x', nameLocation: 'end' }, series: { type: 'line', encode: { x: 'time', y: 'value' } }, } 16.3.3 计算 SPC 控制图的必要数值 SPC 控制图所使用的数据主要需要计算数据的平均值和标准差（Standard deviation，并非标准误 Standard error）。平均值的计算我们使用 Lodash 中的 _.mean 即可，但 Lodash 并没有提供标准差 的计算方法，所以我们这里也需要自行实现一下标准差的计算方法。 为数组 的长度， 为数组 的平均值。 %5E2%7D%7BN%20-%201%7D%7D%0A%5Cend%7Balign*%7D) function sd(array) { const mean = _.mean(array) const top = array .map(function(x) { return Math.pow(x - mean, 2) }) .reduce(function(left, right) { return left + right }) const bottom = array.length - 1 return Math.sqrt(top / bottom) } 计算所得数据的平均值和标准差后，便可以计算 SPC 控制图中的 UCL 和 LCL 控制值了。UCL 和 LCL 的值分别为以下： 其中从上面的图中我们可以看到，SPC 控制图可以将从 LCL 到 UCL 中间的区域等分为 6 份，显然可以得出控制区域的区间为以下： 在 EChart 中，除了辅助线以外还提供了一个非常实用的工具 —— visualMap。它可以将图表中某一个区域内的元素统一为一种颜色，这正好可以应用到 SPC 控制图的三个控制区域上。 首先我们需要计算所需要的数据。 const mean_X = _.mean(X) const sd_X = sd(X) const ucl = mean_X + 3 * sd_X const lcl = mean_X - 3 * sd_X const areaA = [ [ mean_X + 2 * sd_X, mean_X + 3 * sd_X ], [ mean_X - 3 * sd_X, mean_X - 2 * sd_X ] ] const areaB = [ [ mean_X + sd_X, mean_X + 2 * sd_X ], [ mean_X - 2 * sd_X, mean_X - sd_X ] ] const areaC = [ [ mean_X - sd_X, mean_X + sd_X ] ] 16.3.4 绘制 SPC 控制图 首先我们将控制线通过 markLine 组件绘制在图表上。 const option = { // ... yAxis: { type: 'value', name: 'x', nameLocation: 'end', max: Math.max(ucl + 5, Math.max(...X)), min: Math.min(lcl - 5, Math.min(...X)) }, series: { // ... markLine: { data: [ { name: 'UCL', yAxis: ucl }, { name: 'Area B', yAxis: areaB[0][1] }, { name: 'Area C', yAxis: areaC[0][1] }, { name: 'Mean', yAxis: mean_X }, { name: 'Area C', yAxis: areaC[0][0] }, { name: 'Area B', yAxis: areaB[1][0] }, { name: 'LCL', yAxis: lcl } ] } } } 然后结合 visualMap 我们便可以将完整的 SPC 控制图绘制出来了。 const option = { // ... visualMap: { top: 10, right: 10, // visualMap 图例位置 pieces: [ /* Area A */ { gt: areaA[0][0], lte: areaA[0][1], color: '#cc0033' }, /* Area B */ { gt: areaB[0][0], lte: areaB[0][1], color: '#ffde33' }, /* Area C */ { gt: areaC[0][0], lte: areaC[0][1], color: '#096' }, /* Area B */ { gt: areaB[1][0], lte: areaB[1][1], color: '#ffde33' }, /* Area A */ { gt: areaA[1][0], lte: areaA[1][1], color: '#cc0033' } ] } } 小结 在我们进行数据分析的时候，如果只有独立的数据图表而没有加以辅助的工具，数据分析工作的效率就会大大降低。所以利用数学计算配合图形展示的方式为数据图表添加辅助线以及其他辅助工具（如标注区域等），可以为数据图表的使用者带来极大的便利性。 "},"基于JavaScript开发灵活的数据应用/16.更高维度的数据可视化图表.html":{"url":"基于JavaScript开发灵活的数据应用/16.更高维度的数据可视化图表.html","title":"16.更高维度的数据可视化图表","keywords":"","body":"第 17 节 更高维度的数据可视化图表 我们在前面的 16 个章节中分别学习了如何使用 JavaScript 对各种类型的数据结构进行操作处理、通过结合不同的数据结构来进行简单的数据统计，以及各种数据可视化图表的创建使用。而在这一节内容正式开始之前，我们先来简单地复习和梳理一下数据统计的基本原理，以便我们在进入后面的章节时能够更好地理解实际问题。 我们在第 11 节中曾经学习过名义数据和计量数据的概念，而这些都是对于不同维度的数据进行定义。而数据分析最基本的前提条件便是找出所需要进行分析的数据维度，就比如一个商家销售记录中的订单价格、订单类型、下单时间都是各种不同的维度。 而多维数据（多个数据，两个及以上）的组合是数据分析的基础，因为在很多情况下只针对一维数据的分析（如平均值、方差等）是很难反应出实际情况也无法直接与目标问题相关联的。所以我们在进行实际的分析之前，首先要找出我们需要进行分析的维度组合，比如交易额与时间（计量数据与有序数据）、交易类型和订单金额（分类数据与计量数据）等等。这些二维数据我们在前面的数据图表学习中都有不同程度的学习和使用过，而在这一节中我们将学习比二维更高的多维数据可视化。 17.1 多维数据集 实际上我们在进行各种数据分析的工作时，所能遇到的数据集基本上都会是拥有多个维度的，比如我们在第 5 节中所使用的 crew 人员数据集，每一个人便有 4 个维度的数据。 但这个数据集并不适合用来演示本章节所需要学习的内容，所以我们还需要其他数据集来进行使用。 还记得我们这本小册的介绍页面中的这个数据图表吗？ 这张图表是 ECharts 官方实例中的一个实例，光是在这张图表中就已经使用了 5 个不同的数据维度： X 轴：日期（时间） Y 轴：AQI 指数 散点颜色：城市（分类） 散点大小：PM2.5 指数 颜色明暗度：二氧化硫指数 而其实在实际的数据集中，除此以外还有 PM10 指数、一氧化碳、二氧化氮以及空气污染程度，足足 9 个维度的数据。且其中有 6 个维度的数据都是数值数据，所以这个数据集非常适合作为多维数据分析的用例。 17.1.1 组合并转换数据集 在 ECharts 的官方实例代码中，我们可以得到这个数据集。 const data = [ ['北京',1,55,9,56,0.46,18,6,'良'], ['北京',2,25,11,21,0.65,34,9,'优'], ['北京',3,56,7,63,0.3,14,5,'良'], ['北京',4,33,7,29,0.33,16,6,'优'], ['北京',5,42,24,44,0.76,40,16,'优'], ['北京',6,82,58,90,1.77,68,33,'良'], ['北京',7,74,49,77,1.46,48,27,'良'], ['北京',8,78,55,80,1.29,59,29,'良'], ['北京',9,267,216,280,4.8,108,64,'重度污染'], ['北京',10,185,127,216,2.52,61,27,'中度污染'], ['北京',11,39,19,38,0.57,31,15,'优'], ['北京',12,41,11,40,0.43,21,7,'优'], ['北京',13,64,38,74,1.04,46,22,'良'], ['北京',14,108,79,120,1.7,75,41,'轻度污染'], ['北京',15,108,63,116,1.48,44,26,'轻度污染'], ['北京',16,33,6,29,0.34,13,5,'优'], ['北京',17,94,66,110,1.54,62,31,'良'], ['北京',18,186,142,192,3.88,93,79,'中度污染'], ['北京',19,57,31,54,0.96,32,14,'良'], ['北京',20,22,8,17,0.48,23,10,'优'], ['北京',21,39,15,36,0.61,29,13,'优'], ['北京',22,94,69,114,2.08,73,39,'良'], ['北京',23,99,73,110,2.43,76,48,'良'], ['北京',24,31,12,30,0.5,32,16,'优'], ['北京',25,42,27,43,1,53,22,'优'], ['北京',26,154,117,157,3.05,92,58,'中度污染'], ['北京',27,234,185,230,4.09,123,69,'重度污染'], ['北京',28,160,120,186,2.77,91,50,'中度污染'], ['北京',29,134,96,165,2.76,83,41,'轻度污染'], ['北京',30,52,24,60,1.03,50,21,'良'], ['北京',31,46,5,49,0.28,10,6,'优'], ['广州',1,26,37,27,1.163,27,13,'优'], ['广州',2,85,62,71,1.195,60,8,'良'], ['广州',3,78,38,74,1.363,37,7,'良'], ['广州',4,21,21,36,0.634,40,9,'优'], ['广州',5,41,42,46,0.915,81,13,'优'], ['广州',6,56,52,69,1.067,92,16,'良'], ['广州',7,64,30,28,0.924,51,2,'良'], ['广州',8,55,48,74,1.236,75,26,'良'], ['广州',9,76,85,113,1.237,114,27,'良'], ['广州',10,91,81,104,1.041,56,40,'良'], ['广州',11,84,39,60,0.964,25,11,'良'], ['广州',12,64,51,101,0.862,58,23,'良'], ['广州',13,70,69,120,1.198,65,36,'良'], ['广州',14,77,105,178,2.549,64,16,'良'], ['广州',15,109,68,87,0.996,74,29,'轻度污染'], ['广州',16,73,68,97,0.905,51,34,'良'], ['广州',17,54,27,47,0.592,53,12,'良'], ['广州',18,51,61,97,0.811,65,19,'良'], ['广州',19,91,71,121,1.374,43,18,'良'], ['广州',20,73,102,182,2.787,44,19,'良'], ['广州',21,73,50,76,0.717,31,20,'良'], ['广州',22,84,94,140,2.238,68,18,'良'], ['广州',23,93,77,104,1.165,53,7,'良'], ['广州',24,99,130,227,3.97,55,15,'良'], ['广州',25,146,84,139,1.094,40,17,'轻度污染'], ['广州',26,113,108,137,1.481,48,15,'轻度污染'], ['广州',27,81,48,62,1.619,26,3,'良'], ['广州',28,56,48,68,1.336,37,9,'良'], ['广州',29,82,92,174,3.29,0,13,'良'], ['广州',30,106,116,188,3.628,101,16,'轻度污染'], ['广州',31,118,50,0,1.383,76,11,'轻度污染'], ['上海',1,91,45,125,0.82,34,23,'良'], ['上海',2,65,27,78,0.86,45,29,'良'], ['上海',3,83,60,84,1.09,73,27,'良'], ['上海',4,109,81,121,1.28,68,51,'轻度污染'], ['上海',5,106,77,114,1.07,55,51,'轻度污染'], ['上海',6,109,81,121,1.28,68,51,'轻度污染'], ['上海',7,106,77,114,1.07,55,51,'轻度污染'], ['上海',8,89,65,78,0.86,51,26,'良'], ['上海',9,53,33,47,0.64,50,17,'良'], ['上海',10,80,55,80,1.01,75,24,'良'], ['上海',11,117,81,124,1.03,45,24,'轻度污染'], ['上海',12,99,71,142,1.1,62,42,'良'], ['上海',13,95,69,130,1.28,74,50,'良'], ['上海',14,116,87,131,1.47,84,40,'轻度污染'], ['上海',15,108,80,121,1.3,85,37,'轻度污染'], ['上海',16,134,83,167,1.16,57,43,'轻度污染'], ['上海',17,79,43,107,1.05,59,37,'良'], ['上海',18,71,46,89,0.86,64,25,'良'], ['上海',19,97,71,113,1.17,88,31,'良'], ['上海',20,84,57,91,0.85,55,31,'良'], ['上海',21,87,63,101,0.9,56,41,'良'], ['上海',22,104,77,119,1.09,73,48,'轻度污染'], ['上海',23,87,62,100,1,72,28,'良'], ['上海',24,168,128,172,1.49,97,56,'中度污染'], ['上海',25,65,45,51,0.74,39,17,'良'], ['上海',26,39,24,38,0.61,47,17,'优'], ['上海',27,39,24,39,0.59,50,19,'优'], ['上海',28,93,68,96,1.05,79,29,'良'], ['上海',29,188,143,197,1.66,99,51,'中度污染'], ['上海',30,174,131,174,1.55,108,50,'中度污染'], ['上海',31,187,143,201,1.39,89,53,'中度污染'] ] 17.1.2 语义化代码 由于数据集中的每一行的承载方式都是一个数组而不是我们前面所习惯使用的对象字面量，所以为了能让我们接下来所编写的代码更具可读性，需要使用一个用于“翻译”维度信息的工具来帮助我们和这份代码的阅读者更好地进行理解。 我们可以通过配合 LoDash 库所提供的方法来实现一个用于描述实际维度与数组下标之间关系的字典或对象，标识为 d（维度，dimension）。 const d = _.mapValues(_.invert( [ 'city', 'date', 'aqi', 'pm25', 'pm10', 'co', 'no2', 'so2', 'pollution' ] ), parseInt) //=> { // city: 0, // date: 1, // ... // } 这样我们就可以比较好地获取到某一个维度的数组下标了。 data[0][d['aqi']] //=> 55 事实上在 ECharts 中可以直接把 [ 'city', 'date', ... ] 这个维度数据放在 dataset.source 的第一行来实现类似的效果。 另外由于在 ECharts 中分组的表现形式必须为多个数据系列（Series），而我们的数据集是混在一起的，所以我们可以通过再实现一个简单的小工具来完成数据集的分割。 function subDataset(dataset, property, targetValue) { return dataset.filter(function(row) { return row[property] === targetValue }) } console.log(subDataset(data, 0, '广州')) //=> [ // [ '广州', 1, 26, 37, 27, 1.163, 27, 13, '优' ], // [ '广州', 2, 85, 62, 71, 1.195, 60, 8, '良' ], // [ '广州', 3, 78, 38, 74, 1.363, 37, 7, '良' ], // ... // ] 17.2 ECharts 中的多维表现方式 在我们前面学习过的数据可视化图表中，绝大部分都是对一维或二维数据进行可视化的图表。而实际上我们在 ECharts 中可以通过各种不同的方式将各种组件组合在一维或二维图表上，以表达更高维度的信息。 就以我们上面的散点图作为例子，散点的颜色、大小、明暗程度都算是不同的维度，这些都是可以用来增加图表维度容量的组件，我们可以按需使用。 17.2.1 基础图表 在加入表示更高维度的组件之前，我们需要先将最基础的图表绘制出来。 这里我们选取数据集中的日期 date 以及 AQI 指数 aqi 作为直角坐标轴的二维数据。 const option = { dataset: [ { source: subDataset(data, 0, '北京') }, { source: subDataset(data, 0, '广州') }, { source: subDataset(data, 0, '上海') } ], legend: {}, xAxis: { type: 'category' }, yAxis: { type: 'value' }, series: [ { name: '北京', datasetIndex: 0, type: 'scatter', encode: { x: d['date'], y: d['aqi'] } }, { name: '广州', datasetIndex: 1, type: 'scatter', encode: { x: d['date'], y: d['aqi'] } }, { name: '上海', datasetIndex: 2, type: 'scatter', encode: { x: d['date'], y: d['aqi'] } } ] } 可以不难地发现其实这个基础的图表中就已经包含了 3 个维度了，那么接下来就使用更多的数据组件将不同的数据维度表示出来。 17.2.2 添加组件 在 ECharts 中有一个非常强大的组件名为 visualMap，字面意思是“视觉映射组件”。它的作用是将维度数据中的数据与图表上的视觉元素进行映射，并依托 Web 应用的天然优势为可视化图表添加可操作特性，使得图表更具实用性。 我们在上一节中就曾经使用过该组件。 官方文档中说明 visualMap 支持绑定图表元素中的以下视觉元素： symbol: 图元的图形类别。 symbolSize: 图元的大小。 color: 图元的颜色。 colorAlpha: 图元的颜色的透明度。 opacity: 图元以及其附属物（如文字标签）的透明度。 colorLightness: HSL 颜色的明暗度。 colorSaturation: HSL 颜色的饱和度。 colorHue: HSL 颜色的色调。 其中图元的类别、颜色（比如前面的按组分类）可以与离散型数据（如分类数据）相绑定，而其余的（包括颜色在内）可以与连续型数据（数值数据）相绑定。 作为例子我们先使用图元的大小和数据集中的 PM2.5 数据相绑定。 const option = { // ... visualMap: [ { type: 'continuous', // 定义为连续型数据 text: [ 'PM2.5' ], dimension: d['pm25'], // 绑定到 PM2.5 数据 inRange: { // 范围内的图元样式 symbolSize: [ 10, 70 ] // 图元大小范围 }, // 定义图例位置 left: 'right', top: '10%' } ] } visualMap 还支持为范围内的内容设置可视区间，即在原本的范围内，图表的使用者还可以根据自己的需求自行调整所需要的区间大小。 const option = { // ... visualMap: [ { // ... calculable: true // 展示区间手柄 } ] } 17.2.3 多个 visualMap 组件 既然已经通过 visualMap 组件将第四个维度展示出来了，那么我们就趁热打铁把更多的维度展示在图表上吧，详细的使用方法可以自行查看 ECharts 的官方文档，这里不再赘述。 图形类别 → 污染等级（pollution） 图元的颜色的透明度 → 二氧化硫浓度（so2） const option = { // ... visualMap: [ // ... { type: 'piecewise', text: [ '污染等级' ], dimension: d['pollution'], pieces: [ { value: '优', symbol: 'circle' }, { value: '良', symbol: 'rect' }, { value: '轻度污染', symbol: 'roundRect' }, { value: '中度污染', symbol: 'triangle' }, { value: '重度污染', symbol: 'diamond' }, ], left: 'right' }, { type: 'continuous', text: [ '二氧化硫浓度' ], dimension: d['so2'], min: 0, max: 50, inRange: { colorAlpha: [ 0.5, 1 ], }, calculable: true, orient: 'horizontal', top: 'bottom' } ] } 17.3 有趣的特殊维度——时间 时间是一个非常有趣的维度，因为时间维度在进行统计和可视化的过程中并没有一个标准的计量单位。比如在上面这个数据集中，时间的计量单位是天（day），总容量为 31。31 并不算是一个较大的基数，而若需要将时间维度的容量增大却有两种截然不同的方法： 计量单位不变，向单边或双边扩容，即扩大时间范围； 时间范围不变，缩小计量单位，即更细化维度颗粒度。 第一种方法不必作过多的说明，我们需要详细认识的是第二种方法。时间维度的计量单位有非常多：年、季、月、周、日、时、分、秒，更小的甚至还有毫秒、微秒。 一般来说，我们每向更细的方向修改一次时间计量单位，时间维度的总容量都会出现激增的情况。还记得我们在第 6 节中曾经学习和使用过的时间序列控制工具吗？通过不同的组合方式并加以统计方法，就可以运用到时间维度上并展示在数据图表上。 在 ECharts 中有一个非常厉害的组件叫 dataZoom，它的作用跟前面的 visualMap.calculable 有些类似。它可以在一个维度上设定一个范围值，并通过可自由操控的方式对数据的视野范围进行移动和缩放。 这个工具经常会被使用在时间维度上，因为它的使用方式和设计原理与时间维度实在是太相称了，话不多说我们直接看代码。 const option = { // ... dataZoom: [ { type: 'slider' // 定义为独立的、可操作的滑动组件 } ] } 是的，就这么简单的几行代码就完成了对 dataZoom 的引入和配置。当图表上只有一个图表并且 X 坐标轴（当然也可以使用在 Y 坐标轴）唯一时，ECharts 内部会自动完成其配置。而更详细的配置方法可以自行参考官方文档。 而若出现原本时间维度的总容量较大，而希望图表的初始展示范围只选取其中的一部分时，通过为 dataZoom 添加初始配置即可。 const option = { // ... dataZoom: [ { type: 'slider', startValue: 15, endValue: 31 } ] } 小结 这一节中我们学习了如何充分利用 ECharts 所提供的各种工具来扩张我们在二维平面上数据图表的维度容量。同时我们也看到了 Web 为传统统计、数据可视化所带来的新变化，非常简单、直接、直观的可操作性使得数据可视化图表变得非常的生动和更加实用。 本节为本小册中，介绍关于 ECharts 使用的最后一节。从下一节开始，我们将正式进入开发 JavaScript 数据应用的环节，学习开发一个真正具有实际价值的数据应用。 习题 请自行收集身边的各种数据，并整理成多维度数据集。结合本节所学知识自行开发一个具有良好可用性的多维度数据图表。 "},"基于JavaScript开发灵活的数据应用/17.动态数据应用·用数据流概念重新理解数据转换.html":{"url":"基于JavaScript开发灵活的数据应用/17.动态数据应用·用数据流概念重新理解数据转换.html","title":"17.动态数据应用·用数据流概念重新理解数据转换","keywords":"","body":"第 18 节 动态数据应用 · 用数据流概念重新理解数据转换 我们在前面的章节（如第 8 节和第 9 节）中学习了如何对我们不同的数据内容进行转换从而得到另外一种新的数据以满足我们的实际需求。 而在动态数据应用的开发中，数据的来源很有可能是多个数据源甚至来自不确定的数据源（统一数据接口的不同数据源），而这些数据源中很有可能包括流式数据源。流式数据源与传统统计学中的数据集有着非常大的差别，一般来说统计学所使用的数据源都来自于静态数据集，也就是说统计结果的时效性依赖于数据集的时效性，一旦数据集过时也就意味着统计结果的过时。而流式数据集的好处是数据内容可以不断地更新，比如股票数据、人口数据、天气数据等等，具有较强的时效性。 而在 JavaScript 的数据应用中，流式数据集的来源可以有很多种类，可以使来自服务端的实时数据（实时通讯或服务器推送等）也可以是来自用户的实时操作（数据录入等）。当然如何接受实时数据并不是我们这本小册所关注的内容，我们要学习的是当我们需要利用流式数据集时，如何更好地处理数据处理或者进行数据统计。 18.1 数据层面 · 不断产生的数据——流式数据 流式数据顾名思义就是以流的方式产生的数据，最显而易见的流式数据就是随着时间发展不断产生新元素的时序数据。 18.1.1 两种不同的流式数据 一般来说数据流是以块（chunk）的形式不断到达数据处理层的，比如时序数据中，数据流会不断地把每一个单位时间内数据块产生和传递到数据消费方。 dataSource.on('tick', function(time, chunkData) { console.log(time, chunkData) }) //=> 1 {...} //=> 2 {...} //=> 3 {...} //=> ... 数据块是数据流的基本形式，但有的时候数据提供方（如一些第三方服务的 SDK）会先行对实时数据进行处理，并通过如响应式（Reactive）的方式将变更后的完整实时数据集提供给数据消费方。 如果需要进行处理和统计的实时数据集形式为后者，那么作为消费方只需要关心如何响应新数据集即可，其余的与静态数据集并无差别。 setInterval(function() { console.log(dataSource.dataset.length) }, 1e3) // run per second //=> 0 //=> 1 //=> 2 //=> ... 18.1.2 流式数据的处理和计算 我们可以使用两个非常简单且熟悉的例子，来说明这两种不同的数据流的差别，分别为平均数和众数。对一组数据进行数学统计时，这两个数学特征值在中都是非常重要的指标。在第 5 节中我们就已经学习过这两个数学特征值的计算方法。 假设我们有一个实时数据源，它会随着时间不断地产生一个数值（实时温度、股票价格、股票交易量等等），而我们需要计算其在一个时间周期内的平均数和众数。 假若该实时数据源是以完整的数据集提供给我们的时候我们就可以直接使用前面的方法进行计算即可。（_.reduceByKey 方法请参考第 5 节） function mode(array) { if (array.length [] NaN [] //=> [ 1 ] 1 [ 1 ] //=> [ 1, 2 ] 1.5 [ 1, 2 ] //=> [ 1, 2, 2 ] 1.67 [ 2 ] //=> ... 但若数据源是通过数据块的形式提供给消费方时，情况就有点不一样了，我们先来看看平均值的计算。 我们知道平均值的计算公式是数组的总和 除以数组的长度 ，假设我们要给数组 的子集，前 个元素的数组进行求平均，就可以得到以下两条公式。 ![\\begin{gather} m_n = \\frac{\\sum_{i=1}^n x_i}{n} \\\\ m_{n-1}= \\frac{\\sum_{i=1}^{n-1} x_i}{n-1} \\end{gather}](https://juejin.im/equation?tex=%5Cbegin%7Bgather%7D%0Am_n%20%3D%20%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5En%20x_i%7D%7Bn%7D%20%5C%5C%0Am_%7Bn-1%7D%3D%20%5Cfrac%7B%5Csum_%7Bi%3D1%7D%5E%7Bn-1%7D%20x_i%7D%7Bn-1%7D%0A%5Cend%7Bgather%7D) 我们通过对 2 式对 1 式进行变形就可以得到我们所需要的公式。 ![m_n = \\frac{{m_{n-1} \\times (n-1) + x_n}}{n}](https://juejin.im/equation?tex=m_n%20%3D%20%5Cfrac%7B%7Bm_%7Bn-1%7D%20%5Ctimes%20(n-1)%20%2B%20x_n%7D%7D%7Bn%7D) 这条公式表示了长度为 的数组 的平均值等于数组 的前 个元素的平均值乘以 再加上第 个元素后除以 。其中 就可以理解为数据流中的数据块，我们只需要维护上一个平均值和上一个数据集长度即可。以下例子假设数据集不断“吐出”数值 1,2,3,4 并以此类推。 let mean = 0 let n = 0 dataSource.on('tick', function(time, chunkData) { mean = ((mean * n) + chunkData） / (++n) console.log(mean) }) //=> 1 //=> 1.5 //=> 2 //=> 2.5 // ... 但众数就不一样了，众数的每次计算都需要对数据集的整体进行计算，而没办法像平均值一样简单地通过增量式的计算方法进行统计。所以对于以数据块形式进行消费的数据集来说，如统计众数这种整体计算或同比环比等错位计算需求，消费方需要自行维护所接收到的所有数据块，并组合成一个完整的数据集，然后在对数据集进行统计。 当然只针对于统计众数来说，也可以通过维护一个元素和频次的的哈希表来减少计算的次数以满足增量计算的需求，但这也只是一个变相的维护完整数据集而已。当我们需要对数据集进行多种不同的处理和统计需求时，更稳妥的方式还是需要维护完整的数据集。 18.2 逻辑层面 · 流式处理数据 —— 函数串流 上面我们先从数据层面利用数据流的概念重新理解了数据集，而现在我们把目光往上移动，看看如何利用数据流的概念重新理解数据处理。 事实上我们在本小册的前面这么多章节中就已经接触了很多这样的例子了，就比如最常见的词频统计，我们将一个一维的字符串数据一步一步地进行拆分、转换处理，最后得到一个二维的数据集，中间经过了以下步骤： 分割单词：\"foo foo bar\" → [\"foo\", \"foo\", \"bar\"] 添加频次：[\"foo\", \"foo\", \"bar\"] → [[\"foo\", 1], [\"foo\", 1], [\"bar\", 1]] 合并同类项：[[\"foo\", 1], [\"foo\", 1], [\"bar\", 1]] → [[\"foo\", 2], [\"bar\", 1]] 数据形式转换：[[\"foo\", 2], [\"bar\", 1]] → [{ word: \"foo\", count: 2 }, { word: \"bar\", count: 1 }] 如果我们把每一个步骤都单独以一个函数的形式编写，便可以得到以下处理函数。 // 分割单词 function splitWords(string) { return string.split(/\\s+/g) } // 添加频次 function addCount(words) { return words.map(function(word) { return [ word, 1 ] }) } // 合并同类项 function sumWordCount(tuples) { return _.reduceByKey(tuples, function(left, right) { return left + right }) } // 数据形式转换 function convertTuplesToDataset(tuples) { return tuples.map(function(tuple) { return { word: tuple[0], count: tuple[1] } }) } 把这些处理函数组合起来，便完成了整个词频统计流程。 const rawText = \"foo foo bar\" const dataset = convertTuplesToDataset( sumWordCount( addCount( splitWords(rawText) ) ) ) console.log(dataset) //=> [ //=> { word: \"foo\", count: 2 }, //=> { word: \"bar\", count: 1 } //=> ] 以函数封装的方式将数据处理的的逻辑抽象出来，第一可以让代码逻辑变得比较简洁干净，二来可以避免代码中副作用（原数据被修改）的产生，减少数据上出现以外的情况。 18.2.1 虚拟实体 Getter 而且暂且抛开词频统计不说，假设我们将上面的四个步骤用 A、B、C、D 表示，可以表示为以下流程。 如果说我们有另外一个数据转换的流程可以复用其中的步骤 A 和 B，并在其后接着完成步骤 E 和 F。 而因为两个流程的起始点都是一样的，所以不仅仅可以复用前端重合的步骤，就连结果也是可以被复用的。这里就要介绍到一种编程语言中的概念 Getter。 Getter 指的是通过定义一个无传入参数函数，在函数中经过若干处理逻辑后返回一个值，而 Getter 的使用方并知道该对象是一个函数，使用的时候只像在调用一个变量。 const object = { name: 'iwillwen', // Getter get message() { return `Hello ${this.name}` } } console.log(object.message) //=> Hello iwillwen object.name = 'juejin' console.log(object.message) //=> Hello juejin 我们可以把前面的词频统计流程利用 Getter 整合起来。 const wordCountAnalyzer = { rawText: '', get splittedWords() { return splitWords(this.rawText) }, get wordsWithOne() { return addCount(this.splittedWords) }, get wordsWithCount() { return sumWordCount(this.wordsWithOne) }, get wordCountDataset() { return convertTuplesToDataset(this.wordsWithCount) } } wordCountAnalyzer.rawText = 'hello world' console.log(wordCountAnalyzer.wordCountDataset) //=> [ // { word: 'hello', count: 1 }, // { word: 'world', count: 1 } // ] wordCountAnalyzer.rawText = 'Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua' console.log(wordCountAnalyzer.wordCountDataset) //=> [ // { word: 'Lorem', count: 1 }, // { word: 'ipsum', count: 1 }, // ... // ] 我们可以发现当我们修改 wordCountAnalyzer.rawText 后，wordCountAnalyzer.wordCountDataset 也同时随着改变，而中间流程的 Getter 也会随着变化。 应用到我们前面假设的多处理流程中就会是这样的： const object = { originalValue: '', // ─┐ 数据源 // │ get A() { // 18.2.2 Getter with Vue.js 而 Getter 的特性在一些开发框架中则通过其内部的响应逻辑完成，比如 Vue.js 中则提供 computed 的接口以完成对其 data 内容的转换。 后面的章节中将会使用 Vue.js 作为本小册的 UI 开发框架，不了解的同学可以自行通过官方文档、其他教程或小册进行学习。 const vm = new Vue({ // ... data: { originalValue: '' }, computed: { A() { return methodA(this.originalValue) }, B() { return methodB(this.A) } } }) console.log(vm.B) //=> something processed by method B 18.3 动态地流式处理数据流 上面我们分别介绍了数据流的概念以及通过封装函数和应用 Getter 的方式对数据进行流式的处理。Getter 的好处是可以让数据处理的过程在数据的不断变化中自动化起来，而不断变化恰恰正是数据流的特点，那么将这两者组合起来便会将数据流的流动路径往后延长，让流式数据集也能享受全自动数据处理的优势。 但有的时候在我们的数据处理逻辑中，需要处理的对象并不只有原数据本身，有一些数据处理逻辑是需要引入参数的，比如筛选过滤需要引入一个或多个筛选条件，这样便跟上面 Getter 的“无参数函数”有所冲突了。更甚者，这些需要引入的参数本身也是动态的，无法写死在处理逻辑中。 对于这种情况，我们一般的做法便是将这些参数也看作是一个流式数据源，并将其一同引入到处理流程中，当然其切入的点可能并一定是从流程的最初始位置，而是在其被需要的位置直接引入。 这里我们直接使用 Vue.js 作为例子，我们通过模拟一个不断有新数据产生的实时数据集，然后我们需要通过一个过滤参数将过滤后的数据展示出来。 Type Filter: None ---------- {{type}} Timestamp: {{item.timestamp}} - Type: {{item.type}} - Value: {{item.value}} // app.js const vm = new Vue({ el: '#app', data: { dataset: [], typeFilter: 'none', typesSet: [ 'foo', 'bar', 'test' ] }, computed: { filteredDataset() { if (this.typeFilter === 'none') { return this.dataset } return this.dataset.filter(item => item.type === this.typeFilter) } }, mounted() { // 模拟流式数据集 setInterval(() => { const randomType = this.typesSet[Math.round(Math.random() * (this.typesSet.length - 1))] this.dataset.push({ type: randomType, timestamp: Date.now(), value: Math.random().toString(32).substr(2) }) }, 1e3) } }) DEMO 在线地址：https://codepen.io/iwillwen/pen/ebEwZE?editors=1010 小结 我们终于在这一小节中介绍到了跟本小册标题相关的动态数据了，这对许多只了解和使用过静态数据集的同学来说会是一个非常新鲜的事物。我们还学习了两种不同的数据流数据和它们对应的处理消费方式，知道了如何使用合适的方式进行相应的处理。 在接下来的章节中我们将更深入动态数据应用的开发中来。 习题 请模仿平均数和众数的应用，分别举出一对可以应用在数据块和整体流式数据集的例子； 请利用 18.3 中的 DEMO，对其中的动态数据集和过滤条件进行添加和调整，寻找更多的可能性； 请模仿 18.3 的 DEMO，将我们前面所学习到的词频统计使用到 Vue.js 应用中。 "},"基于JavaScript开发灵活的数据应用/18.动态数据应用·使用Vue.js为数据流添加动态转换过滤器.html":{"url":"基于JavaScript开发灵活的数据应用/18.动态数据应用·使用Vue.js为数据流添加动态转换过滤器.html","title":"18.动态数据应用·使用Vue.js为数据流添加动态转换过滤器","keywords":"","body":"第 19 节 动态数据应用 · 使用 Vue.js 为数据流添加动态转换过滤器 在上一节中我们学习了如何利用 Vue.js 配合我们之前所学习过的数据处理方法来处理流式数据。在这一节中，我们将继续学习如何利用 Vue.js 来应对结构不确定的数据流。 19.1 基于数据的动态转换过滤器 在上一节中我们通过一个既定的 typeSet 来模拟一个不断产生数据的流式数据集，而在我们使用 Vue.js 进行构建的数据应用中，也是根据这个 typeSet 来提前生成了一个用于过滤数据的过滤器。 但有的时候前端的数据应用并不知道来自其他数据服务的数据内容究竟有哪些过滤项，那么我们便需要根据数据应用所得到的实际数据来生成过滤器。 function mockDataSource(typesSet) { const dataset = [] const timer = setInterval(() => { const randomType = typesSet[Math.round(Math.random() * (typesSet.length - 1))] dataset.push({ type: randomType, timestamp: Date.now(), value: Math.random().toString(32).substr(2) }) }, 1e3) return { dataset, stop() { clearInterval(timer) } } } const dataSource = mockDataSource(Array(10).fill(1).map((_, i) => `type${i + 1}`)) 这段代码中我们模拟了一个包含多种可过滤数据 type 的流式数据集，且该数据集过滤字段内容是“不可预知”的。那么我先把它利用 Vue.js 展示到页面上看一下。 DEMO 在线地址：https://codepen.io/iwillwen/pen/oJKMaK?editors=1010 很好，现在我们再把上一节中层间实现过的类型过滤器应用到这里来。但不一样的是这一次这个流式数据集中所包含的类型都是不可知的，那么按照我们上一节中所学习到的方法，我们则可以将流式数据集中的类型集通过流失处理的方式也处理成一个数据流，应用到过滤器选项中。 我们可以通过使用 Lodash 中的 groupBy 方法先将流式数据集按照 type 字段进行聚合，然后再通过 keys 方法得到聚合后的聚合键集，从而得到动态的过滤选项。 Type Filter: None ---------- {{type}} Type Timestamp Value {{item.type}} {{item.timestamp}} {{item.value}} function mockDataSource(typesSet) { const dataset = [] const timer = setInterval(() => { const randomType = typesSet[Math.round(Math.random() * (typesSet.length - 1))] dataset.push({ type: randomType, timestamp: Date.now(), value: Math.random().toString(32).substr(2) }) }, 1e3) return { dataset, stop() { clearInterval(timer) } } } const dataSource = mockDataSource(Array(10).fill(1).map((_, i) => `type${i + 1}`)) new Vue({ el: '#app', data: { typeFilter: 'none', dataset: dataSource.dataset }, computed: { typesSet() { return _.keys(_.groupBy(this.dataset, 'type')) }, filteredDataset() { if (this.typeFilter === 'none') { return this.dataset } return this.dataset.filter(item => item.type === this.typeFilter) } } }) DEMO 在线地址：https://codepen.io/iwillwen/pen/PXMBvb?editors=1010 19.2 更复杂的动态转换过滤器 笔者在工作中经常会遇到一些非常复杂的动态数据开发需求，其中不乏如 BI（Business Intelligence）之类的项目，具体可以参考如 Superset、Metabase 等等优秀的开源项目。在这些项目中，数据与数据应用之间是相隔离的（特别是通用的开源项目），也就是数据应用除了知道数据源以一个二维表的形式存在以外，对这个数据集的内容和结构完全不清楚。 一般这种情况会出现一个可配置的方案，也就是数据应用本身是一个可配置的通用转换、过滤、展示工具，而数据源和表结构则以配置的方式传递给数据应用。为了表达这种情况的极端性，我们先从模拟一个较为复杂的数据集开始。 function genTypes(columnName, count = 10) { return Array(count).fill(1).map((_, i) => `${columnName}-type${i + 1}`) } function genColumns(count = 10) { return Array(count).fill(1).map((_, i) => { const columnName = `column${i + 1}` const types = genTypes(columnName) return { name: columnName, types } }) } function mockDataSource(columnsCount = 10) { const dataset = [] const columns = genColumns(columnsCount) const timer = setInterval(() => { const timestamp = Date.now() const value = Math.random().toString(32).substr(2) const item = { timestamp, value } columns.forEach(({ name, types }) => { const randomType = types[Math.round(Math.random() * (types.length - 1))] item[name] = randomType }) dataset.push(item) }, 1e3) return { dataset, stop() { clearInterval(timer) } } } const dataSource = mockDataSource(4) setInterval(() => { console.log(dataSource.dataset[dataSource.dataset.length - 1]) // The last inserted one }, 1e3) //=> { timestamp: 1547970415609, value: '4ta9d9chh9o', column1: 'column1-type1', column2: 'column2-type7', column3: 'column3-type2', column4: 'column4-type6' } //=> { timestamp: 1547970416612, value: 'cobh86f288', column1: 'column1-type7', column2: 'column2-type6', column3: 'column3-type9', column4: 'column4-type1' } //=> ... 19.2.1 将未知结构的数据集展示在页面上 在这个例子中我们模拟了一个拥有多个不同字段的数据集，而且其中的每一个字段都有多种不确定的可过滤值。现在我们需要将这个数据集展示到页面上，由于数据应用在开发的时候是不清楚数据集的结构的，所以在展示之前首先需要对数据集进行转换以得到该数据集的字段列表。 因为数据结构在数据到达之前是不可知的，而且一般情况下我们需要约定数据集中的每一个个体数据都严格符合整体结构。这样的情况下，便可以通过取得数据集中的第一个记录来取得该数据集的整体结构。 {{column}} {{item[column]}} // ... new Vue({ el: '#app', data: { dataset: dataSource.dataset }, computed: { columnNames() { if (this.dataset && this.dataset.length > 0) { return _.keys(this.dataset[0]) } return [] } } }) DEMO 在线地址：https://codepen.io/iwillwen/pen/NeQmRX?editors=1010 19.2.2 为未知结构的数据集添加动态过滤器 我们已经将这个复杂的数据集通过动态地感知到其结构以后展示在了页面上，那么接下来便需要对这个数据集进行转换过滤了，因为对各种不确定的数据集进行各种操作正正就是 BI 项目的基本需求。 而且对于这种拥有多个不同字段的数据集，数据应用拥有高度可配置的过滤机制往往是最起码的要求。数据表格展示作为最基本的数据展示方式，我们可以回想一下数据应用领域中的“老大哥”——Microsoft Excel。对于 Excel 本身来说，每一个处理的表格文件都是一个不确定的数据集，而作为用户的我们可以通过其中的“筛选过滤”功能对数据集中的各种字段进行过滤，而且这个机制是可以多字段叠加的。那么在我们开发的数据应用中该如何进行开发呢？ 首先需要设计好的是，因为在这个需求中我们要控制两个对象，一个是数据集本身，另外一个则是控制过滤器本身的配置集。我们将这个过滤器的配置集单独处理，每个过滤器包含两个值：字段名和过滤目标值。默认情况下每一个过滤器都是为了将数据集中的制定字段的指定值记录过滤出来，当然在实际应用开发中很有可能还有有更多的选项，比如大于小于之类的过滤方式。 const filters = [ { column: '', value: '' }, // ... ] 当我们只有一个过滤器的时候，我们可以直接判断数据集中的每一个记录中的指定字段是否为指定过滤值。那么当有多个过滤器时，我们可以使用 JavaScript 中的一个原生 API Array.prototype.every 来完成这一操作。 const row = { /* ... */ } const filters = [ /* ... */ ] const isPassed = filters.every(filter => { if (filter.column === 'none' || filter.value === 'none') { return true } return row[filter.column] === filter.value }) 通过 Vue.js 的一些比较基本的使用方法，我们可以非常方便地对过滤器的配置集进行管理。 new Vue({ // ... data: { // ... filters: [] }, methods: { addFilter() { this.filters.push({ column: 'none', value: 'none' }) }, removeFilter(index) { this.filters.splice(index, 1) } } }) 但是要让用户能够通过数据应用所提供的功能，来为数据集添加动态过滤器，那么首先就得让用户知道当前有哪些可选值。所以跟需要知道数据集结构中有哪些字段一样，过滤器的可选值还包含了每一个字段中有哪些现有值可以作为过滤的目标值。那么还记得我们在第 10 节中曾经学习过的行式数据集和列式数据集的转换方法吗？在默认的行式数据集中，我们很难通过某一个字段名取得该字段的所有可选值。但是使用列式数据集在处理这个需求时，则变得有着非常好的天然优势。配合着 Lodash 的 _.uniq 取得每一个字段中的所有唯一值。 new Vue({ // ... data: { // ... dataset: dataSource.dataset }, computed: { colOrientedDataset() { return rowOriented2ColOriented(this.dataset) }, columnNames() { if (this.dataset && this.dataset.length > 0) { return _.keys(this.dataset[0]) } return [] }, optionsOfColumns() { return _.fromPairs( this.columnNames.map(columnName => [ columnName, _.uniq(this.colOrientedDataset[columnName]) ]) ) }, } }) 取得这些信息之后，就可以在页面上开发过滤器的控制组件了。我们使用一个简单的列表来表示这个过滤器的配置集，而列表中的每一个元素包含两个 组件分别对应着过滤器的对应字段和过滤目标值。 组件中则分别使用前面准备好的 columnNames 和 optionsOfColumns 来生成 可选项。 Add Filter None {{columnName}} = None {{option}} x 最后我们将这些元素都整合起来便可以得到一个相当不错的效果。 Add Filter None {{columnName}} = None {{option}} x {{column}} {{item[column]}} // ... const dataSource = mockDataSource(4) function applyColumn(colDataset, columnName) { if (!_.has(colDataset, columnName)) { colDataset[columnName] = [] } return colDataset } function rowOriented2ColOriented(rowDataset) { let colDataset = {} rowDataset.forEach(function(row, i) { const columnNames = _.keys(row) columnNames.forEach(function(columnName) { colDataset = applyColumn(colDataset, columnName) colDataset[columnName][i] = row[columnName] }) }) return colDataset } new Vue({ el: '#app', data: { filters: [], dataset: dataSource.dataset }, computed: { colOrientedDataset() { return rowOriented2ColOriented(this.dataset) }, columnNames() { if (this.dataset && this.dataset.length > 0) { return _.keys(this.dataset[0]) } return [] }, optionsOfColumns() { return _.fromPairs( this.columnNames.map(columnName => [ columnName, _.uniq(this.colOrientedDataset[columnName]) ]) ) }, filteredDataset() { return this.dataset.filter(row => { return this.filters.every(({ column, value }) => { if (column === 'none' || value === 'none') { return true } return row[column] === value }) }) } }, methods: { addFilter() { this.filters.push({ column: 'none', value: 'none' }) }, removeFilter(index) { this.filters.splice(index, 1) } } }) DEMO 在线地址：https://codepen.io/iwillwen/pen/Rvbeox?editors=1010 小结 在本小节中我们从较为简单的流式数据集触发，一步一步地尝试添加动态过滤器，并且也从简单的、确定的数据集向更常见的复杂且不确定结构的数据集学习，最后在这种数据集上结合软件工程中的“分治”手段将复杂的问题切分为三个部分：动态数据源、动态数据源的转换过滤展示以及过滤机制的控制管理。相信从第一节开始学习到现在的你已经掌握了非常多的各种数据结构和对他们进行逻辑处理的方法，那么在最后一节中我们将着手开发一个实际的项目，把我们曾经学习过的东西应用起来。 习题 尝试在过滤器机制中为每一个过滤器添加过滤方法，即从原本的等于添加如大于、小于、不等于、包含、不包含等等，完成后在评论区提交你的 CodePen 地址。 "},"基于JavaScript开发灵活的数据应用/19.动态数据应用·应用高大上的动态数据流（上）.html":{"url":"基于JavaScript开发灵活的数据应用/19.动态数据应用·应用高大上的动态数据流（上）.html","title":"19.动态数据应用·应用高大上的动态数据流（上）","keywords":"","body":"第 20 节 动态数据应用 · 应用高大上的动态数据流（上） 我们已经学会了如何将一个不断生成的数据源展示在页面上并加以转换处理和过滤，但是到现在为止我们使用的都是通过自行模拟的实时数据源，并没有真正地接触到从其他系统得到的实时数据源。那么在本节中我们将要自己实现一个真正的实时数据源，并将其应用到我们的数据应用中。 20.1 构建真实实时数据源 笔者是一个游戏爱好者，前些天发现家里的网络在某一个时间段会变得非常不稳定，而在笔者喜欢的其中一款游戏中便自带了一个用于监控网络情况的数据图表工具。而这个图表的数据源其实就是通过对游戏服务器的 IP 进行持续的发送 Ping 请求，并记录其返回耗时。 20.1.1 Ping 而 Ping 工具事实上就是我们对网络情况进行监控的一个基本工具，我们可以使用这一行命令检查我们本地设备到 www.baidu.com 所在服务器（经过 DNS 解析后的 CDN 节点）的网络情况。 $ ping www.baidu.com PING www.a.shifen.com (14.215.177.39): 56 data bytes 64 bytes from 14.215.177.39: icmp_seq=0 ttl=56 time=9.315 ms 64 bytes from 14.215.177.39: icmp_seq=1 ttl=56 time=7.433 ms 64 bytes from 14.215.177.39: icmp_seq=2 ttl=56 time=7.327 ms 64 bytes from 14.215.177.39: icmp_seq=3 ttl=56 time=19.945 ms 64 bytes from 14.215.177.39: icmp_seq=4 ttl=56 time=6.379 ms 64 bytes from 14.215.177.39: icmp_seq=5 ttl=56 time=9.088 ms ... 我们可以看到其中的一个重要指标便是 time 字段，这个字段所表示的便是从我们本地设备连接到 www.baidu.com 所在 CDN 节点并完成返回的耗时。一般来说 Ping 工具会在上一次发送 Ping 信号后一秒进行下一次发送，而如果网络情况良好的话，几毫秒的耗时基本可以忽略不计并把这个数据看做一个平均一秒生成一个新数据的实时数据源。 20.1.2 Commands Piping 在 Unix 或 Linux 系统中，命令行有一个非常有用的特性叫命令串流（Pipe），意思是在一行命令中运行多个程序，每一个程序通过标准输入输入（Standrad Input/Output）按顺序串联形成一个串流。 假设有程序 a 和程序 b，在命令行中运行 a | b。其中 a 程序会向标准输出中打出 Hello, World.，那么在 b 程序中就可以通过标准输入得到 Hello, World.。 比如假设在某一个文件夹下有许多不同的文件，我希望查找该文件夹根目录下文件名包含 .md 的文件，就可以通过串流 ls 命令（列出当前文件夹根目录下所有文件、文件夹）和 grep 命令（按指定匹配模式匹配输入数据中的内容）来实现。 $ ls -l | grep .md -rw-r--r--@ 1 iwillwen staff 7527 11 22 2017 15113423841119.md -rw-r--r--@ 1 iwillwen staff 1159 11 22 2017 15113423841120.md -rw-r--r--@ 1 iwillwen staff 16474 11 23 2017 15113424478129.md -rw-r--r--@ 1 iwillwen staff 461 11 23 2017 15113991864913.md -rw-r--r--@ 1 iwillwen staff 6021 11 26 2017 15116829262749.md ... 那么我们这里可以使用 ping 命令对 www.baidu.com 进行网络通信检查，并使用 GNU 中的 awk 命令对 Ping 工具所返回的数据进行处理和提取。 $ ping www.baidu.com | awk 'match($0, /time=(.*)ms|timeout/) { print (RLENGTH > 7) ? substr($0, RSTART+5, RLENGTH-8) : 9999; fflush() }' 6.243 9.578 9.297 7.441 8.182 35.143 ... 现在我们已经得到了不断生成的实时数据源，但是我们要怎么将它变成一个我们的数据应用能够使用的数据源呢？我们还需要将其变成一个 Web 服务。 20.1.3 Pipe STDOUT to Web with Node.js 我们需要将来自标准输入的内容变成一个 Web 服务以提供给基于 JavaScript 的数据应用使用，而比较可惜的我们目前找不到一个现成的通用工具来实现这个需求。所以我们需要借助 Node.js 的 Web 服务能力来实现这个需求，另外我们还需要使用到 Unix 或 Linux 自带的 nc 工具。 nc 工具可以将来自标准输入的数据通过 TCP 连接传递到指定服务上。而我们还需要使用 Node.js 分别构建一个 TCP 服务和 HTTP 服务，分别用于接收来自 nc 的 TCP 数据流和为 JavaScript 数据应用提供 HTTP 接口。 具体 Node.js 程序代码如下： // shells-web.js const http = require('http') const net = require('net') const url = require('url') const { Transform } = require('stream') const streams = {} const HTTP_PORT = 8080 const NET_PORT = 1337 const httpServer = http.createServer((req, res) => { const id = url.parse(req.url).pathname.substr(1) if (!streams[id]) { res.writeHead(404) res.end('Stream not found.') return } res.writeHead(200, { 'Connection': 'keep-alive', 'Content-Type': 'text/plain', 'Access-Control-Allow-Origin': '*' }) res.flushHeaders() streams[id] .on('') .pipe(res) }) const ncServer = net.createServer(connection => { const id = Math.random().toString(32).substr(2) const stream = new Transform({ transform(chunk, encoding, callback) { callback(null, chunk) } }) connection.pipe(stream) connection.once('end', () => { stream.destroy() delete streams[id] }) streams[id] = stream connection.write(`Pipeline is served on http://localhost:${HTTP_PORT}/${id}\\n`) connection.write(`Example: curl -v http://localhost:${HTTP_PORT}/${id}`) }) ncServer.listen(NET_PORT, () => { console.log(`Net Server is binding on localhost:${NET_PORT}`) }) httpServer.listen(HTTP_PORT, () => { console.log(`HTTP Server is binding on localhost:${HTTP_PORT}`) }) 使用 Node.js 运行这个程序便可以分别在 1337 端口和 8080 端口开启 TCP 服务和 HTTP 服务。 $ node shells-web.js Net Server is binding on localhost:1337 HTTP Server is binding on localhost:8080 20.1.4 Ping → Web 当前面的准备工作都完成以后，我们就可以将这些都串联起来，为 JavaScript 服务提供一个基于 Ping 工具的实时数据源了。 $ ping www.baidu.com | awk 'match($0, /time=(.*)ms|timeout/) { print (RLENGTH > 7) ? substr($0, RSTART+5, RLENGTH-8) : 9999; fflush() }' | nc localhost 1337 Pipeline is served on http://localhost:8080/ Example: curl -v http://localhost:8080/ 现在我们使用 curl 工具来验证一下我们的转换工具是否生效了。 $ curl -v http://localhost:8080/ * Trying ::1... * TCP_NODELAY set * Connected to localhost (::1) port 8080 (#0) > GET /lb83qkua0eo HTTP/1.1 > Host: localhost:8080 > User-Agent: curl/7.54.0 > Accept: */* > 非常好！值得一提的是，我们使用 Node.js 所创建的 HTTP 服务是以 HTTP 长连接的方式将 ping 的数据不断输出的，而不是利用普通的 TCP 连接。而这种形式的 HTTP 接口在浏览器端的 JavaScript 中该如何使用呢？ 20.2 应用“高大上的动态数据流” 得到了真正的动态实时数据流以后，我们就要在我们的 JavaScript 数据应用中进行应用了。但是我们前面使用 Node.js 作为基础平台提供的 HTTP 接口是一个长连接的方式不断提供数据的，那么我们应该如何将长连接中不断出现的新数据获得得到呢？ 20.2.1 读取长连接数据 Fetch API 是浏览器为 JavaScript 提供的一个用于访问 HTTP 接口的 API。但是一般来说我们在使用 fetch 函数都是用于获取一次性输出完成的 HTTP 接口，其实对于这种长连接接口，我们也使用 fetch 来获取其中的实时数据。 fetch 函数执行之后在其返回的 Promise 对象中会提供一个 Response 对象，我们可以通过这个对象再取得一个 ReadableStreamDefaultReader 对象，这个 reader 对象便是我们读取数据流中的数据的入口。 fetch('http://localhost:8080/') .then(res => res.body.getReader()) .then(reader => { // ... }) 我们调用 reader 对象的 read 方法，该方法会返回一个 Promise 对象，该 Promise 对象的结果是一个包含 value 和 done 的对象。value 是一个 Uint8Array 数组，我们可以将其理解为二进制数据，我们需要首先将其转换为字符串然后再解析为数字也就是我们需要的网络延迟值。而 done 则是当前长连接是否已经被关闭，如果还没有被关闭我们则需要继续读取。 const read = ({ value, done }) => { if (done) return // 解析数据 const ping = parseFloat(new TextDecoder(\"utf-8\").decode(value)) if (ping > 0) { // 输出获取到的 ping 值 console.log(ping) } // 继续读取 if (!done) reader.read().then(read) } reader.read().then(read) 最后我们把这些都整合到一起，做成一个封装好的数据源对象。 class PingSource { constructor(streamUrl, onData) { this.streamUrl = streamUrl this.dataset = [] this.onData = onData } load(streamUrl) { this.streamUrl = streamUrl this.loadStream() } loadStream() { this.controller = new AbortController() const signal = this.controller.signal fetch(this.streamUrl, { signal }) .then(res => res.body.getReader()) .then(reader => { const read = ({ value, done }) => { if (done || signal.aborted) return const ping = parseFloat(new TextDecoder(\"utf-8\").decode(value)) if (ping > 0) { const now = Date.now() if (this.onData) { this.onData(ping, now) } this.dataset.push({ ping, timestamp: now }) } if (!done && !signal.aborted) { reader.read() .then(read) .catch(handleError) } } reader.read() .then(read) .catch(handleError) }) } stop() { if (this.controller) { this.controller.abort() } } } function handleError(err) { return false // console.error(err) } // 创建数据源 const pingSource = new PingSource() // 加载数据 pingSource.load('http://localhost:8080/') // 验证数据源实时性 setInterval(() => { console.log(pingSource.dataset.length) }, 1e3) //=> 1 //=> 2 //=> 3 // ... 这样我们的实时数据源便已经准备好了！接下来我们把他跟我们前面所学过的知识结合起来吧。 20.2.2 展示数据 我们所得到的实时数据流是一个以数值为内容的时间序列，所以我们可以使用折线图来表达这些数据。我们在 PingSource 的构建函数中提供了一个 onData 的回调函数接口，我们可以通过这个回调函数不断地将新数据传递给 ECharts，已达到数据不断出现在图表上的目的。 const chartEl = document.querySelector('#chart') const myChart = echarts.init(chartEl) // 创建数据源 const pingSource = new PingSource('http://localhost:8080/', () => { myChart.setOption({ dataset: { source: pingSource.dataset }, xAxis: { type: 'time' }, yAxis: { type: 'value' }, tooltip: { trigger: 'axis' }, series: { type: 'line', name: 'ping', encode: { x: 'timestamp', y: 'ping' } } }) }) // 开始加载数据 pingSource.loadStream() DEMO 在线地址（需自行更改数据流地址）：https://codepen.io/iwillwen/pen/pGJvNe?editors=0010 20.3 优化数据源——为实时数据流添加自动过期机制 我们已经将我们的实时数据源与我们的图表连接起来，并可以在页面上看到不断生成的实时数据了。但是过不了多久我们就会发现，实时数据不断在图表上堆积但实时数据很多时候是具有较短的时效性的，而我们现在所使用的网络监控数据便是其中的一种。我们并不需要关心 1 分钟甚至 30 秒以前的网络状态，我只需要知道很短的时间内我的网络状况即可。 那么为了避免出现图表上存在过多无用数据，我们需要为我们的实时数据源添加自动过期的机制。一般来说自动过期的实现方法是为数据添加 TTL 参数（Time To Live，存活时间），但是 TTL 的实际实现细节是十分复杂的，在这里我们可以进行取巧。前面说到 Ping 工具我们可以看做是一个每秒钟产生一次数据的数据源，那么加入我们需要为我们的每一个 ping 数据添加一个 30 秒的 TTL 参数，即每一个数据可存活 30 秒。在当前场景中可以近似的看做是我们只存 30 秒的数据，即只存储最近 30 个实时数据，一旦数据集中的数据个数超过 30 便将前面的数据删除。 class PingSource { // ... setTTL(seconds) { this.ttl = seconds } loadStream() { // ... const read = ({ value, done }) => { // ... if (ping > 0) { // 检查超时 if (this.ttl && this.ttl > 0 && this.dataset.length === this.ttl) { // 到达超时上线，删除第一个数据 this.dataset.shift() } // ... } // ... } // ... } } 我们将这个特性应用到图表上便可以实现这样的效果。 // ... // 设置超时 pingSource.setTTL(30) // 开始加载数据 pingSource.loadStream() DEMO 在线地址：https://codepen.io/iwillwen/pen/XObmNd?editors=0010 20.4 为网络监控应用添加异常检测机制 一个像是心电图的实时网络状况监控图表已经通过我们的努力展示在了我们的数据应用上，但是一般来说在有监控功能的同时，还需要具有异常检测功能。也就是说我们用于监控网络波动的数据应用，除了让我们知道当前 ping 值情况以外，还需要具有异常检测、报警的功能。 但是我们又如何才能知道当前数据是否异常呢？这里便需要使用到一些统计方法。用于检测某一个数据点是否为一个数据系列中的异常值（统计学中可以称之为离群值，Outlier）的方法有很多，比如均值检验、方差检验等等。但这些对于不熟悉统计学的同学来说还是有一些复杂，所以我们这里会使用一种非常简单、便于计算也便于理解的方法来进行判断。 20.4.1 异常值检测 还记得我们在第 16 节中曾经学习过一种名为 SPC 控制图的复杂数据图表吗？SPC 控制图引入了一种叫做控制区域的概念，我们便可以借用这个概念来对异常值进行检测。若当前 ping 值超过区域 A 的控制上限（数据均值加 3 倍的标准差）时，便将其判定为异常值。 其中我们选用当前值以前的数据作为判定依据，因为假若当前数据为一个非常离谱的异常值（比如前面我们在配置 awk 工具时便设定了如果 ping 信号超时便返回 9999 毫秒），所计算出来的标准差也会大得离谱，可能导致判定失准。 function sdBy(array, path) { const mean = _.meanBy(array, path) const top = array.map(row => _.get(row, path)) .map(function(x) { return Math.pow(x - mean, 2) }) .reduce(function(left, right) { return left + right }) const bottom = array.length - 1 return Math.sqrt(top / bottom) } // 对前面的数据进行计算判断 const previousPings = pingSource.dataset.slice(0, pingSource.dataset.length - 1) const meanPing = _.meanBy(previousPings, 'ping') const sigma = sdBy(previousPings, 'ping') const isOutlier = !(this.pingSource.dataset.length 0 && ping > this.threshold) && // 阈值判断 ping > (meanPing + 3 * sigma) // 均值 + 3 * Sigma 判断 当判定一个 ping 值为异常值时，我们便将其记录下来。为了能够方便地对异常值进行管理和展示，我们也同样为异常值准备一个控制单元，并且将其应用到图表上进行展示。 class OutlierSource { constructor(pingSource, onSlow) { this.pingSource = pingSource this.onSlow = onSlow this.dataset = [] } setTTL(seconds) { this.ttl = seconds } computeAndAdd(ping, timestamp) { // 对前面的数据进行计算判断 const previousPings = this.pingSource.dataset.slice(0, this.pingSource.dataset.length - 1) const meanPing = _.meanBy(previousPings, 'ping') const sigma = sdBy(previousPings, 'ping') const isOutlier = ping > (meanPing + 3 * sigma) // 均值 + 3 * Sigma 判断 if (this.ttl && this.ttl > 0 && this.dataset.length === this.ttl) { this.dataset.shift() } if (isOutlier) { this.dataset.push({ ping, timestamp }) if (this.onSlow) { try { this.onSlow(ping, timestamp) } catch(err) { handleError(err) } } } else { this.dataset.push({ ping: 0, timestamp }) } } } 但这个时候我们又发现在一般情况下网络都是非常好的，只是稍微出现了一些小波动，而这个判定方法依然将其判定为异常值。所以除了通过控制上限进行判定外，我们还需要添加量个阈值控制。两个阈值分别代表不同的程度，一个较低的阈值代表超过该阈值的 ping 才有可能是异常值，而另外一个较高的阈值代表超过该阈值的 ping 一定是异常值。 class OutlierSource { // ... setThreshold(ping) { this.threshold = ping } setMaxPing(ping) { this.max = ping } computeAndAdd(ping, timestamp) { // ... const isOutlier = (this.max && this.max > 0 && ping > this.max) || // 接受上限判断 (this.threshold && this.threshold > 0 && ping > this.threshold) && // 阈值判断 ping > (meanPing + 3 * sigma) // 均值 + 3 * Sigma 判断 // ... } } // 设置异常阈值 outlierSource.setThreshold(30) // 设置接受上限 outlierSource.setMaxPing(460) 20.4.2 展示异常情况 这些都整合起来以后，让我们看一下在图表上表达的效果。 class OutlierSource { constructor(pingSource, onSlow) { this.pingSource = pingSource this.onSlow = onSlow this.dataset = [] } setTTL(seconds) { this.ttl = seconds } setThreshold(ping) { this.threshold = ping } setMaxPing(ping) { this.max = ping } computeAndAdd(ping, timestamp) { // 对前面的数据进行计算判断 const previousPings = this.pingSource.dataset.slice(0, this.pingSource.dataset.length - 1) const meanPing = _.meanBy(previousPings, 'ping') const sigma = sdBy(previousPings, 'ping') const isOutlier = (this.max && this.max > 0 && ping > this.max) || // 接受上限判断 (this.threshold && this.threshold > 0 && ping > this.threshold) && // 阈值判断 ping > (meanPing + 3 * sigma) // 均值 + 3 * Sigma 判断 if (this.ttl && this.ttl > 0 && this.dataset.length === this.ttl) { this.dataset.shift() } if (isOutlier) { this.dataset.push({ ping, timestamp }) if (this.onSlow) { try { this.onSlow(ping, timestamp) } catch(err) { handleError(err) } } } else { this.dataset.push({ ping: 0, timestamp }) } } } function handleError(err) { return false // console.error(err) } function sdBy(array, path) { const mean = _.meanBy(array, path) const top = array.map(row => _.get(row, path)) .map(function(x) { return Math.pow(x - mean, 2) }) .reduce(function(left, right) { return left + right }) const bottom = array.length - 1 return Math.sqrt(top / bottom) } const chartEl = document.querySelector('#chart') const myChart = echarts.init(chartEl) const outliers = [] // 创建数据源 const pingSource = new PingSource() // 创建离群值处理实例 const outlierSource = new OutlierSource(pingSource, ping => { console.warn(`NETWORK SLOW!! ${ping}ms`) }) pingSource.load('http://localhost:8080/77sl06lf3io', (ping, timestamp) => { outlierSource.computeAndAdd(ping, timestamp) myChart.setOption({ dataset: [ { source: pingSource.dataset }, { source: outlierSource.dataset } ], xAxis: { type: 'time' }, yAxis: { type: 'value' }, tooltip: { trigger: 'axis' }, series: [ { type: 'line', name: 'ping', encode: { x: 'timestamp', y: 'ping' } }, { type: 'bar', name: 'outlier', datasetIndex: 1, encode: { x: 'timestamp', y: 'ping' } } ], animation: false }) }) // 设置超时 const TTL = 30 pingSource.setTTL(TTL) outlierSource.setTTL(TTL) // 设置异常阈值 outlierSource.setThreshold(30) // 设置接受上线 outlierSource.setMaxPing(460) DEMO 在线地址：https://codepen.io/iwillwen/pen/bzdKYY?editors=0010 20.4.3 展示异常总体情况 除了可以在图表上展示出每一个异常值情况外，我们还可以用一个仪表盘图表来展示最近一段时间内的网络情况，比如我们就用异常值的个数占一段时间内的总数据数量的比例作为我们评价网络情况的一个指标。 我们可以在 OutlierStore 上添加一个 Getter 来取得真实的异常值数量，然后在 ECharts 图表的配置上添加一个仪表盘图表以展示当前整体网络状况。 class OutlierSource { // ... get count() { return this.dataset.filter(({ ping }) => ping > 0).length } } // ... myChart.setOption({ // ... series: [ // ... { name: '异常率', type: 'gauge', center: [ '80%', '55%' ], detail: { formatter:'{value}%' }, animation: true, axisLine: { lineStyle: { color: [[0.2, '#91c7ae'], [0.6, '#63869e'], [1, '#c23531']] } }, data: [ { value: (outlierSource.count / TTL * 100).toFixed(2), name: '异常率' } ] } ] }) DEMO 在线地址：https://codepen.io/iwillwen/pen/OdVddO?editors=0010 小结 这一节中，我们学习了如何使用一系列简单的工具创造一个真实的实时数据源，并将其应用到了我们的 JavaScript 数据应用中。我们还是用了一些非常简单的统计方法来对我们的数据进行一些检验和判定。 下一节将会是本小册的最后一节，我们会从一个更为实际的场景出发，开发一个具有实际用途的、可交互的数据应用。 习题 像笔者一样，从身边的实际体验中寻找灵感，看看有哪些是可以变成我们数据应用的统计、研究对象的，做成一个小 DEMO 跟大家分享一下吧！ "},"基于JavaScript开发灵活的数据应用/20.动态数据应用·应用高大上的动态数据流（下）.html":{"url":"基于JavaScript开发灵活的数据应用/20.动态数据应用·应用高大上的动态数据流（下）.html","title":"20.动态数据应用·应用高大上的动态数据流（下）","keywords":"","body":""},"大厂H5开发实战手册/01.大厂H5开发概述.html":{"url":"大厂H5开发实战手册/01.大厂H5开发概述.html","title":"01.大厂H5开发概述","keywords":"","body":"大厂 H5 开发概述 H5 开发及其前世今生 在腾讯，「H5 开发」有设立对应的实体岗位：「UI 开发工程师」，这个岗位早在两三年前由「网页重构工程师」演变而来，最早出现在 SNG（社交网络事业群）的用户体验设计部（ISUX）。与阿里和百度不同的是，腾讯的岗位职能分得比较细，传统的「网页重构工程师」虽然也属于前端范畴，但其工作职责主要负责静态网页制作（设计稿还原成为网页）和少量的 JavaScript 脚本逻辑开发，但随着 HTML5 和 CSS3 相关技术标准的出现与普及，重构工程师除了前面提及的基本工作，还要肩负「CSS3 动效开发」等 UI 相关的工作，「重构」的工作定义已然无法契合新时代的要求，于是便有了「H5 开发」的概念。 在京东，前端开发岗目前尽管没有细分出「H5 开发工程师」或「UI 开发工程师」这种实体的职位，但为了针对性地招聘人才，一些技术部门（如凹凸实验室）仍然会以「H5 开发工程师」或「H5 前端开发工程师」来招人。「H5 开发工程师」的职责要求其实与腾讯的「UI 开发工程师」基本一样，未来也许会统一沿用腾讯「UI 开发工程师」的叫法并设立相应的实体职位。「H5 开发」其实不太需要后端开发经验（有则为加分项），偏向界面还原制作、前端脚本逻辑的实现，同时与谷歌 2017 年提出的新岗位-动效设计师（Motion Designer）也有交集，要求具备动效设计以及开发的能力，一句话来概括就是「基于 HTML5、CSS3 等网页技术，负责可视化 UI 界面及动效的开发」。 我们可以用一张图来直观表达「H5 开发」相关岗位的具体工作内容，如下： 一名合格的「H5 开发工程师」不仅需要会做「PC 端网页」、「移动端网页」，还需要会做各类强交互、多动效的「 HTML5 营销活动页面」，甚至还要做动效及脚本逻辑复杂的「HTML5 小游戏」。 H5 开发的能力模型 岗位划分了员工的专业范畴，而某个岗位的职位等级则划分了员工在其专业范畴上的能力及资历的高低深浅。这就是为什么京东、腾讯等公司会开设专业晋升通道，制定每个职级的能力模型，并以此来评估人们在其专业范畴上的综合水平。 而对于职位本身的专业能力要求，我们也同样可以梳理出相应的评估模型，了解这个模型，一方面可以帮助大家定位自己在某个专业方向上的水平和位置，而另一方面则可以作为岗位招聘者面试时对应聘者能力定位的初步评判依据。 参考前面提及的「H5 开发」相关岗位的具体工作内容，我们大致可以梳理出「H5 开发」的能力模型，如下： 这个能力模型长着一张三角脸，往下代表能力的基础性，往上代表能力的进阶。其中「基础页面开发」、「响应式页面开发」、「滑屏应用开发」以及「动画效果开发」是岗位的基础能力要求，「游戏开发」是高阶能力要求。换一个说法，掌握「基础页面开发」，我们就能应付「PC 端网页」的开发；掌握「响应式页面开发」，我们可以撸「移动端网页」；掌握了「滑屏应用开发」以及「动画效果开发」，我们能开发各类强交互、多动效的「 HTML5 营销活动页面」；而掌握了「H5 游戏开发」，我们才能做动效及脚本逻辑复杂的「HTML5 小游戏」。 具备基础能力要求的同学，只能说拿到了岗位应聘的敲门砖，能否进到门内，要看有没有具备高阶能力的同学与你竞争；而兼具基础能力和高阶能力的同学，应聘的时候已然是半条腿迈进了门。另外半条腿，则取决于通用能力方面（如沟通能力、稳定性等）的评估，以及薪资要求是否与职级评定相匹配等非技术方面的因素。 需要提一下的是，上面并没有把「性能优化」考虑进去，因为「性能优化」是每一个开发岗位所必需的通用意识和能力，并非「H5 开发」所特定的要求。 是不是有点像打怪通关升级？越往上说明你功力越深厚，竞争力越大。 问题是，我们该如何达成这些能力？有没有对应的指导方向或案例借鉴？ 这本小册将围绕「基础页面开发」、「响应式页面开发」、「滑屏应用开发」以及「动画效果开发」这 4 大基础能力展开叙述。「H5 游戏开发」以 微信小游戏开发入门：从 0 到 1 实现井字棋游戏 小册独立解读，有兴趣的读者可以关注下。 下面先从「基础页面开发」说起。 "},"大厂H5开发实战手册/02.基础页面开发.html":{"url":"大厂H5开发实战手册/02.基础页面开发.html","title":"02.基础页面开发","keywords":"","body":"基础页面开发 「基础页面开发」的能力可以定义为： 依据设计稿（PSD 或 Sketch）及交互要求，利用 JavaScript、HTML 和 CSS 等技术将设计稿高保真转换为网页的能力。 该能力是前端开发工程师的立业之本，自然也是「H5 开发」最最基础的要求。然而虽然是最基础的能力要求，平时我们却会发现身边的前端同学对它掌握十分到位的却是为数不多，要知道「做出一个页面」和「做好一个页面」是两码事。 当然，偏脚本开发方向的前端开发工程师可能不会要求精通「基础页面开发」，但至少也需要了解一个网页的基础构成，熟悉 HTML、CSS 在网页开发中各自所承担的角色及其相应用处。 除了熟练使用 JavaScript、HTML 和 CSS 等基础的网页技术，「基础页面开发」另一个非常重要的技能是「切图」，不会「切图」意味着我们无法将设计稿中的图层元素转换成为网页中所需要的图片，将设计稿高保真转换成为网页也就成了天方夜谭。 接下来通过一个案例说明「基础页面开发」是如何涵盖「切图、HTML 和 CSS」这些技能点的，JavaScript 在本小节不是核心故不做阐述。 通常我们会从视觉设计师手中拿到 PSD 设计稿，然后根据设计稿及设计师提供的相关视觉规范说明，一步步将其还原成真实网页。 例如这样一个 PC 站点的设计稿案例（点击放大图片，首屏的 MM 是不是很赞(✿◡‿◡)）： 我们分 5 个步骤来完成这个案例设计稿的页面开发。 步骤1 - 设计稿审查 看到帅锅美驴，不要急着瞪眼流口水，拿到一个设计稿，也不要急于动手。 我们需要站在开发者的角度，先做一个初步的设计稿审查，其目的及意义主要有两个： 了解设计稿的开发友好性 帮助视觉设计师发现并指出有哪些地方的设计对开发不友好，例如是否存在展示缺陷（缺乏经验的视觉设计师一个常见的问题是没有考虑按钮或标签文字数量的溢出情况）？是否开发成本高或者根本无法实现？ 了解设计稿的排版布局及内容构成 帮助自己全局理解页面的设计细节，特别是排版布局及内容构成。利用模块化的思想将设计稿解构成一个个组件，并明确每一个组件的可复用性，包括可复用的范围。 这里着重说下第 2 点，为了更快更直观地帮助自己「了解设计稿的排版布局及内容构成」，可以先将网页的排版布局及内容构成抽象成线框图。 我们上面的设计稿案例可大体上抽象成（点击放大图片）： 跨页面可复用组件 参考上述的设计稿线框图，我们可以提取出如下的「跨页面可复用组件」： Header - 顶部导航 Footer - 底部信息 当前页面可复用组件 除去跨页面可复用的组件，剩余的区域，我们可以进一步抽出当前页面可复用的组件，以减少后续重复性的开发工作。 参考上述的设计稿线框图，我们可以提取出如下「当前页面可复用组件」： Billboard - 信息公告牌 Ad-board - 商品广告位 设计稿审查的过程中，如何将内容模块按照合适的颗粒度抽离成为组件，并确定其可复用性及复用范围？这是需要在日常工作中逐步培养的能力。 事实上，设计稿的审查流程一般都比较固定，我们可以将其整理成为团队内通用的审查清单： 确定设计稿的开发友好性（是否有还原成本高或无法还原的地方） 确定一些特殊的元素是否有合理的边界处理（如文案超出外层容器的边界怎么办） 确定页面的框架结构（Layout） 确定跨页面可复用的组件（Site Component） 确定当前页面可复用的组件（Page Component） ... 步骤2 - 编写页面骨骼框架 设计稿审查完毕后我们就可以着手准备进行页面编码的工作啦。 我们可以把页面想象成一套房子，HTML 可以决定网页的框架结构（房子有几间房，各个区域的用途是什么），CSS 可以决定网页的样式（房子该如何装修，房间具体的尺寸是多少），而 JavaScript 则可以决定网页的具体交互和功能的实现（门如何打开，空调如何启动）。 在正式编写页面骨骼框架之前，我们需要了解以下几个重要的网页开发概念。 盒模型 HTML 文档中的每个元素都可以被描绘成矩形盒子，这些矩形盒子通过一个模型来描述其占用的空间，这个模型称为标准盒模型。盒模型通过四个边界来呈现元素的大小：margin（外边距）、border（边框）、padding（内边距）、content（内容区域），如下图所示： 那么计算一个盒子的宽高，是不是可以用以下公式呢？ 盒子总宽度 = width + padding + border + margin No~ 在 IE 浏览器下，IE 没有使用标准盒模型。它们认为的元素宽度 width 计算公式如下： 元素宽度 = width + padding + border 盒子总宽度 = 元素宽度 + margin 为了解决这个问题，CSS3 中新增了一个盒模型的计算方式：box-sizing box-sizing: content-box | padding-box | border-box; 默认值：content-box 为了简单地规避元素盒模型大小可变性造成的网页排版问题，一般我们会在样式重置的规则中，将盒模型设置成 border-box，添加如下规则： *, *:before, *:after { -webkit-box-sizing: border-box; -moz-box-sizing: border-box; box-sizing: border-box; } 设置成 border-box 之后的盒子宽度计算公式如下： 盒子总宽度 = width 不管 margin + border + padding + content-width 大于还是小于元素宽度 width，盒子的总宽度始终固定为 width。 以案例中的广告位模块为例，当盒模型设置成 border-box 之后： 布局 我们可以把网页理解成是由一个个盒子排列组合而成的，那么盒子之间又是怎么排列布局的呢？ 网页常见的布局方式大概有五种：普通文档流布局、浮动布局（Float）、绝对布局（Absolute）、弹性布局（Flex）、网格布局（Grid）。 普通文档流布局 默认的布局方式，由块级元素（display: block）和行内元素（display: inline）等组成，元素之间按照从左到右，从上到下的顺序排列。 浮动布局 相对于普通文档流布局，浮动布局会脱离普通文档流，分为左右浮动，一般会在普通文档流布局的上面进行界面的布局，如果想避免浮动布局遮盖普通布局的情况，可以考虑使用清除浮动。 绝对布局 元素使用 position: absolute 属性进行绝对布局，使用绝对布局的元素会脱离文档流，其定位是参考祖先元素中 position 为非 static 值的第一个元素。 弹性布局 也称 Flex 布局，是一个完整的模块，而不是一个单一属性，其中有的属性是设置在父元素上，有些则是设置在子元素上。如果我们说传统的布局是建立在块级元素和行内元素的文本流上，那么 Flex 布局就是建立在 flex-flow 的轴方向上的。 网格布局 是用于制定行与列的二维 CSS 布局方法，可以将页面分割成数个主要的区域，或者用来定义组件内部元素间的大小、位置和图层之间的关系。 以上是常用的五种网页布局方法，在实际项目中，我们应该根据场景选择适当的方法。 语义化 HTML 的标签虽然不多，但在编写的过程中，也会时不时犹豫应该使用 div 还是 p 标签，是使用 span 还是 i 标签？不管使用哪个标签，大体上都能实现想要的效果。 HTML 语义化就是根据具体的内容，选择合适的标签进行代码的编写，这样既能便于开发者阅读和维护，也能让搜索引擎的爬虫更好地识别。简单的说，就是可以让机器更容易读懂网页内容。 如果用语义化的标签编写网页结构，可以写成如下结构： 步骤3 - 填充网页血肉内容 HTML 结构确定之后，我们需要进一步往页面中填充设计稿的内容，于是「切图」便成为我们「H5 开发」的必备技能。每个人都有自己熟悉的一套切图流程，但你是否考虑过更优、更高效的切图技巧呢？ Photoshop 更新迭代至今，Adobe 已为我们切图提供了几种便利的方法，下面会一一介绍，也欢迎大家在留言区交流其他的切图方法。 方法1 - Extract Assets 资源生成器 Extract Assets 是 Photoshop CC 2014 版本新增的一个特性，主要用来快速导出适用于 Web 和屏幕设计的资源，你可以用它导出 JPG、PNG、GIF，甚至是 SVG 图像资源。 通过 Extract Assets，你可以： 将 PSD 中的图层或图层组导出为一个或多个的图像资源 导出 JPG、PNG、GIF 或 SVG 类型的图像资源 为所有图像资源设置 1x、2x 等多分辨率的版本 预览每个图像资源 轻松将图像资源导出到你首选的文件夹中 确保每当 PSD 发生变化时，被导出的资源都能得到自动更新 使用方法 按照以下步骤启用 Extract Assets 生成图像资源。 启用 Extract Assets 打开 PSD 文件后，选择「文件」 > 「生成」 > 「图像资源」 更改图层或图层组的名字为适当的文件格式扩展名（.jpg、.png 或 .gif 等） 资源生成器默认会在 PSD 的同一层目录下创建 assets 文件夹，如图： 经过以上步骤，切图工作就完成了！切图只需要简单的三步： 打开 PSD 文件 打开 「生成 > 图像资源」 更改图层或图层组的文件名 Extract Assets 进阶 从一个图层或图层组中生成多个资源，请用半角逗号分隔该图层或图层组的名称 music.png, music.jpg, music_on.png 图像资源保存到子文件夹中 子文件夹/music.png 指定图像品质和大小参数 默认情况下， JPEG 资源会以 90% 品质生成， PNG 资源会以 32 位图像生成， GIF 资源则会以基本 Alpha 透明度生成 我们可以通过以下办法设置 JPEG 资源的参数： 添加所需的输出品质作为资源名称的后缀：jpg(1-10) 或者 jpg(1-100%)，例如： music.jpg5 music.jpg50% 添加所需的输出图片大小（相对大小或者支持的单位：px, in, cm 和 mm）作为该资源名称前缀。Photoshop 会相应的缩放图像，例如： 200% music.png 240x300 music.png 注意：前缀和资源名称之间要添加一个空格字符 为资源指定默认位置 可以为生成的资源指定文件的默认位置，例如想将图层导出到 hi-res/ （存放二倍图，并加上 @2x 的后缀），lo-res/ 存放缩小 50% 的图标，可进行如下配置： A. 创建空图层B. 更改空图层的名称为 default hi-res/@2x + 50% lo-res/ 方法2 - Export Artboards, Layers, and more Photoshop CC 2015 版本之后添加了 Artboards 功能，有点类似 Sketch 里面的 Artboards。具体使用方法类似 Sketch 的 Export 功能，右键点击所需要导出的图层或图层组，点击弹出菜单中的 Export As 或 导出为 即可。 方法3 - PS 动作切图 细心的同学可能会发现，用 Extract Assets 切图存在一个问题，它只能切画布范围内的资源，超出画布的部分会直接被裁减掉，如下图： 如果想切完整的图片该怎么办？建议用原始的「导出图层」的方式来切图，步骤如下： 右键点击图层或图层组 选择转换为智能对象 编辑内容 导出图片 为了避免重复劳动，我们可以用 PS 录制一个切图的动作，如图： 顺利的话，我们通过 PS 的动作切图，可以得到如下结果： 步骤4 - 润色 编写 CSS 是前端开发中，比较愉快的一步。在此过程中，你可以一步步见证代码神奇的力量。编写可用的 CSS 比较容易，但是要维护它却不简单。 CSS 是一种定义样式结构，被用于描述网页上信息的排版方式的语言。由于其声明属性的方式不具备编程语言流程性控制的特点，而且自身「层叠」的特性，难以写出低耦合度的代码。不好好组织，容易造成不同地方的 class 相互影响，引起样式冲突等问题。所以 CSS 命名是样式代码组织中最重要的一环。 BEM 在各类 CSS 命名规范中，BEM 命名规范被更多人所接受。 BEM 是一种基于组件的命名方法，它的基本思想是将用户界面划分成独立的模块，即使是复杂的用户界面，也能让开发过程变得简单、快速。并且可以在一定程度上提高代码的可复用性，而不用纯粹的复制粘贴。 BEM 的意思就模块（Block）、元素（Element）、修饰符（Modifier），使用这种命名方式可以让 CSS 的类名变得有实际意义且能自我解释，具有更高的开发友好性。 Block - 模块，名字的单词之间用 `-` 符号连接 Element - 元素，模块中的子元素，用 `__` 符号连接 Modifier - 修饰符，表示父元素或子元素的其他形态，用 `--` 符号连接 在没用 BEM 之前，我们可能会这样组织 CSS 类名： 上述写法虽然也给 class 赋予了一定的语义，但容易产生样式冲突的情况。 用 BEM 命名重写之后： 这样命名的好处是，模块语义化了，便于后期的维护，而且减少了 CSS 样式的层层嵌套，提升了网页的渲染效率。 通常在开发中使用 BEM 命名方法，会搭配 CSS 的预处理语言，如 SCSS 等。这可以一定程度上解决手写冗长命名的繁琐。 // 以下是 SCSS 代码 .search-bar { &__input { ... } &__button { ... } } 将 BEM 用于中大型项目之后，我们会发现，当嵌套的层级越多时，类名也会越长，这给编写 HTML 代码带来了一些麻烦，同时也增加了 HTML 的文件大小。 那么问题来了，如何解决 BEM 命名冗长的问题？ 姓氏命名法 为了进一步简化 CSS 的命名，我们凹凸实验室团队推广的 CSS 命名规范并不严格遵循 BEM 规范，不强制使用两个下划线「_ _ 」来分隔 B 和 E，而 E 和 M 之间也不一定要用两个中划线做分隔「- -」。 如： 老师，简化版的 BEM 好像也没有解决命名冗长的问题呀？ 确实，如果按照这种继承的写法，再结合「给小孩取名」的生活场景，会出现下面的情况： 有位同学的名字叫「李小璐」，他的儿子名字叫「李小璐乃亮」，他的孙子叫「李小璐乃亮皮几万」。。。 而事实上，他的孩子只需要保留「李」姓就可以了，名字是可以随便取的。 所以在纠结怎么给一个元素做 CSS 命名的时候，联想一下我们身边的姓名是怎么起的吧。我们凹凸实验室在业务中推广使用的「姓氏命名法」也因此而诞生。 如果要关联上 BEM 命名方法，姓氏命名法中的 Block 就是「姓」，Element 就是「名字」，而 Modifier 就表示这个人的某种状态，例如：「范冰冰 - - 很美」。 如何优化？ 对于上面 app_market_answer 的案例，我们可以确定模块的姓氏是「app_market_answer」，名字随意取的话，我们可以尝试如下优化： 去围观 我们将 app_market_answer_item_top 改成了 app_market_answer_itop ，将 app_market_answer_item_middle 改成了 app_market_answer_imid ，只保留了「姓」。 如何进一步优化？ 姓氏可以进一步简化，例如 app_market 可以看成是「复姓」，我们有时候为了书写便利，可以将两个单词的首字母结合在一起形成一个新的「单姓」，如 am 。追求便利的副作用之一是牺牲了代码的可读性。如果你做的项目或页面没有太大的二次维护或者交叉维护的可能性，推荐做此简化。 对于上面 app_market_answer 的案例，我们可以进一步优化成： 去围观 小结 ClassName 的命名应该尽量精短、明确，以英文单词命名，且全部字母为小写，避免意义不明的缩写 单词之间统一使用下划线 _ 或 - 连接 学习 BEM 的思想，参考使用姓氏命名法规范 定义样式模块，提高代码的可复用性 步骤5 - 兼容性测试 兼容性测试是网页开发中必不可少的一步，我们主要关注两点： 页面在各个浏览器中，以及不同分辨率下是否能正常显示（HTML / CSS 兼容性） 网页的功能是否能在各个浏览器中正常使用（JavaScript 兼容性） 「IE 虐我千百遍，我待 IE 如初恋」，这是圈内流传比较广的一句话，可见要做好网页的兼容性是件很不容易的事情。除了 IE 上有比较多的兼容性问题，移动端上的 Android 低版本浏览器也会有较多的问题。 所以在开发之初，我们要大致了解网站最终的用户群体有哪些，他们会使用怎样的设备，会用什么浏览器访问我们的网站？以此来决定我们是否要保持对低端浏览器的兼容性。 兼容性的基本原则是： 渐进增强与平稳退化。 在低端浏览器能够保持可用性和可访问性，然后再渐进增强，逐步增加功能及优化用户体验。 如果遇到兼容性问题，可以按如下步骤处理： 确认触发的场景：什么浏览器，什么版本，什么情况下触发的问题，做到稳定复现。 找出问题原因：是什么问题导致的，具体表现如何？ 确定解决办法：参考现成的解决方案，如哪些属性不能使用以及相应的 Hack 处理 收集兼容性处理方法，积累成文档 小结 本小节通过「5 个基础页面开发的步骤」来阐述如何将一个设计稿案例转换成为网页，并给大家介绍了具有凹凸实验室特色的 CSS 样式命名方法：「姓氏命名法」。 掌握了「基础页面开发」，我们就拥有了「将设计稿变成保真网页」的能力，这就犹如学一门武功时迈出了第一步，有了良好的脉络根基，才可以继续学习更高级的招式技能。 "},"大厂H5开发实战手册/03.响应式页面开发.html":{"url":"大厂H5开发实战手册/03.响应式页面开发.html","title":"03.响应式页面开发","keywords":"","body":"响应式页面开发 响应式页面开发的能力可以定义为： 利用一套代码实现页面的布局和排版以适配不同分辨率的设备。 响应式页面开发要求我们解决两大问题： 为不同特性（如横屏还是竖屏等）的浏览器视窗使用不同的样式代码 让页面元素的尺寸能够依据浏览器视窗尺寸变化而平滑变化 本小节的学习目标是学会解决上述问题并能够开发这样一个经典的移动端响应式页面： 我们分 3 个步骤来实现这样一个响应式页面。 步骤 1 - 添加 viewport meta 标签 在页头 head 标签内添加 viewport meta 标签是实现响应式页面的第一步。 viewport meta 标签源于 Apple 公司，用来定义 iOS Safari 浏览器展示网页内容的可视范围及缩放比率。它虽然没有成为W3C标准，但是被其他绝大多数的移动端浏览器所支持（目前已知 IE Mobile 10 不支持）。W3C 尝试将 viewport meta 标签的功能进行标准化并通过 CSS 的 @viewport 规则来实现同样的功能，但这个标准目前还在草案中，兼容性也没有 viewport meta 标签好。 PageSpeed 准则 Google 网页性能分析工具 PageSpeed Insights 的其中一条准则就是： 网页应在 head 标签内添加 viewport meta 标签，以便优化在移动设备上的展示效果，其推荐的设置为： 扩展阅读 Mozilla《Using the viewport meta tag to control layout on mobile browsers》 Google《Configure the viewport》 Mozilla《@viewport》 步骤 2 - 使用 Media Queries Media Queries 是为指定特性的浏览器视窗应用指定样式的手段，可以看成是 CSS 样式的过滤器或拦截器，通常情况下它可以通过 「@media 规则」结合「6 个查询参数」来拦截设备的浏览器特性（如显示类型、视窗高度、视窗宽度、横竖屏等），藉此可以为不同的特性应用不同的样式代码（相当于为不同的设备应用了不同的 CSS 样式）。 6 个参数 参数名称 参数描述） min-width 当视窗宽度大于或等于指定值时，@media 规则下的样式将被应用 max-width 当视窗宽度小于或等于指定值时，@media 规则下的样式将被应用 min-height 当视窗高度大于或等于指定值时，@media 规则下的样式将被应用 max-height 当视窗高度小于或等于指定值时，@media 规则下的样式将被应用 orientation=portrait 当视窗高度大于或等于宽度时，@media 规则下的样式将被应用 orientation=landscape 当视窗宽度大于高度时，@media 规则下的样式将被应用 2 种用法 方法 1，使用 link 标签，根据指定特性引入特定的外部样式文件 方法 2，直接在 style 标签或 样式文件内使用 @media 规则 @media (max-width: 640px) { /*当视窗宽度小于或等于 640px 时，这里的样式将生效*/ } 样式断点 Media Queries 所使用的查询参数的临界值又可称为「样式断点」。 在响应式页面开发过程中，对于「样式断点」我们需要掌握 2 个重要的技巧： 依据目标设备的分辨率，制定一套合适的样式断点，并为不同的断点定制必要的 CSS 样式。 移动端优先的页面，可使用 min-width 查询参数从小到大来定义断点。 如果我们页面的响应式设计要涵盖从手机到高清大屏幕，什么样的「样式断点」比较合理呢？ 我们可以从业界一些热门可靠的 CSS 框架中寻找参考答案，例如 Bulma，其采用的「样式断点」有 5 个： 断点名称 断点描述） mobile 移动设备断点，视窗宽度 ≤ 768 px tablet 平板电脑设备断点，视窗宽度 ≥ 769 px desktop 桌面电脑断点，视窗宽度 ≥ 1024 px widescreen 宽屏电脑断点，视窗宽度 ≥ 1216 px fullhd 高清宽屏电脑断点，视窗宽度 ≥ 1408 px 在实际工作中，「样式断点」的制定需要我们同视觉设计师一起沟通确认，因为视觉设计师可能需要根据不同的断点为页面设计不同的视觉表现。 一个小例子 如果针对 tablet 及以上的设备定制样式，我们就可以这样写了： @media (min-width: 769px) { /* tablet 及以上的设备，页面背景色设置为红色 */ body { background-color: red; } } 课外作业 使用桌面版的 Chrome 浏览器，打开 Google 的 在线 Media Queries 例子 直观感受下使用 Media Queries 的效果（请注意缩放浏览器窗口观察页面展示效果） 了解 Bulma 框架 扩展阅读 Google 《Responsive Web Design Basic》 步骤 3 - 使用 Viewport 单位及 rem Media Queries 只解决了「为不同特性的浏览器视窗使用不同的样式代码」的问题，而 Viewport 单位及 rem 的应用，则是为了解决第二个问题：让页面元素的尺寸能够依据浏览器视窗尺寸变化而平滑变化。 关于 Viewport 单位及 rem 单位的基本概念，可通过下面的扩展阅读进行回顾复习。 BTW：本文所提及的 Viewport，译为「视窗」，其含义与扩展阅读中相关文章中的「视口」一致。 方法 1 - 仅使用 vw 作为 CSS 长度单位 在仅使用 vw 单位作为唯一 CSS 单位时，我们需遵守： 利用 Sass 函数将设计稿元素尺寸的像素单位转换为 vw 单位 // iPhone 6尺寸作为设计稿基准 $vw_base: 375; @function vw($px) { @return ($px / $vm_base) * 100vw; } 无论是文本字号大小还是布局高宽、间距、留白等都使用 vw 作为 CSS 单位 .mod_nav { background-color: #fff; &_list { display: flex; padding: vw(15) vw(10) vw(10); // 内间距 &_item { flex: 1; text-align: center; font-size: vw(10); // 字体大小 &_logo { display: block; margin: 0 auto; width: vw(40); // 宽度 height: vw(40); // 高度 img { display: block; margin: 0 auto; max-width: 100%; } } &_name { margin-top: vw(2); } } } } 1 物理像素线（也就是普通屏幕下 1px ，高清屏幕下 0.5px 的情况）采用 transform 属性 scale 实现 .mod_grid { position: relative; &::after { // 实现1物理像素的下边框线 content: ''; position: absolute; z-index: 1; pointer-events: none; background-color: #ddd; height: 1px; left: 0; right: 0; top: 0; @media only screen and (-webkit-min-device-pixel-ratio: 2) { -webkit-transform: scaleY(0.5); -webkit-transform-origin: 50% 0%; } } ... } 对于需要保持高宽比的图，应改用 padding-top 实现 .mod_banner { position: relative; // 使用padding-top 实现宽高比为 100:750 的图片区域 padding-top: percentage(100/750); height: 0; overflow: hidden; img { width: 100%; height: auto; position: absolute; left: 0; top: 0; } } 由此，我们不需要增加其他任何额外的脚本代码就能够轻易实现一个常见布局的响应式页面，效果如下： 体验地址：视口单位布局 —— vw 单位 友情提醒：桌面版 Chrome 支持的字体大小默认不能小于 12PX，可通过 「chrome://settings/ 显示高级设置－网络内容－自定义字体－最小字号（滑到最小）」设置后再到模拟器里体验 DEMO。 方法 2 - vw 搭配 rem，寻找最优解 方法 1 实现的响应式页面虽然看起来适配得很好，但是你会发现由于它是利用 Viewport 单位实现的布局，依赖于视窗大小而自动缩放，无论视窗过大还是过小，它也随着视窗过大或者过小，失去了最大最小宽度的限制，有时候不一定是我们所期待的展示效果。试想一下一个 750px 宽的设计稿在 1920px 的大屏显示器上的糟糕样子。 当然，你可以不在乎移动端页面在 PC 上的展现效果，但如果有低成本却有效的办法来修复这样的小瑕疵，是真切可以为部分用户提升体验的。 我们可以结合 rem 单位来实现页面的布局。rem 弹性布局的核心在于根据视窗大小变化动态改变根元素的字体大小，那么我们可以通过以下步骤来进行优化： 给根元素的字体大小设置随着视窗变化而变化的 vw 单位，这样就可以实现动态改变其大小 其他元素的文本字号大小、布局高宽、间距、留白都使用 rem 单位 限制根元素字体大小的最大最小值，配合 body 加上最大宽度和最小宽度，实现布局宽度的最大最小限制 核心代码实现如下： // rem 单位换算：定为 75px 只是方便运算，750px-75px、640-64px、1080px-108px，如此类推 $vw_fontsize: 75; // iPhone 6尺寸的根元素大小基准值 @function rem($px) { @return ($px / $vw_fontsize ) * 1rem; } // 根元素大小使用 vw 单位 $vw_design: 750; html { font-size: ($vw_fontsize / ($vw_design / 2)) * 100vw; // 同时，通过Media Queries 限制根元素最大最小值 @media screen and (max-width: 320px) { font-size: 64px; } @media screen and (min-width: 540px) { font-size: 108px; } } // body 也增加最大最小宽度限制，避免默认100%宽度的 block 元素跟随 body 而过大过小 body { max-width: 540px; min-width: 320px; } 体验地址：https://jdc.jd.com/demo/ting/vw_rem_layout.html 扩展阅读 Mozilla《Length》 凹凸实验室 《利用视口单位实现适配布局》 小结 在实际工作过程中，考虑到设计以及开发成本，视觉设计师是不大可能为每种不同分辨率的设备分别设计不同的稿子的，拿移动端页面来说，通常会以 iPhone 7 的分辨率（宽为 750 px）作为基准分辨率来出设计稿。因此「响应式页面开发」也便成为了移动互联网时代「H5 开发」的必备技能。 本小节所介绍的「利用 Viewport 单位及 rem 实现响应式页面」，相对于传统的 JavaScript 脚本结合 rem 的方式来得更简单优雅。 "},"大厂H5开发实战手册/04.滑屏应用开发.html":{"url":"大厂H5开发实战手册/04.滑屏应用开发.html","title":"04.滑屏应用开发","keywords":"","body":"滑屏应用开发 滑屏应用开发的能力可以定义为： 利用 JavaScript 和 CSS3 来实现单页面应用的滑屏效果，包括上下滑屏、左右滑屏，以及局部元素的滑动切换效果。 滑屏 H5 应用在国内是异常火爆的一种内容展示交互形式，被广泛用于各类线上营销活动场景中。 滑屏应用开发要求我们： 至少要掌握主流滑屏组件（如 Swiper）的具体用法 能不依赖已有组件实现简易的滑屏效果，了解滑屏的技术细节 上图为基础的滑屏页面效果示例。 善用利器 在平时工作过程中，考虑到项目的紧迫性和实现成本，我们大多数时候会使用业界已有滑屏组件，如： Swiper：Most modern mobile touch slider with hardware accelerated transitions. 其它更多滑屏组件的选择可查阅《awesome-javascript》。 基于 Swiper 组件，只需数行代码即可创建一个基础的「滑屏应用」，以上下滑屏为例: HTML (Jade)：约定的 HTML 结构 div.swiper-container div.swiper-wrapper div.swiper-slide div.swiper-slide div.swiper-slide CSS (SCSS) ：指定滑屏的尺寸为视窗大小 .swiper-container { width: 100vw; height: 100vh; } JavaScript：初始化为竖直方向上的滑屏应用 new Swiper('.swiper-container', { direction: 'vertical', }) 善用成熟的组件可以让我们免去从零实现滑屏效果的成本，并能保证开发速度和稳定性，解决 80% 的应用场景，但缺点是定制化成本较高，另外就是代码冗余，有时候你只用了它 20% 的功能，但却要加载其 100% 的体积。当然，如果我们的滑屏应用场景不需要做定制化效果，也不用太在意那几十 KB 的体积的时候，利用业界成熟组件是首选方式。 知其所以然 善用利器，我们只做到了知其然。有些时候现有的滑屏组件不一定能满足个性化的业务需求，我们不得不去做二次开发，甚至需要根据个性化需求重新开发一款适用当前应用场景的滑屏组件，这就要求我们知其所以然。 作为示例，接下来我们探索下如何实现一个简单的 swiper。 我们将滑屏应用的实现分为两大部分： 判断用户的手势动作 根据手势动作执行相应滑屏过渡动画 为了更易理解，大家可以先在移动端体验以下三个例子，然后再阅读下面内容。 滑屏应用例子 swiper.js 版本 滑屏应用例子 hammer.js 版本 滑屏应用例子 无依赖版本 手势动作判断 手势动作判断是实现滑屏应用的核心逻辑。 对于上下滑屏应用，我们主要实现的手势动作有：瞬间的上下滑动和按住拖拽滑动。 瞬间的上下滑动除了要考虑滑动的始末位置，还要考虑时间间隔，即滑动速度。若满足一定的速度则代表用户是果断切换上下屏的动作，反之，则是犹豫保留在当前屏的动作。 我们看下核心代码， var _this = this var drag = false var y0 = 0 var deltaY = 0 var time0 = 0 this.$swiper.on('touchstart', function (ev) { drag = _this.$swiper y0 = ev.touches[0].pageY time0 = new Date() }) this.$swiper.on('touchend', function (ev) { var interval = new Date() - time0 drag = false // 拖拽完成后，判断移动方向、移动速度和移动距离等 // 若划动速度满足，则执行上划或下划过渡动画。 // 若划动速度不满足，则判断是否划动距离是否大于阈值(如 Swiper 容器的高度的一半)，若大于则执行上划或下划过渡画面，反之回到当前活跃块。 _this.panEnd(deltaY, deltaY / interval) }) this.$swiper.on('touchmove', function (ev) { if (drag) { deltaY = ev.touches[0].pageY - y0 // 设置 .swiper-wrapper 按住拖拽的位移。 _this.pan(deltaY) } }) 事实上，业界已经有许多很好用的判断手势动作的插件，如知名的 hammer.js 或 zepto 的 touch 模块。大家也可以通过阅读 hammer.js 的源码来进一步学习手势动作判断处理的逻辑。 滑屏过渡动画 过渡动画是让滑屏效果更自然的必要手段。 实现过渡动画的常见方式有两种：CSS3 或 JavaScript 动画，我们下面以 CSS3 动画作为示例。 这个过程我们需要关注的是什么时候触发动画，以及动画偏移的量为多少。 假设当前活跃块的索引为 activeIndex，将其与 swiper 容器的高度相乘并取反，可得到 .swiper-wrapper 的偏移量，然后设置适当的 CSS transition-duration 属性即可轻松实现过渡动画效果： this.translate = -(this.activeIndex * this.swiperHeight) this.$swiperWrapper.css({ 'transform': 'translate3d(0, '+ this.translate +'px, 0)', 'transition': 'transform '+ 0.3 +'s' }) 若想保证一个过渡完成后，才能接收用户的下一个操作，则可以增加 animating 属性。动画过渡前就将其设置为 true，然后在 .swiper-wrapper 的 transitionend 事件触发时再将其设置为 false： this.$swiperWrapper.on('transitionend', function(ev) { if (ev.propertyName === 'transform') { _this.animating = false } }) 上述是最基本的位移过渡动画，你还可以依样画葫芦实现渐隐渐现、3D 翻转动画等。 源码分享 前面 3 个体验例子的源码放在 Coding.net 上，源码附注释，读者可以课后查阅。 滑屏应用例子源码 Swiper 版本 滑屏应用例子源码 hammer.js 版本 滑屏应用例子源码 无依赖版本 一个实际案例 最后放一个典型的滑屏 H5 应用的实际案例 —— 京东 2018 校园招聘，供大家体验参考。 （京东 2018 校园招聘） 值得一提的是，这个滑屏 H5 案例使用了凹凸实验室自研开源的 HTML5 构建工具 ELF 进行构建，利用 ELF 提供的命令行工具，我们只需敲一个命令就可以搭建一个具有基础功能的滑屏应用，大大提升开发效率。 如果说 Swiper 是开发滑屏应用的利器，那么 ELF 则是开发 HTML5 应用的利器。 如果没有 Swiper，那么我们每次开发一个滑屏应用的时候，都要重新去写一遍滑屏手势的判断逻辑，还要重新写一遍滑屏的过渡动画。ELF 解决的是类似的问题，将搭建 HTML5 应用的重复过程自动化，将功能组件化、将交互形式模板化。它基于 Webpack 进行自动化构建，提供基础功能组件和脚手架案例模板；利用 ELF 提供的命令行工具 elf-cli，开发者可自由通过模板和组件的组合来快速定制开发各种 HTML5 场景应用。 实际上 ELF 本身基本上浓缩了前一个小节「响应式页面开发」和本小节「滑屏应用开发」的大部分内容，读者有兴趣可以移步 ELF 官网 进一步了解下 ELF 的功能特性。 性能贴士 在开发滑屏应用的时候，我们应该尽可能做到以下几点来保证页面的顺畅体验： 做到延迟加载，避免浪费资源和并发加载资源数过高。 做到预加载，预加载必要的资源，避免白屏。 在滑屏动画过渡期间，不要做繁重的任务，避免因占用资源过高而导致卡顿。 小结 本小节通过案例以及源码的方式，为大家介绍了如何利用业界优秀的滑屏开源组件「Swiper」来快速开发滑屏应用，同时也解读了滑屏应用的关键处理逻辑：手势判断处理。 至此，我们学习了 「H5 开发」能力模型的前三种基础能力，在实际工作过程中，当视觉设计师妹子扔给我们一个设计稿（PSD）时，至少心里不会慌慌了。回想下第 2 小节「基础页面开发」，我们知道如何将一个设计稿转换成为高保真网页；如果这个设计稿是一个移动端的稿子，需要适配各种手机设备，那么第 3 小节「响应式页面开发」给我们指引了方向；而如果它是一个单页面的滑屏 H5 活动，第 4 小节「滑屏应用开发」里可以找到相应的开发思路。 但是，如果这个设计稿里面包含了许多动画效果的设计元素，需要我们做各种动效，该怎么办？ "},"大厂H5开发实战手册/05.动效开发1：让它动起来.html":{"url":"大厂H5开发实战手册/05.动效开发1：让它动起来.html","title":"05.动效开发1：让它动起来","keywords":"","body":"动效开发 1：让它动起来 在现实生活中，人们的大脑习惯了被动态的东西所吸引，适当的动画效果可以为网页添加有价值的交互和反馈，提升用户的情感体验。 情感设计的主要目标是促进人与人之间的沟通，即便媒介是网页。一旦我们在这方面做得到位，电脑本身将回归背后，而网页的个性化将因此得到凸显。—— Aarron Walter，Designing For Emotion 一书的作者 动画效果是情感设计的重要手段，从本小节开始，我们将为大家介绍「H5 开发」的第四个重要的能力 —— 「动画效果开发」，简称「动效开发」，即综合利用 JavaScript、CSS(3)、SVG、Canvas 等多种 Web 技术手段开发出动人的网页动态效果。 回想下我们第 1 小节提及的 「H5 开发」三角形能力模型，「动效开发」处在三角形的上部，毫无疑问这项能力越强，在此岗位中的竞争力越大。 动效开发 —— 先「动」而后「效」，为网页添加动态元素的方法有很多： GIF、Flash —— 廉颇老矣，尚能饭否？ 视频 —— 可远观而不可亵玩焉 CSS3 结合 JavaScript —— 当红小生 我们将把重心放在 CSS3 动画上面，因为 CSS3 在现如今的网页动效开发中占据着最为重要的一席，作为老大哥 CSS 的补充，它像是专门为「H5 开发」量身定制的动效武器。 拿起这件武器准备杀出一条血路之前，得先找到它的扳机在哪里。 CSS3 Transition 在 CSS3 的世界里，让网页元素动起来的第一个方法是利用 transition，基于 transition 可以让元素的某个 CSS 属性从指定的开始状态过渡到特定的结束状态。我们将元素「从指定的开始状态过渡到特定的结束状态」这个过程简称为「状态变换」，注意这里的过渡，事实上 transition 便像是页面元素「状态变换」的润滑剂，如果没有 transition，元素「状态变换」的过程将会显得生硬而突兀（如下图中左边的小圆球，查看 DEMO）。 transition 可作用于普通的 CSS 属性（如 background 、opacity ...），也可以作用于 CSS3 出现时新引入的 transform 属性，而利用后者可以实现 3D 的过渡效果。transform 属性就像是 CSS3 这个动效武器子弹里的火药，大家可以通过 MDN 的 《transform》 一文进行进一步地了解学习，务必做到深谙其门道，避免一知半解。 一个 3D 过渡动效例子 如前面所说，利用 transition 结合 transform 可实现元素的 3D 过渡动效，所以我们这个例子的目标是：利用 transform 属性画一个立方体，然后利用 transition 实现立方体的翻转效果。大家不妨打开 CodePen 按照以下步骤亲自动手试试，或者直接 查看 DEMO 体会最终的结果。 步骤 1 - 准备立方体的 HTML 代码 一个立方体（.cube）的 6 个面（.cube-face）。 步骤 2 - 利用 CSS(3) 将 6 个面组装成立体形状的立方体 这里使用了 SCSS 样式预处理语言，如果你正在 CodePen 上跟着做，注意将样式预处理器（CSS Preprocessor）配置成为 SCSS。 // demo styles $cube-size: 300px; $cube-radius: $cube-size / 2; .demo { width: $cube-size; height: $cube-size; perspective: 1000px; position: relative; margin: 30px auto; } .cube { width: 100%; height: 100%; transform-style: preserve-3d; position: absolute; &-face { border: 2px solid #000; width: 100%; height: 100%; position: absolute; overflow: hidden; opacity: 0.6; backface-visibility: visible; &.is-front { transform: translateZ( $cube-radius ); } &.is-back { transform: rotateX( -180deg ) translateZ( $cube-radius ); } &.is-right { transform: rotateY( 90deg ) translateZ( $cube-radius ); } &.is-left { transform: rotateY( -90deg ) translateZ( $cube-radius ); } &.is-top { transform: rotateX( 90deg ) translateZ( $cube-radius ); } &.is-bottom { transform: rotateX( -90deg ) translateZ( $cube-radius ); } } img { width: 100%; } } 至此，我们得到一个正面朝着我们的边长为 300px 的立方体，为了让它在网页上呈现 3D 的视觉效果，我们写了以下几行关键的代码： 利用 3D 旋转 rotateX 或 rotateY，以及 Z 轴位移 translateZ 来衔接拼装立方体的每一个面 设置每一个面的背面可见性：backface-visibility: visible，注意这里前一行代码 opacity: 0.6 是辅助性的，而 backface-visibility 属性的默认值其实即 visible，这里写出来便于大家理解代码。 在立方体的父级元素上设置透视距离：perspective: 1000px 在立方体上设置变形方式：transform-style: preserve-3d 以上关键代码的关键 CSS 属性，在小册后面的「聊一聊 3D」小节中会有进一步的解读，这里就不多说了。读者也可自行在 MDN 上搜到具体的说明资料，建议结合资料和本例子亲自把玩体会。 步骤 3 - 让立方体显得更立体点 为了让立方体默认看起来更立体点（不是单纯地正面对着我们），可以利用 rotate 将立方体在 X 和 Y 轴上各旋转 15deg，让它正面斜对着我们。 注意：以下代码需要合并到前面步骤 2 里的代码中去。 .cube { ... &.show-default { transform: translateZ( - $cube-radius ) rotateY( -15deg ) rotateX(-15deg); } &.show-left { transform: translateZ( - $cube-radius ) rotateY( 90deg ); } &-face { ... opacity: 0.9; ... } ... } 我们给立方体新增了两个表示状态的类 show-default 和 show-left，分别表示它「默认的展示状态 - 正面斜对着我们」和「左面正对着我们」，读者可以依样画葫芦添加另外几个面对着我们的样式代码。 步骤 4 - 设置立方体的 transition 属性 最后一步就是给立方体添加 transition 属性，让它的状态变换拥有过渡动画效果。 通过查阅 MDN 资料可得 transition 的用法为： .transition-target { transition: ; } 我们为立方体加上相应的代码： .cube { ... // = transform // = ease // = 1s // = 0 transition: transform ease 1s; ... } 此时如果我们将立方体 div 容器的 show-default 类名替换成 show-left，就可以看到它左面旋转至我们眼前的 3D 效果啦。 案例最终的效果如下图所示： Transition 动画的局限性和适用性 transition 实现的动画有下面这些特点： 支持有限的 CSS 属性 可通过《CSS animated properties》一文查看支持过渡动效的 CSS 属性。 隐式过渡（implicit transitions） transition 的过渡动画是隐式的（如下图所示，图片来源于 MDN），即除了动画的开始状态和结束状态我们可以自定义之外，「状态变换」的具体过程由浏览器自动执行，中途无法进行人为干预。当然，我们还可以为浏览器执行动画时指定动画的具体时长（duration），以及时间轴函数（timing function）。 一次性、不可暂停或反转 transition 只支持两个状态之间的变换过渡，不支持多个状态的连续变换过渡，并且状态的变换是一次性的（无法循环）， 不可暂停，且不可反转（从状态 A 过渡到 B 后不能立即又过渡回 A）。 所以，在实际应用中我们常常利用 transition 来做那些轻量的、修饰性的动效，用于增强用户在网页上操作时得到的反馈。例如： 元素「hover」 或「点击」后的反馈 弹窗「打开」或「关闭」时的效果 ... 扩展阅读 通过 Mozilla 的 MDN 文档来了解 transition 的详细说明及使用示例： 《Using CSS transitions》 结合 CodePen 代码示例了解 transition 和 transform 的相关属性: 《CSS Transitions and Transforms for Beginners》 CSS3 Animation 如果我们想让元素的动效支持多个状态之间的连续过渡变换、支持循环，甚至支持暂停或反转，我们该怎么办？答案就是：animation -- 利用 CSS3 让网页元素动起来的第二个方法。 学习 animation 动画需首先掌握两个关键的基本知识点： 关键帧（@keyframes） animation 属性 关键帧（@keyframes） @keyframes 用来定义动画的具体内容，它包括以下内容： 动画叫什么名字？ 动画开始、中间及结束状态有哪些？（可以理解成每个状态对应一个关键帧） 每个状态出现在动画过程中的哪个时间点？ 我们来瞅一个 @keyframes 的实际例子，来源于有名的 animation 动画库 Animate.css，其中的「bounceIn」动效的关键帧代码如下： @keyframes bounceIn { from, 20%, 40%, 60%, 80%, to { animation-timing-function: cubic-bezier(0.215, 0.61, 0.355, 1); } 0% { opacity: 0; transform: scale3d(0.3, 0.3, 0.3); } 20% { transform: scale3d(1.1, 1.1, 1.1); } 40% { transform: scale3d(0.9, 0.9, 0.9); } 60% { opacity: 1; transform: scale3d(1.03, 1.03, 1.03); } 80% { transform: scale3d(0.97, 0.97, 0.97); } to { opacity: 1; transform: scale3d(1, 1, 1); } } 显然，这段关键帧的代码做了以下事情： 定义了动画的名称为「bounceIn」 将动画过程划分成了 6 个状态（6 个关键帧） 除了开始和结束这两个时间位置外，另外 4 个关键帧的时间位置分别为：20%、40%、60% 和 80% animation 属性 细心的读者会发现上面示例中的 animation-timing-function 相关代码，其实是 animation 属性相关的知识点，除了关键帧之外，谙熟 animation 属性（及其“子”属性）的具体含义及用法，也是学习 animation 动效的基本要求。 @keyframes 用来定义一个动画的具体状态内容，而 animation 属性用来定义一个元素执行某个动画时的相关动画设定，包括： 指定元素用什么动画？（animation-name） 动画的持续时间是多少？（animation-duration） 浏览器用什么样的时间轴函数来执行该动画？（animation-timing-function） 是否需要延时执行该动画？(animation-delay) 动画循环执行的次数是多少？（animation-iteration-count） 动画执行的方向是什么？（animation-direction） 动画填充模式是什么？（animation-fill-mode） 动画执行状态是运行还是暂停？（animation-play-state） 对于 animation 相关属性的介绍和使用示例，可以在 MDN 找到十分详尽的资料，这里就不搬运了，读者可以点击括号内的链接进行逐一学习。 值得一提的是，animation 动画的延时可以设置为负值（试试看），善用负值的 animation-delay 有时候可以用最少的代码实现出乎意料的动效。 上图的案例（查看 DEMO）来源于《CSS Animation Tricks: State Jumping, Negative Delays, Animating Origin, and More》 一文，利用负值 animation-delay 复用同一个动画轻松实现。相同的效果如果用 GIF 或 transition 来实现的话，恐怕会复杂很多。 例子 - 让立方体自己转起来 为了更好地体会 transition 和 animation 两者做动效的异同之处，我们接下来试着利用 animation 改写前面 transition 做的立方体例子，让它自己转动起来。 步骤 1 - 利用 @keyframes 定义转动的动画 定义一个名为「autoRotate」的关键帧动画，并将 transition 版本例子中显示立方体每一面的代码搬到 @keyframes 中去。 立方体有 6 个面，所以我们把整个动画划分为 6 个关键帧，如下所示： @keyframes autoRotate { // show-front 0%, 100% { transform: translateZ( - $cube-radius ); } // show-back 16.5% { transform: translateZ( - $cube-radius ) rotateX( -180deg ); } // show-left 33% { transform: translateZ( - $cube-radius ) rotateY( 90deg ); } // show-right 49.5% { transform: translateZ( - $cube-radius ) rotateY( -90deg ); } // show-top 66% { transform: translateZ( - $cube-radius ) rotateX( -90deg ); } // show-bottom 82.5% { transform: translateZ( - $cube-radius ) rotateX( 90deg ); } } 步骤2 - 将 transition 属性替换成 animation 属性 利用 animation 属性，在立方体上应用我们前面定义的「autoRotate」动画，并做以下设定： 时间轴函数（animation-timing-function）为 ease 持续时间（animation-duration）为 18 秒 执行次数（animation-iteration-count）为 infinite，即无限次 执行方向（animation-direction）为 alternate，即正、反向交替执行 // transition: transform ease 1s; animation: autoRotate ease 18s alternate infinite; 以上两个简单的步骤完成了 animation 替代 transition 实现更丰富的动效，读者可以通过 查看完整示例代码 并修改 animation 属性的其他设定（如 animation-play-state 等）来加深体会。 扩展阅读 结合 CodePen 案例学习 animation 的每一个属性：CSS Animation for Beginners 学习 animation 动画的小奇巧：CSS Animation Tricks: State Jumping, Negative Delays, Animating Origin, and More 小结 动效开发以「动」为始，本小节结合示例介绍了利用 CSS3 让网页元素动起来的两种方法——transition 和 animation，通过对比和结合来加深读者对这两种方法制作动效的理解与体会。 "},"大厂H5开发实战手册/06.动效开发2：聊一聊3D.html":{"url":"大厂H5开发实战手册/06.动效开发2：聊一聊3D.html","title":"06.动效开发2：聊一聊3D","keywords":"","body":"动效开发 2：聊一聊 3D 我们在前一小节的案例中制作了一个立方体，其实就已经接触到了 3D。 所有东西一跟 3D 扯上关系，复杂指数都是噌噌噌往上走。不过也正常，毕竟多了一个维度，要有三维应有的尊严。 3D Transforms 要怎么写？能写翻牌效果吗？能写翻书效果吗？能写出立体书的效果吗？往下看，答案都在这里面。 很多时候，仅仅将元素进行二维层面的变换显然不是人类的终点，毕竟十二维空间都可能不是极限（视频: 从一维空间到十二维空间）。 Intro to 3D Transforms 的作者 David DeSandro 说，现在可是 21 世纪，可我们竟然还在跟三十年前的二维空间界面扯皮。所幸 2011 年，我们有了 CSS3，我们还有了 3D Transforms，真是一个值得奔走相告的大事件。 3D 变换相较 2D 变换，坐标系中多了 Z 轴，也就意味着物体除了上下左右，还可以前后移动。而 rotate 在 2D 中的旋转方式，在 3D 中与 rotateZ 相当。 那么，单纯地将 transform 中的参数扩展出 Z 维度，就能实现 3D 效果了吗？我看见 CSS3 笑了。 perspective 概念理解 什么是 perspective ？词典中翻译为观点、远景、透视图。这是一个非常抽象的概念，需要一点空间想象力。 我们先抛开这个概念，尝试使用刚才说到的知识点进行翻牌（咦）效果的尝试，聪明的你一定分分钟码出来： 1 2 .card-front { background: red; } .card-back { background: blue; transform: rotateY( 180deg ); } /* 翻牌动作 */ .card.flipped { transform: rotateY( 180deg ); } 但是放浏览器里一看，这不对呀，为什么用 3D 的代码写出了 2D 的效果？ 这个时候有请我们的 perspective 透视君。 学过素描的人一定对透视的概念不陌生，透视是保证素描写生真实合理的基础。 视频：透视学之一点透视法 CSS3 中的 perspective 在这样一个体系里就代表着元素与观者之间的距离，形象点说，就是元素 3D 效果的强度。CSS3 中的 3D 效果消失点固定，变化的是观者与元素之间的距离。不过 perspective 数值与 3D 效果强度是成反比的，数值越大，元素的 3D 效果越不明显 —— 2000px 的视点意味着你看的是远方的物体，而 100px 则意味着这个物体就在你眼前。 这里有幅图或许能帮助我们想象 3D 效果强度这个概念。 （图片来源：维基百科） 如果还是不懂，还有一个办法，就是在浏览器中边调整 perspective 数值边观察 3D 效果。 消失点 （图片来源：Intro to CSS 3D transforms - Perspective） 左图与右图的元素均绕 Y 轴旋转了 45°，但差别很明显，右图更容易让人想到一个画面中集体开启的窗户。左图的问题就在于，每个元素的消失点各自为政，都在元素的中心点位置，而右图的消失点则统一在实线方框的中心位置。实现方法就是将元素的 perspective 设置转移至元素父容器上。 明眼人会说，这样子可以画个正方体出来了耶。我看见 CSS3 又笑了。 建立三维空间体系 现实总是乳齿残酷~ 有了 perspective 属性，我们顶多是一群会在纸上画素描的家伙，要想徒手造模型，还是太嫩。就拿刚才的翻牌效果来说，如果你翻滚 card 父容器，无论怎么翻，能看到的只有正面的卡片，因为现在的体系就是一张素描绘画，你拿着再逼真的素描画翻到背面，也是看不到真实物体的背面的对吧。超越平面 3D 的关隘就在于 transform-style: preserve-3d 的属性设置，默认值为 flat，即“素描作品”。这个属性的设置旨在告诉子元素需要遵循怎样的空间体系规则。这个属性不能继承，因此只要有子元素需要设置空间体系规则，就得在父元素声明这个属性。 有了浏览器为我们处理空间体系规则，可以省不少事，不需要你担心层级问题，不需要你操心哪个元素转到哪里要消失，哪个元素转到哪里要出现。嗯，笔者从没自己这么干过，从没。 从翻牌到翻书 翻牌那是皇帝干的事儿，我们文化人得翻书。刚才的翻牌都是在方块的中部为轴进行的变换，我们把变换原点 transform-origin 一换，就变成书页在翻了。 一本合上的书正常来说是在 Y 轴右侧，每一页都包含两面，也就是说一本书是由若干个翻页效果组合而成，每一页的变换原点在元素左侧。由此可以在翻牌的基础上迅速整出一个翻书 DEMO（猛戳 查看翻书 DEMO）。 阴影的使用能让翻书效果变得更真实。 （猛戳 查看 DEMO（带阴影）） 3D 动画之 Hard Level：立体书 立体书在外国叫 Pop-Up Book，满满的 “Surprise!” 感。这种超越传统平面书籍的阅读模式常被用于儿童书籍。 （图片来源：A Guided Tour of THE MEL BIRNKRANT COLLECTION） 要用 CSS3 实现这种效果，想想还有点小激动。 首先建立一个立体书规则： 书开，元素起 元素竖起速度小于等于书页开启速度 元素折叠后不可露出书边 元素层叠关系不可反自然 剩下的事也就水到渠成，无非是在每一页建立 3D 体系、立体元素从 rotateY(90deg) 转换到 rotateY(0deg) 的事儿。 （Mozzilla 的小 DEMO） 笔者曾做过一个丧心病狂的立体书触屏页，由于立体书左右两页互相关联的特性，翻牌的方式不太适合用在这里，这里使用的是另一种较为麻烦的方式 —— 不像翻牌方式中的前后两页捆绑，这里的书页左右两页属于一个 3D 体系，通过 translateZ 值的变换控制层级关系，因为在 3D 体系里，z-index 已被抛弃。 猛戳进入 麦芒推广页 体验 3D 立体书效果。 终端支持 由于截至目前为止，CSS3 的 3D 功能还止于炫技的阶段，安卓机与 iOS 的支持效果存在差异且难以调和，从上面那个案例中肉眼可见的坑就能看出，因此除了简单的 3D 转换，不建议在生产项目中大面积使用 3D 深层功能。 3D 与硬件加速 坊间流传这这样一个传说：一旦使用 3D 属性，就能触发设备的硬件加速，从而使得浏览器的表现更佳。但这句话也得看情境—— 想象使用 GPU 加速的动画就像是 Vin Diesel（速度与激情的主角）开着 Dominic 标志性的汽车 —— Dodge Charger。它的定制 900 hp 引擎可以让它在一瞬间从 0 加速到 60 码。但是如果你开着它在拥挤的高速公路上又有什么用呢？这种情况下错的不是你的车辆，而是你还在一条拥堵的高速公路上。—— 《CSS 硬件加速的好与坏》 因此千万别贪心，将 3D 效果数量控制在一定范围内，页面性能才是重中之重。——来自得到惨痛教训的笔者的忠告。 扩展阅读 Intro to CSS3 3D transforms by David DeSandro —— 详尽又新鲜的 3D Transformers 手册，包含许多一看就懂的小 Demo，妈妈再也不用担心我的 3D 了。 Perspective (graphical) —— 对透视学还一知半解的可以看看维基的详细说明。 Unfolding the Box Model: Exploring CSS 3D Transforms by Chris Ruppel —— 非常赞的 3D Transforms 介绍，从 2D 到 3D 过渡，启动联想学习法，一看就明白，就怕你不看。 CSS 硬件加速的好与坏 —— 很多事情都不是一两句能讲清楚的，但是只要深入了解原理，一两句都不用讲就清楚了。 小结 本小节结合案例为大家介绍了实现 3D 效果的几个关键点：透视的概念理解—— perspective、空间变换体系 —— transform-style、Z 轴位移 —— translateZ。读者可以通过我们提供的丰富案例进一步体会 3D 效果的具体实现。 "},"大厂H5开发实战手册/07.动效开发3：补间动画.html":{"url":"大厂H5开发实战手册/07.动效开发3：补间动画.html","title":"07.动效开发3：补间动画","keywords":"","body":"动效开发 3：补间动画 我们已经知道如何利用 CSS3 让网页元素动起来，也知道怎么样让它变得立体，接下来为大家讲解在实际工作过程中最为常见的两种基础动画形式 ——「补间动画」和「逐帧动画」，先从「补间动画」说起。 「补间动画」（Tween Animation）指的是：人为设定动画的关键状态（也就是关键帧），而关键帧之间的过渡过程则由计算机处理渲染的动画处理形式。 回想一下前面两个小节中的各种案例，不难发现 transition 属性实现的动画都属于补间动画，而对于 animation 属性来说，使用了除 steps 和 frames 以外的时间函数（如 ease、linear 或 cubic-bezier 等）的动画都属于补间动画。 可以说补间动画是 CSS3 动画中最常见的一种形式，常见到平时工作中几乎所有的动效需求案例都能找到它的影子。 案例实战 1 - 京东 2017 海外招聘 H5 我们以京东 2017 海外招聘 H5 的第三屏动画为例，为大家讲解如何利用 CSS3 实现补间动画。 步骤 1 - 动效审查与分解 动效审查与分解是动效开发的首要步骤，不管我们开发的是「补间动画」还是「逐帧动画」。根据提供的设计稿，和设计师一起围绕动效进行沟通审查（事实上有经验的设计师会在开始视觉设计之前提前和开发同学沟通动效，设计稿定稿之后再一起回顾沟通），了解设计师对动画时序的想法，并根据自己的开发经验评估预期动效设计的合理性，必要的时候给予设计稿调优建议。 动效审查完毕后，可以输出一张动画属性分解表，以便于后续开发的时候进行追溯调优，如下图所示。 步骤 2 - 根据需求进行切图 根据动画属性分解表，先进行切图（可回顾小册的第 2 小节），将需要添加动效的元素单独切出，如下图所示。 步骤 3 - 页面编码开发 切图完成后，我们根据设计稿进行构建还原，编写对应的页面 HTML 结构和样式。 具体的 HTML 代码和 SCSS 样式如下所示。 宣讲行程 Campus Talk Schedule 09 / 20 INSEAD 09 / 21 NTU U.S 09 / 26 UCLA 09 / 28 UC Berkely 10 / 05 Wharton U.K 10 / 29 LBS .timeline { position: absolute; width: 100%; height: 100%; left: 0; top: 0; &_tit { position: relative; padding: rem(70px) 0 rem(30px); font-size: rem(60px); line-height: rem(90px); color: #fff; text-align: center; span{ display: block; font-size: rem(36px); line-height: rem(50px); } &:after{ content: \"\"; position: absolute; width: rem(92px); height: 1px; background: #ff0000; bottom: 0; left: 50%; margin-left: rem(-46px); }; } &_icon { position: relative; width: rem(102px); height: rem(102px); margin: rem(36px) auto 0; background: url(\"images/p3_01.png?__inline\") no-repeat center; background-size: rem(57px) rem(50px); svg { width: rem(102px); height: rem(102px); stroke: #0084ff; stroke-width: 2px; fill: none; stroke-dasharray: 400; } } &_list { position: relative; bottom: 0; width: rem(900px); height: rem(1224px); margin: 0 auto; padding: rem(68px) 0; display: flex; flex-direction: column; color: #fff; } &_line { position: absolute; width: 1px; height: 100%; background: #0084ff; top: 0; left: 50%; } &_item { position: relative; flex: 1; display: flex; align-items: center; z-index: 9; b { position: absolute; width: rem(16px); height: rem(16px); border-radius: 50%; left: 50%; top: 50%; margin: rem(-7px) 0 0 rem(-7px); z-index: 1; background: #fff; box-shadow: 0 0 0 rem(13px) #0084ff; } &_sp { b{ background: #0084ff; box-shadow: none; } } &_cnt { flex: 1; padding: 0 rem(100px); &:nth-child(1){ text-align:right; }; &:nth-child(2){ text-align:left; }; &.flag{ width: rem(111px); height: rem(65px); i{ display: inline-block; width: rem(111px); height: rem(65px); background-size: 100%; } } &.country{ font-size: rem(36px); color: #66b5ff; } &.time{ font-size: rem(36px); } &.city{ font-size: rem(48px); } .flag_sin{ background: url(\"images/p3_02.png?__inline\") no-repeat; } .flag_us{ background: url(\"images/p3_03.png?__inline\") no-repeat; } .flag_uk{ background: url(\"images/p3_04.png?__inline\") no-repeat; } } } } 步骤 4 - 结合动画属性分解表实现动画 我们从步骤 1 获得了动画属性分解表，下面根据它来一一实现动画。 1. 图标圆形边框的路径描边动画 这样的描边动画效果无法用 CSS3 的方案实现，但可以通过 SVG 的方案来实现。 1.1 确保 SVG 图形设置 stroke 属性实现描边效果 svg { // 设置描边 stroke: #0084ff; stroke-width: 2px; fill: none; } 1.2 对 SVG 图形设置 stroke-dasharray 属性 stroke-dasharray 属性是用来设置描边的虚线的图案范式，也就是设置实线段和虚线段的宽度。 我们对 stroke-dasharray 属性作如下设置，其含义就是，实线段的长度为 320，而虚线段的长度为 0，所以我们看到的仍是一条实线的描边。 stroke-dasharray: 320; // stroke-dasharray: 320 0; 的等价写法 接下来我们利用 stroke-dashoffset 属性使得这条实线描边可以出现和消失。 1.3 利用 stroke-dashoffset 属性实现补间动画 stroke-dashoffset 属性指定了虚线路径起始点的距离。 因此，当我们把 stroke-dashoffset 的值设置为 circle 的路径总长度时，描边轨迹就会完全不可见，而逐步减小其值至 0 时，可使之完全呈现。 我们可以通过脚本获取描边路径的总长度： // 我们取整为320 var path = document.querySelector('circle').getTotalLength(); // 等于313.6517333984375 最后，我们只需要设置初始关键帧和结束关键帧，对 stroke-dashoffset 属性值从 320 变为 0 ，再根据动画时间表里的动画时间、延时以及时间函数进行动画属性设置，就实现了 SVG 路径描边的补间动画，代码如下所示。 .part3.in { .timeline_icon { svg { animation: on_tl_iconsvg .5s 0.9s linear both; } } } @keyframes on_tl_iconsvg{ 0% {stroke-dashoffset: 320;} 100% {stroke-dashoffset: 0;} } 对于 animation-fill-mode 属性的详解，笔者推荐《理解 animation-fill-mode 属性》一文，这里不作赘述。 2. 图标的渐现和上移动画 图标的渐现和上移效果都是作用于图标而言的，因此我们把这两个动画合在一起写。 对于渐现渐隐效果，为了获得更好的性能，我们使用 opacity 属性，而不是 display、visibility 属性；出于同样的考虑，对于偏移效果，则使用 translate 属性，而避免使用 left、right、bottom、top 属性。 选取好合适的 CSS 属性之后，我们最后根据动画分解表进行分析实现。从表中可知，渐变效果的时间为 0.8s，占总时间 1.2s 的比率为 66.66%，再配合从设计稿测量得到的偏移值 480px，最终我们很快就写出了动画代码，如下所示： .part3.in { .timeline_icon { animation: on_tl_icon 1.2s .5s linear both; } } @keyframes on_tl_icon{ 0% {transform: translateY(rem(480px));opacity: 0} // 先渐现 66.66% {transform: translateY(rem(480px));opacity: 1} // 再向上偏移 100% {transform: translateY(0);opacity: 1} } 标题、标题下划线、日程时间轴线的动画实现，也是类似图标渐现和上移动画的做法，这里就不展开了。 下面，我们来详细讲讲如何实现「日程时间轴的列表项按次序出现」的补间动画。 3. 日程时间轴的序列动画 日程时间轴的列表项按次序出现的补间动画，这种对多个元素使用相同的动画效果，且各个元素动画执行时机依次错开的、整齐有序的序列动画效果，我们可称之为序列动画。 首先，我们实现列表项展开的动画效果，代码如下所示。 @keyframes on_tl_item { 0% {transform: scale(0,0); opacity: 0} 100% {transform: scale(1,1); opacity: 1} } 接着，我们利用 animation-delay 属性进行延时控制动画执行时机的依次错开。 根据动画分解表，我们知道动画时长为 0.45s，初始延时 2.35s，而每个列表项之间间隔 0.15s，因此推算得出第 i 个列表项（1 配合 SCSS 的 @for 控制指令用法，我们可以快速地循环输出样式，代码如下所示。 .part3.in { .timeline_item { animation: on_tl_item 0.45s ease both; @for $i from 1 to 10 { &:nth-child(#{$i}) { animation-delay: (2.2s + 0.15s * $i); } } } } 利用 @for 控制指令为多个列表项元素的相同动画效果动态生成样式，并且通过 animation-delay 来控制依次错开动画执行的时机，从而形成整齐有序的序列动画效果。 至此，整个第三屏动画就完成了，查看 完整的 DEMO 进行体验。 案例实战 2 - 京东 App 搜彩蛋：把动效设计的锅扔给设计师 我们知道，动效开发的流程往往是： 设计师和开发童鞋一起构思整个动画的方案 设计师根据动画方案出设计稿 开发童鞋根据设计稿及动画方案自由发挥，进行动效的设计与开发 在这样的流程下，动画成品效果的好与坏往往取决于开发童鞋在动效设计方面的知识和经验是否丰富，而这对于初次接触动效开发的童鞋来说恐怕是极大的挑战。 事实上，大多数前端开发者在动效设计方面并没有太多的积累，难以做出令人拍手称赞的动画效果。而设计师（或动效设计师）却刚好相反，因为他们一般都擅长使用做动效设计的工具 —— Flash 或 AE（After Effects）。 把「动效的设计」交给更专业的设计师，让他们输出完整的「动效稿」，再让开发童鞋依据「动效稿」转换成为网页代码，未尝不是一种好的动效开发方式。（笔者注：腾讯 TGideas 团队早在两三年前就开始探索和实践这种动效开发方式，积累了丰富的实战经验。） 由设计师来负责动效的设计，对项目来说还有以下好处： 设计师与开发的排期由「线性」变为「部分重叠」：设计师交付静态设计稿后，开发就能进行视觉还原构建页面，设计师此时即可进入动效设计。 设计师将动效设计导出为视频，提前取得各方满意度，避免开发期间的反复沟通修改。 对开发童鞋来说，我们会迎来一个新的问题：如何还原「动效稿」，将它转换成保真的网页动效？ 我们接下来以「京东 2017 年 App 搜彩蛋项目 —— 苹果彩蛋」为例，为大家解读如何基于 AE 稿开发补间动画（其思路也适用于逐帧动画）。 读者可以自行 下载本案例所用的 AE 稿。 基于 AE 实现 Web 动效 基于 AE 手工实现 Web 动画的主要工作有两个： 取参 —— 在动效稿上拿到元素的参数信息，如 x/y/z、rotation、动画设定等 开发 —— 通过适当的 Web 技术进行动画开发，如 CSS3/Canvas/SVG 等 取参及 AE 界面使用指引 打开 apple.aep 文件，AE 界面如下： 点击 「信息模块」预览面板的播放按钮或拖动「时间轴模块」的 标记3 即可预览动画。 为了利用 CSS3 animation 属性实现最终的动效，我们需要获取以下关键设置信息： 动画持续时间 animation-duration 关键帧之间的时间轴函数 animation-timing-function 动画延时时间 animation-delay 由于该动画是一次性的，无需设置/获取动画的重复次数（animation-iteration-count）及执行方向（animation-direction）。 我们选取整个苹果彩蛋动画中一个小圆圈（共 60 个）为示例代表，其余元素同理。 现在我们把目光投向「图层、运动模块」的 标记1： （标记1 —— FPS） 由上图可得，FPS 为 12，即 1 秒 12 帧， 1 帧 0.0833 秒。 通过观察苹果彩蛋动画的预览效果可以发现，每个圆的延时时间（animation-delay）、时间轴函数（animation-timing-function）和持续时间（animation-duration）均不相同。换句话说，每个圈都是一个独立的补间动画，所有元素组合起来才是一个完整的补间动画。 双击「标记 2」，进入编组以查看每个圆的信息。 （子元素——圆） 在「查看器」或「图层、运动模块」任意选中一个圆，展开其 变换 属性并单击 位置（标记1），即可显示右侧的元素运动路径（标记2）。同时这也反映了动画的变化速率（即时间轴函数 animation-timing-function），后面会做进一步解读。 值得注意的是：位置 前面的时钟图标为蓝色时，代表当前属性有过渡动画。 （某个圆的时间轴） 综上所述，可从上图得出以下信息点： 该元素共有 4 个关键帧（绿线上的小方块） 只有 Y 轴上发生位移运动（绿线），X 轴上则是静止状态（红线） 延时时间为 1 帧（绿线前面的虚线处） 中间停留时间（第2、3 关键帧之间）为 1 帧 过渡时间为 42 帧（3*12 + 7 - 1）。注意要减去延时时间（1），因为 02:03 包含了它 利用 animation 属性实现动画 在拿到动画所需的各项设定参数信息后，便可以利用我们熟悉的 animation 实现某个圆的补间动画了。 /* 默认定位在第2（或3）帧以让元素默认显示在屏幕内，便于开发调试。 */ .circle-29 { width: 60px; height: 60px; background-color: rgba(0, 224, 93, .7); position: absolute; left: 473px; top: 348px; border-radius: 50%; animation-name: circle29; animation-duration: 3.5s; /* 42 * (1 / 12) */ animation-delay: 0.0833s; /* 1 * (1 / 12) */ animation-fill-mode: both; animation-timing-function: ease-in-out; } @keyframes circle29 { 0% { transform: translate3d(0, 1175px, 0); } 61.90% { /* (2 * 12 + 3 - 1) / 42，注意要减去延时时间（1），因为 02:03 包含了它。下同。*/ transform: translate3d(0, 0, 0); } 64.29% { transform: translate3d(0, 0, 0); } 100% { transform: translate3d(0, -1225px, 0); } } 虽然略微烦琐，但是省去反复调整动画设定的时间，基本做到一次开发即可输出满意的效果。 其余元素参考以上步骤执行即可完成整个苹果彩蛋动画。 假设没有动画预览效果和动效稿，仅靠开发童鞋自由发挥编码完成一个由 60 多个元素组成的动画，简直难于上青天（至少对于笔者来说）。 效果演示 上述实现代码使用 CodePen 做演示，读者可以自行查看体验。 查看单个圆的补间动画 完整的苹果彩蛋动画 或扫码体验： （基于 AE 稿实现的补间动画 —— 2017 年京东 App 搜索彩蛋 ） 小结 本小节以 2 个实际工作中的案例 —— 「2017 京东海外招聘 H5」 及 「2017 年京东 App 搜索彩蛋」，分别为大家讲解了「如何利用 CSS3 实现补间动画」及「基于 AE 稿实现补间动画」的完整过程。在实际工作过程中，如果动画方案较为复杂，可以尝试后者，让设计师使用 AE 设计完整的动画，开发的时候基于 AE 稿来还原动效。当然，无论是哪一种方式，目前看来都免不了较大的人肉开发成本，虽然业界出现了一些能够直接将 AE 动画导出为 Web 动画的插件或开源库（代表性的有 Bodymovin 和 lottie-web，笔者还尝试使用 Bodymovin 实现了前面的苹果彩蛋动画，查看 DEMO），但其实际可用性还有待进一步的验证。 "},"大厂H5开发实战手册/08.动效开发4：逐帧动画.html":{"url":"大厂H5开发实战手册/08.动效开发4：逐帧动画.html","title":"08.动效开发4：逐帧动画","keywords":"","body":"动效开发 4：逐帧动画 前一小节我们花了很大的篇幅去讲解「补间动画」的开发，除了因为它最常见，还因为其中间的许多实现思路（如「动效的审查与分解」、「基于 AE 动效稿还原动画」）同样适用于本小节将要介绍的另一种常见的基础动画形式 —— 「逐帧动画」。 什么是逐帧动画 逐帧动画的英文名字是 Frame-By-Frame Animation，其在维基百科中有如下定义： 定格动画，又名逐帧动画，是一种动画技术，其原理即将每帧不同的图像连续播放，从而产生动画效果。 简而言之，逐帧动画有两个要素： （1）相关联的不同图像，即动画帧（2）连续播放 逐帧动画最经典的例子，莫过于手翻书了。动画帧绘制在书本的不同页上，通过手动翻页来实现连续播放： （图片来源：《一起翻一翻，手翻书的前世今生》） 逐帧动画的前端实现方案 在细聊 CSS3 逐帧动画之前，我们先了解下前端实现逐帧动画的几种方案。 1. 直接使用 GIF GIF 可以有多个动画帧，连续播放是其自身属性，是否循环也是由其本身决定的。 GIF 往往用来实现小细节动画，成本较低、使用方便、兼容性好，但同时也存在画质低、交互不灵活等问题。 2. 使用 JavaScript 控制动画播放 将动画帧合并成雪碧图，放到 background-image 中，通过 JavaScript 改变 background-position 的值来实现动画的播放。 使用 JavaScript 实现逐帧动画，兼容性佳，且交互灵活。 3. 使用 Canvas 及相关库 将动画帧绘制到 Canvas 上，通过不断地重绘即可实现逐帧动画。CreateJS、Pixi.js 等库都提供了成熟的方案。 使用 Canvas 可以利用硬件加速，功能强大，操作灵活，有丰富的类库，但学习成本较高，且老式浏览器不兼容 Canvas。 4. 使用 CSS3 阶梯函数 steps(number_of_steps, direction) CSS3 使用 animation-timing-function 的阶梯函数 steps(number_of_steps, direction) 来实现逐帧动画。 在实际工作过程中，开发「逐帧动画」最为常见的两种方式是第 3 和 4 种，CSS3 Animation 兼容性良好，相对于 JavaScript，CSS3 逐帧动画使用简单，且开发效率更高；而 Canvas 因为其性能优势，帧与帧之间切换的衔接度更高，适合实现帧数或尺寸（宽高）较大的逐帧动画。 案例实战 1 - 利用 CSS3 实现逐帧动画 与使用 JavaScript 实现相同，通过 CSS3 实现逐帧动画时，也是将动画帧放到 background-image 中。 逐帧动画往往有多个不同的动画帧，可以直接通过更改 background-image 的值实现帧的切换，但多个图片文件会带来多个 HTTP 请求，且不利于文件的管理。 比较妥当的做法是，将所有的动画帧合并成一张雪碧图（sprite），通过改变 background-position 的值来实现动画帧切换。因此，逐帧动画也被称为“精灵动画（sprite animation）”。 下面以京东到家的触屏页面《年货送到家》中的一个场景为例，为大家讲解如何利用 CSS3 来实现逐帧动画。 步骤 1 - 将动画帧合并为雪碧图 动画帧的合并方法有很多，可以使用图片处理软件、在线雪碧图工具、自动化脚本等。这里将介绍 Photoshop 中的操作。 准备好需要合并的动画帧，这里使用的动画帧尺寸为 200 x 206 打开 Photoshop - 文件 - 自动 - 联系表 II，选取所有动画帧，设置文档尺寸，注意红框部分取消勾选 背景图层不可见，导出雪碧图并命名为 p8.png 此时，我们可以得到如下的雪碧图 p8.png： 步骤 2 - 元素定位并设置背景 元素的尺寸需与动画帧的尺寸相同/等比例，将雪碧图放到元素的 background-image 中： .page_key { position: absolute; left: 20px; top: 20px; width: 200px; height: 206px; background-image: url(\"../img/p8.png\"); } 步骤 3 - 使用 steps 实现动画播放 通过查看 W3C 文档，可知 steps(number_of_steps, direction) 指定了一个阶梯函数，包含两个参数： 第一个参数指定了函数中的间隔数量（必须是正整数） 第二个参数可选，指定在每个间隔的起点或是终点发生阶跃变化，接受 start 和 end 两个值，默认为 end 可以通过下图更深入地理解 steps 函数： （图片来源：W3C） 我们可以通过两种写法来实现例子中的逐帧动画，下面是第一种写法。 /* 写法一 */ .page_key { animation: p8 steps(1,end) 1.5s infinite; } @keyframes p8 { 0% {background-position: 0 0;} 33.33333% {background-position: 0 -206px;} 66.66667% {background-position: 0 -412px;} 100% {background-position: 0 -618px;} } 这里可能有读者疑惑，steps 的第一个参数为什么是 1？ 前文中提到，steps 是 animation-timing-function 的一个属性值，在 W3C 中有如下说明： For a keyframed animation, the ‘animation-timing-function’ applies between keyframes, not over the entire animation. 也就是说，animation-timing-function 应用于两个关键帧（状态）之间，而非整个动画。在上面的 keyframes 中，我们已经把每个关键帧都写出来了，所以两个关键帧之间的间隔是 1。 既然 steps 第一个参数是指函数的间隔数量，那么我们就可以把 keyframes 的计算直接交给 steps 来完成。 /* 写法二 */ .page_key{ animation: p8 steps(3,end) 1.5s infinite; } @keyframes p8 { 100% {background-position: 0 -618px;} } 上述两种写法最终的动画效果是相同的： 至此，我们便实现了一个简单的 CSS3 逐帧动画，点击查看 DEMO 或扫描二维码： （京东年货到家逐帧动画 DEMO） CSS3 逐帧动画的一些技巧 CSS3 实现逐帧动画虽然简单，但也不乏技巧。 1. step-start 与 step-end 除了 steps 函数，animation-timing-function 还有两个与逐帧动画相关的属性值 step-start 与 step-end。 step-start 等同于 steps(1, start)：动画执行时以开始端点为开始。 step-end 等同于 steps(1, end)：动画执行时以结尾端点为开始。 2. 使用 Sass 完成动画帧的计算 /* 写法一 */ @mixin frame($frameNum, $frameHeight) { @for $i from 0 through $frameNum { #{100/$frameNum*$i}% {background-position: 0 #{-$i*$frameHeight}px;} } } /* 写法二 */ @mixin frame($frameNum, $frameHeight) { 100% {background-position: 0 #{-$frameNum*$frameHeight}px;} } @keyframes p8 { @include frame($frameNum: 3, $frameHeight: 206) } 3. 移动端使用 rem 配合 scale 适配，防止动画抖动 我们知道，rem 的计算会存在误差，因此使用雪碧图时我们并不推荐用 rem。 如果是逐帧动画的话，由于计算的误差，可能会出现动画抖动的情况。 为了解决这个问题，可以参考以下的适配思路： 非逐帧动画部分，使用 rem 做单位 逐帧动画部分，使用 px 做单位，再结合 JavaScript 对动画部分使用 scale 进行缩放 另外也可以通过 SVG 来解决抖动的问题，有兴趣可移步《CSS 技巧：逐帧动画抖动解决方案》 做进一步的了解。 案例实战 2 - 利用 Canvas 做一个会动的京东 JOY CSS3 实现的逐帧动画，如果它的帧数较多或尺寸较大时，移动端可能会存在渲染性能问题，此时建议改用 Canvas 实现。 相对于 CSS3 来说，Canvas 具有更高的学习成本，所以实际项目中推荐使用业务成熟的 Canvas 动画库，如 CreateJS、Pixi.js 等。 下面我们以 「京东 JOY 福星会场 一一 八仙乐游记」 中的其中一个动画为例，为大家讲解如何利用 Canvas 实现逐帧动画。 步骤 1 - 准备动画帧所需的雪碧图 在前面的案例中我们介绍了通过 Photoshop 手动合成雪碧图的方式，这里我们使用 TexturePacker 工具（付费软件，帧动画开发利器，值得购买）来更快地完成同样的事情。 （TexturePacker 用户界面） TexturePacker 导出雪碧图的步骤如下： 将逐帧动画所有帧拖到 TexturePacker 选择逐帧动画的渲染载体（标记1） 根据需要设置其余配置，如：当雪碧图超过 1 张时，请选择 Multipack 选项（标记2） 点击 Publish sprite sheet（标记4）即可导出雪碧图和相应渲染载体的数据（若有） 预览逐帧动画的步骤： 选择所有帧 选择左侧 Sprites 面板其中一帧，然后按 Cmd/Ctrl + A 全选所有帧；或者拖拽选择所有帧。 点击 Anim preview（标记3） 如果我们选了渲染载体为 EaselJS / CreateJS， 其导出的 JSON 文件如下： { \"images\": [ \"hxr-0.png\", \"hxr-1.png\", \"hxr-2.png\", \"hxr-3.png\", \"hxr-4.png\", \"hxr-5.png\" ], \"framerate\": 20, \"frames\": [ [1, 1, 519, 535, 0, -109, -499], [522, 1, 514, 538, 0, -108, -499], [1, 538, 514, 538, 0, -109, -499], ... ], \"animations\": { \"花想容\": { \"frames\": [45, 34, 36, 39, 41, 42, 43, 27, 44, 15, 30, 16, 17, 18, 21, 23, 24, 9, 12, 14, 19, 1, 2, 4, 5, 7, 10, 11, 13, 20, 31, 22, 25, 35, 28, 29, 32, 37, 38, 40, 33, 26, 8, 6, 0, 3] } }, \"texturepacker\": [ \"SmartUpdateHash: $TexturePacker:SmartUpdate:d81882f9ddc9b1a6b4cc21c262ac0125:4ebba912052ed522502e73edaa8a5333:c8130f68479de7028295f1ccf1a4ea15$\", \"Created with TexturePacker (https://www.codeandweb.com/texturepacker) for EaselJS\" ] } TexturePacker 除了生成雪碧图，其导出的 JSON 文件其实还包含了逐帧动画所需的运行数据，只需结合渲染载体的相应 API 即可快速实现逐帧动画。 步骤 2 - 实现动画 以 CreateJS 为例。 准备 HTML: 准备 CreateJS 代码： var hxrCanvas = document.getElementById(\"hxr-canvas\") var hxrStage = new createjs.Stage(hxrCanvas) // 将上 JSON 数据进行修改：如 \"images\" 和 \"animations\" 字段 var spriteSheet = new createjs.SpriteSheet({ \"images\": [ preload.getResult('hxr0'), preload.getResult('hxr1'), preload.getResult('hxr2'), preload.getResult('hxr3'), preload.getResult('hxr4'), preload.getResult('hxr5'), ], \"framerate\": 20, \"frames\": [ [1, 1, 519, 535, 0, -109, -499], [522, 1, 514, 538, 0, -108, -499], [1, 538, 514, 538, 0, -109, -499], ... ], \"animations\": { \"play\": { \"frames\": [45, 34, 36, 39, 41, 42, 43, 27, 44, 15, 30, 16, 17, 18, 21, 23, 24, 9, 12, 14, 19, 1, 2, 4, 5, 7, 10, 11, 13, 20, 31, 22, 25, 35, 28, 29, 32, 37, 38, 40, 33, 26, 8, 6, 0, 3] } }, }) hxrSprite = new createjs.Sprite(spriteSheet) hxrSprite.x = 0 hxrSprite.y = 0 hxrStage.addChild(hxrSprite) hxrSprite.gotoAndPlay(\"play\") // 播放指定的动作 \"play\" 这样即可完成一个逐帧动画，点击体验 DEMO ，或扫描二维码： （ Canvas 逐帧动画 DEMO ） 相关资源下载 逐帧动画源文件（用于 TexturePacker 合成） TexturePacker 导出后的文件（适用于未购买 TexturePacker 的读者） 案例 2 完整项目源码 小结 本小节结合案例为大家讲解了两种最为常见的逐帧动画实现方案：「基于 CSS3 Animation 实现逐帧动画」和「基于 Canvas 实现逐帧动画」。考虑到 Canvas 的方案需要引入第三方的脚本库（以 CreateJS 为例，引入的脚本库体积大小在 190 多 KB，GZIP 后仍然有 50 多 KB），在实际工作过程中，应尽量使用 CSS3 来实现逐帧动画，当 CSS3 实现的逐帧动画出现性能体验问题（或预估到会有此类问题）时，再考虑使用 Canvas 的实现方案。 "},"大厂H5开发实战手册/09.动效开发5：SVG动画.html":{"url":"大厂H5开发实战手册/09.动效开发5：SVG动画.html","title":"09.动效开发5：SVG动画","keywords":"","body":"动效开发 5：SVG 动画 CSS3 动画已然足够强大，不过还是有一些它做不到的地方，例如轨迹（路径）动画的实现。配合 SVG，可以让 Web 动效有更多的可能性。 案例实战 - 实现一个购物袋的 loading 动效 下面以一个购物袋的 loading 动效为示例，带领大家上手 SVG 动画。 其中旋转通过 CSS 来完成，但是旋转之后圆弧缩短变成笑脸的嘴巴需要借助 SVG 来实现。 步骤 1 - 声明 SVG 视窗 指定一个宽高都为 100 像素的区域，width=\"100\" 和 width=\"100px\" 是等价的，当然也可以使用其他的合法单位，例如 cm、mm、em 等。 阅读器会设置一个默认的坐标系统，见下图：左上角为原点，其中水平（x）坐标向右递增，垂直（y）坐标向下递增。 在没有指定的情况下，所有数值的默认单位都是像素。 步骤 2 - 绘制购物袋 购物袋由两个部分组成，先画下面的主体： 任何形状都可以使用路径元素画出，描述轮廓的数据放在它的 d 属性中。 样式中的 fill 用来设置填充色 路径数据由命令和坐标构成 指令 说明 M 20 40 表示移动画笔到 (20,40) L 80 40 表示绘制一条线到 (80, 40) A 10 10 90 0 1 70 100 绘制一个椭圆弧 圆弧命令以字母 A 开始，后面紧跟着 7 个参数，这 7 个参数分别用来表示： 椭圆的 x 半径和 y 半径 椭圆的 x 轴旋转角度 圆弧的角度小于 180 度，为 0；大于或等于 180 度，则为 1 以负角度绘制为 0，否则为 1 终点的x、y坐标 接下来绘制购物袋上面的部分： 上面的部分是一个半圆弧，同样用路径来画出，当然也可以使用基础形状来完成。 样式中的 stoke 和 stroke-width 分别用来设置描边色和描边的宽度。 步骤 3 - 绘制眼睛 使用基础形状，画两个小圆点。四个属性分别是位置坐标、半径和填充颜色。 步骤 4 - 绘制嘴巴 嘴巴是一段圆弧，我绘制了一个圆，然后描边了其中的一段，并且做了一个旋转，来让它的角度处于正确的位置。 stroke-linecap：用来定义开放路径的终结,可选 round|butt|square stroke-dasharray：用来创建虚线 stroke-dashoffset：设置虚线位置的起始偏移值，在下一个步骤里，它会和 stroke-dasharray 一起用来实现动效 步骤 5 - 给嘴巴部分添加动效 @keyframes mouth { 0% { transform: rotate(-80deg); stroke-dasharray: 60, 95; stroke-dashoffset: 0; } 40% { transform: rotate(280deg); stroke-dasharray: 60, 95; stroke-dashoffset: 0; } 70%, 100% { transform: rotate(280deg); stroke-dashoffset: -23; stroke-dasharray: 42, 95; } } 动画分为两个部分： 圆弧旋转 旋转之后缩短变形 在一个循环里，最后留有 30% 的时间保持一个停留状态。 步骤 6 - 给眼睛添加动画 两只眼睛都是沿着圆弧运动 ，例如左眼，首先用一个路径来规定它的运动轨迹： 然后使用 animateMotion 来设置动画： dur：动画的时间 repeatCount：重复次数 keyPoints：运动路径的关键点 timePoints：时间的关键点 calcMode：控制动画的运动速率的变化，discrete | linear | paced | spline 四个属性可选 mpath：指定一个外部定义的路径 步骤 7 - 将不同部位的动画组合到一起 眼睛的动画是从嘴巴旋转完成开始，到嘴巴变形完成结束，因此和嘴巴的动画一样，设置了四个对应的关键时间点。 为了让衔接更顺畅，眼睛的动画开始比嘴巴变形开始稍微提前了一点点。 Bingo！小功告成！查看 DEMO 初探 SMIL SMIL 的全称为 Synchronized Multimedia Integration Language（同步多媒体集成语言），按照 W3C 规范对 SMIL 的描述，它是一种允许用户在网页上定义可交互多媒体内容的 XML 语言，可结合 XHTML 和 SVG 一起使用来实现网页动态效果。 在上面的案例中，我们使用了一个名为 animateMotion 的元素来实现眼睛的轨迹动画，其实便属于 SMIL 的知识范畴。 除了 animationMotion 用于实现轨迹动画之外，SMIL 还提供了另外两个元素来定义父级对象的动画，分别为： animate：用于设置父元素的数值属性（如 width、height、color 等）的过渡动画 animateTransform：用于设置父元素的 transform 属性的过渡动画 SMIL 的兼容性 除了微软系浏览器 及 Opera Mini 外，其他主流浏览器均支持 SMIL。 （数据来源：caniuse.com，截至 2018 年 3 月 14 日） Chrome 45 版本曾声称准备弃用 SMIL ，但随后撤回了弃用计划。 SMIL 的一个小例子 如下利用 SMIL 同时改变圆的位置和颜色： 可见 SMIL 的动画元素是可以叠加使用的，查看 DEMO。 扩展阅读 Animating SVG with CSS：利用 SVG 结合 CSS 实现一个动态广告图 Creating Cel Animations With SVG：利用 SVG 结合 CSS 实现逐帧（定格）动画 Cel Animation：用于辅助实现 SVG 逐帧（定格）动画的一个 SASS @mixin 函数 SVG - animationMotion：了解 animationMotion 元素 SVG animation with SMIL：了解使用 SMIL 实现 SVG 动画的方法 小结 SVG 在网页中的角色更像是类似图片一样的媒体对象，其动画也常常和 CSS 有关联，当然利用 SMIL 仍然可以为 SVG 添加独立的动效，除了微软系的浏览器不支持之外，其兼容性还是相当可观的。在平时工作过程中，矢量图标的动画、轨迹动画特别适合使用 SVG 来实现。 "},"大厂H5开发实战手册/10.动效开发6：动效之效.html":{"url":"大厂H5开发实战手册/10.动效开发6：动效之效.html","title":"10.动效开发6：动效之效","keywords":"","body":"动效开发 6：动效之效 回头看看，我们花了 5 个小节来啰唆「动效开发」的「动」： 如何动 —— 第 5 小节《让它动起来》 立体地动 —— 第 6 小节《聊一聊 3D》 让浏览器帮忙动 —— 第 7 小节《补间动画》 一帧一帧地动 —— 第 8 小节《逐帧动画》 让 SVG 动 —— 第 9 小节《SVG 动画》 我们花费力气去做的事情毋庸置疑是重要的，但它距离突破也许还差一点别的东西。就好比一个歌手拼命练习各种花式唱法 —— 高音、颤音、延音无所不能，但缺了情感就算不上伟大的歌手。动效开发也是一样的道理，「动」是招式是基本要求，而「效」才是真正的修炼之道。 我们思考动效之「效」，其实就是要思考如何让我们做出来的动画具备最佳的体验效果，它包括两个方面的内容： 感官体验 —— 如何「动」得自然、有情感、能吸引人？ 物理性能 —— 如何「动」得更流畅？ “要写 CSS3 动画，必先学技术。要写好 CSS3 动画，还是得深入探索传统动画的精华。”—— EC，京东凹凸实验室首席动效开发 对于「如何提升动画的体验效果」这个话题，我们不妨先以电影之眼来看看 CSS3 动画，也许能从中窥得一些门道。 以电影之眼看 CSS3 动画 CSS3 动画的变形基础（transform）包含 4 种变形方式（translate、rotate、scale、skew），同时还可设置 2D、3D、变形原点（transform-origin）、透视（perspective）、透视原点（perspective-origin）等等特性；动画时间轴函数包含 9 种基本模式（ease、linear、ease-in、ease-out、ease-in-out、step-start、step-end、steps），甚至还可以使用 cubic-bezier 写出任何你想要的模式；再加上动画持续时间（animation-duration）等设定，各种排列组合，CSS3 动画简直拥有了整个世界。 （图片源自《动画的时间掌握》） 关键帧与时间轴 根据 维基 的释义，动画是指由许多帧静止的画面，以一定的速度（如每秒 16 张）连续播放时，肉眼因视觉残象产生错觉，而误以为画面活动的作品（GIF 图片正是运用这种原理）。因此最初的动画是通过几张快速翻动的连续画面制作而成，而后经历了电影摄影技术的出现、电脑科技的进步，逐渐转向数字化。 将上面的 GIF 拖入 PS 之后打开时间轴窗口即可看到每一帧的画面： 无论是 2D 还是 3D 动画，关键帧，正如其名，是动画制作中最关键的部分，同时也是最难把握的部分。曾经有位设计师告诉我，在大学的第一节 flash 课的课后作业，老师要求大家上交一份小球动画，包含气球、石球与皮球，并告诉大家，以相同的外观表现出不同的质感是在考验你对关键帧的悟性，而这一个作业就能体现你是否适合学习动画。 A 需要很大的力才能使一个炮弹移动。一旦它移动了，同样需要很大的力才能阻挡它前进。B 一只气球只需要很小的力去移动它，但空气阻力使它很快停止动作。这两个例子都画了动作分格线，可以看出在银幕上表现物体的轻重，取决于对它们动作的时间掌握。——《动画的时间掌握》 在《动画制作流程介绍》提供的视频中可以看到关键帧在动画制作中所起的地基般的作用。 （画面上方的手绘图即为「怪物公司」的关键帧） 与关键帧紧密关联的即为时间轴（或摄制表），时间轴是补齐中间帧不可或缺的一项，在传统动画制作中，导演就是通过制定时间轴来掌控整部动画的节奏的。 （摄制表，图片来源：《动画的时间掌握》） 在 CSS3 中，@keyframes 正是动画的关键帧容器。@keyframes 中包含的包括 transform 在内的元素形态设定构成了关键帧的画面。@keyframes 中的百分比即为时间轴的体现。中间帧则由浏览器自动完成（回顾第 7 小节的补间动画）。 现在我们知道了 CSS3 动画的结构与传统动画之间的关系，重点来了， CSS3 动画可以做出一部动画电影吗？ 用 CSS3 动画做一部动画电影 现在就让我们来探讨一下用 CSS3 动画做一部吸引人的动画电影都需要些什么。 首先，你需要一个故事 首先你需要一个故事，即使只是一堆雪花往下掉，也是包含故事的——为什么下雪？是冬天来了？那是冬天的第一场雪吗？第一场雪有什么特点呢？好吧，作为一个从没见过雪的南方人，我承认我给自己挖了个坑，不过就是类似这种思路，让我们拥有了一个故事，所以，即使只有一秒钟的动画也是有故事的。Use your imagination. 小贴士：在做影视题材的专题页时，我会首先根据相关影视的预告片确定入场动画的风格与基调，观看预告片不仅能够了解影片的风格，同时还能学习其字幕出现、消失以及转场的方式，获得一种节奏感，也就是上面所说的时间掌控。在看电影正片时也可留意影片开头与结尾字幕出现的形式，尤其是科幻片，电影字幕的设计与电影风格相辅相成，常常能让你脑洞大开——原来还能这么玩。 [窃听风云3]预告片 中字幕出现的方式表现出信号干扰的效果，由此可以将影片相关专题作出这样的开场动画—— 简单的几个不同色调的图片进行替换就能做出类似效果，代码也灰常简单（看 demo）： @keyframes peoInner{ 0%, 12.5%, 16.5%, 20.5% { background:none; } 10%, 12% { background:url(../img_bg/casts_adv_green_red.jpg) no-repeat 0 0; } 14%, 16% { background:url(../img_bg/casts_adv_green_red.jpg) no-repeat 0 -725px; } 18%, 20% { background:url(../img_bg/casts_adv_green_red.jpg) no-repeat 0 -725px; } 13%, 17%, 21%, 100% { background:url(../img_bg/cast_adv_01.jpg) no-repeat top center; } } 但是，需要注意的是，这种变换 background 的动画方式属于页面性能中的大忌，不建议使用。可使用多个 DOM 结点控制透明度动画来实现同样的效果。 设计关键帧与时间轴 当我们在脑内小剧场构思好动画小故事之后（当然，你也可以将它写下来），我们就可以进行关键帧与时间轴的设计了。 任何人都可以用电脑动画软件将一个物体移动。但是如何赋予物体重量、大小、规模、移动和幽默感，这些都与你如何移动物体相关。电脑不能为动画师创造动画，动画师仍然需要了解时间掌握的原则知识以赋予电脑动画生命力。——《动画的时间掌握》 这时需要注意的是因果关系对动画的影响，“一个动画师必须懂得自然界物体运动的力学知识”，这样“才能创造情绪和表达正确的感觉。” 我们来看看为了使动画更加流畅真实，迪士尼爷爷想出了什么办法。「白雪公主与七个小矮人」作为 80、90 后动画电影启蒙，使用了一项革新动画制作的技术——转描机。 （图片来源：视频 【DizAvenue】制作白雪公主的故事 The Making of Snow White） 迪士尼动画十二原则的运用 视频中有一个细节，迪士尼爷爷让动画师注意那位大叔在跳踢踏舞时重力对裤腿的作用（20 分 20 秒）。是的，迪士尼爷爷强调的就是动画与物理学的关系。 迪士尼工作室在早期，将他们在动画实践中所总结出的规律总结成为了经典的《动画12原则》，可以说这 12 原则就是让迪士尼动画在当时脱颖而出的黄金原则，即便是现如今看来，这 12 原则也并不过时，甚至可以扩展运用至网页交互动效中。 依其第 5 条「动作的惯性跟随和重叠」，我们可以将网页元素看作一个有重量、有结构、有柔韧性的物体进行动画设计，会得到意想不到的效果。事实上已经有人这么做了—— （dribbble’s stripe checkout，图片来源：The Art of Animation） （图片来源：Giving Animations Life） 在实现过程中，我们可以选择合适的时间轴函数来达成这些效果，或者使用 Bounce.js 这样的弹性动效库，给元素加上弹性动效后，通常能够事半功倍地增加动效的活力与吸引力，但同样的，过犹不及，一切动效的添加都要讲究适度。 对于时间轴函数之贝塞尔曲线的应用，笔者推荐两个工具：贝塞尔曲线在线调试工具 以及 贝塞尔缓动函数库，能够帮助大家快速选取合适的贝塞尔曲线函数。 其第 8 条「次要动作」，在案例《拍拍七夕活动页－七叻个夕》中就得到应用（目前案例已下线），如下图所示： 头花的颤抖的次要动作的加入，不仅衬托得人物的抖动的主要动作更加生动、真实，还令人物情绪的体现更加饱满、感觉更有生命力。 对于这十二条原则的进一步学习，笔者推荐《入门必读！迪士尼影响至今的十二条动画经典法则 》 一文，里面介绍了每条法则的具体内容，必定能让你有所受益。 对动画过渡时间的把握 Google 在 Material Design 指南中提及 动效过渡时间：对于用于交互操作场景的补间动画而言，短动画时间应该控制在 150～200ms，而长动画控制在 300～400ms。而对于用于呈现场景的补间动画则视具体而定，以真实世界为参考标准是最好的。 不断地修改与调整 这是一个需要细致与耐心的过程，你得在不断的调整中保持大局观，避免陷入细节的纠结，同时又需要有能够将别扭的细节调整好的灵感。说白了就是同时拥有汉子的粗犷与妹子的细腻。节奏是一个很重要的因素，与银幕上的动画类似，CSS3 动画创作者的意念必须即时并完全交给观众。 意念清晰易懂靠两个因素： (1) 好的表现手法和设计，要使每个主要动作能以最清楚和最有效的方式呈现在银幕上。(2) 好的时间掌握，要有足够的时间先使用户预感到将有什么事情发生，然后用于表现动作本身，最后要有好的收尾。 这三者中，任何一项所占时间太多，便会感觉节奏太慢，用户会感到不耐烦，动画的出现便如同鸡肋。 反之，如果时间太短，那么用户在注意到它之前，动作已经结束，创作者的意念未能充分表达，就浪费掉了。——《动画的时间掌握》 别忘了性能测试 这是有可能推翻前面两步甚至三步的一个步骤。不过即便发生了这样的事，也不要气馁，这并不意味着之前做的前功尽弃，反而是个宝贵的财富——对于性能的感受又多了一次体验，而其中的一些动画心得或许下次能用上。 别只专注于动画的实现 （动画来源：Pseudo-Elements Animations and Transitions） 这是个使用最简单的 CSS 属性 —— padding、line-height、box-shadow 实现了令人吃了一斤效果的栗子，就像一道脑筋急转弯一样，让大家对 CSS3 动画的理解不止于 CSS3 的新属性，我们曾经用烂的 CSS2.0 属性同样也能开出花儿。然而，这个例子所用的 CSS 属性对于性能的影响并不适用于生产环境。 更高效的 CSS 属性 我们知道，页面渲染的一般过程为 JS > CSS > 计算样式 > 布局 > 绘制 > 渲染层合并，如下图所示： 其中，Layout（重排）和 Paint（重绘） 是整个环节中最为耗时的两环，所以我们应尽量避免使用触发这两个环节的 CSS 属性。 例如，最基本的一个注意点是：使用切换类名的方式来触发动画，而不是使用 diaplay: none 属性值，因为它会引起相关元素的重排和重绘。 除此之外，下面几个属性的替换使用也是值得推荐的： translate 属性替换 top/left/right/bottom scale 属性换 width/height opacity 属性替换 display/visibility 笔者这里推荐 CSS Triggers，通过它你可以查阅到各 CSS 属性及其影响的环节，从而避免不小心使用到性能开销较大的属性。 除此之外，对动画渲染的优化还有其他方式，这里抛出 @登平登平 在 《H5 动画 60fps 之路》一文中的总结，同学们可以前往原文进行进一步的学习。 扩展阅读 《入门必读！迪士尼影响至今的十二条动画经典法则 》 —— 详细了解迪士尼十二条动画经典法则 《让界面动画更自然－ISUX》 —— 如何合理选用动画曲线函数 贝塞尔曲线在线调试工具 以及 贝塞尔缓动函数库 —— 帮助你快速选取合适的贝塞尔曲线函数 The Guide To CSS Animation: Principles and Examples —— 很老的一篇英文文章，以示例的方式介绍了迪士尼的十二条动画法则 小结 我们看到，CSS3 动画并不只是由 transform、opacity 等简单组成，它还可以包含许许多多的设计、想法、甚至感情。「台上一分钟，台下十年功」这句话在动效开发上也适用，或许在所有事物上都适用。 目前为止，用 CSS3 动画拍电影只是个概念，但想象一下你是这部电影的导演，所有元素都是可调度的场景与角色，用 CSS3 动画拍电影是不是也没有那么遥远了？ 最后，放上迪士尼爷爷的一段话，在我做动画甚至做任何事时它将不断地在脑海中回响。 曾经有人问迪士尼，「白雪公主」大受欢迎的秘密是什么？他回答说： “我们只能确定一件事，每一个人都有童年，每次拍一部新片，我们不是为大人而拍，也不只是为小孩子拍，我们是为了唤醒每个人内心深处那种早就被遗忘的纯真世界。” "},"大厂H5开发实战手册/11.总结.html":{"url":"大厂H5开发实战手册/11.总结.html","title":"11.总结","keywords":"","body":"总结 总算写到了这里，围绕「H5 开发」的四大能力，小册的所有内容便已算告“终”了，看完所有内容的你不知道现在对于下面的问题是否有了清晰的答案。 我拿出什么样的作品（或能力），才能真正满足「H5 开发」相关岗位的要求，使得我去面试的时候，至少技术面（专业能力）是完全过关的？ 这「终」字带了引号，因为我们会随时回来修订，包括但不限于： 大家提出的问题反馈、修改意见 结合时下最新的专业内容更新相关章节 围绕「H5 开发」添加新的内容 「H5 开发」是一个前端职业方向，其涵义会随着时代的更迭而更迭， 我们为大家撰写的这本小册也同样如此，「内容与时俱进」是我们对所有读者的一个小小的承诺，希望大家现在觉得它有用，至少指明了一个方向，两三年后再回头翻看它时也仍然觉得它有价值。从这个角度来看，这「终」其实是一个新的开始 —— 我们和大家一起交流进步的开始。 最后我想感谢小册内容的所有贡献者：Koppt、JC、EC、大婷、小婷、陈老湿、AV，你们的内容与经验孕育了小册本身。几个人一起写一本小册的难度肯定要比一个人写来的高，每个人的笔墨风格各异，排版喜好不一，幸好我们的目标是一致的，围绕着「H5 开发」这个主题，一起努力做了串联整合，降低多人协作对内容组织的整体影响，尽力保证小册的阅读体验。 同时感谢掘金提供的小册平台。 希望这本小册能成为你们海海编程人生中的小小体验。 书中的示例及源码 小册里面的例子比较分散，为了方便大家学习，已做了一个例子和源码的聚合页，请 猛击这里 ！ "},"如何使用Canvas制作出炫酷的网页背景特效/01.什么是Canvas.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/01.什么是Canvas.html","title":"01.什么是Canvas","keywords":"","body":"什么是 Canvas 前一段学习了一个学知识的方法论，个人觉得很有用，推荐给大家，就是在学习一个概念的时候，先问一下这个知识的概念是什么，然后再看一下这个知识它被提出来的目的是什么，然后如果你能将其用一句话说清楚，那么你就理解了该知识点。 所以对于什么是 Canvas，我们也按照这个方法来分析。 什么是 Canvas 在 MDN 中是这样定义 的： 是 HTML5 新增的元素，可用于通过使用 JavaScript 中的脚本来绘制图形。例如，它可以用于绘制图形、制作照片、创建动画，甚至可以进行实时视频处理或渲染。 这里需要划重点的是， 只是一个画布，本身并不具有绘图的能力，绘图必须使用 JavaScript 等脚本语言。 标签允许脚本语言动态渲染位图像。 标签创建出了一个可绘制区域，JavaScript 代码可以通过一套完整的绘图功能类似于其他通用二维的 API 访问该区域，从而生成动态的图形。 我们可以认为 标签只是一个矩形的画布。JavaScript 就是画笔，负责在画布上画画。 例如，我的个人博客中的背景就是使用 Canvas 制作的。 我们审查元素可以看到整个背景就是一个 Canvas 元素，宽度和高度都是 100%。 Canvas 解决了什么问题 我在 MSDN（《Microsoft Developer Network》是微软一个期刊产品，专门介绍各种编程技巧）上找到了 Canvas 出现的背景，来给大家简单介绍一下。 在互联网出现的早期，Web 只不过是静态文本和链接的集合。1993 年，有人提出了 img 标签，它可以用来嵌入图像。 由于互联网的发展越来越迅猛，Web 应用已经从 Web 文档发展到 Web 应用程序。但是图像一直是静态的，人们越来越希望在其网站和应用程序中使用动态媒体（如音频、视频和交互式动画等），于是 Flash 就出现了。 但是随着 Web 应用的发展，出现了 HTML5，在 HTML5 中，浏览器中的媒体元素大受青睐。包括出现新的 Audio 和 Video 标签，可以直接将音频和视频资源放在 Web 上，而不需要其他第三方。 其次就是为了解决只能在 Web 页面中显示静态图片的问题，出现了 Canvas 标签。它是一个绘图表面，包含一组丰富的 JavaScript API，这些 API 使你能够动态创建和操作图像及动画。img 对静态图形内容起到了哪些作用，Canvas 就可能对可编写脚本的动态内容起到哪些作用。 一句话总结 Canvas 是什么 什么是 Canvas？Canvas 是为了解决 Web 页面中只能显示静态图片这个问题而提出的，一个可以使用 JavaScript 等脚本语言向其中绘制图像的 HTML 标签。 浏览器支持情况 Canvas 已经受到了主流浏览器的支持，并且支持情况良好，具体支持情况如下： 元素 Chrome IE Firefox Safari Opera Canvas 4.0+ 9.0+ 2.0+ 3.1+ 9.0+ 怎么在网页上画一个圆 通过上述的介绍，大家应该大体上明白了 是可以在 Web 页面上绘制图形的 HTML 标签。那么为什么要使用这种技术而不是其他的呢？ 这里我们就要分析一下 canvas 和其他技术的区别了。 怎么在网页上画一个圆？这是笔者之前在面试的时候遇到的一个问题 (ಥ_ಥ) 我想到的方法有以下几种，当然，如果你有更（qí）好（jì）方（yín）式（qiǎo）也可以留言。 直接使用图片，如果需求只是显示一个圆形，那么可以直接使用图片。 使用 div + CSS3 的 border + border-radius 模拟一个圆。 使用 svg。可能对于很多前端来说，svg 和 png、jpg 等其他图片格式是一样的，但其实还是有一定的差别。下面我们会详细介绍 svg。 Canvas + JavaScript 动态画一个圆。 那么我们来分析一下以上几种方式的优劣性： 使用图片可以说是以上几种方式中排名倒数第一的了，因为直接使用图片首先会增加一次请求（制作成精灵图另说），其次是不易更改，如果想换一种颜色就需要更换图片，代价太大。 使用 div + CSS3 的方式适用于单个的圆，实现起来比较简单，代价也比较小，但增加了一个没有意义的 DOM 节点，不符合语义化编程规范。 使用 svg 和 Canvas 都可以使用脚本语言来动态写入一个圆。 那么，使用 svg 和 Canvas 又有什么区别呢？ svg 和 Canvas 的区别 什么是 svg 刚刚我们介绍了 Canvas，那么什么是 svg 呢？ svg（Scalable Vector Graphics，可缩放矢量图形）是基于 XML（可扩展标记语言，标准通用标记语言的子集），用于描述二维矢量图形的一种图形格式。它由 W3C（万维网联盟）制定，是一个开放标准。 简单的说就是，svg 可以用来定义 XML 格式的矢量图形。 因为其本质是 XML 文件，所以 svg 是使用 XML 文档描述来绘图的。和 HTML 一样，如果我们需要修改 svg 文件，可以直接使用记事本打开修改。 Canvas 和 svg 的区别 Canvas 和 svg都允许你在浏览器中创建图形，但是它们在根本上是不同的，那么 Canvas 和 svg 有什么根本区别呢？ 就如刚刚介绍的那样，svg 本质上是一种使用 XML 描述 2D 图形的语言。 svg 创建的每一个元素都是一个独立的 DOM 元素，既然是独立的 DOM 元素，那么我们就可以通过 css 和 JavaScript 来操控 dom。可以对每一个 DOM 元素进行监听。 并且因为每一个元素都是一个 DOM 元素，所以修改 svg 中的 DOM 元素，系统会自动进行 DOM 重绘。 Canvas 通过 JavaScript 来绘制 2D 图形，Canvas 只是一个 HTML 元素，其中的图形不会单独创建 DOM 元素。因此我们不能通过 JavaScript 操控 Canvas 内单独的图形，不能对其中的具体图形进行监控。 在 Canvas 中，一旦图形被绘制完成，它就不会继续得到浏览器的关注。如果其位置发生变化，那么整个场景也需要重新绘制，包括任何或许已被图形覆盖的对象。 实际上 Canvas 是基于像素的即时模式图形系统，绘制完对象后不保存对象到内存中，当再次需要这个对象时，需要重新绘制；svg 是基于形状的保留模式图形系统，绘制完对象后会将其保存在内存中，当需要修改这个对象信息时，直接修改就可以了。这种根本的区别导致了很多应用场景的不同。 Canvas svg 依赖分辨率（位图） 不依赖分辨率（矢量图） 单个 HTML 元素 每一个图形都是一个 DOM 元素 只能通过脚本语言绘制图形 可以通过 CSS 也可以通过脚本语言绘制 不支持事件处理程序 支持事件处理程序 弱的文本渲染能力 最适合带有大型渲染区域的应用程序（比如谷歌地图） 图面较小，对象数量较大（>10k）时性能最佳 对象数量较小 ()、图面更大时性能更佳 所以是选择 Canvas 还是 svg 还是需要看自己的需求。 本小册主要介绍 Canvas 的相关内容，对 svg 不做过多的介绍~ "},"如何使用Canvas制作出炫酷的网页背景特效/02.Canvas的应用场景.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/02.Canvas的应用场景.html","title":"02.Canvas的应用场景","keywords":"","body":"Canvas 的应用场景 经过第 1 节的介绍，你应该了解 Canvas 的介绍 Canvas 提出的背景 Canvas 和其他在 Web 中显示图像的技术的区别 你应该已经明白 Canvas 究竟是什么和 Canvas 的大致用途。(づ｡◕‿‿◕｡)づ 这一节将为你展示 30+ 个 Canvas 实例，让你感受下 Canvas 的强大作用。 绘制图表 绘制图表应该是 Canvas 最为实用的功能之一了吧(๑•̀ㅂ•́)و✧ 因为 Canvas 通过 JavaScript 可以动态传入参数绘制图形，所以我们可以使用 Canvas 作为容器，通过 JavaScript 动态传入的参数将数据以图表的形式显示出来。 不仅显示更为方便，而且修改数据也同样的简单。同时也可以有一些简单的动画和交互效果，对于可视化的数据展示更为友好。 这些都是传统的 png/jpg 静态显示图片所不能比拟的。 现在的一些数据可视化的 js 库（如 ECharts）大部分都是使用 Canvas 实现的。 小游戏 如今人们使用手机的频率越来越高，因此用浏览器打开网址就可以玩的游戏越来越受到开发者和用户的喜爱。 而 Canvas 因其独特的性质可以说是 Web 游戏的不二之选，基本上所有的 HTML5 游戏引擎都是基于 Canvas 开发的。那么为什么会使用 Canvas 来开发游戏呢？ 首先是因为 Canvas 不需要借助任何插件就可以在网页中绘图。并且其强大的绘图 API 可以操纵页面上的每一个元素。 下面我们来欣赏一下用 Canvas 制作的几款简单的小游戏~ 这是一款小型的赛车游戏，可以使用键盘的方向键来控制赛车的行驶方向，没有按键操作，速度就会变成 0。 这是一款五子棋的小游戏，模拟五子棋游戏规则，游戏开始时一方先走，然后另一方再走，依次循环，直至一方有连成一条线的五个棋子，会自动判断输赢。 就连经典的俄罗斯方块游戏也可以使用 Canvas 来制作。也是需要通过键盘的方向键来控制方块，左右方向键是控制方块移动的方向，下键是加速下落，上键是翻转方块，直至某一行完全被填满就被消除。 还有前一段挺火的你画我猜小游戏也可以通过 Canvas 来实现。保存了鼠标的轨迹，还有清除屏幕和橡皮擦等功能。也可以将其保存为一张图片。 手残党，这个 gif 录制了好几遍(ಥ_ಥ)。 这是一款迷宫类的小游戏，同样是通过键盘的方向键来控制小球的移动，最终到达某个地点就会判定通过游戏。 活动页面 相信很多的营销活动大家都做过，Canvas 也可以写活动页面哦~(๑•̀ㅂ•́)و，✧这是很多公司的营销策略~ 例如： 很常见的活动页面，某宝店铺的常见套路，模拟转盘抽奖。点击按钮，转盘转动，然后转盘停止，指针落在哪个区域就提示中奖的奖品。 另一个比较常见的活动页面是刮刮乐的页面，在刮刮乐的区域，鼠标会显示为硬币的形状，然后按住鼠标并拖动，经过区域就会显示出最底层的图片，同时上层图片消失。模拟刮刮乐效果，刮开一定比例面积之后“刮奖”完成，返回回调函数。 小特效 Canvas 还可以做一些小特效哦，这些小特效可以装饰你 的网站，使它变得更加精致~ 这个特效也可以在活动页面中用到。逼真的模拟了纸片下落的过程，随机出现的纸片有随机生成的颜色，然后模拟重力下落过程。 这个其实是很不错的，只不过 gif 图片看得不是特别清楚。随机生成的大小随机的圆形或方形粒子组成指定的文字，粒子会自动缩放，给人闪烁的感觉。 这个特效也是由粒子组合成文字的特效，只不过文字的内容是当前的时间，因为是 gif 图，所以大家看不到和鼠标的交互，这里粒子散开是因为我鼠标进行了点击，就是点击屏幕，粒子就会散开，点击的时间越长，粒子就越分散。当松开鼠标之后，所有的粒子就又全部回到原位~ 试想一下，如果你的个人网站中的当前时间使用了这样一个小特效，是不是会让访客觉得很有趣呢~٩(๑>◡ 同样的小特效还有这个 loading，使用 canvas 制作一个这样的 loading，也会给你的网站增添亮点。 炫酷背景 上述几种应用场景都只是带大家了解一下，不做过多的介绍，当然也还有其他的应用场景，这里也不过多的介绍，下面来介绍下本小册主要给大家分析的效果：炫酷背景特效。 因为 Canvas 的特性，所以如果你的网站想要一个炫酷的背景，那么 Canvas 无疑是最好的选择，让我们一起来欣赏一下 canvas 可以做出哪些炫酷的背景。 这个特效是使用 three.js 和 Canvas 制作出的 3D 线条，随机生成的线条构建成 3D 的立体空间，还有和鼠标的交互，鼠标的移动会使得 3D 空间移动。 这个气泡背景也是很赞的，随机生成透明度不同的气泡，气泡不断移动，渐变色的背景也在不断变换，给人以梦幻的感觉。 这个的变换频率其实没有这么快，两次变换中间是有几秒钟的停留时间的，因为制作的 gif 大小有要求，所以中间的给截掉了，只保留变换的部分。 这个特效给人的感觉是和钻石表面类似的菱角感觉，然后背景也是使用的渐变的颜色。一定时间就会变换一次。QQ 的登录框就是和这个类似的特效。 这个背景是黑客帝国的代码雨特效，可能男程序员会比较喜欢，代码从上向下下落的效果。 我个人是很喜欢这个特效的，前一段时间也将其作为我的个人博客的背景，该特效的背景是一个渐变色，随机生成的“小星星”会从下向上移动，最重要的是和鼠标有互动。鼠标经过的地方会产生“星星”并自动和其他的星星连成线。 这个特效也是很不错的，模拟星空，随机生成的 “星星” 会有位移，透明度也在不断变化，会有 “流星” 随机从上向下掉落，并会有小尾巴的效果~ 这个特效是以黑色为背景，彩色的随机实心 + 空心圆圈构成，所有的圈圈用直线相连，并且一直移动。 这个相交线特效其实也很简单，随机生成的线条在移动，相交的地方为小圆点。 带大家欣赏完这么多的特效之后，你是不是已经想使用 Canvas 来装饰你的个人网站了呢？心动不如行动，下面来带大家一起从零开始，一点一点分析怎么制作属于你自己的炫酷网页背景特效~ε==(づ′▽`)づ 划重点：第 3 节的最后给出了本小册中全部特效的源码~ (｡♥‿♥｡) ha "},"如何使用Canvas制作出炫酷的网页背景特效/03.手摸手带你入门Canvas.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/03.手摸手带你入门Canvas.html","title":"03.手摸手带你入门Canvas","keywords":"","body":"手摸手带你入门 Canvas 创建 Canvas 画布 当我只在页面上写一个 Canvas 标签时，将其背景颜色设置为黑色，会是什么效果呢？ Title #canvas { background: #000; } 我们打开浏览器来看一下： 在上面的例子中页面上只有一个 Canvas，没有设置宽高，那么会自动创建一个 300 * 150 的画布（单位默认为 px）。 那么我们怎么改变画布的大小呢，有三种方式 HTML 设置 width、height； CSS 设置 width、height； JS 动态设置 width、height。 我们来试一下这三种方式。有的人会问了，这不是很简单的么，还有介绍的必要吗？这就和我们听数学课是一样的，那些很简单的知识点你就不注意听，然后 10 分钟过后，一脸懵逼的不知道老师在讲什么，或者说是遇到问题了不知道错在哪，往往也都是基础的问题没有仔细听~ HTML 属性设置 width、height 我们先来看一下直接使用 HTML 属性来设置 width、height： Title #canvas { background: #000; } var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); context.beginPath(); context.arc(100, 100, 50, 0, Math.PI * 2, true); context.closePath(); context.fillStyle = 'rgb(255,255,255)'; context.fill(); 我们设置 Canvas 画布的宽度为 400，高度为 400，背景颜色为黑色（在 HTML 属性中直接设置宽度和高度是可以不加单位的，默认单位是 px）。在 Canvas 上画了一个圆心坐标为 100px、100px，半径为 50px 的白色的圆。来看一下浏览器中的显示效果： CSS 属性设置 width、height 还是上面那个例子，这次我们将宽度和高度使用 CSS 来设置： Title #canvas { background: #000; width: 400px; height: 400px; } var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); context.beginPath(); context.arc(100, 100, 50, 0, Math.PI * 2, true); context.closePath(); context.fillStyle = 'rgb(255,255,255)'; context.fill(); 我们来看下浏览器中的显示效果： OMG ヽ(；´Д｀)ﾉ，怎么会是这个样子，我明明是要画一个圆啊，怎么变成椭圆了，是不是我代码写的有问题？ 检查下代码，没问题呀o((⊙﹏⊙))o.那么为什么会显示成这个样子呢？ 原来是因为如果使用 CSS 来设置宽高的话，画布就会按照 300 * 150 的比例进行缩放，也就是将 300 * 150 的页面显示在 400 * 400 的容器中。 JS 属性设置 width、height 那我们再来看一下如果使用 JS 来设置宽高会是神马效果呢~ Title #canvas { background: #000; } var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.arc(100, 100, 50, 0, Math.PI * 2, true); context.closePath(); context.fillStyle = 'rgb(255,255,255)'; context.fill(); 在浏览器中的效果如下： 这样就是正常的嘛~ 所以我们尽量使用 HTML 的width 和 height 属性或者直接使用 JS 动态来设置宽高，不要使用 CSS 设置。 获取 Canvas 对象 在前面的例子中，我们已经创建了一个 Canvas 画布，那么第二步要做的就是获取到 Canvas 的上下文环境，对应的语法为： canvas.getContext(contextType, contextAttributes); 上下文类型（contextType）： 2d（本小册所有的示例都是 2d 的）：代表一个二维渲染上下文 webgl（或\"experimental-webgl\"）：代表一个三维渲染上下文 webgl2（或\"experimental-webgl2\"）：代表一个三维渲染上下文；这种情况下只能在浏览器中实现 WebGL 版本2 (OpenGL ES 3.0)。 第二个参数并不是经常用到，所以这里就不给大家介绍了，有兴趣的可以查阅 MDN 文档~ 通常在创建好一个 Canvas 标签的时候，我们要做的第一步就是要先获取到这个 Canvas 的上下文对象： var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); 绘制路径 使用过 PS 的应该都会知道在 PS 中有路径的概念，在 Canvas 中也有路径的概念。只不过和 PS 中的路径不同的是，PS 中的路径是矢量的，而 Canvas 中的路径不是。下面我们来看一下有哪些创建路径的方法： 方法 描述 fill() 填充路径 stroke() 描边 arc() 创建圆弧 rect() 创建矩形 fillRect() 绘制矩形路径区域 strokeRect() 绘制矩形路径描边 clearRect() 在给定的矩形内清除指定的像素 arcTo() 创建两切线之间的弧/曲线 beginPath() 起始一条路径，或重置当前路径 moveTo() 把路径移动到画布中的指定点，不创建线条 lineTo() 添加一个新点，然后在画布中创建从该点到最后指定点的线条 closePath() 创建从当前点回到起始点的路径 clip() 从原始画布剪切任意形状和尺寸的区域 quadraticCurveTo() 创建二次方贝塞尔曲线 bezierCurveTo() 创建三次方贝塞尔曲线 isPointInPath() 如果指定的点位于当前路径中，则返回 true，否则返回 false 看完了上述方法你是不是有点不知所措，一下子这么多方法(╬￣皿￣)=○ 你可以把上面的表格作为一个“字典”，在下面的代码中如果遇到不认识的方法可以查找一下，一回生，二回熟。 下面我将上面的方法分为以下几部分来给大家介绍下。 使用 Canvas 画一个点 我们先从最基本的开始，使用 Canvas 画一个点。其实画一个点也就相当于画一个半径为 1 的圆，那我们就可以改造这一节开始的例子，将半径由 50 变为 1。 Title #canvas { background: #000; } var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.arc(100, 100, 1, 0, Math.PI * 2, true); context.closePath(); context.fillStyle = 'rgb(255,255,255)'; context.fill(); 让我们来看一下效果： 有没有看到左上部分有一个白色的点，没有看到？没有看到的同学点开大图看一下(／_＼) 细心的小伙伴可能会发现我们改动了哪里： context.arc(100, 100, 1, 0, Math.PI * 2, true); 将第三个参数由 50 改为了 1，聪明的你一定可以猜出来 arc() 这个方法的作用了。\\（￣︶￣）/，稍后我们再介绍 arc() 函数。 先来看一下在获取完 Canvas 的上下文环境之后，我们又做了哪些操作： context.beginPath(); // 起始一条路径，或重置当前路径 context.arc(100, 100, 1, 0, Math.PI * 2, true); // 创建弧/曲线 context.closePath(); // 创建从当前点回到起始点的路径 context.fillStyle = 'rgb(255,255,255)'; // 设置或返回用于填充绘画的颜色、渐变或模式 context.fill(); // 填充当前绘图（路径） 我们可以总结出，使用 Canvas 绘制图像的步骤： 通过使用 Canvas 绘制一个点，我们了解了在 Canvas 中绘图的大致步骤，下面我们来看一下刚刚提到的 arc() 方法。 绘制弧/曲线 arc() 方法创建弧/曲线（用于创建圆或部分圆）。 context.arc(x,y,r,sAngle,eAngle,counterclockwise); x：圆心的 x 坐标 y：圆心的 y 坐标 r：圆的半径 sAngle：起始角，以弧度计（弧的圆形的三点钟位置是 0 度） eAngle：结束角，以弧度计 counterclockwise：可选。规定应该逆时针还是顺时针绘图。false 为顺时针，true 为逆时针 比如我们想画一个顺时针的四分之一圆，应该怎么写呢？ var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.arc(100, 100, 50, 0, Math.PI * 0.5, false); context.strokeStyle=\"white\"; context.stroke(); 我们先来看一下浏览器中的效果： 是不是你想要的效果呢(๑´ㅂ`๑) 其实只要找好起始角和结束角就成功一半了呢。 因为我们设置的起始角是 0，对照 w3cschool 上的截图可知弧度的 0 的位置是 3 点钟方向，然后结束角我们设置为 0.5 PI，也就是 6 点钟方向，然后我们再设置描边颜色并且进行描边，就得出上图的效果。 这里你可能会问，为什么这个不是闭合的图形呢？因为我只设置了 beginPath 并没有设置 closePath，所以这就不是一条闭合的路径。我们加上 cloasePath 看一下效果。 如果跟着我一起写代码的话你就会发现，这个是空心的，并没有整个路径都被填充，这是怎么回事呢？ 这是因为 stroke() 和 fill() 的区别，根据上面的两个例子，我们很容易看出这两个函数的区别：一个是描边，一个是填充。 stroke() ：描边 fill() ：填充 我们可以通过 strokeStyle属性 和 fillStyle属性来设置描边和填充的颜色。这里不仅可以设置单一的颜色，还可以设置渐变。 绘制直线 下面我们来绘制一条线。 var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.moveTo(50,50); context.lineTo(100,100); context.strokeStyle = '#fff'; context.stroke(); 我们来看一下浏览器中的效果： 在绘制直线的例子中，我们使用了 moveTo(x,y)：把路径移动到画布中的指定点，不创建线条 lineTo(x,y)：添加一个新点，然后在画布中创建从该点到最后指定点的线条 这里需要注意以下几点： 如果没有 moveTo，那么第一次 lineTo 的就视为 moveTo 每次 lineTo 后如果没有 moveTo，那么下次 lineTo 的开始点为前一次 lineTo 的结束点。 也就是这种情况： var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.lineTo(200, 200); context.lineTo(200, 100); context.lineTo(100,50); context.strokeStyle = '#fff'; context.stroke(); 我们没有设置 moveTo，而是设置了三个 lineTo，这也是可以的，将三个 lineTo 设置的点依次连接就好~ 效果如下： 在绘制了直线之后，我们来看一下怎么给绘制的直线添加样式： 样式 描述 lineCap 设置或返回线条的结束端点样式 lineJoin 设置或返回两条线相交时，所创建的拐角类型 lineWidth 设置或返回当前的线条宽度 miterLimit 设置或返回最大斜接长度 我们来看下这些 属性 是怎么使用的。 var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.moveTo(10,10); context.lineTo(100,100); context.lineWidth = 10; context.lineCap = 'round'; context.strokeStyle = '#fff'; context.stroke() 我绘制了一条由点 (10,10) 到点 (100,100) 的直线，然后将其宽度设置为 10，并且加上“圆角”的效果。 这里我们要注意区分哪些是方法哪些是属性，如果是方法，只需要在括号中传入参数就可以；如果是属性，那么我们就要使用等号给其赋值。有的时候你会奇怪，为什么我这么设置了但是却没有效果呢？很有可能是你将方法和属性搞混了哦 (●ﾟωﾟ●) 绘制矩形 在了解了最基本的绘制点、线的方法之后，我们来看一下如何绘制一个矩形。 var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.fillStyle = '#fff'; context.fillRect(10, 10, 100, 100); context.strokeStyle = '#fff'; context.strokeRect(130, 10, 100, 100); 这里我们使用下面的方法： fillRect(x,y,width,height)：绘制一个实心矩形 strokeRect(x,y,width,height)：绘制一个空心矩形 同样的，我们可以通过 fillStyle() 和 strokeStyle() 来设置填充的颜色和描边的颜色。 颜色、样式和阴影 上面几个函数教大家怎么绘制点、线、以及圆形和矩形，都是通过先创建路径，然后再使用 fill() 或 stroke() 进行填充或者描边。 下面我们再具体看一下都可以给路径设置哪些属性来改变其样式。 属性 描述 fillStyle 设置或返回用于填充绘画的颜色、渐变或模式 strokeStyle 设置或返回用于笔触的颜色、渐变或模式 shadowColor 设置或返回用于阴影的颜色 shadowBlur 设置或返回用于阴影的模糊级别 shadowOffsetX 设置或返回阴影距形状的水平距离 shadowOffsetY 设置或返回阴影距形状的垂直距离 fillStyle 和 strokeStyle 这两个属性我们一直在使用，所以对于它们我们不再作过多的介绍。 设置阴影 设置阴影我们用到的是 shadowBlur 这个属性。 var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.beginPath(); context.arc(100,100,50,0,2*Math.PI,false); context.fillStyle = '#fff'; context.shadowBlur = 20; context.shadowColor = '#fff'; context.fill() 同样的方（tao）法（lu），我们只要在 fill() 方法之前设置模糊指数（shadowBlur）和颜色（shadowColor）就可以了。让我们来看一下浏览器中的效果： 在暗色背景中有一个亮色的圆并且加了阴影效果，是不是很像发光的月亮呢(●´∀｀●)ﾉ 设置渐变 我们先来看一下怎么设置渐变： 方法 描述 createLinearGradient() 创建线性渐变（用在画布内容上） createPattern() 在指定的方向上重复指定的元素 createRadialGradient() 创建放射状/环形的渐变（用在画布内容上） addColorStop() 规定渐变对象中的颜色和停止位置 其中绘制渐变主要用到了 createLinearGradient() 方法，我们来看一下这个方法： context.createLinearGradient(x0,y0,x1,y1); x0：开始渐变的 x 坐标 y0：开始渐变的 y 坐标 x1：结束渐变的 x 坐标 y1：结束渐变的 y 坐标 这是设置比如说我们下一个粉色到白色的由上向下的渐变： var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; var grd = context.createLinearGradient(100,100,100,200); grd.addColorStop(0,'pink'); grd.addColorStop(1,'white'); context.fillStyle = grd; context.fillRect(100,100,200,200); 我们看一下浏览器中的效果： 可以看出，createLinearGradient() 的参数是两个点的坐标，这两个点的连线实际上就是渐变的方向。我们可以使用 addColorStop() 方法来设置渐变的颜色。 gradient.addColorStop(stop,color);: stop：介于 0.0 与 1.0 之间的值，表示渐变中开始与结束之间的位置 color：在结束位置显示的 CSS 颜色值 我们可以设置多个颜色断点，比如，要实现一个彩虹的效果，只需要多增加几个颜色断点就可以了~ var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; var grd = context.createLinearGradient(0,0,0,400); grd.addColorStop(0,'rgb(255, 0, 0)'); grd.addColorStop(0.2,'rgb(255, 165, 0)'); grd.addColorStop(0.3,'rgb(255, 255, 0)'); grd.addColorStop(0.5,'rgb(0, 255, 0)'); grd.addColorStop(0.7,'rgb(0, 127, 255)'); grd.addColorStop(0.9,'rgb(0, 0, 255)'); grd.addColorStop(1,'rgb(139, 0, 255)'); context.fillStyle = grd; context.fillRect(0,0,400,400); 效果如下： 图形转换 在了解完了最基本的绘制路径和设置样式之后，我们来看一下怎么来进行图形的变换。 我们先来看一下图形转换都有哪些方法： 方法 描述 scale() 缩放当前绘图至更大或更小 rotate() 旋转当前绘图 translate() 重新映射画布上的 (0,0) 位置 transform() 替换绘图的当前转换矩阵 setTransform() 将当前转换重置为单位矩阵，然后运行 transform() 缩放 我们来看一下怎么使用 Canvas 实现缩放的功能，绘制一个矩形；放大到 200%，再次绘制矩形；放大到 200%，然后再次绘制矩形；放大到 200%，再次绘制矩形： var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.strokeStyle = 'white'; context.strokeRect(5,5,50,25); context.scale(2,2); context.strokeRect(5,5,50,25); context.scale(2,2); context.strokeRect(5,5,50,25); 只是使用 scale() 方法就可以实现缩放的效果，我们再来看一下浏览器中的显示情况： 可以看到，在设置 scale() 方法之后再设置的矩形，无论是线条的宽度还是坐标的位置，都被放大了。并且 scale() 的效果是可以叠加的，也就是说，我们在上面的例子中使用了两次 scale(2,2) 那么，最后一个矩形相对于第一个矩形长和宽，以及坐标的位置就放大了 4 倍。 旋转 其实在图形变换中，只要掌握了一种，其他的图形变换方式就会迎刃而解了。我们再来看一下旋转的例子吧。 var canvas = document.getElementById(\"canvas\"); var context = canvas.getContext(\"2d\"); var cx = canvas.width = 400; var cy = canvas.height = 400; context.fillStyle = 'white'; context.rotate(20*Math.PI/180); context.fillRect(70,30,200,100); 我们使用的是 rotate() 方法 context.rotate(angle); angle : 旋转角度，以弧度计。 如需将角度转换为弧度，请使用 degrees*Math.PI/180 公式进行计算。 举例：如需旋转 5 度，可规定下面的公式：5*Math.PI/180。 在刚刚的例子中，我们将画布旋转了 20°，然后再画了一个矩形。 通过上述两个例子，我们会发现一个特点，在进行图形变换的时候，我们需要画布旋转，然后再绘制图形。 这样的结果是，我们使用的图形变换的方法都是作用在画布上的，既然对画布进行了变换，那么在接下来绘制的图形都会变换。这点是需要注意的。 比如我对画布使用了 rotate(20*Math.PI/180) 方法，就是将画布旋转了 20°，然后之后绘制的图形都会旋转 20°。 图像绘制 Canvas 还有一个经常用的方法是drawImage()。 方法 描述 drawImage() 向画布上绘制图像、画布或视频 context.drawImage(img,sx,sy,swidth,sheight,x,y,width,height); img：规定要使用的图像、画布或视频 sx：可选。开始剪切的 x 坐标位置 sy：可选。开始剪切的 y 坐标位置 swidth：可选。被剪切图像的宽度 sheight：可选。被剪切图像的高度 x：在画布上放置图像的 x 坐标位置 y：在画布上放置图像的 y 坐标位置 width：可选。要使用的图像的宽度（伸展或缩小图像） height：可选。要使用的图像的高度（伸展或缩小图像） 经过上面对 Canvas 常见方法的介绍，相信你也可以绘制一些基本的图形了，你看到的那些炫酷的效果都是由这些简单的图形构成的。在下一节我将会带大家分析怎么使用这些最基本的元素来组成炫酷的特效~~ 源码 本小册中各种特效的源码地址：sunshine940326/canvas "},"如何使用Canvas制作出炫酷的网页背景特效/04.炫酷背景特效的通性.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/04.炫酷背景特效的通性.html","title":"04.炫酷背景特效的通性","keywords":"","body":"炫酷背景特效的通性 第 1 节我们对 Canvas 进行了简单的介绍，第 2 节介绍了 Canvas 的应用场景，在第 3 节中，我们对 Canvas 绘制图形进行了简单的介绍。 在第 2 节中，我们欣赏了众多的 Canvas 应用场景，本小册的重点就是教怎么才能写出炫酷的网页背景特效。 前面全部都是在介绍和讲一些 Canvas 基础，本节，将带大家分析那些看上去特别炫酷的特效都有哪些通性。 通过第 2 节的实例，我们可以总结出适合做背景的炫酷特效都具有哪些特征，在接下来的章节中我们将结合具体的实例实现。 接下来，我们来分析下本小册的主题：“制作炫酷的网页背景特效”，我们可以从中提取出以下关键词： 背景 炫酷 效果 我们分别从这三个方面来分析，一个炫酷的网页背景都有哪些通性。 背景 我们要制作的是一个可以作为背景的特效，那么首要的条件就是这是一个背景，我们这里所说的背景是一个全屏的背景，充满你整个屏幕，我们来分析下 “全屏” 背景应该是怎样的。 在普通的页面制作中，我们观察设计稿，可以看出，背景往往是纯色的或者是渐变的，再或者就是有规律的可以平铺的图形。 为什么要将背景设置为纯色、渐变或可平铺的图形呢？ 首先是因为用户使用的显示屏的尺寸我们是不知道的，甚至不知道是移动设备还是 PC，综合起来，能够显示我们网站的设备就太多了。 为了适配所有的设备，尽可能让所有的设备都能够显示出相同的效果，不能相差太远，这种情况我们就只能将背景设置为单一的颜色，或者两种颜色（渐变），再或者一些可平铺的图案，让其在各个终端下都有相同的显示效果。 说到渐变，我个人是比较喜欢将背景设置为渐变的，关注我的朋友可能都知道，我文章的封面图一般都是一个渐变的背景 + 文字。简洁却不简单，因为每一个渐变图案都是我自己精挑细选的。 也有人问我我的渐变颜色的取值都是从哪里去的呢？是我有独特的审美吗，(/□＼*) 我也希望是我自己做出来的啦，但是，答案，当然不是的啦，都是在网站上 down 的。网址可以分享给大家：uigradients。 这个网站可以自己生成渐变色，你的配色也可以跟大家分享，可以保存为图片，也可以导出为 CSS 样式。 我们可以从这个网站上找到喜欢的配色，然后导出为 CSS 样式使用。 我们看上面的两个例子，背景都是使用了渐变元素。第一个例子是一个气泡的效果。背景使用的是随机生成的颜色，使用我们上节介绍的 Canvas 设置渐变的方式。 下面的星空背景的渐变实际上不是使用 Canvas 写的，只是使用 CSS 写出的效果。实现的方式是： 下面的树是一个 png 的背景 然后我们将 body 的颜色设置为黑色到蓝色的由上向下的渐变： background: linear-gradient(to bottom,#000000 0%,#5788fe 100%); 效果如下： 接下来我们要设置一个全屏的遮罩，将这个遮罩的背景色设置为红色，然后使用 CSS3 的 animation 属性，使用 animation 改变其透明度，由 0 变为 0.9。 .filter { width: 100%; height: 100%; position: absolute; top: 0; left: 0; background: #fe5757; animation: colorChange 30s ease-in-out infinite; animation-fill-mode: both; mix-blend-mode: overlay; } @keyframes colorChange { 0%, 100% { opacity: 0; } 50% { opacity: .9; } } 效果就和上面动态的效果一样。 炫酷 第二个关键词是“炫酷”，我们要做到炫酷的特点，就是要让别人看到你的博客背景之后，发出 “哎呦，不错哦” 的感叹！ 那么你的博客背景有怎样的特点才会让用户眼前一亮呢？我分析主要是因为以下两个原因： 动 随机 因为网页技术的发展，最先开始只能显示单一的文字，然后慢慢开始支持图片资源，直到 HTML5 才支持音频和视频等媒体资源，并且现在大部分我们看到的资源都是图片 —— 也就是静态资源。 所以，页面上有元素在“动”，都将会吸引我们的眼球。 怎么能让页面上的元素动起来呢？我们有以下几种方式： gif 图 CSS3 动画 js 控制 svg Canvas 以上几种方式都可以创建动画，但是怎样的动画更能引人入胜呢？ 这就需要符合另一个特点：“随机”。设置为“随机” 的动画有什么好处呢？ 人都有一种心理，一旦找到事物发展的规律，便对其失去了兴趣。 也就是说，如果你的动画是一个规律的，并且规律是简单可寻的，那么用户在看过一次之后，找到了其中的规律，第二次再看的时候便不会再对其感兴趣。 相反，我们就可以写出让用户每一次打开都不一样的特效，这样用户会感觉到“新奇”，便会对你的网站感兴趣。 使用 gif 图大家都知道，只能是有规律的“动”，并且 gif 图片的尺寸不宜过大，在我们的网页背景中，基本上是不会用到的。 CSS3 实现的动画效果，也是只能做有规律的“动”，并且 CSS 只能操纵单个的 DOM 元素，一旦元素到达一定的数量，代价是比较大的。 所以我们选择 js + Canvas 来实现“随机”的“动”。 具体的写法我们将会在后面的章节介绍。我们先来接着看第三个特点：效果。 效果 这里我们说的效果主要是与鼠标之间的交互效果。 与鼠标之间有互动的效果主要是产生用户行为的反馈，比如在网页制作中，我们经常使用 hover 变色表示用户的鼠标在元素上方悬停。这就是用户行为的一种反馈。 我们经常使用的与鼠标之间的交互效果主要有两种： 鼠标跟随 视觉差 记得当年 QQ 空间盛行的时候，就有很多这种鼠标跟随的效果，鼠标滑过的路径，能够生产一个长长的尾巴，甚是招人喜欢。同样的，如果我们能实现鼠标跟随的效果，也是极好的。 我们又拿出了这个特效 (ಥ_ಥ) 在这个例子中，我们可以看出，在鼠标经过的地方会出现 “星星” 连成线的效果。 用户很喜欢这种鼠标跟随的效果，个人觉得就是因为它使得网站的显示效果和用户的行为产生了联系，使用户的行为得到了反馈。 还有一种经常见到的效果是数据差的效果，比如： 这是锤子官网的一个特效，鼠标移动到哪哪就会下沉，并且如果你仔细看的话就会发现，上面的月份数字和底部的图片不是在一个层级上的，更加有立体的感觉，这就是视觉差的特效。 这种特效不需要用 Canvas，只需要 CSS 就可以实现，实现方式也不是本节重点，有需要的可以私聊。 我们来总结一下，炫酷的网页背景特效有哪些特点： 背景 单一颜色 渐变 平铺 炫酷 动 随机 特效（与用户交互） 鼠标跟随 视觉差 "},"如何使用Canvas制作出炫酷的网页背景特效/05.怎么实现随机粒子.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/05.怎么实现随机粒子.html","title":"05.怎么实现随机粒子","keywords":"","body":"怎么实现随机粒子 在第 4 节中，我们分析了炫酷背景特效的通性都有哪些，经过这些分析，你是不是已经手痒痒，想要自己实现一番但又不知从何下手呢？ 本节，我将带大家实现在炫酷网页背景特效中的一个最常见的效果：随机粒子。 随机粒子特效分析 如果只是一个纯色或者渐变的背景，肯定会显得有点单调，我们还需要在渐变的基础上加一点 “料”，而这些 “料”通常都是粒子特效。 那么“粒子特效” 都有什么特点呢？ 粒子 规则图形 随机 数量多 粒子特效这些年还是比较流行的，好多地方都可以看出使用了粒子特效。那么粒子特效是什么呢？ 百度百科中对粒子特效定义如下： 将无数的单个粒子组合使其呈现出固定形态，借由控制器，脚本来控制其整体或单个的运动，模拟出现真实的效果。 上面的例子是一种常见的粒子特效，使用若干粒子构成文字 “Hello World”，并且每一个粒子都在运动，和物理学的 “粒子” 概念类似。 粒子特效的首要特点是数量多，在物理学中，粒子是能够以自由状态存在的最小物质组成部分，所以粒子的第一个特点就是数量多。 粒子特效的第二个特点是运动，正是因为组成物体的粒子在不断运动，我们才能看到物体在不断运动。 粒子特效第三个特点是随机，排列有整齐排列之美，凌乱有凌乱之美，整齐排列的可以直接平铺背景实现，直接使用 img 图片就可以。 但是要想有随机效果使用 img 图片就不可以了，所以我们主要使用 Canvas 实现随机粒子效果。各项参数都是随机生成的。 这个例子已经引用好多遍了╥﹏╥...但是它真的是很有特点啊，炫酷特效的通性全部都占有 o(////▽////)q 在这个例子中，我们可以将背景上的小 “星星” 看成粒子。粒子的数量是可以自己设置的，位置是随机出现的，大小也是随机生成的，包括透明度也是随机的，这样基本上每一个粒子都是独一无二的。 然后给粒子设置阴影以营造发光的特效，粒子在不断地“动”，做上升运动。 为什么设置随机粒子特效会受欢迎呢？我们来分析一下。首先是我们生成的每一个粒子都是独一无二的，并且每一次刷新位置都是随机的。这种效果是使用其他方式绘制图形都实现不了的（使用 svg 也是可以的，但是本小册不对 svg 绘图做过多的介绍ﾍ(;´Д｀ﾍ)）。 实现随机粒子特效 现在我们来一起实现一个随机粒子特效。 效果如下： 创建全屏 Canvas 首先，我们需要一个全屏的 Canvas 画布。 Title html,body { margin:0; overflow:hidden; width:100%; height:100%; cursor:none; background:black; } var ctx = document.getElementById('canvas'), content = ctx.getContext('2d'), WIDTH, HEIGHT; WIDTH = document.documentElement.clientWidth; HEIGHT = document.documentElement.clientHeight; ctx.width = WIDTH; ctx.height = HEIGHT; 我们使用 WIDTH、HEIGHT 两个常量储存屏幕宽度和高度信息，我们习惯使用大写来表示改变量为常量，不可变，将屏幕宽度和高度信息储存在常量中是因为我们在稍后还会用到。 这时，你应该得到一个全屏的并且为黑色的 Canvas。 设置 Round_item 类 在创建了一个全屏的 Canvas 之后，我们来创建单个的 Round_item 类。 首先我们 Round_item 类需要有什么参数呢？我们要设置的是位置随机、透明度随机、半径随机的圆。为了区分不同的圆，我们还应该设置一个唯一的 index 参数。 所以我们需要的参数有： x 坐标 y 坐标 半径 透明度 index 根据上面这些可以得出我们的 Round_item 类： function Round_item(index,x,y) { this.index = index; this.x = x; this.y = y; this.r = Math.random() * 2 + 1; var alpha = (Math.floor(Math.random() * 10) + 1) / 10 / 2; this.color = \"rgba(255,255,255,\" + alpha + \")\"; } 这里我们使用了构造函数的方式来创建单个的圆，我们还需要一个变量 initRoundPopulation 来设置 round 的个数，然后我们便可以通过 for 循环创建出 initRoundPopulation 个圆。 设置 draw() 方法 在设置了单个的 Round_item 类之后，我们还要给每一个 round 设置 draw() 方法，所以我们需要将 draw() 方法设置在 Round_item 的原型中，这样我们创建出来的每一个 Round_item 实例对象都拥有了 draw() 方法。 draw() 方法的内容就是我们第 3 节讲到的画圆的方式，这里也就不再过多的说明了，忘记的快去第 3 节补习补习ヽ(；´Д｀)ﾉ Round_item.prototype.draw = function () { content.fillStyle = this.color; content.shadowBlur = this.r * 2; content.beginPath(); content.arc(this.x, this.y, this.r, 0, 2 * Math.PI, false); content.closePath(); content.fill(); }; 设置初始化 init() 函数 然后我们就需要设置初始化 init() 函数了，在 init() 函数中，我们的主要任务是创建单个的 round，然后使用其 draw() 方法。 function init() { for(var i = 0; i 至此，我们已经完成了随机粒子的实现，完整的代码如下： Title html,body { margin:0; overflow:hidden; width:100%; height:100%; cursor:none; background:black; } var ctx = document.getElementById('canvas'), content = ctx.getContext('2d'), round = [], WIDTH, HEIGHT, initRoundPopulation = 80; WIDTH = document.documentElement.clientWidth; HEIGHT = document.documentElement.clientHeight; ctx.width = WIDTH; ctx.height = HEIGHT; function Round_item(index,x,y) { this.index = index; this.x = x; this.y = y; this.r = Math.random() * 2 + 1; var alpha = (Math.floor(Math.random() * 10) + 1) / 10 / 2; this.color = \"rgba(255,255,255,\" + alpha + \")\"; } Round_item.prototype.draw = function () { content.fillStyle = this.color; content.shadowBlur = this.r * 2; content.beginPath(); content.arc(this.x, this.y, this.r, 0, 2 * Math.PI, false); content.closePath(); content.fill(); }; function init() { for(var i = 0; i 随意写的代码，欢迎大家 review~ "},"如何使用Canvas制作出炫酷的网页背景特效/06.使你的随机粒子动起来.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/06.使你的随机粒子动起来.html","title":"06.使你的随机粒子动起来","keywords":"","body":"使你的随机粒子动起来 在第 5 节，我们使用 js + Canvas 一起制作了随机粒子特效，那么怎么才能使你的随机粒子动起来呢？本节就跟我一起来试一试吧 (๑´ㅂ`๑) animate() 函数 本节的代码是在第 5 节代码的基础上完成的，在第 5 节我们已经实现了随机粒子的效果，本节的目标是能够让粒子动起来。 其实，Canvas 制作动画是一个不断擦除再重绘的过程，跟最原始实现动画的方式类似。在纸片上画每一帧，然后以很快的速度翻动小本本，就会有动画的效果。 现在我们实现动画需要在很短的时间内不断的清除内容再重新绘制，新的图形和原先清除的图形之间有某种位置关系，速度足够快的话，我们就会看到动画的效果。 所以我们需要一个 animate() 函数，这个函数的作用是帮助我们形成动画，我们在这个函数中首先需要清除当前屏幕，这里的清除函数用到的是 content.clearRect() 方法。 我们先来看一下 canvas 的 content.clearRect() 方法： context.clearRect(x,y,width,height); x：要清除的矩形左上角的 x 坐标 y：要清除的矩形左上角的 y 坐标 width：要清除的矩形的宽度，以像素计 height：要清除的矩形的高度，以像素计 在刚刚的分析中可以得出，我们需要清除的区域是整个屏幕，所以 content.clearRect() 的参数就是 content.clearRect(0, 0, WIDTH, HEIGHT);，这里我们就用到了之前获取的屏幕宽度和高度的常量：WIDTH 和 HEIGHT。这样我们就将屏幕上的所有内容都清除了。 清除了屏幕内容之后我们就要重新绘制图形，重新绘制的图形是需要和原图形之间有一定的关系，我们先制作一个简单的效果 —— 粒子匀速上升。粒子匀速上升，也就是 y 坐标在不断地变化，既然是匀速的，那么也就是在相同的时间位移是相同的。 我们将粒子位移的变化函数 move() 写在 Round_item 的原型上。稍后我们再实现。 重新绘制完图形之后，我们就完成了清除屏幕内容再重新绘制新的图形的任务。那么还需要有一个步骤 —— “ 不断”，要想实现动画的效果，就需要 “不断” 地进行清除再重绘，并且中间间隔的时间还不能过长。 这时你可能会想到使用 js 的 setTimeout() 方法，但是 setTimeout 和 setInterval 的问题是，它们都不精确。它们的内在运行机制决定了时间间隔参数实际上只是指定了把动画代码添加到浏览器 UI 线程队列中以等待执行的时间。如果队列前面已经加入了其他任务，那动画代码就要等前面的任务完成后再执行。 我们需要使用另外一个函数 —— requestAnimationFrame() 。 window.requestAnimationFrame() 方法告诉浏览器，你希望执行动画，并请求浏览器调用指定的函数在下一次重绘之前更新动画。该方法使用一个回调函数作为参数，这个回调函数会在浏览器重绘之前调用。 requestAnimationFrame() 函数可以说是专门用来写动画的。那么 requestAnimationFrame() 有什么优点呢？ 编写动画循环的关键是要知道延迟时间多长合适。一方面，循环间隔必须足够短，这样才能让不同的动画效果显得平滑流畅；另一方面，循环间隔还要足够长，这样才能确保浏览器有能力渲染产生的变化。 大多数电脑显示器的刷新频率是 60Hz，大概相当于每秒钟重绘 60 次。大多数浏览器都会对重绘操作加以限制，不超过显示器的重绘频率，因为即使超过那个频率用户体验也不会有提升。因此，最平滑动画的最佳循环间隔是 1000ms/60，约等于 16.6ms。 requestAnimationFrame 采用系统时间间隔，保持最佳绘制效率，不会因为间隔时间过短，造成过度绘制，增加开销；也不会因为间隔时间太长，使动画卡顿不流畅，让各种网页动画效果能够有一个统一的刷新机制，从而节省系统资源，提高系统性能，改善视觉效果。 所以我们就使用 requestAnimationFrame() 函数递归的调用 animate() 函数来实现动画的效果。 function animate() { content.clearRect(0, 0, WIDTH, HEIGHT); for (var i in round) { round[i].move(); } requestAnimationFrame(animate); } 创建 move() 函数 在上一节，我们说到了使用 move() 函数来改变 round 的 y 坐标。那么我们就来实现一下。 和第 5 节的 draw() 方法相同，我们也要将 move() 方法写在 Round_item 的原型上，这样我们创建的每一个 round 都具有了 move() 方法。 在 move() 方法中，我们只需要改变 round 的 y 坐标即可，并且设置边界条件，当 y 坐标的值小于 -10（也可以是其他负值），代表该 round 已经超出了屏幕，这个时候我们要将其移动到屏幕的最底端，这样才能保证我们创建的粒子数不变，一直是 initRoundPopulation 的值。 这样就是一个粒子在不断地上升，上升到了最顶端再移动到最底端的循环过程，看起来像是有源源不断的粒子，但其实总数是不变的。 在 y 坐标的变化之后，我们还需要使用新的 y 坐标再来重新绘制一下该 round。 经过上面的分析，move() 写起来是不是很简单呢？ Round_item.prototype.move = function () { this.y -= 0.15; if (this.y 在 init() 中加入 animate() 我们想要实现动画的效果，还需要在 init() 中加入 animate() 函数。 最后，我们来看一下动画完整的实现代码吧: Title html, body { margin: 0; overflow: hidden; width: 100%; height: 100%; cursor: none; background: black; } var ctx = document.getElementById('canvas'), content = ctx.getContext('2d'), round = [], WIDTH, HEIGHT, initRoundPopulation = 80; WIDTH = document.documentElement.clientWidth; HEIGHT = document.documentElement.clientHeight; ctx.width = WIDTH; ctx.height = HEIGHT; function Round_item(index, x, y) { this.index = index; this.x = x; this.y = y; this.r = Math.random() * 2 + 1; var alpha = (Math.floor(Math.random() * 10) + 1) / 10 / 2; this.color = \"rgba(255,255,255,\" + alpha + \")\"; } Round_item.prototype.draw = function () { content.fillStyle = this.color; content.shadowBlur = this.r * 2; content.beginPath(); content.arc(this.x, this.y, this.r, 0, 2 * Math.PI, false); content.closePath(); content.fill(); }; function animate() { content.clearRect(0, 0, WIDTH, HEIGHT); for (var i in round) { round[i].move(); } requestAnimationFrame(animate) } Round_item.prototype.move = function () { this.y -= 0.15; if (this.y 效果如下： 参考文章： 深入理解定时器系列第二篇——被誉为神器的requestAnimationFrame "},"如何使用Canvas制作出炫酷的网页背景特效/07.使你的鼠标和屏幕互动.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/07.使你的鼠标和屏幕互动.html","title":"07.使你的鼠标和屏幕互动","keywords":"","body":"使你的鼠标和屏幕互动 在第 5 节，我们实现了随机粒子；第 6 节，我们让随机粒子动了起来，并且简单介绍了 Canvas 制作动画的原理。 本节我们一起来看一下 Canvas 是怎么和我们的鼠标互动的。 我们先来看一下这个效果。 然后我们分析一下这个效果：鼠标移动，会在经过的地方创建一个圆，圆的半径由小变大，达到某个固定大小时该圆消失。圆的颜色也是在随机变化的（gif 图片时间较短，效果不明显）。 创建 Canvas 元素 首先我们还是要创建并获取 Canvas 元素，相信大家对此步骤应该很熟悉了吧。 这里也顺带将需要的参数直接写好了，我们将一些可以控制的变量直接写在参数中，这样在后面就可以获取参数直接使用。设置参数主要是为了更改方便。 Title * { padding: 0; margin: 0; } #canvas { background: #000; } var canvas = document.getElementById('canvas'), ctx = canvas.getContext('2d'), WIDTH = canvas.width = document.documentElement.clientWidth, HEIGHT = canvas.height = document.documentElement.clientHeight, para = { num: 100, color: false, // 颜色 如果是false 则是随机渐变颜色 r: 0.9, // 圆每次增加的半径 o: 0.09, // 判断圆消失的条件，数值越大，消失的越快 a: 1 }, color, color2, round_arr = []; // 存放圆的数组 我们就创建一个黑色的全屏 Canvas 元素。 onmousemove 事件 在创建完了 Canvas 元素之后，我们要写鼠标移动的事件了，我们要考虑一下鼠标事件怎么写。 观察一下刚刚的 gif 图片，可以看出，在鼠标移动的过程中，不断地在鼠标滑过的位置产生一个逐渐变大的圆。 那么怎么让效果动起来呢？这就用到第 6 节讲到的知识了，我们在 Canvas 中创建动画的方式就是不断地清除屏幕内容然后重绘。 我们可以看出来，移动的轨迹是由一个一个的圆构成的，如果移动的速度过快的话，那么就可以明显看出一个一个的圆。 既然轨迹是由很多圆构成，那么我们就应该使用数组储存圆的信息（坐标、半径），然后在鼠标移动的时候将鼠标的位置信息储存在数组中。 所以在鼠标移动的过程我们首先要获得鼠标的坐标，然后将鼠标的坐标以及其他信息 push 到数组中去： window.onmousemove = function (event) { mouseX = event.clientX; mouseY = event.clientY; round_arr.push({ mouseX: mouseX, mouseY: mouseY, r: para.r, // 设置半径每次增大的数值 o: 1, // 判断圆消失的条件，数值越大，消失得越快 }) }; 设置 color 我们已经将圆的相关信息储存在 round_arr 数组中了，现在要在 animate() 函数中将圆显示出来。animate() 函数我们稍后再介绍。 创建圆需要的坐标信息以及半径，我们在鼠标移动的事件中都已经将其 push 到 round_arr 数组中了，还有一个条件是需要设置的，那就是颜色。 怎么对颜色进行处理呢？在 para 参数中，我们可以看出，其中有设置 color 值。如果 color 值不为 false，那么设置的圆的颜色就是设置的 color 值；如果设置的 color 值为 false，那么圆的颜色就是随机的。 if (para.color) { color2 = para.color; } else { color = Math.random() * 360; } 那么怎么设置颜色的渐变呢？我们将 color 的颜色值依次增加一个增量。 if (!para.color) { color += .1; color2 = 'hsl(' + color + ',100%,80%)'; } 要让颜色一直改变，我们要将上面颜色改变的代码放在一个一直执行的函数。我们将上面改变颜色的代码放在下面我们要介绍的 animate() 函数中。 animate() 函数 我们需要一个一直在执行的函数，这个函数主要负责动画的 animate() 函数。从函数名就可以看出这个函数的作用，的确，我们需要在该函数中写动画。 第 6 节写动画的主要思想是 —— 清除屏幕再重新绘制，这里的 animate() 函数也是这样的。 我们先来清除屏幕。 ctx.clearRect(0, 0, WIDTH, HEIGHT); 接着使用 round_arr 数组中的数据将一个一个的圆绘制出来。 for (var i = 0; i 然后我们还需要一直执行这个函数： window.requestAnimationFrame(animate); 我们来看下完整的 animate() 函数： function animate() { if (!para.color) { color += .1; color2 = 'hsl(' + color + ',100%,80%)'; } ctx.clearRect(0, 0, WIDTH, HEIGHT); for (var i = 0; i 小结 以上，我们就写完了一个完整的鼠标跟随效果的例子，让我们来看一下主要的有哪些步骤： 创建 Canvas 元素，设置参数 鼠标移动事件，将坐标信息 push 到数组 设置颜色 设置动画 animate() 函数 我们来看一下这个例子的完整代码： Title * { padding: 0; margin: 0; } #canvas { background: #000; } var canvas = document.getElementById('canvas'), ctx = canvas.getContext('2d'), WIDTH = canvas.width = document.documentElement.clientWidth, HEIGHT = canvas.height = document.documentElement.clientHeight, para = { num: 100, color: false, // 颜色 如果是false 则是随机渐变颜色 r: 0.9, o: 0.09, // 判断圆消失的条件，数值越大，消失的越快 a: 1, }, color, color2, round_arr = []; window.onmousemove = function (event) { mouseX = event.clientX; mouseY = event.clientY; round_arr.push({ mouseX: mouseX, mouseY: mouseY, r: para.r, o: 1 }) }; // 判断参数中是否设置了 color，如果设置了 color，就使用该值、 // 如果参数中的 color 为 false，那么就使用随机的颜色 if (para.color) { color2 = para.color; } else { color = Math.random() * 360; } function animate() { if (!para.color) { color += .1; color2 = 'hsl(' + color + ',100%,80%)'; } ctx.clearRect(0, 0, WIDTH, HEIGHT); for (var i = 0; i "},"如何使用Canvas制作出炫酷的网页背景特效/08.制作属于你自己的特效.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/08.制作属于你自己的特效.html","title":"08.制作属于你自己的特效","keywords":"","body":"制作属于你自己的特效 至此，本小册已接近尾声，你找到制作炫酷网页背景特效的 “套路” 了吗？ 本节，我们将总结一下，怎么才能制作出属于自己的 Canvas 炫酷背景特效。 用户喜欢哪些效果 作为一个网站的用户，在浏览网页的时候，你会喜欢怎样的网页背景呢？ 背景颜色不宜过多 粒子数量多 粒子在动 能和鼠标进行交互 背景颜色 因为网站还是以阅读为主，所以网站的背景颜色要适合阅读，最好还是设置为传统的 “白纸黑字”，使用浅色颜色作为背景，同时饱和度不宜过高，最好设置透明度。 并且背景颜色最好是 1~2 种颜色，不要设置过多的颜色，不然会影响阅读。 背景颜色可以直接使用 CSS 样式设置，不需要使用 Canvas。 粒子特效 为什么大家都喜欢粒子特效呢？首先是因为粒子的颗粒度可以设置得比较小，不会影响阅读，如果你将一张很大的图片设置为背景，那么网页上还有其他的部分，背景肯定是会被遮挡的，这样用户就看不到图片的全部内容。 所以设置为粒子特效，用户可以看到粒子的形状颜色，这样即使其他的粒子被遮挡，用户也会知道被遮挡的部分是什么内容。 其次是因为粒子的随机性，可以设置随机的透明度、随机的坐标、随机的颜色以及随机的大小，可以使得设置的每一个粒子都不同，并且每一次刷新页面，就会又重新生成新的不同的例子。用户永远不知道在哪一个位置有一个怎样的粒子。 粒子在动 大多数用户比较喜欢动效，但是对于网页的背景来说，动作的幅度又不能太大，动作也不要过于复杂，只是一些简单的位移并且动作的幅度也要小一点，让用户的潜意识里面知道这些粒子在动就可以，不能使用户的全部注意力都在粒子上面而忽视了网页的内容。 和鼠标进行交互 用户一般还喜欢自己的操作能够得到网页的响应，所以我们可以设置鼠标跟随的效果或者视觉差的效果，加上和鼠标交互的特效，会使用户感到你的网站与众不同。 小结 上述的几个特点都是用户比较喜欢的，但是你要根据你的情况来选择使用哪一种或者哪几种特效。 也不建议将所有的特效都来一遍，这样会使得你的网站过于花哨，而使用户忽视了网站的内容。 其实，制作炫酷的网页背景特效最难的不是你需要写多么难的 Canvas 代码，而是你的想象，你的想法。 Canvas 的 API 也就那么几个，好的创意可以让你仅仅使用有限的 API 排列组合出无限种可能。 好的创意个人认为是可遇不可求的，需要你的空间想象能力和审美能力。那你会问了， 实在没有好的创意那该怎么办呢？ 如果你自己没有想到好的创意的话，那就跟着我的套路走吧，最起码可以拿 60 分。 "},"如何使用Canvas制作出炫酷的网页背景特效/09.使你的Canvas更加优雅.html":{"url":"如何使用Canvas制作出炫酷的网页背景特效/09.使你的Canvas更加优雅.html","title":"09.使你的Canvas更加优雅","keywords":"","body":"使你的 Canvas 更加优雅 本节作为本小册的最后一节，将带大家一起对你的 Canvas 进行优化，使你的 Canvas 更加优雅。我们来看一下都有哪些方法可以优化我们的 Canvas。 常见的 Canvas 优化方法 避免浮点数的坐标点 绘制图形时，长度与坐标应选取整数而不是浮点数，原因在于 Canvas 支持半个像素绘制。 会根据小数位实现插值算法实现绘制图像的反锯齿效果，如果没有必要请不要选择浮点数值。 使用多层画布去画一个复杂的场景 一般在游戏中这个优化方式会经常使用，但是在我们的背景特效中不经常使用，这个优化方式是将经常移动的元素和不经常移动的元素分层，避免不必要的重绘。 比如在游戏中，背景不经常变换和人物这些经常变换的元素分成不同的层，这样需要重绘的资源就会少很多。 用 CSS transform 特性缩放画布 如果你使用 left、top 这些 CSS 属性来写动画的话，那么会触发整个像素渲染流程 —— paint、layout 和 composition。 但是使用 transform 中的 translateX/Y 来切换动画，你将会发现，这并不会触发 paint 和 layout，仅仅会触发 composition 的阶段。 这是因为 transform 调用的是 GPU 而不是 CPU。 离屏渲染 名字听起来很复杂，什么离屏渲染，其实就是设置缓存，绘制图像的时候在屏幕之外的地方绘制好，然后再直接拿过来用，这不就是缓存的概念吗?!︿(￣︶￣)︿. 建立两个 Canvas 标签，大小一致，一个正常显示，一个隐藏（缓存用的，不插入 DOM 中）。先将结果 draw 到缓存用的 canvas 上下文中，因为游离 Canvas 不会造成 UI 的渲染，所以它不会展现出来；再把缓存的内容整个裁剪再 draw 到正常显示用的 Canvas 上，这样能优化不少。 离屏渲染 我们主要来介绍一下 Canvas 的离屏渲染优化，就拿第 5 节和第 6 节的那个示例来继续。 忘记的童鞋再去重温下第 5 节和第 6 节的内容。 离屏渲染的主要过程就是将一个一个的粒子先在屏幕之外创建出来，然后再使用 drawImage() 方法将其“放入”到我们的主屏幕中。 在了解了思想之后，我们就来实现一下吧！ｂ（￣▽￣）ｄ 我们首先要在全局设置一个变量 useCache 来存放我们是否使用离屏渲染这种优化方式。 var useCache = true; Round_item 方法 然后我们在 Round_item 原型的 draw() 方法中创建每一个离屏的小的 canvas。 function Round_item(index, x, y) { this.index = index; this.x = x; this.y = y; this.useCache = useChache; this.cacheCanvas = document.createElement(\"canvas\"); this.cacheCtx = this.cacheCanvas.getContext(\"2d\"); this.r = Math.random() * 2 + 1; this.cacheCtx.width = 6 * this.r; this.cacheCtx.height = 6 * this.r; var alpha = (Math.floor(Math.random() * 10) + 1) / 10 / 2; this.color = \"rgba(255,255,255,\" + alpha + \")\"; if(useChache){ this.cache(); } } 有人会产生疑问，为什么这里的 cacheCanvas 画布的宽度要设置为 6 倍的半径？那是因为，我们创建的 cacheCanvas 不仅仅是有圆，还包括圆的阴影，所以我们要将 cacheCanvas 的面积设置得稍微大一些，这样才能将圆带阴影一起剪切到我们的主 Canvas 中。 在 draw() 方法中，我们新创建了 cacheCanvas，并获取到了 cacheCanvas 的上下文环境，然后设置其宽高。 然后我们判断了 useChache 变量的值，也就是说，如果我们将 useChache 设置为 true，也就是使用缓存，我们就调用 this.cache() 方法。接下来，我们来看一下 this.cache() 方法。 this.cache() 方法 同样的，我们也是在 Round_item 的原型中设置 this.cache() 方法。 在 this.cache() 方法中，我们的主要任务是在每一个 cacheCanvas 中都绘制一个圆。 Round_item.prototype.cache = function () { this.cacheCtx.save(); this.cacheCtx.fillStyle = this.color; this.cacheCtx.shadowColor = \"white\"; this.cacheCtx.shadowBlur = this.r * 2; this.cacheCtx.beginPath(); this.cacheCtx.arc(this.r * 3, this.r * 3, this.r, 0, 2 * Math.PI); this.cacheCtx.closePath(); this.cacheCtx.fill(); this.cacheCtx.restore(); }; 这里需要注意的是，和在 draw() 方法中画的圆不同之处是，要注意这里设置的圆心坐标，是 this.r * 3，因为我们创建的 cacheCanvas 的宽度和高度都是 6 * this.r，我们的圆是要显示在 cacheCanvas 的正中心，所以设置圆心的坐标应该是 this.r * 3,this.r * 3。 draw() 方法 既然设置了 cacheCanvas，那么我们在 draw() 中，就需要使用 Canvas 的 drawImage 方法将 cacheCanvas 中的内容显示在屏幕上。 Round_item.prototype.draw = function () { if( !useChache){ content.fillStyle = this.color; content.shadowBlur = this.r * 2; content.beginPath(); content.arc(this.x, this.y, this.r, 0, 2 * Math.PI, false); content.closePath(); content.fill(); }else{ content.drawImage(this.cacheCanvas, this.x - this.r, this.y - this.r); } }; 这里也是要判断下，如果没有使用缓存的话，还是使用最原始的创建圆的方式。 这样，我们就完成了离屏渲染的优化，我们来一起看一下完整的代码： Title html, body { margin: 0; overflow: hidden; width: 100%; height: 100%; cursor: none; background: black; } var ctx = document.getElementById('canvas'), content = ctx.getContext('2d'), round = [], WIDTH, HEIGHT, initRoundPopulation = 80, useChache = true; WIDTH = document.documentElement.clientWidth; HEIGHT = document.documentElement.clientHeight; ctx.width = WIDTH; ctx.height = HEIGHT; function Round_item(index, x, y) { this.index = index; this.x = x; this.y = y; this.useCache = useChache; this.cacheCanvas = document.createElement(\"canvas\"); this.cacheCtx = this.cacheCanvas.getContext(\"2d\"); this.cacheCtx.width = 6 * this.r; this.cacheCtx.height = 6 * this.r; this.r = Math.random() * 2 + 1; var alpha = (Math.floor(Math.random() * 10) + 1) / 10 / 2; this.color = \"rgba(255,255,255,\" + alpha + \")\"; if(useChache){ this.cache(); } } Round_item.prototype.draw = function () { if( !useChache){ content.fillStyle = this.color; content.shadowBlur = this.r * 2; content.beginPath(); content.arc(this.x, this.y, this.r, 0, 2 * Math.PI, false); content.closePath(); content.fill(); }else{ content.drawImage(this.cacheCanvas, this.x - this.r, this.y - this.r); } }; Round_item.prototype.cache = function () { this.cacheCtx.save(); this.cacheCtx.fillStyle = this.color; this.cacheCtx.shadowColor = \"white\"; this.cacheCtx.shadowBlur = this.r * 2; this.cacheCtx.beginPath(); this.cacheCtx.arc(this.r * 3, this.r * 3, this.r, 0, 2 * Math.PI); this.cacheCtx.closePath(); this.cacheCtx.fill(); this.cacheCtx.restore(); }; function animate() { content.clearRect(0, 0, WIDTH, HEIGHT); for (var i in round) { round[i].move(); } requestAnimationFrame(animate) } Round_item.prototype.move = function () { this.y -= 0.15; if (this.y "},"开发者必备的Docker实践指南/01.基础概念：浅谈虚拟化和容器技术.html":{"url":"开发者必备的Docker实践指南/01.基础概念：浅谈虚拟化和容器技术.html","title":"01.基础概念：浅谈虚拟化和容器技术","keywords":"","body":"浅谈虚拟化和容器技术 相信所有对 Docker 有所耳闻的朋友都知道，它是一款以容器虚拟化技术为基础的软件，因此在了解有关 Docker 的概念知识和使用方法之前，虚拟化和容器技术是我们不可或缺的基础知识。在本小册的第一个小节里，我们就先来尝一尝这道有关虚拟化和容器技术的开胃菜吧。 虚拟化技术 如果要用简单的语句来阐述虚拟化技术的话，那么可以这么解释： 虚拟化技术是一种将计算机物理资源进行抽象、转换为虚拟的计算机资源提供给程序使用的技术。 这里所指的计算机资源，就包括了 CPU 提供的运算控制资源，硬盘提供的数据存储资源，网卡提供的网络传输资源等。 为程序跨平台兼容而生 虚拟化这个概念并不是什么新事物了，早在 20 世纪 60 年代，IBM 就用它来描述一套能够抽象硬件资源的实验性系统。 在计算机技术发展的早期，各类计算平台、计算资源所提供的接口、调用方式十分杂乱，没有像今天这样相对统一的标准。由于要适配不同的平台，写各种兼容代码，这无形给开发者带来了很多的困扰。这种混乱甚至都出现在 IBM 这一家公司下不同机型的机器上，所以 IBM 的工程师们创造了虚拟化技术，用来帮助程序快速适配不同平台的物理机器。 熟悉计算机原理的朋友应该知道，程序对计算机资源的调用主要依赖于操作系统所给出的接口。我们的程序通过操作系统提供的接口，向物理硬件发送指令。 所以，要实现程序跨平台兼容的方法其实很简单，只要操作系统或者物理硬件所提供的接口调用方式一致，程序便不需要兼容不同硬件平台的接口，而只需要针对这一套统一的接口开发即可。虚拟化技术正是通过其本身适配不同平台的硬件，而加以抽象成统一的接口，来实现程序跨平台运行这一目的的。 时至今日，我们之所以关注和使用虚拟化技术，实现跨平台运行应用程序依然是很大一部分的原因。 将虚拟化应用于资源管理 在虚拟化技术的发展过程中，人们逐渐发现了虚拟化的另一大用途，也就是将之应用于计算机资源的管理。 这其中的道理其实并不复杂，虚拟化技术本身就是抽象计算机的物理资源进而加工成虚拟的计算资源的，它自然很容易从中做“手脚”，来告诉应用程序一些虚假的资源数据。例如，我们只要告诉程序计算机只有 4GB 内存，那么不管真实的物理机是 8GB、16GB 还是 32GB，应用程序都会按照 4GB 这个虚假的值来处理它的逻辑。 通过虚拟化技术来管理计算机资源的方式，不但让我们对计算机资源的控制变得更加灵活，也大幅提高了计算机资源的使用率。 部分同学一直有一个误解：实现虚拟化的程序本身就要占用计算机的资源，而运转在其中的程序也不会降低它们对资源的消耗，怎么又会产生 1 + 1 这里要注意了，我们所说的是提高计算机资源使用率，而非减少程序资源的占用率，这两者看似很相近，其实并非是同一个概念。虚拟化技术能够提高计算机资源的使用率，是指利用虚拟化，我们可以将原来程序用不到的一些资源拿出来，分享给另外一些程序，让计算机资源不被浪费。 例如，这里我们有一台运行 Nginx 的机器，由于 Nginx 运行对系统资源的消耗并不高，这就让系统几乎 95% 以上的资源处于闲置状态。这时候我们通过虚拟化技术，把其他的一些程序放到这台机器上来运行，它们就能够充分利用闲置的资源。这带来的好处就是我们不需要再为这些程序单独部署机器，从而节约不少的成本。 部分读者读到这里就会产生疑惑了，我本身就可以在操作系统里安装这些程序并且同时运行，为什么还要把它们分别装到不同的虚拟环境中去呢？ 其实道理很简单，虽然我们能够在操作系统里同时运行多个程序，但前提得是这些程序本身不存在冲突。这里的冲突体现在很多的方面，例如不同的程序同时使用了同一个端口；不同程序依赖于同一个工具库的不同版本；程序本身限制了同时开启的进程数等。虚拟化技术通过资源隔离的方式，无形地也可以把这些程序隔离在不同的虚拟环境中，既然虚拟环境不同，自然运行在不同环境中的程序就不会互相干扰或争抢资源了。 虚拟化的分类 说完虚拟化的起源和应用，我们得说说虚拟化的分类了。所谓虚拟化的分类，其实主要指的是我们在实现虚拟化的方式上的区别。 对于虚拟化技术的分类，有很多种不同的方式，有的之间也有互相重合的部分，但总体来说可以区分为两大类：硬件虚拟化、软件虚拟化。 所谓硬件虚拟化，指的是物理硬件本身就提供虚拟化的支持。举个例子来说，某个平台的 CPU，能够将另外一个平台的指令集转换为自身的指令集执行，并给程序完全运行在那个平台上的感觉。又或者说，CPU 能够自身模拟裂变，让程序或者操作系统认为存在多个 CPU，进而能够同时运行多个程序或者操作系统。这些都是硬件虚拟化的体现。 而软件虚拟化则指的是通过软件的方式来实现虚拟化中关键的指令转换部分。依然用 CPU 的例子来说话，在软件虚拟化实现中，通过一层夹杂在应用程序和硬件平台上的虚拟化实现软件来进行指令的转换。也就是说，虽然应用程序向操作系统或者物理硬件发出的指令不是当前硬件平台所支持的指令，这个实现虚拟化的软件也会将之转换为当前硬件平台所能识别的。 当然，在实际场景中，虚拟化还能进行更加细化的分类，例如： 平台虚拟化：在操作系统和硬件平台间搭建虚拟化设施，使得整个操作系统都运行在虚拟后的环境中。 应用程序虚拟化：在操作系统和应用程序间实现虚拟化，只让应用程序运行在虚拟化环境中。 内存虚拟化：将不相邻的内存区，甚至硬盘空间虚拟成统一连续的内存地址，即我们常说的虚拟内存。 桌面虚拟化：让本地桌面程序利用远程计算机资源运行，达到控制远程计算机的目的。 …… 由于虚拟化的分类实在太多，且不是这本小册关注的重点，这里就不全部罗列了。总之，从实现上来说，皆是硬件虚拟化和软件虚拟化两个方案的相互组合、组装而得。 虚拟机 在这些虚拟化分类或者说是虚拟化实现中，我们要着重讲一下虚拟机 ( Virtual Machine )。所谓虚拟机，通常来说就是通过一个虚拟机监视器 ( Virtual Machine Monitor ) 的设施来隔离操作系统与硬件或者应用程序和操作系统，以此达到虚拟化的目的。这个夹在其中的虚拟机监视器，常常被称为 Hypervisor。 之所以我们在这里单独谈谈虚拟机，是因为它对于我们开发者来说是个再熟悉不过的概念了。从我们习惯用来搭建虚拟操作系统环境的 VMware Workstation、Xen 等软件，到 Java 虚拟机 JVM，PHP 虚拟机 HHVM 等等，都充活跃在我们程序开发到程序运行的过程中。 这时候有的读者可能会眼前一亮，发现原来 JVM、HHVM 等特定语言运行环境中的核心部分，也是虚拟化的一种实实在在的实现。没错，只要大家仔细分析和思考一下就会发现，它们正是基于虚拟化的思想来实现的。它们通过隔离程序和操作系统，将程序的指令转换为当前所在操作系统平台所能执行的指令，达到了不用对程序进行任何修改即可执行的目的。也正是这个原因，这些语言的程序都具有非常强的跨平台性。 虽然虚拟机技术得益于 Hypervisor 的加持，使得应用程序或者操作系统可以在无任何修改的情况下运行在另一平台上，但大家很容易发现，其有一个致命的缺陷，就是所有的指令都必须经过虚拟机监视器的处理。这也就意味着，虚拟机的性能是低下的，例如运行在 ZendVM 或者 HHVM 中的 PHP 程序，所有代码虽然编译成了 Opcode 码，但其依然是通过虚拟机才最终转换为机器所能识别的机器码去执行。 这种效率的低下有时候是无法容忍的，为了解决这个问题，真实的虚拟机程序常常不完全遵循 Hypervisor 的设计结构，而是引入一些其他技术来解决效率问题。 例如，在 VMware Workstation、Xen 中我们能够看到硬件辅助虚拟化的使用，通过让指令直达支持虚拟化的硬件，以此避开了效率低下的 Hypervisor。而如 JRE、HPHP 中，除了基于 Hypervisor 实现的解释执行机制外，还有即时编译 ( Just In Time ) 运行机制，让程序代码在运行前编译成符合当前硬件平台的机器码，这种方式就已经不属于虚拟化的范畴了。 容器技术 容器技术是一种全新意义上的虚拟化技术，按分类或者实现方式来说，其应该属于操作系统虚拟化的范畴，也就是在由操作系统提供虚拟化的支持。 所谓容器技术，指的是操作系统自身支持一些接口，能够让应用程序间可以互不干扰的独立运行，并且能够对其在运行中所使用的资源进行干预。当然，目前来说容器技术还没有一个严格的定义，其实现方式也各有不同，所以这里只能算是我的一点小小总结归纳。 由于应用程序的运行被隔离在了一个独立的运行环境之中，这个独立的运行环境就好似一个容器，包裹住了应用程序，这就是容器技术名字的由来。 容器技术近年来已经是一个火遍大江南北的概念了，其之所以能名声大噪，很重要的一个原因是其在运行性能上要远超虚拟机等其他虚拟化实现。更甚一步说，运行在容器虚拟化中的应用程序，在运行效率上与真实运行在物理平台上的应用程序不相上下。 为什么容器技术能够造就近乎完美的运行效率呢？这就得从容器技术如何实现应用程序的指令转换开始说起。下面这张图展示了容器技术如何进行指令转换的。 ... 实在无奈，没有找到容器技术进行指令转换的图片，因为容器技术压根没有做指令转换。是的，你没有听错，有时候解决问题的最佳方法就是不解决它。 由于没有指令转换，运行在容器中的应用程序自身必须支持在真实操作系统上运行，也就是必须遵循硬件平台的指令规则。 很多同学这时候就有疑问了，指令都不转换，也没有解决程序跨平台兼容的问题，这算哪门子虚拟化技术。 没错，正是这种原因，很多人并不认同容器技术属于虚拟化技术的范畴。不过另一派观点认为，容器技术提供了相对独立的应用程序运行的环境，也提供了资源控制的功能，所以我们依然可以归纳其为一种实现不完全的虚拟化技术。 虚拟机 VS 容器 这里我们直接通过虚拟机和容器技术的剖析图来分析，就更容易看出容器虚拟化是如何在效率上完胜虚拟机的。 由于没有了虚拟操作系统和虚拟机监视器这两个层次，大幅减少了应用程序运行带来的额外消耗。 更准确的来说，所有在容器中的应用程序其实完全运行在了宿主操作系统中，与其他真实运行在其中的应用程序在指令运行层面是完全没有任何区别的。 留言互动 在阅读完这一小节后，相信你对虚拟化和容器技术已经有了初步的认识，这里给大家留一道思考题： 通过容器技术与其他常见的虚拟化技术 ( 例如虚拟机 ) 实现各自的优势和劣势，说说它们各自有怎样的适用场景。 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对虚拟化技术、容器技术等还有不甚了解之处，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/02.基础概念：这是Docker的简历.html":{"url":"开发者必备的Docker实践指南/02.基础概念：这是Docker的简历.html","title":"02.基础概念：这是Docker的简历","keywords":"","body":"这是 Docker 的简历 在了解虚拟化和容器技术后，我们就更容易理解 Docker 的相关知识了。在这一小节中，我将介绍关于 Docker 的出现和发展，Docker 背后的技术。同时，我们将阐述 Docker 在虚拟化领域中的定位以及其带来的变革。 Docker 开源项目 如果说 Docker 的诞生，就必须从 Docker 这个开源项目提起 ( 虽然它现在已经不叫 Docker 了 )。Docker 项目是一个由 Go 语言实现的容器引擎，它最初由 dotCloud 这家做云服务的公司在 2013 年开源。 由于 Docker 带来的巨大的便利，让很多开发、测试和运维等软件开发环节上的工作被简化甚至省去，所以在短短的几年间便成为虚拟化乃至整个技术领域的热词。同时，许多开发者乃至大型科技企业都参与到了 Docker 相关领域的贡献中来，为 Docker 及其生态圈贡献了许多优秀的软件项目，这大大提高了 Docker 生态的完整性，也让 Docker 日益健壮。 也许 dotCloud 自己也没有想到，云服务没卖出几个钱，反倒是 Docker 越来越火。拥有商业头脑的他们，干脆不再做云服务了，也把公司名字改成 Docker Inc. 专门从事 Docker 周边的生意。 当然，Docker 的商业化也带来了一定的变化。为了更好的进行商业运作，Docker Inc. 将 Docker 开源项目的名称修改为了 Moby，所以大家要是在 GitHub 上没有搜索到 Docker 不要觉得惊讶，因为它现在的名字是 Moby ( https://github.com/moby/moby )。 关于 Moby 和 Docker 更多的内容，这里给大家提供一下参考资料，有兴趣的朋友们可以前往阅读： Docker改名啦？什么是 Moby Project 对于 Docker 改名 Moby ，大家怎么看？ Introducing Moby Project Docker 所带来的改变 简单说了一些 Docker 的故事，接来下我们就必须重点说一下 Docker 所带来的改变。正是这些对我们工作方式的改变，让我们越来越难以离开 Docker，又源于我们对 Docker 如此的喜爱，让 Docker 能够在短时间内就从雏鸟成长为大鹏，成为万众瞩目的新星。 云计算时代的挑战 在计算机技术发展的早期，几乎所有的程序都是在开发后部署到一台或是少数几台服务器上的。那时的程序也几乎都是集所有模块和运行时环境为一身的“全栈应用”，虽然这些程序可以基于一套良好、完善的协议栈 ( 譬如一套完整的 MVC 架构 ) 进行开发，但再好的架构也无法让应用服务在这种体系下快速发展。 随着互联网的极速发展，应用程序的功能越来越丰富，而需要迭代的速度要求也越来越高，为了实现这些目标，应用的开发逐渐趋向服务化甚至微服务化。每个应用程序都有其对应依赖的操作系统或者其他程序，而在将应用程序细分为不同的微服务或者是其他形式的微小应用模块后，解决这种依赖问题会愈发显得棘手。有的应用运行环境特别复杂，搭建过程也极易出错，这都是让开发、测试、运维人员焦头烂额的地方。更多时候，开发者们肯定更愿意将他们宝贵的时间用在实际的开发中，而不是纠缠着应用运行环境的问题上。 同时，由于物理硬件的更新迭代速度已经难以追赶互联网的脚步，应用的部署逐渐转向集群化。应用模块的数量乘上每个应用所部署的机器的数量，会是一个非常庞大的数字。相信所有的开发或者运维都不会愿意把时间浪费在逐一搭建服务器环境这种重复的劳动上。 这些变化都对应用的开发、部署带来了不小的挑战。 我想很多读者已经想到了应对这些挑战的办法了，没错，那就是虚拟化技术。通过虚拟化技术可以让环境的搭建变得更加的容易，对我们快速部署分布式应用服务体系提供了极大的便利。 进而言之，如果我们把管理环境的复杂度，更轻量级的虚拟化实现等更加实际的问题考虑进去，容器技术自然成了虚拟化技术中最佳的选择项。 皆为效率 如果说在分布式部署中应用容器技术是一个方向，那么 Docker 就是在这个方向上跑得最快也最完美的运动员了。Docker 不论从实现容器技术的完整性上来说，还是从上手易用性来说，都是可圈可点的。 好了，这里我要穿插一下推荐 Docker 的原因了。我们使用 Docker 的目的其实很简单，就是利用它的全面性和易用性带来的提升我们的工作效率。了解了这个目的，我想大家会更容易理解很多场合 Docker 能派上用场的原因。当然，通过这个道理，你也就明白了为什么我会说 Docker 是一门新时代开发者必须掌握的技术了。毕竟所有的老板都希望找到会得多、干活快的优秀开发者 ( 亦或者说，会的多、干活快是优秀开发者所必备的品质 )。 再怎么从理论上说快也是很难服众的，是骡子是马拉出来“跑个分”就知道了。Docker 官方对 Docker 在工作上带来的提升做了调查研究，分别从工作效率的提升和技术设计投入的减少等方面数据化了 Docker 所做出的突出贡献。 相信看到这些数据，你已经明白为何 Docker 备受关注的原因了。 Docker 的技术实现 这里我们再简单了解一下 Docker 的技术实现，以便有探索欲望的读者查找相关资料进行深入阅读。 Docker 的实现，主要归结于三大技术：命名空间 ( Namespaces ) 、控制组 ( Control Groups ) 和联合文件系统 ( Union File System ) 。 Namespace 命名空间是 Linux 核心在 2.4 版本后逐渐引入的一项用于运行隔离的模块。 相信很多开发者在不同的编程语言中都见过命名空间的概念，在这些编程语言中，命名空间的主要目的就是为了集合相同模块的类，区分不同模块间的同名类。 同样的道理，Linux 内核的命名空间，就是能够将计算机资源进行切割划分，形成各自独立的空间。 就实现而言，Linux Namespaces 可以分为很多具体的子系统，如 User Namespace、Net Namespace、PID Namespace、Mount Namespace 等等。 这里我们以进程为例，通过 PID Namespace，我们可以造就一个独立的进程运行空间，在其中进程的编号又会从 1 开始。在这个空间中运行的进程，完全感知不到外界系统中的其他进程或是其他进程命名空间中运行的进程。 利用 PID Namespace，Docker 就实现了容器中隔离程序运行中进程隔离这一目标。 Control Groups 资源控制组 ( 常缩写为 CGroups ) 是 Linux 内核在 2.6 版本后逐渐引入的一项对计算机资源控制的模块。 顾名思义，资源控制组的作用就是控制计算机资源的。与以隔离进程、网络、文件系统等虚拟资源为目的 Namespace 不同，CGroups 主要做的是硬件资源的隔离。 之前我们提到了，虚拟化除了制造出虚拟的环境隔离同一物理平台运行的不同程序之外，另一大作用就是控制硬件资源的分配，CGroups 的使用正是为了这样的目的。 需要再强调一次的是，CGroups 除了资源的隔离，还有资源分配这个关键性的作用。通过 CGroups，我们可以指定任意一个隔离环境对任意资源的占用值或占用率，这对于很多分布式使用场景来说是非常有用的功能。 例如，我们在服务器上部署一个业务服务和一个健康监控服务。通常情况下，监控服务只会占用很少的计算机资源，但我们无法保证其不会因为一些逻辑问题产生 Bug 进而过分消耗计算机资源。而它申请的计算机资源越多，意味着业务服务所能使用的计算机资源也就越少，最后甚至可能造成物理服务器的崩溃。 上述的问题在没有隔离实现的普通运行环境下是比较难解决的，因为所有不从系统层面出发的限制程序资源使用的方式都并不完全有效。由于 CGroups 实现于操作系统，而操作系统垄断着系统资源的分配，所以其完全能够限制隔离环境下应用的资源占有量。 Union File System 联合文件系统 ( Union File System ) 是一种能够同时挂载不同实际文件或文件夹到同一目录，形成一种联合文件结构的文件系统。联合文件系统本身与虚拟化并无太大的关系，但 Docker 却创新的将其引入到容器实现中，用它解决虚拟环境对文件系统占用过量，实现虚拟环境快速启停等问题。 在 Docker 中，提供了一种对 UnionFS 的改进实现，也就是 AUFS ( Advanced Union File System )。 AUFS 将文件的更新挂载到老的文件之上，而不去修改那些不更新的内容，这就意味着即使虚拟的文件系统被反复修改，也能保证对真实文件系统的空间占用保持一个较低水平。 也许这个表述还不够形象，那么我们来用 Git 进行比较，会让大家会更容易理解。大家知道，我们在 Git 中每进行一次提交，Git 并不是将我们所有的内容打包成一个版本，而只是将修改的部分进行记录，这样即使我们提交很多次后，代码库的空间占用也不会倍数增加。 同样的，通过 AUFS，Docker 大幅减少了虚拟文件系统对物理存储空间的占用。由此，Docker 也开创出了虚拟化领域很多新的轻量级解决方案，这在之后的小节里我们会提到。 Docker 的理念 在对 Docker 及其背后的一些技术有了一个初步了解之后，我们还要着重说一下 Docker 本身的一些设计理念。如果说熟悉 Docker 背后的技术能够更好的帮助你正确使用 Docker，那么理解 Docker 的理念将更好的指导你如何搭配 Docker 容器间的关系。 让我们先来从一张 Docker 官方提供的架构图来看看 Docker 对容器结构的设计。 与其他虚拟化实现甚至其他容器引擎不同的是，Docker 推崇一种轻量级容器的结构，即一个应用一个容器。 举个具体的例子，在常见的虚拟机实现中，我们要搭建一套 LAMP 结构的服务，我们通常会建立一个虚拟机，在虚拟机中安装上 Linux 系统，之后分别安装 Apache、MySQL 和 PHP。而在 Docker 里，最佳的实践是分别基于 Apache、MySQL 和 PHP 的镜像建立三个容器，分别运行 Apache、MySQL 和 PHP ，而它们所在的虚拟操作系统也直接共享于宿主机的操作系统。 如果我们将 Docker 的轻量级容器实现和虚拟机的一些参数进行对比，更容易得到结果。 属性 Docker 虚拟机 启动速度 秒级 分钟级 硬盘使用 MB 级 GB 级 性能 接近原生 较低 普通机器支撑量 数百个 几个 虽然这里只列出了一些 Docker 的优势项，但这些优势都是对我们开发中环境搭建和使用极其有帮助的内容。就拿启动速度来说，我们在开发中显然不愿意调整环境或更新代码后要等待几分钟来让其生效，Docker 秒级的启动速度几乎让我们感知不到我们对环境做了什么改动。而像虚拟机占用大量操作系统资源，导致我们本地开发使用电脑过慢 ( 有时候不得不将环境搭建在另外的机器上，但这显然在代码编写到运行自测的过程中增加很多工作量 ) 等问题，也容易得到解决。 当然，在 Docker 中能实现这样的设计理念，还要归功于几项基础设施的支持。 首先，只有在容器技术的支撑下，应用即容器的方案才能有效的实施。因为容器技术既剔除了 Hypervisor 层，又干掉了虚拟操作系统的概念，让容器中应用运行的消耗与真实操作系统中运行的消耗几乎完全一致。只有这样，我们才能像在真实操作系统中开启应用一样开启新的容器，而不用过分担心虚拟化带来的性能消耗。 其次，基于联合文件系统的底层文件系统支持，让容器能够很容易在真实操作系统中共享存储资源，并由此带来了对存储空间的低消耗。与动辄就要独立开辟十几 GB 甚至几十 GB 的虚拟化实现相比，要存在巨大的优势。 当然，Docker 也支持你在容器中同时运行很多种程序，但其容器设计本身并不针对这种方案，所以如果你以这种方案在 Docker 中搭建环境，你会花费不少时间做出一些本来并不需要做的事情。虽然这看上去动手性很强，但我并不推荐在工作中这么去做，因为我们使用 Docker 本身就是为了效率，浪费时间在这些不必要的事情上，已经违背了我们使用 Docker 的初衷。 我们能用 Docker 做些什么 从理论上我们已经知道 Docker 能够为我们的工作带来巨大的便利，那么将其放于实践中，我们应该如何正确的使用它呢？这里我摘录整理了一段来自 Docker 官方文档的指导意见，希望能够对大家的实践提供参考。 更快、更一致的交付你的应用程序 使用 Docker 后，开发者能够在本地容器中得到一套标准的应用或服务的运行环境，由此可以简化开发的生命周期 ( 减少在不同环境间进行适配、调整所造成的额外消耗 )。对于整个应用迭代来说，加入 Docker 的工作流程将更加适合持续集成 ( Continuous Integration ) 和持续交付 ( Continuous Delivery )。 举个具体的例子： 开发者能够使用 Docker 在本地编写代码并通过容器与其他同事共享他们的工作。 他们能够使用 Docker 将编写好的程序推送至测试环境进行自动化测试或是人工测试。 当出现 Bugs 时，开发者可以在开发环境中修复它们，并很快的重新部署到测试环境中。 在测试完成后，部署装有应用程序的镜像就能完成生产环境的发布。 跨平台部署和动态伸缩 基于容器技术的 Docker 拥有很高的跨平台性，Docker 的容器能够很轻松的运行在开发者本地的电脑，数据中心的物理机或虚拟机，云服务商提供的云服务器，甚至是混合环境中。 同时，Docker 的轻量性和高可移植性能够很好的帮助我们完成应用的动态伸缩，我们可以通过一些手段近实时的对基于 Docker 运行的应用进行弹性伸缩，这能够大幅提高应用的健壮性。 让同样的硬件提供更多的产出能力 Docker 的高效和轻量等特征，为替代基于 Hypervisor 的虚拟机提供了一个经济、高效、可行的方案。在 Docker 下，你能节约出更多的资源投入到业务中去，让应用程序产生更高的效益。同时，如此低的资源消耗也说明了 Docker 非常适合在高密度的中小型部署场景中使用。 留言互动 在这节中，我们溯源 Docker 的历史，从其诞生的背景和其解决的问题出发，阐述了 Docker 背后的技术和 Docker 本身的设计理念。这里给大家留一道思考题： Docker 所提倡的轻量级虚拟化与其他虚拟化实现中的完整操作系统虚拟化有什么样的优势，其优势又能应用到哪些实际的场景中去呢？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 的发展历史，Docker 背后的技术或者 Docker 所推崇的理念还有不解之处，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/03.基础概念：了解Docker的核心组成.html":{"url":"开发者必备的Docker实践指南/03.基础概念：了解Docker的核心组成.html","title":"03.基础概念：了解Docker的核心组成","keywords":"","body":"了解 Docker 的核心组成 在掌握 Docker 的一些背景知识后，我们还不得不花费一节的篇幅来简单介绍有关 Docker 核心的一些知识。当然，大家不要觉得有“核心”这类的词，我们就要在这一节中深入 Docker 底层去讲解原理性的东西，更确切的说这一节更像一张词汇表，在掌握这些与 Docker 紧密相关的词汇后，大家可以更好的理解之后小节中的内容。 四大组成对象 在之前的小节里，我们提到了 Docker 实现容器引擎的一些技术，但那些都是一些相对底层的原理实现，在 Docker 将它们封装后，我们并不会直接操作它们。在 Docker 中，另外提供出了一些软件层面的概念，这才是我们操作 Docker 所针对的对象。 在 Docker 体系里，有四个对象 ( Object ) 是我们不得不进行介绍的，因为几乎所有 Docker 以及周边生态的功能，都是围绕着它们所展开的。它们分别是：镜像 ( Image )、容器 ( Container )、网络 ( Network )、数据卷 ( Volume )。 镜像 镜像 ( Image ) 这个概念相信大家不会陌生，因为它是其他虚拟化技术 ( 特别是虚拟机 ) 中常常被使用的一个概念。所谓镜像，可以理解为一个只读的文件包，其中包含了虚拟环境运行最原始文件系统的内容。 当然，Docker 的镜像与虚拟机中的镜像还是有一定区别的。首先，之前我们谈到了 Docker 中的一个创新是利用了 AUFS 作为底层文件系统实现，通过这种方式，Docker 实现了一种增量式的镜像结构。 每次对镜像内容的修改，Docker 都会将这些修改铸造成一个镜像层，而一个镜像其实就是由其下层所有的镜像层所组成的。当然，每一个镜像层单独拿出来，与它之下的镜像层都可以组成一个镜像。 另外，由于这种结构，Docker 的镜像实质上是无法被修改的，因为所有对镜像的修改只会产生新的镜像，而不是更新原有的镜像。 容器 容器 ( Container ) 就更好理解了，在容器技术中，容器就是用来隔离虚拟环境的基础设施，而在 Docker 里，它也被引申为隔离出来的虚拟环境。 如果把镜像理解为编程中的类，那么容器就可以理解为类的实例。镜像内存放的是不可变化的东西，当以它们为基础的容器启动后，容器内也就成为了一个“活”的空间。 用更官方的定义，Docker 的容器应该有三项内容组成： 一个 Docker 镜像 一个程序运行环境 一个指令集合 关于镜像与容器的更多细节知识，我们在后面的小节中还会单独进行讲解。 网络 对于大部分程序来说，它们的运行都不会是孤立的，而是要与外界或者更准确的说是与其他程序进行交互的，这里的交互绝大多数情况下指的就是数据信息的交换。网络通讯是目前最常用的一种程序间的数据交换方式了。 由于计算机网络领域拥有相对统一且独立的协议等约定，其跨平台性非常优秀，所有的应用都可以通过网络在不同的硬件平台或操作系统平台上进行数据交互。特别是在分布式云计算的时代，应用或服务间的通讯更是充分依赖于网络传输，所以自然拥有一套完善的网络体系支撑，是承载应用运行所必须的基础设施。 在 Docker 中，实现了强大的网络功能，我们不但能够十分轻松的对每个容器的网络进行配置，还能在容器间建立虚拟网络，将数个容器包裹其中，同时与其他网络环境隔离。 另外，利用一些技术，Docker 能够在容器中营造独立的域名解析环境，这使得我们可以在不修改代码和配置的前提下直接迁移容器，Docker 会为我们完成新环境的网络适配。对于这个功能，我们甚至能够在不同的物理服务器间实现，让处在两台物理机上的两个 Docker 所提供的容器，加入到同一个虚拟网络中，形成完全屏蔽硬件的效果。 正是因为拥有强大的网络功能，才能让我们制造健壮的 Docker 应用体系。 数据卷 除了网络之外，文件也是重要的进行数据交互的资源。在以往的虚拟机中，我们通常直接采用虚拟机的文件系统作为应用数据等文件的存储位置。然而这种方式其实并非完全安全的，当虚拟机或者容器出现问题导致文件系统无法使用时，虽然我们可以很快的通过镜像重置文件系统使得应用快速恢复运行，但是之前存放的数据也就消失了。 为了保证数据的独立性，我们通常会单独挂载一个文件系统来存放数据。这种操作在虚拟机中是繁琐的，因为我们不但要搞定挂载在不同宿主机中实现的方法，还要考虑挂载文件系统兼容性，虚拟操作系统配置等问题。值得庆幸的是，这些在 Docker 里都已经为我们轻松的实现了，我们只需要简单的一两个命令或参数，就能完成文件系统目录的挂载。 能够这么简单的实现挂载，主要还是得益于 Docker 底层的 Union File System 技术。在 UnionFS 的加持下，除了能够从宿主操作系统中挂载目录外，还能够建立独立的目录持久存放数据，或者在容器间共享。 在 Docker 中，通过这几种方式进行数据共享或持久化的文件或目录，我们都称为数据卷 ( Volume )。 Docker Engine 时至今日，Docker 生态已经远比它诞生之初要庞大许多，虽然我们仍然习惯使用 Docker 这个名字去指代实现容器技术支持的软件，但显然更加容易与其他的概念产生混淆。这里我们很有必要对这个 Docker 中最核心的软件进行介绍，不仅因为它在 Docker 生态中扮演着中心的地位，也因为它是我们在开发中实实在在接触最多的东西。 目前这款实现容器化的工具是由 Docker 官方进行维护的，Docker 官方将其命名为 Docker Engine，同时定义其为工业级的容器引擎 ( Industry-standard Container Engine )。在 Docker Engine 中，实现了 Docker 技术中最核心的部分，也就是容器引擎这一部分。 docker daemon 和 docker CLI 虽然我们说 Docker Engine 是一款软件，但实实在在去深究的话，它其实算是由多个独立软件所组成的软件包。在这些程序中，最核心的就是 docker daemon 和 docker CLI 这俩了。 所有我们通常认为的 Docker 所能提供的容器管理、应用编排、镜像分发等功能，都集中在了 docker daemon 中，而我们之前所提到的镜像模块、容器模块、数据卷模块和网络模块也都实现在其中。在操作系统里，docker daemon 通常以服务的形式运行以便静默的提供这些功能，所以我们也通常称之为 Docker 服务。 在 docker daemon 管理容器等相关资源的同时，它也向外暴露了一套 RESTful API，我们能够通过这套接口对 docker daemon 进行操作。或者更确切的说，是通过这套 RESTful API 对 docker daemon 中运行的容器和其他资源进行管理。 通常来说，我们是采用在控制台或者命令行输入命令来控制 docker daemon 的，因为这样很酷也更容易适应那些有或者没有图形界面的操作系统。 那么问题来了，如果我们在控制台中编写一个 HTTP 请求以借助 docker daemon 提供的 RESTful API 来操控它，那显然是个费脑、费手又费时间的活儿。所以在 Docker Engine 里还直接附带了 docker CLI 这个控制台程序。 熟悉程序结构的朋友们比较容易看出来，docker daemon 和 docker CLI 所组成的，正是一个标准 C/S ( Client-Server ) 结构的应用程序。衔接这两者的，正是 docker daemon 所提供的这套 RESTful API。 留言互动 在这节中，我们了解了 Docker 中核心的概念，这些基础知识能够帮助我们更好的理解之后我们对 Docker 的实践学习。这里给大家留一道思考题： Docker 的四大核心模块背后各由哪些技术提供支持，它们又在 Docker 实现虚拟运行环境的过程各扮演了什么样的角色？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 的核心概念以及 Docker Engine 的基础知识有什么不理解之处，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/04.安装运行：搭建Docker运行环境.html":{"url":"开发者必备的Docker实践指南/04.安装运行：搭建Docker运行环境.html","title":"04.安装运行：搭建Docker运行环境","keywords":"","body":"搭建 Docker 运行环境 既然 Docker 是一款实用软件，我们就不得不先从它的安装说起，只有让 Docker 运行在我们的计算机上，才能更方便我们对 Docker 相关知识和使用方式的学习。得益于与商业性的优雅结合，Docker 背后拥有大量的优秀开发者为其提供技术支持，而这个优势所造就的结果之一，就是 Docker 拥有丰富且完善的安装体系，我们可以很轻松的通过多种方式安装和运行 Docker。 安装前的准备 由于 Docker 容器实现本身就采用了 Linux 内核中很多的特性，所以它自然与 Linux 系统亲密性很高，所以我们可以很轻松的将 Docker Engine 安装在 Linux 系统中。 不过，在安装之前，我还得不厌其烦的啰嗦一些基本概念，让大家在安装 Docker 时能够更好的进行选择。掌握这些概念，能够帮助大家理解一些安装流程中操作的目的，不至于总是一味的进行“下一步”式安装。 Docker Engine 的版本 在安装 Docker 之前，我们先来了解一下 Docker 的版本定义，这有利于我们在之后的开发中选择和使用合适的 Docker 版本。 对于 Docker Engine 来说，其主要分为两个系列： 社区版 ( CE, Community Edition ) 企业版 ( EE, Enterprise Edition ) 社区版 ( Docker Engine CE ) 主要提供了 Docker 中的容器管理等基础功能，主要针对开发者和小型团队进行开发和试验。而企业版 ( Docker Engine EE ) 则在社区版的基础上增加了诸如容器管理、镜像管理、插件、安全等额外服务与功能，为容器的稳定运行提供了支持，适合于中大型项目的线上运行。 社区版和企业版的另一区别就是免费与收费了。对于我们开发者来说，社区版已经提供了 Docker 所有核心的功能，足够满足我们在开发、测试中的需求，所以我们直接选择使用社区版进行开发即可。在这本小册中，所有的内容也是围绕着社区版的 Docker Engine 展开的。 从另外一个角度，Docker Engine 的迭代版本又会分为稳定版 ( Stable release ) 和预览版 ( Edge release )。不论是稳定版还是预览版，它们都会以发布时的年月来命名版本号，例如如 17 年 3 月的版本，版本号就是 17.03。 Docker Engine 的稳定版固定为每三个月更新一次，而预览版则每月都会更新。在预览版中可以及时掌握到最新的功能特性，不过这对于我们仅是使用 Docker 的开发者来说，意义并不是特别重大的，所以我还是更推荐安装更有保障的稳定版本。 在主要版本之外，Docker 官方也以解决 Bug 为主要目的，不定期发布次要版本。次要版本的版本号由主要版本和发布序号组成，如：17.03.2 就是对 17.03 版本的第二次修正。 Docker 的环境依赖 由于 Docker 的容器隔离依赖于 Linux 内核中的相关支持，所以使用 Docker 首先需要确保安装机器的 Linux kernel 中包含 Docker 所需要使用的特性。以目前 Docker 官方主要维护的版本为例，我们需要使用基于 Linux kernel 3.10 以上版本的 Linux 系统来安装 Docker。 也许 Linux kernel 的版本还不够直观，下面的表格就直接展示了 Docker 对主流几款 Linux 系统版本的要求。 操作系统 支持的系统版本 CentOS CentOS 7 Debian Debian Wheezy 7.7 (LTS)Debian Jessie 8 (LTS)Debian Stretch 9Debian Buster 10 Fedora Fedora 26Fedora 27 Ubuntu Ubuntu Trusty 14.04 (LTS)Ubuntu Xenial 16.04 (LTS)Ubuntu Artful 17.10 当然，在较低版本的 Linux 系统中也能安装 Docker，不过只能是版本较低的 Docker，其功能存在一些缺失，或者与最新版本有所区别。在这本小册里，我们主要以较新版本的 Docker 功能和操作作为介绍，所以如果条件允许，建议将系统升级到支持最新版本 Docker 的系统版本。 在 Linux 系统中安装 Docker 因为 Docker 本身就基于 Linux 的核心能力，同时目前主流的 Linux 系统中所拥有的软件包管理程序，已经可以很轻松的帮助我们处理各种依赖问题，所以在 Linux 中安装 Docker 并非什么难事。 更多的细节就不多说了，Docker 已经为我们准备了好了各系统的安装包，毕竟安装 Docker 并不是我们所要掌握的重点，所以这里我就直接给出安装的命令了。 CentOS $ sudo yum install yum-utils device-mapper-persistent-data lvm2 $ $ sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo $ sudo yum install docker-ce $ $ sudo systemctl enable docker $ sudo systemctl start docker Debian $ sudo apt-get install apt-transport-https ca-certificates curl gnupg2 software-properties-common $ $ curl -fsSL https://download.docker.com/linux/debian/gpg | sudo apt-key add - $ sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/debian $(lsb_release -cs) stable\" $ sudo apt-get update $ sudo apt-get install docker-ce $ $ sudo systemctl enable docker $ sudo systemctl start docker Fedora $ sudo dnf -y install dnf-plugins-core $ $ sudo dnf config-manager --add-repo https://download.docker.com/linux/fedora/docker-ce.repo $ sudo dnf install docker-ce $ $ sudo systemctl enable docker $ sudo systemctl start docker Ubuntu $ sudo apt-get install apt-transport-https ca-certificates curl software-properties-common $ $ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - $ sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\" $ sudo apt-get update $ sudo apt-get install docker-ce $ $ sudo systemctl enable docker $ sudo systemctl start docker 上手使用 在安装 Docker 完成之后，我们需要先启动 docker daemon 使其能够为我们提供 Docker 服务，这样我们才能正常使用 Docker。 在我们通过软件包的形式安装 Docker Engine 时，安装包已经为我们在 Linux 系统中注册了一个 Docker 服务，所以我们不需要直接启动 docker daemon 对应的 dockerd 这个程序，而是直接启动 Docker 服务即可。启动的 Docker 服务的命令其实我已经包含在了前面谈到的安装命令中，也就是： $ sudo systemctl start docker 当然，为了实现 Docker 服务开机自启动，我们还可以运行这个命令： $ sudo systemctl enable docker docker version 在 Docker 服务启动之后，我们先来尝试一个最简单的查看 Docker 版本的命令：docker version。 $ sudo docker version Client: Version: 18.06.1-ce API version: 1.38 Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:23:03 2018 OS/Arch: linux/amd64 Experimental: false Server: Engine: Version: 18.06.1-ce API version: 1.38 (minimum version 1.12) Go version: go1.10.3 Git commit: e68fc7a Built: Tue Aug 21 17:25:29 2018 OS/Arch: linux/amd64 Experimental: false 这个命令能够显示 Docker C/S 结构中的服务端 ( docker daemon ) 和客户端 ( docker CLI ) 相关的版本信息。在默认情况下，docker CLI 连接的是本机运行的 docker daemon ，由于 docker daemon 和 docker CLI 通过 RESTful 接口进行了解耦，所以我们也能修改配置用于操作其他机器上运行的 docker daemon 。 docker info 如果想要了解 Docker Engine 更多相关的信息，我们还可以通过 docker info 这个命令。 $ sudo docker info Containers: 0 Running: 0 Paused: 0 Stopped: 0 Images: 0 Server Version: 18.06.0-ce Storage Driver: overlay2 Backing Filesystem: extfs Supports d_type: true Native Overlay Diff: true Logging Driver: json-file Cgroup Driver: cgroupfs ## ...... Live Restore Enabled: false 在 docker info 这条命令的结果中，我们可以看到正在运行的 Docker Engine 实例中运行的容器数量，存储的引擎等等信息。由于命令结果比较多，这里我省略了大部分内容，大家可以自己操作来尝试获得完整的信息。在之后的章节里，较多结果的命令我也会省去一些与讲解内容无关的部分，节约大家阅读的时间并强化重点。 配置国内镜像源 在很多编程语言中，为了更好的向大家提供依赖包的管理，通常都会有一些组织研发相应的包管理工具，例如 Java 的 Maven，PHP 的 Composer，Node.js 的 NPM 等等。而这些管理工具背后，也对应着一个默认的依赖包仓库。 由于众所周知的原因，我们直接连接这些位于国外服务器上的仓库去获取依赖包速度是非常慢的，这时候我们通常会采用国内一些组织或开发者贡献的国内镜像仓库 ( 注意，这里的“镜像”是指复制于国外源的意思，而不是 Docker 里的镜像 )。 在 Docker 中也有一个由官方提供的中央镜像仓库，不过，它与之前我们所说的国外依赖包仓库一样，除了慢的可怜以外，还经常莫名其妙的完全无法访问。 为了解决这个问题，我们最佳的方式依旧是在国内找一个镜像仓库的镜像源进行替换。很感谢 DaoCloud、阿里云等企业的支持，在国内我们可以找到许多镜像源。这里我们给出一个由 Docker 官方提供的国内镜像源： https://registry.docker-cn.com ( 注：部分读者反映配置了这个镜像源无效，大家需要注意此地址的协议是 https，不要搞错哟 ) 那么有了地址，我们要如何将其配置到 Docker 中呢？ 在 Linux 环境下，我们可以通过修改 /etc/docker/daemon.json ( 如果文件不存在，你可以直接创建它 ) 这个 Docker 服务的配置文件达到效果。 { \"registry-mirrors\": [ \"https://registry.docker-cn.com\" ] } 在修改之后，别忘了重新启动 docker daemon 来让配置生效哟： $ sudo systemctl restart docker 要验证我们配置的镜像源是否生效，我们可以通过 docker info 来查阅当前注册的镜像源列表。 $ sudo docker info ## ...... Registry Mirrors: https://registry.docker-cn.com/ ## ...... 留言互动 在这节中，在这一小节中我们掌握了如何在 Linux 中安装上了 Docker Engine，也学习使用了几个简单的 docker 命令的使用。这里给大家留一道实践题： 尝试自己在 Linux 系统中安装和运行 Docker Engine。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Engine 的安装以及启动运行还有什么疑问，或者在操作的过程中出现了无法处理的问题，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/05.安装运行：在Windows和Mac中使用Docker.html":{"url":"开发者必备的Docker实践指南/05.安装运行：在Windows和Mac中使用Docker.html","title":"05.安装运行：在Windows和Mac中使用Docker","keywords":"","body":"在 Windows 和 Mac 中使用 Docker 对于开发来说，Windows 和 macOS 是更为常见和常用的系统，所以也很有必要了解在 Windows 和 macOS 中使用 Docker 的方法。很幸运的是，Docker 的官方对这两个系统提供了强有力的支持，我们可以很轻松的在这两个系统中运行 Docker。在这一小节中，我们就来了解一下 Docker 在 Windows 和 macOS 中安装的方式以及运行的原理。 Docker Desktop 在大多数情况下，我们的开发工作是在 Windows 或 macOS 这两个操作系统中进行的，既然 Docker 是我们用来解决开发、测试到运维整条产品线的工具，自然支持这两个系统是不可或缺的功能。 如同封装 Docker 为我们提供了轻松的虚拟化运行环境一样，Docker 在 Windows 和 macOS 中的安装也是极易完成的。Docker 官方为 Windows 和 macOS 系统单独开辟了一条产品线，名为 Docker Desktop，其定位是快速为开发者提供在 Windows 和 macOS 中运行 Docker 环境的工具。 Docker Desktop 实现容器化与 Docker Engine 是一致的，这就保证了我们在 Windows 和 macOS 中开发所使用的环境可以很轻松的转移到其他的 Docker 实例中，不论这个 Docker 实例是运行在 Windows、macOS 亦或是 Linux。 Docker Desktop 产品线包含两个软件，也就是针对 Windows 系统的 Docker for Windows 和针对 macOS 的 Docker for Mac。 安装 Docker Desktop 在安装 Docker for Windows 和 Docker for Mac 之前，我们依然要了解一下两款软件对操作系统及软硬件的要求，只有达到了这些要求，我们才能顺利的安装上 Docker for Windows 和 Docker for Mac。 对于 Windows 系统来说，安装 Docker for Windows 需要符合以下条件： 必须使用 Windows 10 Pro ( 专业版 ) 必须使用 64 bit 版本的 Windows 对于 macOS 系统来说，安装 Docker for Mac 需要符合以下条件： Mac 硬件必须为 2010 年以后的型号 必须使用 macOS El Capitan 10.11 及以后的版本 另外，虚拟机软件 VirtualBox 与 Docker Desktop 兼容性不佳，建议在安装 Docker for Windows 和 Docker for Mac 之前先卸载 VirtualBox。 在确认系统能够支持 Docker Desktop 之后，我们就从 Docker 官方网站下载这两个软件的安装程序，这里直接附上 Docker Store 的下载链接，供大家直接下载： Docker for Windows ( https://store.docker.com/editions/community/docker-ce-desktop-windows ) Docker for Mac ( https://store.docker.com/editions/community/docker-ce-desktop-mac ) 安装 Docker for Windows 和 Docker for Mac 的方法十分简单，按 Windows 或 macOS 常见的软件安装方式安装即可。 启动 Docker 像 Linux 中一样，我们要在 Windows 和 macOS 中使用 Docker 前，我们需要先将 Docker 服务启动起来。在这两个系统中，我们需要启动的就是刚才我们安装的 Docker for Windows 和 Docker for Mac 了。 启动两个软件的方式很简单，我们只需要通过操作系统的快捷访问功能查找到 Docker for Windows 或 Docker for Mac 并启动即可。 打开软件之后，我们会在 Windows 的任务栏或者 macOS 的状态栏中看到 Docker 的大鲸鱼图标。 Docker for Windows 或 Docker for Mac 在启动时，这只大鲸鱼上的集装箱会一直闪动，这说明 Docker 程序正在部署 docker daemon 所需要的一些环境并执行 docker daemon 的启动。当集装箱不再闪动，就说明 Docker 服务已经准备就绪，我们就可以在 Windows 和 macOS 中使用 Docker 了。 Docker Desktop 为我们在 Windows 和 macOS 中使用 Docker 提供了与 Linux 中几乎一致的方法，我们只需要打开 Windows 中的 PowerShell 获得 macOS 中的 Terminal，亦或者 Git Bash、Cmder、iTerm 等控制台类软件，输入 docker 命令即可。 使用 docker version 能够看到 Docker 客户端的信息，我们可以在这里发现程序运行的平台： λ docker version Client: ## ...... OS/Arch: windows/amd64 ## ...... Docker Desktop 的实现原理 通过之前小节的介绍，我们知道 Docker 的核心功能，也就是容器实现，是基于 Linux 内核中 Namespaces、CGroups 等功能的。那么大体上可以说，Docker 是依赖于 Linux 而存在的。那么问题来了，Docker Desktop 是如何实现让我们在 Windows 和 macOS 中如此顺畅的使用 Docker 的呢？ 其实 Docker Desktop 的实现逻辑很简单：既然 Windows 和 macOS 中没有 Docker 能够利用的 Linux 环境，那么我们生造一个 Linux 环境就行啦！Docker for Windows 和 Docker for Mac 正是这么实现的。 由于虚拟化在云计算时代的广泛使用，Windows 和 MacOS 也将虚拟化引入到了系统本身的实现中，这其中就包含了之前我们所提到的通过 Hypervisor 实现虚拟化的功能。在 Windows 中，我们可以通过 Hyper-V 实现虚拟化，而在 macOS 中，我们可以通过 HyperKit 实现虚拟化。 Docker for Windows 和 Docker for Mac 这里利用了这两个操作系统提供的功能来搭建一个虚拟 Linux 系统，并在其之上安装和运行 docker daemon。 除了搭建 Linux 系统并运行 docker daemon 之外，Docker Desktop 系列最突出的一项功能就是我们能够直接通过 PowerShell、Terminal 这类的控制台软件在 Windows 和 macOS 中直接操作虚拟 Linux 系统中运行的 docker daemon。 实现这个功能得益于 docker daemon 对外提供的操作过程并不是复杂且领域性强的 IPC 等方式，而是通用的 RESTful Api 的形式。也就是说，Docker Desktop 只要实现 Windows 和 macOS 中的客户端，就能够直接利用 Hypervisor 的网络支持与虚拟 Linux 系统中的 docker daemon 进行通讯，并对它进行控制。 这其实就是我们之前所提到 docker daemon 使用 RESTful Api 作为控制方式的优势体现了。 主机文件挂载 控制能够直接在主机操作系统中进行，给我们使用 Docker Desktop 系列软件提供了极大的方便。除此之外，文件的挂载也是 Docker Desktop 所提供的大幅简化我们工作效率且简化使用的功能之一。 之前我们谈到了，Docker 容器中能够通过数据卷的方式挂载宿主操作系统中的文件或目录，宿主操作系统在 Windows 和 macOS 环境下的 Docker Desktop 中，指的是虚拟的 Linux 系统。 当然，如果只能从虚拟的 Linux 系统中进行挂载，显然不足以达到我们的期望，因为最方便的方式必然是直接从 Windows 和 macOS 里挂载文件了。 要实现我们所期望的效果，也就是 Docker 容器直接挂载主机系统的目录，我们可以先将目录挂载到虚拟 Linux 系统上，再利用 Docker 挂载到容器之中。这个过程被集成在了 Docker Desktop 系列软件中，我们不需要人工进行任何操作，整个过程已经实现了自动化。 Docker Desktop 对 Windows 和 macOS 到虚拟 Linux 系统，再到 Docker 容器中的挂载进行了实现，我们只需要直接选择能够被挂载的主机目录 ( 这个过程更多也是为了安全所考虑 )，剩下的过程全部由 Docker Desktop 代替我们完成。这相比于普通虚拟机软件进行挂载的过程来说，完全不能用百倍效率来比较了。 配置 Docker Desktop 在我们使用 Docker Desktop 系列之前，我们还会简单修改其的一些配置，以便更好的合理搭配操作系统与 Docker Desktop 系列软件。 我们可以通过 Docker for Windows 或 Docker for Mac 的大鲸鱼图标打开配置页面：在大鲸鱼弹出的菜单中选择 Settings ( Windows ) 或 Preferences ( macOS )。 打开 Docker for Windows 和 Docker for Mac 的配置页面后，我们可以发现几个配置页面。这里我不逐一把每个页面进行截图了，大家可以自己动手查看页面每个页面的内容。 Docker for Windows 和 Docker for Mac 的配置项目较 Docker Engine 来说要多上许多，这主要是因为 Docker Desktop 是 Docker Engine 的超集，所以其不仅包含了 Docker Engine 的配置内容，还要包含诸如虚拟机实现等其他配置。 我这里抽出几个与 Docker 相关的关键配置，分别简单说明它们的作用： 文件系统挂载配置 在 Docker for Windows 的 Shared Drivers 面板，以及在 Docker for Mac 中的 File Sharing 面板中，包含了我们之前提到的将本机目录挂载到 Hypervisor 里 Linux 系统中的配置。 资源控制配置 在 Advanced 面板中，我们可以调整 Docker 最大占用的本机资源。当然，更准确的说我们是在调整虚拟 Linux 环境所能占用的资源，是通过这个方式影响 Docker 所能占用的最大资源。 网络配置 在 Docker for Windows 的 Network 面板，以及在 Docker for Mac 中的 Advanced 面板中，我们可以配置 Docker 内部默认网络的子网等内容。这个网络的作用以及更详细的内容，我们会在之第 9 节中进行讲解。 docker daemon 配置 在 Daemon 面板里，我们可以直接配置对 docker daemon 的运行配置进行调整。默认情况下，在 Daemon 面板里只有 Insecure registries 和 Registry mirrors 两个配置，分别用来定义未认证镜像仓库地址和镜像源地址。 我们可以点击切换按钮切换到 Advanced 模式，在这个模式下，我们可以直接编辑 docker daemon 的 daemon.json 配置文件，实现更具体、完整的配置 docker daemon 的目的。 低系统版本解决方案 Docker Desktop 系列为我们在 Windows 和 macOS 中使用 Docker 提供了巨大的便利，几乎让我们可以在数分钟内搭建 Windows 和 macOS 中 Docker 的运行环境，并得到像 Linux 中使用 Docker 一样的体验。但 Docker Desktop 依然存在一定的局限性，其中最大的莫过于其对 Windows 和 macOS 的苛刻要求。虽然我们提倡保持操作系统的更新换代，以得到最新的功能以及更好的安全保障，但依然有很多情况下我们不得不使用低版本的 Windows 和 macOS。对于这种情况，Docker 官方也提供了相应的解决方案。 首先，让我们来聊聊为什么 Docker for Windows 和 Docker for Mac 会对操作系统有如此严苛的要求。其实原因很简单，刚才我们谈到了，Docker for Windows 和 Docker for Mac 的实现分别依靠了 Windows 中的 Hyper-V 和 macOS 中的 HyperKit，而这两个虚拟化工具只在高版本的 Windows 和 macOS 系统中才提供出来。 既然知道了原因，解决方案自然也就有了，既然我们不能利用 Hyper-V 或 HyperKit 来创建虚拟的 Linux 系统，那就找一个能够替代它们的工具，用其创建虚拟 Linux 系统即可。 Docker Toolbox Docker 官方为我们找到了用于搭建虚拟 Linux 系统的软件，即 Oracle 的 VirtualBox，并以此封装了另一个集成的 Docker 运行环境软件：Docker Toolbox。 安装 Docker Toolbox 的过程也十分简单，下载安装包并按常规软件一样安装即可。这里直接我直接提供给大家 Docker Toolbox 安装包的连接，方便大家下载。 Docker Toolbox for Windows ( https://download.docker.com/win/stable/DockerToolbox.exe ) Docker Toolbox for Mac ( https://download.docker.com/mac/stable/DockerToolbox.pkg ) 安装完 Docker Toolbox 后，我们有几项与 Docker for Windows 和 Docker for Mac 不同的使用方法需要注意。 由于不能很好的与系统以及 VirtualBox 互通结合，我们启动、关闭、重启 Docker 服务不能完全实现自动化，所以这里 Docker 为我们提供了 Docker QuickStart Terminal 这个工具来处理这些过程。换个方式说，我们必须通过它来启动和操作 Docker，而不能再直接使用 PowerShell、Terminal 这类软件了。 另外一个不便之处就是文件系统的挂载，由于 Docker Toolbox 无法直接操作 VirtualBox 实现挂载，所以这个过程需要我们人工来进行。整个挂载的方式与我们之前谈到的一样，区别只是需要我们手动操作。将本机目录挂载到虚拟 Linux 系统中的配置在 VirtualBox 的 Settings 中，我们将本机需要挂载的目录配置进去并保存即可。 留言互动 在这节中，在这一小节中我们掌握了如何在 Windows 和 macOS 安装 Docker Desktop 并进行配置，了解了 Docker Desktop 的实现原理。这里给大家留一道思考题： 除了在 Windows 或 macOS 中搭建虚拟的 Linux 系统来实现基于 Linux Container 运行 Docker 这种方式外，你是否还知道直接使用 Windows 或 macOS 本身的容器技术运行 Docker 的方法？尝试了解这些实现方式，说说它们背后的原理。 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Desktop 的安装、配置还有内部实现还有什么不解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/06.使用容器：镜像与容器.html":{"url":"开发者必备的Docker实践指南/06.使用容器：镜像与容器.html","title":"06.使用容器：镜像与容器","keywords":"","body":"镜像与容器 镜像和容器作为 Docker 里最基础的概念，我们很有必要了解 Docker 对它们的很多定义以及其他与它们有关的知识。在这一小节里，我们就专门针对镜像与容器两个概念展开，细致的梳理与这两者有关的概念和定义。 Docker 镜像 如果进行形象的表述，我们可以将 Docker 镜像理解为包含应用程序以及其相关依赖的一个基础文件系统，在 Docker 容器启动的过程中，它以只读的方式被用于创建容器的运行环境。 从另一个角度看，在之前的小节里我们讲到了，Docker 镜像其实是由基于 UnionFS 文件系统的一组镜像层依次挂载而得，而每个镜像层包含的其实是对上一镜像层的修改，这些修改其实是发生在容器运行的过程中的。所以，我们也可以反过来理解，镜像是对容器运行环境进行持久化存储的结果。 深入镜像实现 与其他虚拟机的镜像管理不同，Docker 将镜像管理纳入到了自身设计之中，也就是说，所有的 Docker 镜像都是按照 Docker 所设定的逻辑打包的，也是受到 Docker Engine 所控制的。 这么说起来也许还不够具体，让我们来做一个比较。我们常见的虚拟机镜像，通常是由热心的提供者以他们自己熟悉的方式打包成镜像文件，被我们从网上下载或是其他方式获得后，恢复到虚拟机中的文件系统里的。而 Docker 的镜像我们必须通过 Docker 来打包，也必须通过 Docker 下载或导入后使用，不能单独直接恢复成容器中的文件系统。 虽然这么做失去了很多灵活性，但固定的格式意味着我们可以很轻松的在不同的服务器间传递 Docker 镜像，配合 Docker 自身对镜像的管理功能，让我们在不同的机器中传递和共享 Docker 变得非常方便。这也是 Docker 能够提升我们工作效率的一处体现。 对于每一个记录文件系统修改的镜像层来说，Docker 都会根据它们的信息生成了一个 Hash 码，这是一个 64 长度的字符串，足以保证全球唯一性。这种编码的形式在 Docker 很多地方都有体现，之后我们会经常见到。 由于镜像层都有唯一的编码，我们就能够区分不同的镜像层并能保证它们的内容与编码是一致的，这带来了另一项好处，就是允许我们在镜像之间共享镜像层。 举一个实际的例子，由 Docker 官方提供的两个镜像 elasticsearch 镜像和 jenkins 镜像都是在 openjdk 镜像之上修改而得，那么在我们实际使用的时候，这两个镜像是可以共用 openjdk 镜像内部的镜像层的。 这带来的一项好处就是让镜像可以共用一些存储空间，达到 1 + 1 事实上，这个优势是更为明显的。一个虚拟机镜像的占用空间往往用 GB 来衡量，在同一台物理机上存放几个就已经是了不起的事情了。而 Docker 管理之下的镜像，占用空间是以 MB 为单位进行衡量的，加之镜像之间还能够共享部分的镜像层，也就是共享存储空间，所以我们在常见的硬盘里放下几十、数百个镜像也不是什么难事。 在之后的小节里，我们会讲到如何导出镜像，在导出镜像的时候，我们可以更清晰的看到镜像层的体现，这个留至后面我们来讲解。 查看镜像 镜像是由 Docker 进行管理的，所以它们的存储位置和存储方式等我们并不需要过多的关心，我们只需要利用 Docker 所提供的一些接口或命令对它们进行控制即可。 如果要查看当前连接的 docker daemon 中存放和管理了哪些镜像，我们可以使用 docker images 这个命令 ( Linux、macOS 还是 Windows 上都是一致的 )。 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE php 7-fpm f214b5c48a25 9 days ago 368MB redis 3.2 2fef532eadb3 11 days ago 76MB redis 4.0 e1a73233e3be 11 days ago 83.4MB cogset/cron latest c01d5ac6fc8a 15 months ago 125MB 在 docker images 命令的结果中，我们可以看到镜像的 ID ( IMAGE ID)、构建时间 ( CREATED )、占用空间 ( SIZE ) 等数据。 这里需要注意一点，我们发现在结果中镜像 ID 的长度只有 12 个字符，这和我们之前说的 64 个字符貌似不一致。其实为了避免屏幕的空间都被这些看似“乱码”的镜像 ID 所挤占，所以 Docker 只显示了镜像 ID 的前 12 个字符，大部分情况下，它们已经能够让我们在单一主机中识别出不同的镜像了。 镜像命名 镜像层的 ID 既可以识别每个镜像层，也可以用来直接识别镜像 ( 因为根据最上层镜像能够找出所有依赖的下层镜像，所以最上层进行的镜像层 ID 就能表示镜像的 ID )，但是使用这种无意义的超长哈希码显然是违背人性的，所以这里我们还要介绍镜像的命名，通过镜像名我们能够更容易的识别镜像。 在 docker images 命令打印出的内容中，我们还能看到两个与镜像命名有关的数据：REPOSITORY 和 TAG，这两者其实就组成了 docker 对镜像的命名规则。 来看这个例子： 准确的来说，镜像的命名我们可以分成三个部分：username、repository 和 tag。 username： 主要用于识别上传镜像的不同用户，与 GitHub 中的用户空间类似。 repository：主要用于识别进行的内容，形成对镜像的表意描述。 tag：主要用户表示镜像的版本，方便区分进行内容的不同细节 对于 username 来说，在上面我们展示的 docker images 结果中，有的镜像有 username 这个部分，而有的镜像是没有的。没有 username 这个部分的镜像，表示镜像是由 Docker 官方所维护和提供的，所以就不单独标记用户了。 如果大家再多接触一些镜像，会发现 Docker 中镜像的 repository 部分通常采用的是软件名。这时候大家一定要注意了，镜像还是镜像，镜像名还是镜像名，其与软件命名其实是独立的。 之所以镜像通常直接采用软件名，这还要回归到 Docker 对容器的轻量化设计中。Docker 对容器的设计和定义是微型容器而不是庞大臃肿的完整环境 ( 这当然归功于容器技术在实现虚拟化过程中性能几乎无损 )，这就使得我们通常会只在一个容器中运行一个应用程序，这样的好处自然是能够大幅降低程序之间相互的影响，也有利于利用容器技术控制每个程序所使用的资源。 回过头来，既然我们推崇这种一个容器运行一个程序的做法，那么自然容器的镜像也会仅包含程序以及与它运行有关的一些依赖包，所以我们使用程序的名字直接套用在镜像之上，既祛除了镜像取名的麻烦，又能直接表达镜像中的内容。 在镜像命名中，还有一个非常重要的部分，也就是镜像的标签 ( tag )。镜像的标签是对同一种镜像进行更细层次区分的方法，也是最终识别镜像的关键部分。 通常来说，镜像的标签主要是为了区分同类镜像不同构建过程所产生的不同结果的。由于时间、空间等因素的不同，Docker 每次构建镜像的内容也就有所不同，具体体现就是镜像层以及它们的 ID 都会产生变化。而标签就是在镜像命名这个层面上区分这些镜像的方法。 与镜像的 repository 类似，镜像 tag 的命名方法也通常参考镜像所关联的应用程序。更确切的来说，我们通常会采用镜像内应用程序的版本号以及一些环境、构建方式等信息来作为镜像的 tag。 例如，我们之前示例的结果中就分别有包含 Redis 3.2 版本和 4.0 版本的两个镜像：redis:3.2 和 redis:4.0。 除了单纯使用应用程序版本来作为镜像的标签外，有时候我们也会在其中包含一些构建方式的区别。例如 php:7.2-cli 和 php:7.2-fpm 两个镜像分别表示只包含控制台命令的 PHP 镜像以及包含 PHP-FPM 功能的 PHP 镜像，而他们对应 PHP 版本都是 7.2。 通过组合应用程序和它的版本号来命名镜像，大大方便了我们在 Docker 区别和使用镜像的门槛，与其说我们在使用 Docker 进行来启动容器，这个过程倒更像我们在运行指定版本的应用程序。 另外，Docker 中还有一个约定，当我们在操作中没有具体给出镜像的 tag 时，Docker 会采用 latest 作为缺省 tag。这也就带来了一个共识，也就是绝大多数镜像提供者在提供镜像时，会在 latest 对应的镜像中包含软件最新的版本。这带来了一项小便利，就是我们在不需要了解应用程序迭代周期的情况下，可以利用 latest 镜像保持软件最新版本的使用。 容器的生命周期 要熟悉 Docker 容器，还有一个重要的概念，也就是容器的生命周期。 由于 Docker 揽下了大部分对容器管理的活，只提供给我们非常简单的操作接口，这就意味着 Docker 里对容器的一些运行细节会被更加严格的定义，这其中就包括了容器的生命周期。 这里有一张容器运行的状态流转图： 图中展示了几种常见对 Docker 容器的操作命令，以及执行它们之后容器运行状态的变化。这里我们撇开命令，着重看看容器的几个核心状态，也就是图中色块表示的：Created、Running、Paused、Stopped、Deleted。 在这几种状态中，Running 是最为关键的状态，在这种状态中的容器，就是真正正在运行的容器了。 主进程 如果单纯去看容器的生命周期会有一些难理解的地方，而 Docker 中对容器生命周期的定义其实并不是独立存在的。 在 Docker 的设计中，容器的生命周期其实与容器中 PID 为 1 这个进程有着密切的关系。更确切的说，它们其实是共患难，同生死的兄弟。容器的启动，本质上可以理解为这个进程的启动，而容器的停止也就意味着这个进程的停止，反过来理解亦然。 当我们启动容器时，Docker 其实会按照镜像中的定义，启动对应的程序，并将这个程序的主进程作为容器的主进程 ( 也就是 PID 为 1 的进程 )。而当我们控制容器停止时，Docker 会向主进程发送结束信号，通知程序退出。 而当容器中的主进程主动关闭时 ( 正常结束或出错停止 )，也会让容器随之停止。 通过之前提到的几个方面来看，Docker 不仅是从设计上推崇轻量化的容器，也是许多机制上是以此为原则去实现的。所以，我们最佳的 Docker 实践方法是遵循着它的逻辑，逐渐习惯这种容器即应用，应用即容器的虚拟化方式。虽然在 Docker 中我们也能够实现在同一个容器中运行多个不同类型的程序，但这么做的话，Docker 就无法跟踪不同应用的生命周期，有可能造成应用的非正常关闭，进而影响系统、数据的稳定性。 写时复制机制 写时复制 ( Copy on Write ) 这个词对于开发者来说应该并不陌生，在很多编程语言里，都隐藏了写时复制的实现。在编程里，写时复制常常用于对象或数组的拷贝中，当我们拷贝对象或数组时，复制的过程并不是马上发生在内存中，而只是先让两个变量同时指向同一个内存空间，并进行一些标记，当我们要对对象或数组进行修改时，才真正进行内存的拷贝。 Docker 的写时复制与编程中的相类似，也就是在通过镜像运行容器时，并不是马上就把镜像里的所有内容拷贝到容器所运行的沙盒文件系统中，而是利用 UnionFS 将镜像以只读的方式挂载到沙盒文件系统中。只有在容器中发生对文件的修改时，修改才会体现到沙盒环境上。 也就是说，容器在创建和启动的过程中，不需要进行任何的文件系统复制操作，也不需要为容器单独开辟大量的硬盘空间，与其他虚拟化方式对这个过程的操作进行对比，Docker 启动的速度可见一斑。 采用写时复制机制来设计的 Docker，既保证了镜像在生成为容器时，以及容器在运行过程中，不会对自身造成修改。又借助剔除常见虚拟化在初始化时需要从镜像中拷贝整个文件系统的过程，大幅提高了容器的创建和启动速度。可以说，Docker 容器能够实现秒级启动速度，写时复制机制在其中发挥了举足轻重的作用。 留言互动 在这一小节中，我们对 Docker 的镜像与容器相关的概念进行了进一步的梳理，通过掌握这些词汇，能够更好的帮助大家理解之后小节中的内容。这里给大家留一道思考题： Docker 对镜像与容器的设计有什么独特之处，它们又给 Docker 带来了怎样的优势？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对镜像与容器相关的概念、知识还有不理解的地方，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/07.使用容器：从镜像仓库获得镜像.html":{"url":"开发者必备的Docker实践指南/07.使用容器：从镜像仓库获得镜像.html","title":"07.使用容器：从镜像仓库获得镜像","keywords":"","body":"从镜像仓库获得镜像 之前我们说到了，Docker 与其他虚拟化软件的一处不同就是将镜像管理纳入到了功能之中。实现虚拟化只是程序能够无缝移植的一部分，而有了镜像管理，就真正取代了我们在移植过程中的繁琐操作。利用 Docker 的镜像管理功能，我们可以很方便的通过网络传输和分享镜像，并保障镜像内容的一致性。所以，了解 Docker 的镜像管理方法可以算是掌握 Docker 的第一步。 镜像仓库 在之前的小节里，我们已经提到过 Docker 里集中存放镜像的一个概念，也就是镜像仓库。 如果说我们把镜像的结构用 Git 项目的结构做类比，那么镜像仓库就可以看似 GitLab、GitHub 等的托管平台，只不过 Docker 的镜像仓库托管的不是代码项目，而是镜像。 当然，存储镜像并不是镜像仓库最值得炫耀的功能，其最大的作用是实现了 Docker 镜像的分发。借助镜像仓库，我们得到了一个镜像的中转站，我们可以将开发环境上所使用的镜像推送至镜像仓库，并在测试或生产环境上拉取到它们，而这个过程仅需要几个命令，甚至自动化完成。 获取镜像 虽然有很多种方式将镜像引入到 Docker 之中，但我们最为常用的获取现有镜像的方式还是直接从镜像仓库中拉取，因为这种方式简单、快速、有保障。 要拉取镜像，我们可以使用 docker pull 命令，命令的参数就是我们之前所提到的镜像仓库名。 $ sudo docker pull ubuntu Using default tag: latest latest: Pulling from library/ubuntu 124c757242f8: Downloading [===============================================> ] 30.19MB/31.76MB 9d866f8bde2a: Download complete fa3f2f277e67: Download complete 398d32b153e8: Download complete afde35469481: Download complete 当我们运行这个命令后，Docker 就会开始从镜像仓库中拉取我们所指定的镜像了，在控制台中，我们可以看到镜像拉取的进度。下载进度会分为几行，其实每一行代表的就是一个镜像层。Docker 首先会拉取镜像所基于的所有镜像层，之后再单独拉取每一个镜像层并组合成这个镜像。当然，如果在本地已经存在相同的镜像层 ( 共享于其他的镜像 )，那么 Docker 就直接略过这个镜像层的拉取而直接采用本地的内容。 上面是一个拉取官方镜像并且没有给出镜像标签的例子，大家注意到，当我们没有提供镜像标签时，Docker 会默认使用 latest 这个标签，这个我们在之前的小节中提到过，就不在赘述了。 当然，我们也能够使用完整的镜像命名来拉取镜像。 $ sudo docker pull openresty/openresty:1.13.6.2-alpine 1.13.6.2-alpine: Pulling from openresty/openresty ff3a5c916c92: Pull complete ede0a2a1012b: Pull complete 0e0a11843023: Pull complete 246b2c6f4992: Pull complete Digest: sha256:23ff32a1e7d5a10824ab44b24a0daf86c2df1426defe8b162d8376079a548bf2 Status: Downloaded newer image for openresty/openresty:1.13.6.2-alpine 镜像在被拉取之后，就存放到了本地，接受当前这个 Docker 实例管理了，我们可以通过 docker images 命令看到它们。 $ sudo docker images REPOSITORY TAG IMAGE ID CREATED SIZE ubuntu latest cd6d8154f1e1 12 days ago 84.1MB openresty/openresty 1.13.6.2-alpine 08d5c926e4b6 3 months ago 49.3MB Docker Hub 既然说到镜像仓库，就不得不提 Docker Hub 了。Docker Hub 是 Docker 官方建立的中央镜像仓库，除了普通镜像仓库的功能外，它内部还有更加细致的权限管理，支持构建钩子和自动构建，并且有一套精致的 Web 操作页面。 Docker Hub 的地址是：https://hub.docker.com/ 由于定位是 Docker 的中央镜像仓库系统，同时也是 Docker Engine 的默认镜像仓库，所以 Docker Hub 是开发者共享镜像的首选，那么也就意味着其中的镜像足够丰富。 常用服务软件的镜像，我们都能在 Docker Hub 中找到，甚至能找到针对它们不同用法的不同镜像。 同时，Docker Hub 也允许我们将我们制作好的镜像上传到其中，与广大 Docker 用户共享你的成果。 搜索镜像 由于 Docker Hub 提供了一套完整的 Web 操作界面，所以我们搜索其中的镜像会非常方便。 在上方的搜索条中输入镜像的关键词，回车搜索我们就可以看到镜像搜索的结果了。 在 Docker Hub 的搜索结果中，有几项关键的信息有助于我们选择合适的镜像： OFFICIAL 代表镜像为 Docker 官方提供和维护，相对来说稳定性和安全性较高 STARS 代表镜像的关注人数，这类似 GitHub 的 Stars，可以理解为热度 PULLS 代表镜像被拉取的次数，基本上能够表示镜像被使用的频度 当然，关于镜像更多的信息我们可以在 DETAILS 中看到，这其中通常还包括了每个镜像不同的使用方法。具体如何阅读这些使用说明，我们会在之后的小节里专门介绍。 除了直接通过 Docker Hub 网站搜索镜像这种方式外，我们还可以用 docker CLI 中的 docker search 这个命令搜索 Docker Hub 中的镜像。 $ sudo docker search ubuntu NAME DESCRIPTION STARS OFFICIAL AUTOMATED ubuntu Ubuntu is a Debian-based Linux operating sys… 8397 [OK] dorowu/ubuntu-desktop-lxde-vnc Ubuntu with openssh-server and NoVNC 220 [OK] rastasheep/ubuntu-sshd Dockerized SSH service, built on top of offi… 171 [OK] consol/ubuntu-xfce-vnc Ubuntu container with \"headless\" VNC session… 129 [OK] ansible/ubuntu14.04-ansible Ubuntu 14.04 LTS with ansible 95 [OK] ubuntu-upstart Upstart is an event-based replacement for th… 89 [OK] neurodebian NeuroDebian provides neuroscience research s… 54 [OK] ## ...... 使用 docker search 命令，我们可以得到一个类似于 Docker Hub 网页版搜索的镜像列表结果，其中的信息与网页版也是类似的。通过这种方式我们可以在不方便访问 Web 的环境下搜索镜像，对于控制台爱好者来说也是一种不错的选择。 管理镜像 对镜像的管理要比搜索和获取镜像更常用，所以了解镜像管理相关的操作以及知识是非常有必要的。 除了之前我们所提到的 docker images 可以列出本地 Docker 中的所有镜像外，如果我们要获得镜像更详细的信息，我们可以通过 docker inspect 这个命令。 $ sudo docker inspect redis:3.2 [ { \"Id\": \"sha256:2fef532eadb328740479f93b4a1b7595d412b9105ca8face42d3245485c39ddc\", \"RepoTags\": [ \"redis:3.2\" ], \"RepoDigests\": [ \"redis@sha256:745bdd82bad441a666ee4c23adb7a4c8fac4b564a1c7ac4454aa81e91057d977\" ], ## ...... } ] 在 docker inspect 的结果中我们可以看到关于镜像相当完备的信息，由于条目分类比较多，这里我就不一一罗列展开了。 除了能够查看镜像的信息外，docker inspect 还能查看容器等之前我们所提到的 Docker 对象的信息，而传参的方式除了传递镜像或容器的名称外，还可以传入镜像 ID 或容器 ID。 $ sudo docker inspect redis:4.0 $ sudo docker inspect 2fef532e 参数识别 细心的读者在这里一定发现了一个细节，之前我们所谈到镜像 ID 是 64 个字符，而 docker images 命令里的缩写也有 12 个字符，为什么我这里展示的操作命令里只填写了 8 个字符呢？ 这就有必要专门说说 Docker 所支持的这种传参方式了。 不论我们是通过镜像名还是镜像 ID 传递到 docker inspect 或者其他类似的命令 ( 需要指定 Docker 对象的命令 ) 里，Docker 都会根据我们传入的内容去寻找与之匹配的内容，只要我们所给出的内容能够找出唯一的镜像，那么 Docker 就会对这个镜像执行给定的操作。反之，如果找不到唯一的镜像，那么操作不会进行，Docker 也会显示错误。 也就是说，只要我们提供了能够唯一识别镜像或容器的信息，即使它短到只有 1 个字符，Docker 都是可以处理的。 例如我们有五个镜像： REPOSITORY TAG IMAGE ID CREATED SIZE php 7-fpm f214b5c48a25 11 days ago 368MB ubuntu latest cd6d8154f1e1 13 days ago 84.1MB redis 3.2 2fef532eadb3 13 days ago 76MB redis 4.0 e1a73233e3be 13 days ago 83.4MB openresty/openresty 1.13.6.2-alpine 08d5c926e4b6 3 months ago 49.3MB cogset/cron latest c01d5ac6fc8a 16 months ago 125MB 我们注意到镜像 ID 前缀为 2 的只有 redis:3.2 这个镜像，那么我们就可以使用 2 来指代这个镜像。 $ sudo docker inspect 2 而前缀为 c 的镜像有两个，这时候如果我们直接使用 c 来指代镜像的话，Docker 会提示未能匹配到镜像。 $ sudo docker inspect c [] Error: No such object: c 删除镜像 虽然 Docker 镜像占用的空间比较小，但日渐冗杂的镜像和凌乱的镜像版本会让管理越来越困难，所以有时候我们需要清理一些无用的镜像，将它们从本地的 Docker Engine 中移除。 删除镜像的命令是 docker rmi，参数是镜像的名称或 ID。 $ sudo docker rmi ubuntu:latest Untagged: ubuntu:latest Untagged: ubuntu@sha256:de774a3145f7ca4f0bd144c7d4ffb2931e06634f11529653b23eba85aef8e378 Deleted: sha256:cd6d8154f1e16e38493c3c2798977c5e142be5e5d41403ca89883840c6d51762 Deleted: sha256:2416e906f135eea2d08b4a8a8ae539328482eacb6cf39100f7c8f99e98a78d84 Deleted: sha256:7f8291c73f3ecc4dc9317076ad01a567dd44510e789242368cd061c709e0e36d Deleted: sha256:4b3d88bd6e729deea28b2390d1ddfdbfa3db603160a1129f06f85f26e7bcf4a2 Deleted: sha256:f51700a4e396a235cee37249ffc260cdbeb33268225eb8f7345970f5ae309312 Deleted: sha256:a30b835850bfd4c7e9495edf7085cedfad918219227c7157ff71e8afe2661f63 删除镜像的过程其实是删除镜像内的镜像层，在删除镜像命令打印的结果里，我们可以看到被删除的镜像层以及它们的 ID。当然，如果存在两个镜像共用一个镜像层的情况，你也不需要担心 Docker 会删除被共享的那部分镜像层，只有当镜像层只被当前被删除的镜像所引用时，Docker 才会将它们从硬盘空间中移除。 docker rmi 命令也支持同时删除多个镜像，只需要通过空格传递多个镜像 ID 或镜像名即可。 $ sudo docker rmi redis:3.2 redis:4.0 Untagged: redis:3.2 Untagged: redis@sha256:745bdd82bad441a666ee4c23adb7a4c8fac4b564a1c7ac4454aa81e91057d977 Deleted: sha256:2fef532eadb328740479f93b4a1b7595d412b9105ca8face42d3245485c39ddc ## ...... Untagged: redis:4.0 Untagged: redis@sha256:b77926b30ca2f126431e4c2055efcf2891ebd4b4c4a86a53cf85ec3d4c98a4c9 Deleted: sha256:e1a73233e3beffea70442fc2cfae2c2bab0f657c3eebb3bdec1e84b6cc778b75 ## ...... 留言互动 在本节中，我们对镜像的获取和其他一些关于镜像的基本操作进行了使用展示，介绍了 Docker 的官方镜像仓库 Docker Hub，简单概述了镜像与镜像仓库的关系。这里给大家留一道思考题： Docker 中镜像仓库这项功能设计，在实际工作中能够为我们带来哪些具体的便利？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对镜像的操作与使用还有什么不理解的地方，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/08.使用容器：运行和管理容器.html":{"url":"开发者必备的Docker实践指南/08.使用容器：运行和管理容器.html","title":"08.使用容器：运行和管理容器","keywords":"","body":"运行和管理容器 容器是基于容器技术所建立和运行的轻量级应用运行环境，它是 Docker 封装和管理应用程序或微服务的“集装箱”。在 Docker 中，容器算是最核心的部分了，掌握容器的操作也是 Docker 中最基础的技能了。在这一节中，我们会深入了解容器，展示关于容器的操作。 容器的创建和启动 在了解容器的各项操作之前，我们再来回顾一下之前我们所提及的容器状态流转。 在这幅图中，我们可以看到，Docker 容器的生命周期里分为五种状态，其分别代表着： Created：容器已经被创建，容器所需的相关资源已经准备就绪，但容器中的程序还未处于运行状态。 Running：容器正在运行，也就是容器中的应用正在运行。 Paused：容器已暂停，表示容器中的所有程序都处于暂停 ( 不是停止 ) 状态。 Stopped：容器处于停止状态，占用的资源和沙盒环境都依然存在，只是容器中的应用程序均已停止。 Deleted：容器已删除，相关占用的资源及存储在 Docker 中的管理信息也都已释放和移除。 创建容器 当我们选择好镜像以后，就可以通过 docker create 这个命令来创建容器了。 $ sudo docker create nginx:1.12 34f277e22be252b51d204acbb32ce21181df86520de0c337a835de6932ca06c3 执行 docker create 后，Docker 会根据我们所给出的镜像创建容器，在控制台中会打印出 Docker 为容器所分配的容器 ID，此时容器是处于 Created 状态的。 之后我们对容器的操作可以通过这个容器 ID 或者它的缩略形式进行，但用容器 ID 操作容器就和用镜像 ID 操作镜像一样烦闷，所以我们更习惯于使用容器名来操作容器。 要使用容器名操作容器，就先得给容器命名，在创建容器时，我们可以通过 --name 这个选项来配置容器名。 $ sudo docker create --name nginx nginx:1.12 启动容器 通过 docker create 创建的容器，是处于 Created 状态的，其内部的应用程序还没有启动，所以我们需要通过 docker start 命令来启动它。 $ sudo docker start nginx 由于我们为容器指定了名称，这样的操作会更加自然，所以我们非常推荐为每个被创建的容器都进行命名。 当容器启动后，其中的应用就会运行起来，容器的几个生命周期也会绑定到了这个应用上，这个之前我们已经提及，这里就不在赘述。只要应用程序还在运行，那么容器的状态就会是 Running，除非进行一些修改容器的操作。 在 Docker 里，还允许我们通过 docker run 这个命令将 docker create 和 docker start 这两步操作合成为一步，进一步提高工作效率。 $ sudo docker run --name nginx -d nginx:1.12 89f2b769498a50f5c35a314ab82300ce9945cbb69da9cda4b022646125db8ca7 通过 docker run 创建的容器，在创建完成之后会直接启动起来，不需要我们再使用 docker start 去启动了。 这里需要注意的一点是，通常来说我们启动容器会期望它运行在“后台”，而 docker run 在启动容器时，会采用“前台”运行这种方式，这时候我们的控制台就会衔接到容器上，不能再进行其他操作了。我们可以通过 -d 或 --detach 这个选项告诉 Docker 在启动后将程序与控制台分离，使其进入“后台”运行。 管理容器 容器创建和启动后，除了关注应用程序是否功能正常外，我们也会关注容器的状态等内容。 通过 docker ps 这个命令，我们可以罗列出 Docker 中的容器。 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 89f2b769498a nginx:1.12 \"nginx -g 'daemon of…\" About an hour ago Up About an hour 80/tcp nginx 默认情况下，docker ps 列出的容器是处于运行中的容器，如果要列出所有状态的容器，需要增加 -a 或 --all 选项。 $ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 425a0d3cd18b redis:3.2 \"docker-entrypoint.s…\" 2 minutes ago Created redis 89f2b769498a nginx:1.12 \"nginx -g 'daemon of…\" About an hour ago Up About an hour 80/tcp nginx 在 docker ps 的结果中，我们可以看到几项关于容器的信息。其中 CONTAINER ID、IMAGE、CREATED、NAMES 大家都比较容易理解，分别表示容器 ID，容器所基于的镜像，容器的创建时间和容器的名称。 结果中的 COMMAND 表示的是容器中主程序 ( 也就是与容器生命周期所绑定进程所关联的程序 ) 的启动命令，这条命令是在镜像内定义的，而容器的启动其实质就是启动这条命令。关于 COMMAND 的更多知识，我们在之后的 Docker 镜像制作中会更详细的解读。 结果中的 STATUS 表示容器所处的状态，其值和我们之前所谈到的状态有所区别，主要是因为这里还记录了其他的一些信息。在这里，常见的状态表示有三种： Created 此时容器已创建，但还没有被启动过。 Up [ Time ] 这时候容器处于正在运行状态，而这里的 Time 表示容器从开始运行到查看时的时间。 Exited ([ Code ]) [ Time ] 容器已经结束运行，这里的 Code 表示容器结束运行时，主程序返回的程序退出码，而 Time 则表示容器结束到查看时的时间。 有些读者有疑问，既然是列出容器，应该为命令取一些带有 ls 字眼的名字，为啥会用类似 Linux 中查看进程的 ps 呢？这其实有一部分历史原因，由于容器并非真的包裹住了进程，而只是隔离了进程，进程还是允许在宿主机操作系统之上的，所以列出镜像的过程到更新是查看正在运行的进程，故而有了这样的名字。 当然，在 Docker 逐渐成熟后，命令的命名也没有原来那么随意了，已经逐渐转换为使用大家广泛认可的形式。只是 docker ps 这条命令，还保留着复古的风格。 停止和删除容器 要将正在运行的容器停止，我们可以使用 docker stop 命令。 $ sudo docker stop nginx 容器停止后，其维持的文件系统沙盒环境还是存在的，内部被修改的内容也都会保留，我们可以通过 docker start 命令将这个容器再次启动。 当我们需要完全删除容器时，可以通过 docker rm 命令将容器进行删除。 $ sudo docker rm nginx 正在运行中的容器默认情况下是不能被删除的，我们可以通过增加 -f 或 --force 选项来让 docker rm 强制停止并删除容器，不过这种做法并不妥当。 随手删除容器 与其他虚拟机不同，Docker 的轻量级容器设计，讲究随用随开，随关随删。也就是说，当我们短时间内不需要使用容器时，最佳的做法是删除它而不是仅仅停止它。 有的读者会问，容器一旦删除，其内部的文件系统变动也就消失了，这样做岂不是非常麻烦。要解决这个疑惑，其根本是解决为什么我们会对容器中的文件系统做更改。我这里总结了两个对虚拟环境做更改的原因，以及在 Docker 中如何优雅的解决它们。 在使用虚拟机或其他虚拟化所搭建的虚拟环境时，我们倾向于使用一个干净的系统镜像并搭建程序的运行环境，由于将这类虚拟环境制作成镜像的成本较高，耗时也非常久，所以我们对于一些细小的改动倾向于修改后保持虚拟环境不被清除即可。而在 Docker 中，打包镜像的成本是非常低的，其速度也快得惊人，所以如果我们要为程序准备一些环境或者配置，完全可以直接将它们打包至新的镜像中，下次直接使用这个新的镜像创建容器即可。 容器中应用程序所产生的一些文件数据，是非常重要的，如果这些数据随着容器的删除而丢失，其损失是非常巨大的。对于这类由应用程序所产生的数据，并且需要保证它们不会随着容器的删除而消失的，我们可以使用 Docker 中的数据卷来单独存放。由于数据卷是独立于容器存在的，所以其能保证数据不会随着容器的删除而丢失。关于数据卷的具体使用，在之后的小节会专门讲解。 解决了这两个问题，大家心中的疑虑是不是就小了很多。而事实上，容器的随用随删既能保证在我们不需要它们的时候它们不会枉占很多资源，也保证了每次我们建立和启动容器时，它们都是“热乎”的崭新版本。大家都知道，系统卡就重装，而借助 Docker 秒级的容器启停特性，我们就是可以这么任性的“重装”。 进入容器 很多时间，我们需要的操作并不仅仅是按镜像所给出的命令启动容器而已，我们还会希望进一步了解容器或操作容器，这时候最佳的方式就是让我们进入到容器了。 我们知道，容器是一个隔离运行环境的东西，它里面除了镜像所规定的主进程外，其他的进程也是能够运行的，Docker 为我们提供了一个命令 docker exec 来让容器运行我们所给出的命令。 这里我们试试用容器中的 more 命令查看容器的主机名定义。 $ sudo docker exec nginx more /etc/hostname :::::::::::::: /etc/hostname :::::::::::::: 83821ea220ed docker exec 命令能帮助我们在正在运行的容器中运行指定命令，这对于服务控制，运维监控等有着不错的应用场景。但是在开发过程中，我们更常使用它来作为我们进入容器的桥梁。 熟悉 Linux 的朋友们知道，我们操作 Linux 这个过程，并不是 Linux 内部的某些机能，而是通过控制台软件来完成的。控制台软件分析我们的命令，将其转化为对 Linux 的系统调用，实现了我们对 Linux 的操作。若不是这样，生涩的系统调用方法对普通开发者来说简直就是黑洞一般的存在，更别提用它们控制系统了。 在 Linux 中，大家熟悉的控制台软件应该是 Shell 和 Bash 了，它们分别由 sh 和 bash 这两个程序启动。 说到这里，有读者一定想到了，既然有这两个控制台程序，我们只要在容器里执行它们，然后通过它们去控制容器内的环境，岂不就可以“自由的飞翔”了吗。没错，这里说的进入容器，就是通过 docker exec 命令来启动 sh 或 bash，并通过它们实现对容器内的虚拟环境的控制。 由于 bash 的功能要比 sh 丰富，所以在能够使用 bash 的容器里，我们优先选择它作为控制台程序。 $ sudo docker exec -it nginx bash root@83821ea220ed:/# 在借助 docker exec 进入容器的时候，我们需要特别注意命令中的两个选项不可或缺，即 -i 和 -t ( 它们俩可以利用简写机制合并成 -it )。 其中 -i ( --interactive ) 表示保持我们的输入流，只有使用它才能保证控制台程序能够正确识别我们的命令。而 -t ( --tty ) 表示启用一个伪终端，形成我们与 bash 的交互，如果没有它，我们无法看到 bash 内部的执行结果。 熟悉通过在容器中执行控制台程序进而进入容器这种方法，在开发过程中你能更轻松的观察容器中发生了什么，也更容易排查程序或者环境引起的问题。 衔接到容器 Docker 为我们提供了一个 docker attach 命令，用于将当前的输入输出流连接到指定的容器上。 $ sudo docker attach nginx 这个命令最直观的效果可以理解为我们将容器中的主程序转为了“前台”运行 ( 与 docker run 中的 -d 选项有相反的意思 )。 由于我们的输入输出流衔接到了容器的主程序上，我们的输入输出操作也就直接针对了这个程序，而我们发送的 Linux 信号也会转移到这个程序上。例如我们可以通过 Ctrl + C 来向程序发送停止信号，让程序停止 ( 从而容器也会随之停止 )。 在实际开发中，由于 docker attach 限制较多，功能也不够强大，所以并没有太多用武之地，这里我们就一笔带过，不做详细的解读了。 留言互动 在本节中，我们对容器相关的操作进行了深入的了解，对容器的运行状态及相关知识做了介绍。这里给大家留一道实践题： 试着创建 Nginx 容器，之后进入到容器中，利用相关命令停止 Nginx 程序的运行，观察操作之后容器的状态变化。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对容器相关的操作与使用还有什么不理解的地方，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/09.使用容器：为容器配置网络.html":{"url":"开发者必备的Docker实践指南/09.使用容器：为容器配置网络.html","title":"09.使用容器：为容器配置网络","keywords":"","body":"为容器配置网络 在互联网时代，网络已经成为绝大多数应用进行数据交换的主要通道，Docker 作为集群部署的利器，在网络支持上也下了许多功夫。功能丰富和强大，并不代表使用复杂，在 Docker 的封装下，我们依然可以通过命令和参数轻松的为容器制定不同的网络方案。在这一节中，我们就来了解 Docker 的网络部分。 容器网络 在之前介绍 Docker 核心组成的时候，我们已经简单谈到了容器网络的相关知识。容器网络实质上也是由 Docker 为应用程序所创造的虚拟环境的一部分，它能让应用从宿主机操作系统的网络环境中独立出来，形成容器自有的网络设备、IP 协议栈、端口套接字、IP 路由表、防火墙等等与网络相关的模块。 还是回归上面这幅之前展示过的关于 Docker 网络的图片。在 Docker 网络中，有三个比较核心的概念，也就是：沙盒 ( Sandbox )、网络 ( Network )、端点 ( Endpoint )。 沙盒提供了容器的虚拟网络栈，也就是之前所提到的端口套接字、IP 路由表、防火墙等的内容。其实现隔离了容器网络与宿主机网络，形成了完全独立的容器网络环境。 网络可以理解为 Docker 内部的虚拟子网，网络内的参与者相互可见并能够进行通讯。Docker 的这种虚拟网络也是于宿主机网络存在隔离关系的，其目的主要是形成容器间的安全通讯环境。 端点是位于容器或网络隔离墙之上的洞，其主要目的是形成一个可以控制的突破封闭的网络环境的出入口。当容器的端点与网络的端点形成配对后，就如同在这两者之间搭建了桥梁，便能够进行数据传输了。 这三者形成了 Docker 网络的核心模型，也就是容器网络模型 ( Container Network Model )。 浅析 Docker 的网络实现 容器网络模型为容器引擎提供了一套标准的网络对接范式，而在 Docker 中，实现这套范式的是 Docker 所封装的 libnetwork 模块。 而对于网络的具体实现，在 Docker 的发展过程中也逐渐抽象，形成了统一的抽象定义。进而通过这些抽象定义，便可以对 Docker 网络的实现方式进行不同的变化。 目前 Docker 官方为我们提供了五种 Docker 网络驱动，分别是：Bridge Driver、Host Driver、Overlay Driver、MacLan Driver、None Driver。 其中，Bridge 网络是 Docker 容器的默认网络驱动，简而言之其就是通过网桥来实现网络通讯 ( 网桥网络的实现可以基于硬件，也可以基于软件 )。而 Overlay 网络是借助 Docker 集群模块 Docker Swarm 来搭建的跨 Docker Daemon 网络，我们可以通过它搭建跨物理主机的虚拟网络，进而让不同物理机中运行的容器感知不到多个物理机的存在。 Bridge Driver 和 Overlay Driver 在开发中使用频率较高，之后的小节讲解里，关于容器网络的部分我们都主要围绕着它们展开。 当然，关于 Docker 的网络实现还有非常多的细节。对于开发者来说，我们只是 Docker 的使用者而非技术专家，所以这里我们不做更多详尽的论述。 容器互联 由于 Docker 提倡容器与应用共生的轻量级容器理念，所以容器中通常只包含一种应用程序，但我们知道，如今纷繁的系统服务，没有几个是可以通过单一的应用程序支撑的。拿最简单的 Web 应用为例，也至少需要业务应用、数据库应用、缓存应用等组成。也就是说，在 Docker 里我们需要通过多个容器来组成这样的系统。 而这些互联网时代的应用，其间的通讯方式主要以网络为主，所以打通容器间的网络，是使它们能够互相通讯的关键所在。 要让一个容器连接到另外一个容器，我们可以在容器通过 docker create 或 docker run 创建时通过 --link 选项进行配置。 例如，这里我们创建一个 MySQL 容器，将运行我们 Web 应用的容器连接到这个 MySQL 容器上，打通两个容器间的网络，实现它们之间的网络互通。 $ sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes mysql $ sudo docker run -d --name webapp --link mysql webapp:latest 容器间的网络已经打通，那么我们要如何在 Web 应用中连接到 MySQL 数据库呢？Docker 为容器间连接提供了一种非常友好的方式，我们只需要将容器的网络命名填入到连接地址中，就可以访问需要连接的容器了。 假设我们在 Web 应用中使用的是 JDBC 进行数据库连接的，我们可以这么填写连接。 String url = \"jdbc:mysql://mysql:3306/webapp\"; 在这里，连接地址中的 mysql 就好似我们常见的域名解析，Docker 会将其指向 MySQL 容器的 IP 地址。 看到这里，读者们有没有发现 Docker 在容器互通中为我们带来的一项便利，也就是我们不再需要真实的知道另外一个容器的 IP 地址就能进行连接。再具体来对比，在以往的开发中，我们每切换一个环境 ( 例如将程序从开发环境提交到测试环境 )，都需要重新配置程序中的各项连接地址等参数，而在 Docker 里，我们并不需要关心这个，只需要程序中配置被连接容器的别名，映射 IP 的工作就交给 Docker 完成了。 暴露端口 需要注意的是，虽然容器间的网络打通了，但并不意味着我们可以任意访问被连接容器中的任何服务。Docker 为容器网络增加了一套安全机制，只有容器自身允许的端口，才能被其他容器所访问。 这个容器自我标记端口可被访问的过程，我们通常称为暴露端口。我们在 docker ps 的结果中可以看到容器暴露给其他容器访问的端口。 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 95507bc88082 mysql:5.7 \"docker-entrypoint.s…\" 17 seconds ago Up 16 seconds 3306/tcp, 33060/tcp mysql 这里我们看到，MySQL 这个容器暴露的端口是 3306 和 33060。所以我们连接到 MySQL 容器后，只能对这两个端口进行访问。 端口的暴露可以通过 Docker 镜像进行定义，也可以在容器创建时进行定义。在容器创建时进行定义的方法是借助 --expose 这个选项。 $ sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes --expose 13306 --expose 23306 mysql:5.7 这里我们为 MySQL 暴露了 13306 和 23306 这两个端口，暴露后我们可以在 docker ps 中看到这两个端口已经成功的打开。 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 3c4e645f21d7 mysql:5.7 \"docker-entrypoint.s…\" 4 seconds ago Up 3 seconds 3306/tcp, 13306/tcp, 23306/tcp, 33060/tcp mysql 容器暴露了端口只是类似我们打开了容器的防火墙，具体能不能通过这个端口访问容器中的服务，还需要容器中的应用监听并处理来自这个端口的请求。 通过别名连接 纯粹的通过容器名来打开容器间的网络通道缺乏一定的灵活性，在 Docker 里还支持连接时使用别名来使我们摆脱容器名的限制。 $ sudo docker run -d --name webapp --link mysql:database webapp:latest 在这里，我们使用 --link : 的形式，连接到 MySQL 容器，并设置它的别名为 database。当我们要在 Web 应用中使用 MySQL 连接时，我们就可以使用 database 来代替连接地址了。 String url = \"jdbc:mysql://database:3306/webapp\"; 管理网络 容器能够互相连接的前提是两者同处于一个网络中 ( 这里的网络是指容器网络模型中的网络 )。这个限制很好理解，刚才我们说了，网络这个概念我们可以理解为 Docker 所虚拟的子网，而容器网络沙盒可以看做是虚拟的主机，只有当多个主机在同一子网里时，才能互相看到并进行网络数据交换。 当我们启动 Docker 服务时，它会为我们创建一个默认的 bridge 网络，而我们创建的容器在不专门指定网络的情况下都会连接到这个网络上。所以我们刚才之所以能够把 webapp 容器连接到 mysql 容器上，其原因是两者都处于 bridge 这个网络上。 我们通过 docker inspect 命令查看容器，可以在 Network 部分看到容器网络相关的信息。 $ sudo docker inspect mysql [ { ## ...... \"NetworkSettings\": { ## ...... \"Networks\": { \"bridge\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": null, \"NetworkID\": \"bc14eb1da66b67c7d155d6c78cb5389d4ffa6c719c8be3280628b7b54617441b\", \"EndpointID\": \"1e201db6858341d326be4510971b2f81f0f85ebd09b9b168e1df61bab18a6f22\", \"Gateway\": \"172.17.0.1\", \"IPAddress\": \"172.17.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:11:00:02\", \"DriverOpts\": null } } ## ...... } ## ...... } ] 这里我们能够看到 mysql 容器在 bridge 网络中所分配的 IP 地址，其自身的端点、Mac 地址，bridge 网络的网关地址等信息。 Docker 默认创建的这个 bridge 网络是非常重要的，理由自然是在没有明确指定容器网络时，容器都会连接到这个网络中。在之前讲解 Docker for Win 和 Docker for Mac 安装的时候，我们提到过这两个软件的配置中都有一块配置 Docker 中默认网络的内容，这块所指的默认网络就是这个 bridge 网络。 创建网络 在 Docker 里，我们也能够创建网络，形成自己定义虚拟子网的目的。 docker CLI 里与网络相关的命令都以 docker network 开头，其中创建网络的命令是 docker network create。 $ sudo docker network create -d bridge individual 通过 -d 选项我们可以为新的网络指定驱动的类型，其值可以是刚才我们所提及的 bridge、host、overlay、maclan、none，也可以是其他网络驱动插件所定义的类型。这里我们使用的是 Bridge Driver ( 当我们不指定网络驱动时，Docker 也会默认采用 Bridge Driver 作为网络驱动 )。 通过 docker network ls 或是 docker network list 可以查看 Docker 中已经存在的网络。 $ sudo docker network ls NETWORK ID NAME DRIVER SCOPE bc14eb1da66b bridge bridge local 35c3ef1cc27d individual bridge local 之后在我们创建容器时，可以通过 --network 来指定容器所加入的网络，一旦这个参数被指定，容器便不会默认加入到 bridge 这个网络中了 ( 但是仍然可以通过 --network bridge 让其加入 )。 $ sudo docker run -d --name mysql -e MYSQL_RANDOM_ROOT_PASSWORD=yes --network individual mysql:5.7 我们通过 docker inspect 观察一下此时的容器网络。 $ sudo docker inspect mysql [ { ## ...... \"NetworkSettings\": { ## ...... \"Networks\": { \"individual\": { \"IPAMConfig\": null, \"Links\": null, \"Aliases\": [ \"2ad678e6d110\" ], \"NetworkID\": \"35c3ef1cc27d24e15a2b22bdd606dc28e58f0593ead6a57da34a8ed989b1b15d\", \"EndpointID\": \"41a2345b913a45c3c5aae258776fcd1be03b812403e249f96b161e50d66595ab\", \"Gateway\": \"172.18.0.1\", \"IPAddress\": \"172.18.0.2\", \"IPPrefixLen\": 16, \"IPv6Gateway\": \"\", \"GlobalIPv6Address\": \"\", \"GlobalIPv6PrefixLen\": 0, \"MacAddress\": \"02:42:ac:12:00:02\", \"DriverOpts\": null } } ## ...... } ## ...... } ] 可以看到，容器所加入网络已经变成了 individual 这个网络了。 这时候我们通过 --link 让处于另外一个网络的容器连接到这个容器上，看看会发生什么样的效果。 $ sudo docker run -d --name webapp --link mysql --network bridge webapp:latest docker: Error response from daemon: Cannot link to /mysql, as it does not belong to the default network. ERRO[0000] error waiting for container: context canceled 可以看到容器并不能正常的启动，而 Docker 提醒我们两个容器处于不同的网络，之间是不能相互连接引用的。 我们来改变一下，让运行 Web 应用的容器加入到 individual 这个网络，就可以成功建立容器间的网络连接了。 $ sudo docker run -d --name webapp --link mysql --network individual webapp:latest 端口映射 刚才我们提及的都是容器直接通过 Docker 网络进行的互相访问，在实际使用中，还有一个非常常见的需求，就是我们需要在容器外通过网络访问容器中的应用。最简单的一个例子，我们提供了 Web 服务，那么我们就需要提供一种方式访问运行在容器中的 Web 应用。 在 Docker 中，提供了一个端口映射的功能实现这样的需求。 通过 Docker 端口映射功能，我们可以把容器的端口映射到宿主操作系统的端口上，当我们从外部访问宿主操作系统的端口时，数据请求就会自动发送给与之关联的容器端口。 要映射端口，我们可以在创建容器时使用 -p 或者是 --publish 选项。 $ sudo docker run -d --name nginx -p 80:80 -p 443:443 nginx:1.12 使用端口映射选项的格式是 -p ::，其中 ip 是宿主操作系统的监听 ip，可以用来控制监听的网卡，默认为 0.0.0.0，也就是监听所有网卡。host-port 和 container-port 分别表示映射到宿主操作系统的端口和容器的端口，这两者是可以不一样的，我们可以将容器的 80 端口映射到宿主操作系统的 8080 端口，传入 -p 8080:80 即可。 我们可以在容器列表里看到端口映射的配置。 $ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES bc79fc5d42a6 nginx:1.12 \"nginx -g 'daemon of…\" 4 seconds ago Up 2 seconds 0.0.0.0:80->80/tcp, 0.0.0.0:443->443/tcp nginx 打印的结果里用 -> 标记了端口的映射关系。 在 Windows 和 macOS 中使用映射 Docker 的端口映射功能是将容器端口映射到宿主操作系统的端口上，实际来说就是映射到了 Linux 系统的端口上。而我们知道，在 Windows 和 macOS 中运行的 Docker，其 Linux 环境是被虚拟出来的，如果我们仅仅是将端口映射到 Linux 上，由于虚拟环境还有一层隔离，我们依然不能通过 Windows 或 macOS 的端口来访问容器。 解决这种问题的方法很简单，只需要再加一次映射，将虚拟 Linux 系统中的端口映射到 Windows 或 macOS 的端口即可。 如果我们使用 Docker for Windows 或 Docker for Mac，这个端口映射的操作程序会自动帮助我们完成，所以我们不需要做任何额外的事情，就能够直接使用 Windows 或 macOS 的端口访问容器端口了。 而当我们使用 Docker Toolbox 时，由于其自动化能力比较差，所以需要我们在 VirtualBox 里单独配置这个操作系统端口到 Linux 端口的映射关系。 在 VirtualBox 配置中的端口转发一栏里，进行相关的配置即可。 留言互动 在本节中，我们了解了 Docker 网络相关的知识和操作。这里给大家留一道思考题： 通过 Docker 网络进行的容器互联，与通过宿主机进行端口映射的容器互联有怎样的区别，又各有怎样的优劣？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对容器网络的概念或者使用方法还有什么不解之处，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/10.使用容器：管理和存储数据.html":{"url":"开发者必备的Docker实践指南/10.使用容器：管理和存储数据.html","title":"10.使用容器：管理和存储数据","keywords":"","body":"管理和存储数据 数据是应用程序重要的产出，所以很好的管理和存储数据，是对应用程序劳动结果的尊重。特别是在大数据时代，所有的数据都是重要的资产，保护好数据是每个开发者必须掌握的技能。我们知道，在 Docker 里，容器运行的文件系统处于沙盒环境中，与外界其实是隔离的，那么我们又要如何在 Docker 中合理的通过文件与外界进行数据交换呢？在这一小节中，我们就来介绍 Docker 中与文件数据有关的内容。 数据管理实现方式 Docker 容器中的文件系统于我们这些开发使用者来说，虽然有很多优势，但也有很多弊端，其中显著的两点就是： 沙盒文件系统是跟随容器生命周期所创建和移除的，数据无法直接被持久化存储。 由于容器隔离，我们很难从容器外部获得或操作容器内部文件中的数据。 当然，Docker 很好的解决了这些问题，这主要还是归功于 Docker 容器文件系统是基于 UnionFS。由于 UnionFS 支持挂载不同类型的文件系统到统一的目录结构中，所以我们只需要将宿主操作系统中，文件系统里的文件或目录挂载到容器中，便能够让容器内外共享这个文件。 由于通过这种方式可以互通容器内外的文件，那么文件数据持久化和操作容器内文件的问题就自然而然的解决了。 同时，UnionFS 带来的读写性能损失是可以忽略不计的，所以这种实现可以说是相当优秀的。 挂载方式 基于底层存储实现，Docker 提供了三种适用于不同场景的文件系统挂载方式：Bind Mount、Volume 和 Tmpfs Mount。 Bind Mount 能够直接将宿主操作系统中的目录和文件挂载到容器内的文件系统中，通过指定容器外的路径和容器内的路径，就可以形成挂载映射关系，在容器内外对文件的读写，都是相互可见的。 Volume 也是从宿主操作系统中挂载目录到容器内，只不过这个挂载的目录由 Docker 进行管理，我们只需要指定容器内的目录，不需要关心具体挂载到了宿主操作系统中的哪里。 Tmpfs Mount 支持挂载系统内存中的一部分到容器的文件系统里，不过由于内存和容器的特征，它的存储并不是持久的，其中的内容会随着容器的停止而消失。 挂载文件到容器 要将宿主操作系统中的目录挂载到容器之后，我们可以在容器创建的时候通过传递 -v 或 --volume 选项来指定内外挂载的对应目录或文件。 $ sudo docker run -d --name nginx -v /webapp/html:/usr/share/nginx/html nginx:1.12 使用 -v 或 --volume 来挂载宿主操作系统目录的形式是 -v : 或 --volume :，其中 host-path 和 container-path 分别代表宿主操作系统中的目录和容器中的目录。这里需要注意的是，为了避免混淆，Docker 这里强制定义目录时必须使用绝对路径，不能使用相对路径。 我们能够指定目录进行挂载，也能够指定具体的文件来挂载，具体选择何种形式来挂载，大家可以根据具体的情况来选择。 当挂载了目录的容器启动后，我们可以看到我们在宿主操作系统中的文件已经出现在容器中了。 $ sudo docker exec nginx ls /usr/share/nginx/html index.html 在 docker inspect 的结果里，我们可以看到有关容器数据挂载相关的信息。 $ sudo docker inspect nginx [ { ## ...... \"Mounts\": [ { \"Type\": \"bind\", \"Source\": \"/webapp/html\", \"Destination\": \"/usr/share/nginx/html\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"rprivate\" } ], ## ...... } ] 在关于挂载的信息中我们可以看到一个 RW 字段，这表示挂载目录或文件的读写性 ( Read and Write )。实际操作中，Docker 还支持以只读的方式挂载，通过只读方式挂载的目录和文件，只能被容器中的程序读取，但不接受容器中程序修改它们的请求。在挂载选项 -v 后再接上 :ro 就可以只读挂载了。 $ sudo docker run -d --name nginx -v /webapp/html:/usr/share/nginx/html:ro nginx:1.12 由于宿主操作系统文件挂载在权限允许的情况下能够挂载任何目录或文件，这给系统的安全性造成了一定的隐患，所以我们在使用 Bind Mount 的时候，一定要特别注意挂载的外部目录选择。当然，在保证安全性的前提下，有几种常见场景非常适合使用这种挂载方式。 当我们需要从宿主操作系统共享配置的时候。对于一些配置项，我们可以直接从容器外部挂载到容器中，这利于保证容器中的配置为我们所确认的值，也方便我们对配置进行监控。例如，遇到容器中时区不正确的时候，我们可以直接将操作系统的时区配置，也就是 /etc/timezone 这个文件挂载并覆盖容器中的时区配置。 当我们需要借助 Docker 进行开发的时候。虽然在 Docker 中，推崇直接将代码和配置打包进镜像，以便快速部署和快速重建。但这在开发过程中显然非常不方便，因为每次构建镜像需要耗费一定的时间，这些时间积少成多，就是对开发工作效率的严重浪费了。如果我们直接把代码挂载进入容器，那么我们每次对代码的修改都可以直接在容器外部进行。 挂载临时文件目录 Tmpfs Mount 是一种特殊的挂载方式，它主要利用内存来存储数据。由于内存不是持久性存储设备，所以其带给 Tmpfs Mount 的特征就是临时性挂载。 与挂载宿主操作系统目录或文件不同，挂载临时文件目录要通过 --tmpfs 这个选项来完成。由于内存的具体位置不需要我们来指定，这个选项里我们只需要传递挂载到容器内的目录即可。 $ sudo docker run -d --name webapp --tmpfs /webapp/cache webapp:latest 容器已挂载的临时文件目录我们也可以通过 docker inspect 命令查看。 $ sudo docker inspect webapp [ { ## ...... \"Tmpfs\": { \"/webapp/cache\": \"\" }, ## ...... } ] 挂载临时文件首先要注意它不是持久存储这一特性，在此基础上，它有几种常见的适应场景。 应用中使用到，但不需要进行持久保存的敏感数据，可以借助内存的非持久性和程序隔离性进行一定的安全保障。 读写速度要求较高，数据变化量大，但不需要持久保存的数据，可以借助内存的高读写速度减少操作的时间。 使用数据卷 除了与其他虚拟机工具近似的宿主操作系统目录挂载的功能外，Docker 还创造了数据卷 ( Volume ) 这个概念。数据卷的本质其实依然是宿主操作系统上的一个目录，只不过这个目录存放在 Docker 内部，接受 Docker 的管理。 在使用数据卷进行挂载时，我们不需要知道数据具体存储在了宿主操作系统的何处，只需要给定容器中的哪个目录会被挂载即可。 我们依然可以使用 -v 或 --volume 选项来定义数据卷的挂载。 $ sudo docker run -d --name webapp -v /webapp/storage webapp:latest 数据卷挂载到容器后，我们可以通过 docker inspect 看到容器中数据卷挂载的信息。 $ sudo docker inspect webapp [ { ## ...... \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"2bbd2719b81fbe030e6f446243386d763ef25879ec82bb60c9be7ef7f3a25336\", \"Source\": \"/var/lib/docker/volumes/2bbd2719b81fbe030e6f446243386d763ef25879ec82bb60c9be7ef7f3a25336/_data\", \"Destination\": \"/webapp/storage\", \"Driver\": \"local\", \"Mode\": \"\", \"RW\": true, \"Propagation\": \"\" } ], ## ...... } ] 这里我们所得到的信息与绑定挂载有所区别，除了 Type 中的类型不一样之外，在数据卷挂载中，我们还要关注一下 Name 和 Source 这两个信息。 其中 Source 是 Docker 为我们分配用于挂载的宿主机目录，其位于 Docker 的资源区域 ( 这里是默认的 /var/lib/docker ) 内。当然，我们并不需要关心这个目录，一切对它的管理都已经在 Docker 内实现了。 为了方便识别数据卷，我们可以像命名容器一样为数据卷命名，这里的 Name 就是数据卷的命名。在我们未给出数据卷命名的时候，Docker 会采用数据卷的 ID 命名数据卷。我们也可以通过 -v : 这种形式来命名数据卷。 $ sudo docker run -d --name webapp -v appdata:/webapp/storage webapp:latest 由于 -v 选项既承载了 Bind Mount 的定义，又参与了 Volume 的定义，所以其传参方式需要特别留意。前面提到了，-v 在定义绑定挂载时必须使用绝对路径，其目的主要是为了避免与数据卷挂载中命名这种形式的冲突。 虽然与绑定挂载的原理差别不大，但数据卷在许多实际场景下你会发现它很有用。 当希望将数据在多个容器间共享时，利用数据卷可以在保证数据持久性和完整性的前提下，完成更多自动化操作。 当我们希望对容器中挂载的内容进行管理时，可以直接利用数据卷自身的管理方法实现。 当使用远程服务器或云服务作为存储介质的时候，数据卷能够隐藏更多的细节，让整个过程变得更加简单。 共用数据卷 数据卷的另一大作用是实现容器间的目录共享，也就是通过挂载相同的数据卷，让容器之间能够同时看到并操作数据卷中的内容。这个功能虽然也可以通过绑定挂载来实现，但通过数据卷来操作会更加的舒适、简单。 由于数据卷的命名在 Docker 中是唯一的，所以我们很容易通过数据卷的名称确定数据卷，这就让我们很方便的让多个容器挂载同一个数据卷了。 $ sudo docker run -d --name webapp -v html:/webapp/html webapp:latest $ sudo docker run -d --name nginx -v html:/usr/share/nginx/html:ro nginx:1.12 我们使用 -v 选项挂载数据卷时，如果数据卷不存在，Docker 会为我们自动创建和分配宿主操作系统的目录，而如果同名数据卷已经存在，则会直接引用。 如果有朋友觉得这样对数据卷的操作方式还不够直接和准确，我们还可以通过 docker volume 下的几个命令专门操作数据卷。 通过 docker volume create 我们可以不依赖于容器独立创建数据卷。 $ sudo docker volume create appdata 通过 docker volume ls 可以列出当前已创建的数据卷。 $ sudo docker volume ls DRIVER VOLUME NAME local html local appdata 删除数据卷 虽然数据卷的目的是用来持久化存储数据的，但有时候我们也难免有删除它们以释放空间的需求。直接去 Docker 的目录下删除显然不是好的选择，我们应该通过 Docker 对数据卷的管理命令来删除它们。 我们可以直接通过 docker volume rm 来删除指定的数据卷。 $ sudo docker volume rm appdata 在删除数据卷之前，我们必须保证数据卷没有被任何容器所使用 ( 也就是之前引用过这个数据卷的容器都已经删除 )，否则 Docker 不会允许我们删除这个数据卷。 对于我们没有直接命名的数据卷，因为要反复核对数据卷 ID，这样的方式并不算特别友好。这种没有命名的数据卷，通常我们可以看成它们与对应的容器产生了绑定，因为其他容器很难使用到它们。而这种绑定关系的产生，也让我们可以在容器删除时将它们一并删除。 在 docker rm 删除容器的命令中，我们可以通过增加 -v 选项来删除容器关联的数据卷。 $ sudo docker rm -v webapp 如果我们没有随容器删除这些数据卷，Docker 在创建新的容器时也不会启用它们，即使它们与新创建容器所定义的数据卷有完全一致的特征。也就是说，此时它们已经变成了孤魂野鬼，纯粹的占用着硬盘空间而又不受管理。 此时我们可以通过 docker volume rm 来删除它们，但前提时你能在一堆乱码般的数据卷 ID 中找出哪个是没有被容器引用的数据卷。 为此，Docker 向我们提供了 docker volume prune 这个命令，它可以删除那些没有被容器引用的数据卷。 $ sudo docker volume prune -f Deleted Volumes: af6459286b5ce42bb5f205d0d323ac11ce8b8d9df4c65909ddc2feea7c3d1d53 0783665df434533f6b53afe3d9decfa791929570913c7aff10f302c17ed1a389 65b822e27d0be93d149304afb1515f8111344da9ea18adc3b3a34bddd2b243c7 ## ...... 数据卷容器 在数据卷的基础上，我们有一种相对新颖的用法，也就是数据卷容器。所谓数据卷容器，就是一个没有具体指定的应用，甚至不需要运行的容器，我们使用它的目的，是为了定义一个或多个数据卷并持有它们的引用。 创建数据卷容器的方式很简单，由于不需要容器本身运行，因而我们找个简单的系统镜像都可以完成创建。 $ sudo docker create --name appdata -v /webapp/storage ubuntu 在使用数据卷容器时，我们不建议再定义数据卷的名称，因为我们可以通过对数据卷容器的引用来完成数据卷的引用。而不设置数据卷的名称，也避免了在同一 Docker 中数据卷重名的尴尬。 之前我们提到，Docker 的 Network 是容器间的网络桥梁，如果做类比，数据卷容器就可以算是容器间的文件系统桥梁。我们可以像加入网络一样引用数据卷容器，只需要在创建新容器时使用专门的 --volumes-from 选项即可。 $ sudo docker run -d --name webapp --volumes-from appdata webapp:latest 引用数据卷容器时，不需要再定义数据卷挂载到容器中的位置，Docker 会以数据卷容器中的挂载定义将数据卷挂载到引用的容器中。 虽然看上去数据卷容器与数据卷的使用方法变化不大，但最关键的就在于其真正隐藏了数据卷的配置和定义，我们只需要通过数据卷容器的名称来使用它。这些细节的隐藏，意味着我们能够更轻松的实现容器的迁移。 备份和迁移数据卷 由于数据卷本身就是宿主操作系统中的一个目录，我们只需要在 Docker 资源目录里找到它就可以很轻松的打包、迁移、恢复了。虽然这么做相对其他虚拟化方案来说已经很简单了，但在 Docker 里还不是最优雅的解决方式。 利用数据卷容器，我们还能够更方便的对数据卷中的数据进行迁移。 数据备份、迁移、恢复的过程可以理解为对数据进行打包，移动到其他位置，在需要的地方解压的过程。在数据打包之前，我们先建立一个用来存放打包文件的目录，这里我们使用 /backup 作为例子。 要备份数据，我们先建立一个临时的容器，将用于备份的目录和要备份的数据卷都挂载到这个容器上。 $ sudo docker run --rm --volumes-from appdata -v /backup:/backup ubuntu tar cvf /backup/backup.tar /webapp/storage 在这条命令中，除了挂载的配置外，我们再注意几个选项。通过 --rm 选项，我们可以让容器在停止后自动删除，而不需要我们再使用容器删除命令来删除它，这对于我们使用一些临时容器很有帮助。在容器所基于的镜像之后，我们还看到了一串命令，也就是 tar cvf /backup/backup.tar /webapp/storage，其实如果我们在镜像定义之后接上命令，可以直接替换掉镜像所定义的主程序启动命令，而去执行这一条命令。在很多场合下，我们还能通过这个方法干很多不同的事情。 在备份后，我们就可以在 /backup 下找到数据卷的备份文件，也就是 backup.tar 了。 如果要恢复数据卷中的数据，我们也可以借助临时容器完成。 $ docker run --rm --volumes-from appdata -v /backup:/backup ubuntu tar xvf /backup/backup.tar -C /webapp/storage --strip 恢复的过程与备份的过程类似，只不过把打包的命令转换为解包的命令而已。 另一个挂载选项 上面我们讲到了使用 -v 选项来挂载存在容易混淆的问题，其主要原因是挂载的方式和配置随着 Docker 的不断发展日渐丰富，而 -v 选项的传参方式限制了它能使用的场景。 其实在 Docker 里为我们提供了一个相对支持丰富的挂载方式，也就是通过 --mount 这个选项配置挂载。 $ sudo docker run -d --name webapp webapp:latest --mount 'type=volume,src=appdata,dst=/webapp/storage,volume-driver=local,volume-opt=type=nfs,volume-opt=device=:' webapp:latest 在 --mount 中，我们可以通过逗号分隔这种 CSV 格式来定义多个参数。其中，通过 type 我们可以定义挂载类型，其值可以是：bind，volume 或 tmpfs。另外，--mount 选项能够帮助我们实现集群挂载的定义，例如在这个例子中，我们挂载的来源是一个 NFS 目录。 由于在实际开发中，-v 基本上足够满足我们的需求，所以我们不常使用相对复杂的 --mount 选项来定义挂载，这里我们只是将它简单介绍，供大家参考。 留言互动 在本节中，我们介绍了关于如何在 Docker 中管理和存储数据的方法。这里给大家留一道实践题： 结合我们所提到三种挂载方式各自的适用场景，分别尝试使用它们进行数据挂载。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 中的数据挂载还有不理解的地方，或者对其有独特的见解，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/11.操作镜像：保存和共享镜像.html":{"url":"开发者必备的Docker实践指南/11.操作镜像：保存和共享镜像.html","title":"11.操作镜像：保存和共享镜像","keywords":"","body":"保存和共享镜像 让 Docker 引以为傲的是它能够实现相比于其他虚拟化软件更快的环境迁移和部署，在这件事情上，轻量级的容器和镜像结构的设计无疑发挥了巨大的作用。通过将容器打包成镜像，再利用体积远小于其他虚拟化软件的 Docker 镜像，我们可以更快的将它们复制到其他的机器上。在这一节中，我们就专门来谈谈如何进行这样的迁移。 提交容器更改 之前我们已经介绍过了，Docker 镜像的本质是多个基于 UnionFS 的镜像层依次挂载的结果，而容器的文件系统则是在以只读方式挂载镜像后增加的一个可读可写的沙盒环境。 基于这样的结构，Docker 中为我们提供了将容器中的这个可读可写的沙盒环境持久化为一个镜像层的方法。更浅显的说，就是我们能够很轻松的在 Docker 里将容器内的修改记录下来，保存为一个新的镜像。 将容器修改的内容保存为镜像的命令是 docker commit，由于镜像的结构很像代码仓库里的修改记录，而记录容器修改的过程又像是在提交代码，所以这里我们更形象的称之为提交容器的更改。 $ sudo docker commit webapp sha256:0bc42f7ff218029c6c4199ab5c75ab83aeaaed3b5c731f715a3e807dda61d19e Docker 执行将容器内沙盒文件系统记录成镜像层的时候，会先暂停容器的运行，以保证容器内的文件系统处于一个相对稳定的状态，确保数据的一致性。 在使用 docker commit 提交镜像更新后，我们可以得到 Docker 创建的新镜像的 ID，之后我们也能够从本地镜像列表中找到它。 $ sudo docker images REPOSITORY TAG IMAGE ID CREATED SIZE 0bc42f7ff218 3 seconds ago 372MB ## ...... 像通过 Git 等代码仓库软件提交代码一样，我们还能在提交容器更改的时候给出一个提交信息，方便以后查询。 $ sudo docker commit -m \"Configured\" webapp 为镜像命名 在上面的例子里，我们发现提交容器更新后产生的镜像并没 REPOSITORY 和 TAG 的内容，也就是说，这个新的镜像还没有名字。 之前我们谈到过，使用没有名字的镜像并不是很好的选择，因为我们无法直观的看到我们正在使用什么。好在 Docker 为我们提供了一个为镜像取名的命令，也就是 docker tag 命令。 $ sudo docker tag 0bc42f7ff218 webapp:1.0 使用 docker tag 能够为未命名的镜像指定镜像名，也能够对已有的镜像创建一个新的命名。 $ sudo docker tag webapp:1.0 webapp:latest 当我们对未命名的镜像进行命名后，Docker 就不会在镜像列表里继续显示这个镜像，取而代之的是我们新的命名。而如果我们对以后镜像使用 docker tag，旧的镜像依然会存在于镜像列表中。 $ sudo docker images REPOSITORY TAG IMAGE ID CREATED SIZE webapp 1.0 0bc42f7ff218 29 minutes ago 372MB webapp latest 0bc42f7ff218 29 minutes ago 372MB ## ...... 由于镜像是对镜像层的引用记录，所以我们对镜像进行命名后，虽然能够在镜像列表里同时看到新老两个镜像，实质是它们其实引用着相同的镜像层，这个我们能够从镜像 ID 中看得出来 ( 因为镜像 ID 就是最上层镜像层的 ID )。正是这个原因，我们虽然创建了新的镜像，但对物理存储的占用空间却不是镜像大小直接翻倍，并且创建也在霎那之间。 除了使用 docker tag 在容器提交为新的镜像后为镜像命名这种方式外，我们还可以直接在 docker commit 命令里指定新的镜像名，这种方式在使用容器提交时会更加方便。 $ sudo docker commit -m \"Upgrade\" webapp webapp：2.0 镜像的迁移 在我们将更新导出为镜像后，就可以开始迁移镜像的工作了。 由于 Docker 是以集中的方式管理镜像的，所以在迁移之前，我们要先从 Docker 中取出镜像。docker save 命令可以将镜像输出，提供了一种让我们保存镜像到 Docker 外部的方式。 $ sudo docker save webapp:1.0 > webapp-1.0.tar 在默认定义下，docker save 命令会将镜像内容放入输出流中，这就需要我们使用管道进行接收 ( 也就是命令中的 > 符号 )，这属于 Linux 等系统控制台中的用法，这里我们不做详细讲解。 管道这种用法有时候依然不太友好，docker save 命令还为我们提供了 -o 选项，用来指定输出文件，使用这个选项可以让命令更具有统一性。 $ sudo docker save -o ./webapp-1.0.tar webapp:1.0 在镜像导出之后，我们就可以找到已经存储镜像内容的 webapp-1.0.tar 这个文件了。有兴趣的朋友，可以使用解压软件查看其中的内容，你会看到里面其实就是镜像所基于的几个镜像层的记录文件。 导入镜像 我们可以通过很多种方式将导出的镜像文件复制到另一台机器上，在这么操作之后，我们就要将镜像导入到这台新机器中运行的 Docker 中。 导入镜像的方式也很简单，使用与 docker save 相对的 docker load 命令即可。 $ sudo docker load 相对的，docker load 命令是从输入流中读取镜像的数据，所以我们这里也要使用管道来传输内容。当然，我们也能够使用 -i 选项指定输入文件。 $ sudo docker load -i webapp-1.0.tar 镜像导入后，我们就可以通过 docker images 看到它了，导入的镜像会延用原有的镜像名称。 批量迁移 通过 docker save 和 docker load 命令我们还能够批量迁移镜像，只要我们在 docker save 中传入多个镜像名作为参数，它就能够将这些镜像都打成一个包，便于我们一次性迁移多个镜像。 $ sudo docker save -o ./images.tar webapp:1.0 nginx:1.12 mysql:5.7 装有多个镜像的包可以直接被 docker load 识别和读取，我们将这个包导入后，所有其中装载的镜像都会被导入到 Docker 之中。 导出和导入容器 也许 Docker 的开发者认为，提交镜像修改，再导出镜像进行迁移的方法还不够效率，所以还为我们提供了一个导出容器的方法。 使用 docker export 命令我们可以直接导出容器，我们可以把它简单的理解为 docker commit 与 docker save 的结合体。 $ sudo docker export -o ./webapp.tar webapp 相对的，使用 docker export 导出的容器包，我们可以使用 docker import 导入。这里需要注意的是，使用 docker import 并非直接将容器导入，而是将容器运行时的内容以镜像的形式导入。所以导入的结果其实是一个镜像，而不是容器。在 docker import 的参数里，我们可以给这个镜像命名。 $ sudo docker import ./webapp.tar webapp:1.0 在开发的过程中，使用 docker save 和 docker load，或者是使用 docker export 和 docker import 都可以达到迁移容器或者镜像的目的。 留言互动 在本节中，我们介绍了关于对 Docker 容器和镜像进行迁移的一些方法。这里给大家留一道思考题： 通过 Docker 进行的集群部署和其他虚拟化形式中的集群部署有怎样的区别，在部署过程中 Docker 又是如何发挥它优势的？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对保存和共享镜像还有疑问，或者有更好的实践角度，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/12.操作镜像：通过Dockerfile创建镜像.html":{"url":"开发者必备的Docker实践指南/12.操作镜像：通过Dockerfile创建镜像.html","title":"12.操作镜像：通过Dockerfile创建镜像","keywords":"","body":"通过 Dockerfile 创建镜像 由于 Docker 镜像的结构优势，使它的占用空间远小于普通的虚拟机镜像，而这就大幅减少了 Docker 镜像在网络或者其他介质中转移所花费的时间，进而提高了我们进行迁移部署的效率。不过，你要是以为这就是 Docker 能够快速部署的终极大招那就大错特错了。在这一小节里，我们将谈到 Docker 特有的镜像构建定义文件，也就是 Dockerfile。通过了解它，你能真正体验一种进行秒级镜像迁移的乐趣。 关于 Dockerfile Dockerfile 是 Docker 中用于定义镜像自动化构建流程的配置文件，在 Dockerfile 中，包含了构建镜像过程中需要执行的命令和其他操作。通过 Dockerfile 我们可以更加清晰、明确的给定 Docker 镜像的制作过程，而由于其仅是简单、小体积的文件，在网络等其他介质中传递的速度极快，能够更快的帮助我们实现容器迁移和集群部署。 通常来说，我们对 Dockerfile 的定义就是针对一个名为 Dockerfile 的文件，其虽然没有扩展名，但本质就是一个文本文件，所以我们可以通过常见的文本编辑器或者 IDE 创建和编辑它。 Dockerfile 的内容很简单，主要以两种形式呈现，一种是注释行，另一种是指令行。 # Comment INSTRUCTION arguments 在 Dockerfile 中，拥有一套独立的指令语法，其用于给出镜像构建过程中所要执行的过程。Dockerfile 里的指令行，就是由指令与其相应的参数所组成。 环境搭建与镜像构建 如果具体来说 Dockerfile 的作用和其实际运转的机制，我们可以用一个我们开发中的常见流程来比较。 在一个完整的开发、测试、部署过程中，程序运行环境的定义通常是由开发人员来进行的，因为他们更加熟悉程序运转的各个细节，更适合搭建适合程序的运行环境。 在这样的前提下，为了方便测试和运维搭建相同的程序运行环境，常用的做法是由开发人员编写一套环境搭建手册，帮助测试人员和运维人员了解环境搭建的流程。 而 Dockerfile 就很像这样一个环境搭建手册，因为其中包含的就是一个构建容器的过程。 而比环境搭建手册更好的是，Dockerfile 在容器体系下能够完成自动构建，既不需要测试和运维人员深入理解环境中各个软件的具体细节，也不需要人工执行每一个搭建流程。 编写 Dockerfile 相对于之前我们介绍的提交容器修改，再进行镜像迁移的方式相比，使用 Dockerfile 进行这项工作有很多优势，我总结了几项尤为突出的。 Dockerfile 的体积远小于镜像包，更容易进行快速迁移和部署。 环境构建流程记录了 Dockerfile 中，能够直观的看到镜像构建的顺序和逻辑。 使用 Dockerfile 来构建镜像能够更轻松的实现自动部署等自动化流程。 在修改环境搭建细节时，修改 Dockerfile 文件要比从新提交镜像来的轻松、简单。 事实上，在实际使用中，我们也很少会选择容器提交这种方法来构建镜像，而是几乎都采用 Dockerfile 来制作镜像。所以说，学会 Dockerfile 的编写是所有熟练使用 Docker 的开发者必须掌握的能力。 纸上得来终觉浅，光说很多关于 Dockerfile 的概念其实对我们开发使用来说意义不大，这里我们直接学习如何编写一个用于构建镜像的 Dockerfile。 首先我们来看一个完整的 Dockerfile 的例子，这是用于构建 Docker 官方所提供的 Redis 镜像的 Dockerfile 文件。 FROM debian:stretch-slim # add our user and group first to make sure their IDs get assigned consistently, regardless of whatever dependencies get added RUN groupadd -r redis && useradd -r -g redis redis # grab gosu for easy step-down from root # https://github.com/tianon/gosu/releases ENV GOSU_VERSION 1.10 RUN set -ex; \\ \\ fetchDeps=\" \\ ca-certificates \\ dirmngr \\ gnupg \\ wget \\ \"; \\ apt-get update; \\ apt-get install -y --no-install-recommends $fetchDeps; \\ rm -rf /var/lib/apt/lists/*; \\ \\ dpkgArch=\"$(dpkg --print-architecture | awk -F- '{ print $NF }')\"; \\ wget -O /usr/local/bin/gosu \"https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch\"; \\ wget -O /usr/local/bin/gosu.asc \"https://github.com/tianon/gosu/releases/download/$GOSU_VERSION/gosu-$dpkgArch.asc\"; \\ export GNUPGHOME=\"$(mktemp -d)\"; \\ gpg --keyserver ha.pool.sks-keyservers.net --recv-keys B42F6819007F00F88E364FD4036A9C25BF357DD4; \\ gpg --batch --verify /usr/local/bin/gosu.asc /usr/local/bin/gosu; \\ gpgconf --kill all; \\ rm -r \"$GNUPGHOME\" /usr/local/bin/gosu.asc; \\ chmod +x /usr/local/bin/gosu; \\ gosu nobody true; \\ \\ apt-get purge -y --auto-remove $fetchDeps ENV REDIS_VERSION 3.2.12 ENV REDIS_DOWNLOAD_URL http://download.redis.io/releases/redis-3.2.12.tar.gz ENV REDIS_DOWNLOAD_SHA 98c4254ae1be4e452aa7884245471501c9aa657993e0318d88f048093e7f88fd # for redis-sentinel see: http://redis.io/topics/sentinel RUN set -ex; \\ \\ buildDeps=' \\ wget \\ \\ gcc \\ libc6-dev \\ make \\ '; \\ apt-get update; \\ apt-get install -y $buildDeps --no-install-recommends; \\ rm -rf /var/lib/apt/lists/*; \\ \\ wget -O redis.tar.gz \"$REDIS_DOWNLOAD_URL\"; \\ echo \"$REDIS_DOWNLOAD_SHA *redis.tar.gz\" | sha256sum -c -; \\ mkdir -p /usr/src/redis; \\ tar -xzf redis.tar.gz -C /usr/src/redis --strip-components=1; \\ rm redis.tar.gz; \\ \\ # disable Redis protected mode [1] as it is unnecessary in context of Docker # (ports are not automatically exposed when running inside Docker, but rather explicitly by specifying -p / -P) # [1]: https://github.com/antirez/redis/commit/edd4d555df57dc84265fdfb4ef59a4678832f6da grep -q '^#define CONFIG_DEFAULT_PROTECTED_MODE 1$' /usr/src/redis/src/server.h; \\ sed -ri 's!^(#define CONFIG_DEFAULT_PROTECTED_MODE) 1$!\\1 0!' /usr/src/redis/src/server.h; \\ grep -q '^#define CONFIG_DEFAULT_PROTECTED_MODE 0$' /usr/src/redis/src/server.h; \\ # for future reference, we modify this directly in the source instead of just supplying a default configuration flag because apparently \"if you specify any argument to redis-server, [it assumes] you are going to specify everything\" # see also https://github.com/docker-library/redis/issues/4#issuecomment-50780840 # (more exactly, this makes sure the default behavior of \"save on SIGTERM\" stays functional by default) \\ make -C /usr/src/redis -j \"$(nproc)\"; \\ make -C /usr/src/redis install; \\ \\ rm -r /usr/src/redis; \\ \\ apt-get purge -y --auto-remove $buildDeps RUN mkdir /data && chown redis:redis /data VOLUME /data WORKDIR /data COPY docker-entrypoint.sh /usr/local/bin/ ENTRYPOINT [\"docker-entrypoint.sh\"] EXPOSE 6379 CMD [\"redis-server\"] 其中可以很明确的见到我们之前说的 Dockerfile 文件的两种行结构，也就是指令行和注释行，接下来我们着重关注指令行，因为这是构建镜像的关键。 Dockerfile 的结构 总体上来说，我们可以将 Dockerfile 理解为一个由上往下执行指令的脚本文件。当我们调用构建命令让 Docker 通过我们给出的 Dockerfile 构建镜像时，Docker 会逐一按顺序解析 Dockerfile 中的指令，并根据它们不同的含义执行不同的操作。 如果进行细分，我们可以将 Dockerfile 的指令简单分为五大类。 基础指令：用于定义新镜像的基础和性质。 控制指令：是指导镜像构建的核心部分，用于描述镜像在构建过程中需要执行的命令。 引入指令：用于将外部文件直接引入到构建镜像内部。 执行指令：能够为基于镜像所创建的容器，指定在启动时需要执行的脚本或命令。 配置指令：对镜像以及基于镜像所创建的容器，可以通过配置指令对其网络、用户等内容进行配置。 这五类命令并非都会出现在一个 Dockerfile 里，但却对基于这个 Dockerfile 所构建镜像形成不同的影响。 常见 Dockerfile 指令 熟悉 Dockerfile 的指令是编写 Dockerfile 的前提，这里我们先来介绍几个最常见的 Dockerfile 指令，它们基本上囊括了所有 Dockerfile 中 90% 以上的工作。 FROM 通常来说，我们不会从零开始搭建一个镜像，而是会选择一个已经存在的镜像作为我们新镜像的基础，这种方式能够大幅减少我们的时间。 在 Dockerfile 里，我们可以通过 FROM 指令指定一个基础镜像，接下来所有的指令都是基于这个镜像所展开的。在镜像构建的过程中，Docker 也会先获取到这个给出的基础镜像，再从这个镜像上进行构建操作。 FROM 指令支持三种形式，不管是哪种形式，其核心逻辑就是指出能够被 Docker 识别的那个镜像，好让 Docker 从那个镜像之上开始构建工作。 FROM [AS ] FROM [:] [AS ] FROM [@] [AS ] 既然选择一个基础镜像是构建新镜像的根本，那么 Dockerfile 中的第一条指令必须是 FROM 指令，因为没有了基础镜像，一切构建过程都无法开展。 当然，一个 Dockerfile 要以 FROM 指令作为开始并不意味着 FROM 只能是 Dockerfile 中的第一条指令。在 Dockerfile 中可以多次出现 FROM 指令，当 FROM 第二次或者之后出现时，表示在此刻构建时，要将当前指出镜像的内容合并到此刻构建镜像的内容里。这对于我们直接合并两个镜像的功能很有帮助。 RUN 镜像的构建虽然是按照指令执行的，但指令只是引导，最终大部分内容还是控制台中对程序发出的命令，而 RUN 指令就是用于向控制台发送命令的指令。 在 RUN 指令之后，我们直接拼接上需要执行的命令，在构建时，Docker 就会执行这些命令，并将它们对文件系统的修改记录下来，形成镜像的变化。 RUN RUN [\"executable\", \"param1\", \"param2\"] RUN 指令是支持 \\ 换行的，如果单行的长度过长，建议对内容进行切割，方便阅读。而事实上，我们会经常看到 \\ 分割的命令，例如在上面我们贴出的 Redis 镜像的 Dockerfile 里。 ENTRYPOINT 和 CMD 基于镜像启动的容器，在容器启动时会根据镜像所定义的一条命令来启动容器中进程号为 1 的进程。而这个命令的定义，就是通过 Dockerfile 中的 ENTRYPOINT 和 CMD 实现的。 ENTRYPOINT [\"executable\", \"param1\", \"param2\"] ENTRYPOINT command param1 param2 CMD [\"executable\",\"param1\",\"param2\"] CMD [\"param1\",\"param2\"] CMD command param1 param2 ENTRYPOINT 指令和 CMD 指令的用法近似，都是给出需要执行的命令，并且它们都可以为空，或者说是不在 Dockerfile 里指出。 当 ENTRYPOINT 与 CMD 同时给出时，CMD 中的内容会作为 ENTRYPOINT 定义命令的参数，最终执行容器启动的还是 ENTRYPOINT 中给出的命令。 关于 ENTRYPOINT 和 CMD 的更详细对比，在后一节里我们会提到。 EXPOSE 在第 9 节：为容器配置网络中，在未做特殊定义的前提下，我们直接连接容器网络，只能访问容器明确暴露的端口。而我们之前介绍的是在容器创建时通过选项来暴露这些端口。 由于我们构建镜像时更了解镜像中应用程序的逻辑，也更加清楚它需要接收和处理来自哪些端口的请求，所以在镜像中定义端口暴露显然是更合理的做法。 通过 EXPOSE 指令就可以为镜像指定要暴露的端口。 EXPOSE [/...] 当我们通过 EXPOSE 指令配置了镜像的端口暴露定义，那么基于这个镜像所创建的容器，在被其他容器通过 --link 选项连接时，就能够直接允许来自其他容器对这些端口的访问了。 VOLUME 在一些程序里，我们需要持久化一些数据，比如数据库中存储数据的文件夹就需要单独处理。在之前的小节里，我们提到可以通过数据卷来处理这些问题。 但使用数据卷需要我们在创建容器时通过 -v 选项来定义，而有时候由于镜像的使用者对镜像了解程度不高，会漏掉数据卷的创建，从而引起不必要的麻烦。 还是那句话，制作镜像的人是最清楚镜像中程序工作的各项流程的，所以它来定义数据卷也是最合适的。所以在 Dockerfile 里，提供了 VOLUME 指令来定义基于此镜像的容器所自动建立的数据卷。 VOLUME [\"/data\"] 在 VOLUME 指令中定义的目录，在基于新镜像创建容器时，会自动建立为数据卷，不需要我们再单独使用 -v 选项来配置了。 COPY 和 ADD 在制作新的镜像的时候，我们可能需要将一些软件配置、程序代码、执行脚本等直接导入到镜像内的文件系统里，使用 COPY 或 ADD 指令能够帮助我们直接从宿主机的文件系统里拷贝内容到镜像里的文件系统中。 COPY [--chown=:] ... ADD [--chown=:] ... COPY [--chown=:] [\"\",... \"\"] ADD [--chown=:] [\"\",... \"\"] COPY 与 ADD 指令的定义方式完全一样，需要注意的仅是当我们的目录中存在空格时，可以使用后两种格式避免空格产生歧义。 对比 COPY 与 ADD，两者的区别主要在于 ADD 能够支持使用网络端的 URL 地址作为 src 源，并且在源文件被识别为压缩包时，自动进行解压，而 COPY 没有这两个能力。 虽然看上去 COPY 能力稍弱，但对于那些不希望源文件被解压或没有网络请求的场景，COPY 指令是个不错的选择。 构建镜像 在编写好 Dockerfile 之后，我们就可以构建我们所定义的镜像了，构建镜像的命令为 docker build。 $ sudo docker build ./webapp docker build 可以接收一个参数，需要特别注意的是，这个参数为一个目录路径 ( 本地路径或 URL 路径 )，而并非 Dockerfile 文件的路径。在 docker build 里，这个我们给出的目录会作为构建的环境目录，我们很多的操作都是基于这个目录进行的。 例如，在我们使用 COPY 或是 ADD 拷贝文件到构建的新镜像时，会以这个目录作为基础目录。 在默认情况下，docker build 也会从这个目录下寻找名为 Dockerfile 的文件，将它作为 Dockerfile 内容的来源。如果我们的 Dockerfile 文件路径不在这个目录下，或者有另外的文件名，我们可以通过 -f 选项单独给出 Dockerfile 文件的路径。 $ sudo docker build -t webapp:latest -f ./webapp/a.Dockerfile ./webapp 当然，在构建时我们最好总是携带上 -t 选项，用它来指定新生成镜像的名称。 $ sudo docker build -t webapp:latest ./webapp 留言互动 在本节中，我们介绍了关于 Dockerfile 以及关于它基本使用方面的内容。这里给大家留一道实践题： 编写一个你自己的程序的 Dockerfile，并将它共享给测试和运维人员。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Dockerfile 的基本使用还有疑问，或者有更好的实践角度，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/13.操作镜像：常见的Dockerfile使用技巧.html":{"url":"开发者必备的Docker实践指南/13.操作镜像：常见的Dockerfile使用技巧.html","title":"13.操作镜像：常见的Dockerfile使用技巧","keywords":"","body":"常见 Dockerfile 使用技巧 在掌握 Dockerfile 的基本使用方法后，我们再来了解一些在开发中使用 Dockerfile 的技巧。这一小节的展现方式与之前的略有不同，其主要来自阅读收集和我自身在使用中的最佳实践。也许这里面介绍的不是最为标准或是合乎规范的方式，但一定是能够直接帮助大家在开发中使用 Docker 提升生产力的方式。下面就让我们来看看这些关于 Dockerfile 的使用技巧吧。 构建中使用变量 在实际编写 Dockerfile 时，与搭建环境相关的指令会是其中占有大部分比例的指令。在搭建程序所需运行环境时，难免涉及到一些可变量，例如依赖软件的版本，编译的参数等等。我们可以直接将这些数据写入到 Dockerfile 中完全没有问题，有问题的是这些可变量我们会经常调整，在调整时就需要我们到 Dockerfile 中找到它们并进行更改，如果只是简单的 Dockerfile 文件尚且好说，但如果是相对复杂或是存在多处变量的 Dockerfile 文件，这个工作就变得繁琐而让人烦躁了。 在 Dockerfile 里，我们可以用 ARG 指令来建立一个参数变量，我们可以在构建时通过构建指令传入这个参数变量，并且在 Dockerfile 里使用它。 例如，我们希望通过参数变量控制 Dockerfile 中某个程序的版本，在构建时安装我们指定版本的软件，我们可以通过 ARG 定义的参数作为占位符，替换版本定义的部分。 FROM debian:stretch-slim ## ...... ARG TOMCAT_MAJOR ARG TOMCAT_VERSION ## ...... RUN wget -O tomcat.tar.gz \"https://www.apache.org/dyn/closer.cgi?action=download&filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz\" ## ...... 在这个例子里，我们将 Tomcat 的版本号通过 ARG 指令定义为参数变量，在调用下载 Tomcat 包时，使用变量替换掉下载地址中的版本号。通过这样的定义，就可以让我们在不对 Dockerfile 进行大幅修改的前提下，轻松实现对 Tomcat 版本的切换并重新构建镜像了。 如果我们需要通过这个 Dockerfile 文件构建 Tomcat 镜像，我们可以在构建时通过 docker build 的 --build-arg 选项来设置参数变量。 $ sudo docker build --build-arg TOMCAT_MAJOR=8 --build-arg TOMCAT_VERSION=8.0.53 -t tomcat:8.0 ./tomcat 环境变量 环境变量也是用来定义参数的东西，与 ARG 指令相类似，环境变量的定义是通过 ENV 这个指令来完成的。 FROM debian:stretch-slim ## ...... ENV TOMCAT_MAJOR 8 ENV TOMCAT_VERSION 8.0.53 ## ...... RUN wget -O tomcat.tar.gz \"https://www.apache.org/dyn/closer.cgi?action=download&filename=tomcat/tomcat-$TOMCAT_MAJOR/v$TOMCAT_VERSION/bin/apache-tomcat-$TOMCAT_VERSION.tar.gz\" 环境变量的使用方法与参数变量一样，也都是能够直接替换指令参数中的内容。 与参数变量只能影响构建过程不同，环境变量不仅能够影响构建，还能够影响基于此镜像创建的容器。环境变量设置的实质，其实就是定义操作系统环境变量，所以在运行的容器里，一样拥有这些变量，而容器中运行的程序也能够得到这些变量的值。 另一个不同点是，环境变量的值不是在构建指令中传入的，而是在 Dockerfile 中编写的，所以如果我们要修改环境变量的值，我们需要到 Dockerfile 修改。不过即使这样，只要我们将 ENV 定义放在 Dockerfile 前部容易查找的地方，其依然可以很快的帮助我们切换镜像环境中的一些内容。 由于环境变量在容器运行时依然有效，所以运行容器时我们还可以对其进行覆盖，在创建容器时使用 -e 或是 --env 选项，可以对环境变量的值进行修改或定义新的环境变量。 $ sudo docker run -e MYSQL_ROOT_PASSWORD=my-secret-pw -d mysql:5.7 事实上，这种用法在我们开发中是非常常见的。也正是因为这种允许运行时配置的方法存在，环境变量和定义它的 ENV 指令，是我们更常使用的指令，我们会优先选择它们来实现对变量的操作。 关于环境变量是如何能够帮助我们更轻松的处理 Docker 镜像和容器使用等问题，我们会在下一节中进行实际展示，通过例子大家能够更容易理解它的原理。 另外需要说明一点，通过 ENV 指令和 ARG 指令所定义的参数，在使用时都是采用 $ + NAME 这种形式来占位的，所以它们之间的定义就存在冲突的可能性。对于这种场景，大家只需要记住，ENV 指令所定义的变量，永远会覆盖 ARG 所定义的变量，即使它们定时的顺序是相反的。 合并命令 在上一节我们展示的完整的官方 Redis 镜像的 Dockerfile 中，我们会发现 RUN 等指令里会聚合下大量的代码。 事实上，下面两种写法对于搭建的环境来说是没有太大区别的。 RUN apt-get update; \\ apt-get install -y --no-install-recommends $fetchDeps; \\ rm -rf /var/lib/apt/lists/*; RUN apt-get update RUN apt-get install -y --no-install-recommends $fetchDeps RUN rm -rf /var/lib/apt/lists/* 那为什么我们更多见的是第一种形式而非第二种呢？这就要从镜像构建的过程说起了。 看似连续的镜像构建过程，其实是由多个小段组成。每当一条能够形成对文件系统改动的指令在被执行前，Docker 先会基于上条命令的结果启动一个容器，在容器中运行这条指令的内容，之后将结果打包成一个镜像层，如此反复，最终形成镜像。 所以说，我们之前谈到镜像是由多个镜像层叠加而得，而这些镜像层其实就是在我们 Dockerfile 中每条指令所生成的。 了解了这个原理，大家就很容易理解为什么绝大多数镜像会将命令合并到一条指令中，因为这种做法不但减少了镜像层的数量，也减少了镜像构建过程中反复创建容器的次数，提高了镜像构建的速度。 构建缓存 Docker 在镜像构建的过程中，还支持一种缓存策略来提高镜像的构建速度。 由于镜像是多个指令所创建的镜像层组合而得，那么如果我们判断新编译的镜像层与已经存在的镜像层未发生变化，那么我们完全可以直接利用之前构建的结果，而不需要再执行这条构建指令，这就是镜像构建缓存的原理。 那么 Docker 是如何判断镜像层与之前的镜像间不存在变化的呢？这主要参考两个维度，第一是所基于的镜像层是否一样，第二是用于生成镜像层的指令的内容是否一样。 基于这个原则，我们在条件允许的前提下，更建议将不容易发生变化的搭建过程放到 Dockerfile 的前部，充分利用构建缓存提高镜像构建的速度。另外，指令的合并也不宜过度，而是将易变和不易变的过程拆分，分别放到不同的指令里。 在另外一些时候，我们可能不希望 Docker 在构建镜像时使用构建缓存，这时我们可以通过 --no-cache 选项来禁用它。 $ sudo docker build --no-cache ./webapp 搭配 ENTRYPOINT 和 CMD 上一节我们谈到了 ENTRYPOINT 和 CMD 这两个命令，也解释了这两个命令的目的，即都是用来指定基于此镜像所创建容器里主进程的启动命令的。 两个指令的区别在于，ENTRYPOINT 指令的优先级高于 CMD 指令。当 ENTRYPOINT 和 CMD 同时在镜像中被指定时，CMD 里的内容会作为 ENTRYPOINT 的参数，两者拼接之后，才是最终执行的命令。 为了更好的让大家理解，这里索性列出所有的 ENTRYPOINT 与 CMD 的组合，供大家参考。 ENTRYPOINT CMD 实际执行 ENTRYPOINT [\"/bin/ep\", \"arge\"] /bin/ep arge ENTRYPOINT /bin/ep arge /bin/sh -c /bin/ep arge CMD [\"/bin/exec\", \"args\"] /bin/exec args CMD /bin/exec args /bin/sh -c /bin/exec args ENTRYPOINT [\"/bin/ep\", \"arge\"] CMD [\"/bin/exec\", \"argc\"] /bin/ep arge /bin/exec argc ENTRYPOINT [\"/bin/ep\", \"arge\"] CMD /bin/exec args /bin/ep arge /bin/sh -c /bin/exec args ENTRYPOINT /bin/ep arge CMD [\"/bin/exec\", \"argc\"] /bin/sh -c /bin/ep arge /bin/exec argc ENTRYPOINT /bin/ep arge CMD /bin/exec args /bin/sh -c /bin/ep arge /bin/sh -c /bin/exec args 有的读者会存在疑问，既然两者都是用来定义容器启动命令的，为什么还要分成两个，合并为一个指令岂不是更方便吗？ 这其实在于 ENTRYPOINT 和 CMD 设计的目的是不同的。ENTRYPOINT 指令主要用于对容器进行一些初始化，而 CMD 指令则用于真正定义容器中主程序的启动命令。 另外，我们之前谈到创建容器时可以改写容器主程序的启动命令，而这个覆盖只会覆盖 CMD 中定义的内容，而不会影响 ENTRYPOINT 中的内容。 我们依然以之前的 Redis 镜像为例，这是 Redis 镜像中对 ENTRYPOINT 和 CMD 的定义。 ## ...... COPY docker-entrypoint.sh /usr/local/bin/ ENTRYPOINT [\"docker-entrypoint.sh\"] ## ...... CMD [\"redis-server\"] 可以很清晰的看到，CMD 指令定义的正是启动 Redis 的服务程序，而 ENTRYPOINT 使用的是一个外部引入的脚本文件。 事实上，使用脚本文件来作为 ENTRYPOINT 的内容是常见的做法，因为对容器运行初始化的命令相对较多，全部直接放置在 ENTRYPOINT 后会特别复杂。 我们来看看 Redis 中的 ENTRYPOINT 脚本，可以看到其中会根据脚本参数进行一些处理，而脚本的参数，其实就是 CMD 中定义的内容。 #!/bin/sh set -e # first arg is `-f` or `--some-option` # or first arg is `something.conf` if [ \"${1#-}\" != \"$1\" ] || [ \"${1%.conf}\" != \"$1\" ]; then set -- redis-server \"$@\" fi # allow the container to be started with `--user` if [ \"$1\" = 'redis-server' -a \"$(id -u)\" = '0' ]; then find . \\! -user redis -exec chown redis '{}' + exec gosu redis \"$0\" \"$@\" fi exec \"$@\" 这里我们要关注脚本最后的一条命令，也就是 exec \"$@\"。在很多镜像的 ENTRYPOINT 脚本里，我们都会看到这条命令，其作用其实很简单，就是运行一个程序，而运行命令就是 ENTRYPOINT 脚本的参数。反过来，由于 ENTRYPOINT 脚本的参数就是 CMD 指令中的内容，所以实际执行的就是 CMD 里的命令。 所以说，虽然 Docker 对容器启动命令的结合机制为 CMD 作为 ENTRYPOINT 的参数，合并后执行 ENTRYPOINT 中的定义，但实际在我们使用中，我们还会在 ENTRYPOINT 的脚本里代理到 CMD 命令上。 相对来说，Redis 的 ENTRYPOINT 内容还是简单的，在掌握了 ENTRYPOINT 的相关作用后，大家可以尝试阅读和编写一些复杂的 ENTRYPOINT 脚本。 临摹案例 上面提及的几项只是几个比较常见的 Dockerfile 最佳实践，其实在编写 Dockerfile 时，还有很多不成文的小技巧。 想要学好 Dockerfile 的编写，阅读和思考前人的作品是必不可少的。 前面我们介绍了，Docker 官方提供的 Docker Hub 是 Docker 镜像的中央仓库，它除了镜像丰富之外，给我们带来的另一项好处就是其大部分镜像都是能够直接提供 Dockerfile 文件给我们参考的。 要得到镜像的 Dockerfile 文件，我们可以进入到镜像的详情页面，在介绍中，镜像作者们通常会直接把 Dockerfile 的连接放在那里。 除此之外，进入到 Dockerfile 这个栏目下，我们也能够直接看到镜像 Dockerfile 的内容。在页面的右侧，还有进入 Dockerfile 源文件的连接，如果在 Dockerfile 中有引入其他的文件，我们可以通过这个连接访问到。 另外，我自己也制作了一些软件的镜像，大家可以访问 GitHub 上的项目地址，查阅其中的 Dockerfile 内容：https://github.com/cogset 。 留言互动 在本节中，我们介绍了在开发中使用 Dockerfile 的一些技巧。这里给大家留一道思考题： 在常见的镜像构建中，我们如何合理组合 ENTRYPOINT 和 CMD 并分配它们的工作呢？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对上述我们提及的 Dockerfile 使用技巧还有不理解的地方，或者有其他的技巧想要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/14.操作镜像：使用Docker_Hub中的镜像.html":{"url":"开发者必备的Docker实践指南/14.操作镜像：使用Docker_Hub中的镜像.html","title":"14.操作镜像：使用Docker_Hub中的镜像","keywords":"","body":"使用 Docker Hub 中的镜像 自己编写 Dockerfile 能够很好的实现我们想要的程序运行环境，不过如果装有我们想要环境的镜像已经由热心的开发者构建好并共享在 Docker Hub 上，直接使用它们就会远比自己编写 Dockerfile 并进行构建要来的简单的多了。事实上，在开发过程中我们用到的镜像大部分还是直接采用 Docker Hub 中已经存在的镜像的，即使自己编写 Dockerfile，也只是对已有镜像进行简单的改动，很少会从零开始搭建镜像。在这一节中，我们要来看看如何更好地使用 Docker Hub 上由其他开发者共享的镜像。 选择镜像与程序版本 由于 Docker 的容器设计是程序即容器的，所以组成我们服务系统的多个程序一般会搭建在多个容器里，互相之间协作提供服务。例如一套最简单的 Web 服务，我们可能会需要 Java 容器来运行基于 Spring Boot 的程序，需要 MySQL 容器来提供数据库支持，需要 Redis 容器来作为高速 KV 存储等等。装有这些程序的镜像我们都可以很容易的在 Docker Hub 上找到并直接使用，但在我们使用前，光选择镜像还是不够的，我们还得根据需要选择对应程序版本的镜像。 虽然我们常把软件的版本放在 Tag 里作为镜像名的一部分，但对于一些复杂的应用，除了版本外，还存在很多的变量，镜像的维护者们也喜欢将这些变量一同组合到镜像的 Tag 里，所以我们在使用镜像前，一定要先了解不同 Tag 对应的不同内容。 这里我们来看个例子，下面是由 Docker 官方提供的 OpenJDK 镜像的说明页面。 通常来说，镜像的维护者会在镜像介绍中展示出镜像所有的 Tag，如果没有，我们也能够从页面上的 Tags 导航里进入到镜像标签列表页面。 在 OpenJDK 镜像的 Tag 列表里，我们可以看到同样版本号的镜像就存在多种标签。在这些不同的标签上，除了定义 OpenJDK 的版本，还有操作系统，软件提供者等信息。 镜像维护者为我们提供这么多的标签进行选择，其实方便了我们在不同场景下选择不同环境实现细节时，都能直接用到这个镜像，而不需要再单独编写 Dockerfile 并构建。 但是换句话说，正是有这么多不同标签的镜像存在，所以我们在选择的时候，更要仔细认真，找到我们想要的那个镜像。 Alpine 镜像 如果大家多接触几个镜像，就会发现带有 Alpine 的版本是许多镜像中都常见的标签。带有 Alpine 标签的镜像到底是什么样的存在呢？它与相同软件不同标签的镜像又有什么样的区别呢？ 镜像标签中的 Alpine 其实指的是这个镜像内的文件系统内容，是基于 Alpine Linux 这个操作系统的。Alpine Linux 是一个相当精简的操作系统，而基于它的 Docker 镜像可以仅有数 MB 的尺寸。如果软件基于这样的系统镜像之上构建而得，可以想象新的镜像也是十分小巧的。 在 Docker 里，Alpine 系统的镜像到底有多小，我们不妨来与其他系统镜像做一个比较。 操作系统镜像 占用空间 alpine:latest 4.4 MB ubuntu:latest 84.1 MB debian:latest 101 MB centos:latest 200 MB 可以看到，Alpine 系统镜像的尺寸要远小于其他常见的系统镜像。让我们再来比较同一个软件在基于普通系统的镜像和基于 Alpine 系统的镜像后尺寸上的区别。 镜像标签 占用空间 python:3.6-alpine 74.2 MB python:3.6-jessie 697 MB 由于基于 Alpine 系统建立的软件镜像远远小于基于其他系统的软件镜像，它在网络传输上的优势尤为明显。如果我们选择这类的镜像，不但可以节约网络传输的时间，也能减少镜像对硬盘空间的占用。 当然，有优点也会有缺点，Alpine 镜像的缺点就在于它实在过于精简，以至于麻雀虽小，也无法做到五脏俱全了。在 Alpine 中缺少很多常见的工具和类库，以至于如果我们想基于软件 Alpine 标签的镜像进行二次构建，那搭建的过程会相当烦琐。所以如果你想要对软件镜像进行改造，并基于其构建新的镜像，那么 Alpine 镜像不是一个很好的选择 (这时候我们更提倡基于 Ubuntu、Debian、CentOS 这类相对完整的系统镜像来构建)。 对容器进行配置 除了合理选择镜像外，许多镜像还为我们提供了更加方便的功能，这些细节我们通常都可以在镜像的详情里阅读到。 这里我们以 MySQL 为例，看看通常我们是怎样阅读和使用镜像的特殊功能的。 自己安装过 MySQL 的朋友一定知道，搭建 MySQL 最麻烦的地方并不是安装的过程，而是安装后进行初始化配置的过程。就拿更改 root 账号的密码来说，在初始的 MySQL 里就要耗费不少工作量。 如果我们拿到一个 MySQL 镜像，运行起来的 MySQL 也就约等于一个刚刚安装好的程序，面临的正好是复杂的初始化过程。 好在 MySQL 镜像的维护者们为我们打造了一些自动化脚本，通过它们，我们只需要简单的传入几个参数，就能够快速实现对 MySQL 数据库的初始化。 在 MySQL 镜像的详情里，描述了我们要如何传入这些参数来启动 MySQL 容器。 对于 MySQL 镜像来说，进行软件配置的方法是通过环境变量的方式来实现的 ( 在其他的镜像里，还有通过启动命令、挂载等方式来实现的 )。我们只需要通过这些给出的环境变量，就可以初始化 MySQL 的配置了。 例如，我们可以通过下面的命令来直接建立 MySQL 中的用户和数据库。 $ sudo docker run --name mysql -e MYSQL_DATABASE=webapp -e MYSQL_USER=www -e MYSQL_PASSWORD=my-secret-pw -d mysql:5.7 通过这条命令启动的 MySQL 容器，在内部就已经完成了用户的创建和数据库的创建，我们通过 MySQL 客户端就能够直接登录这个用户和访问对应的数据库了。 如果深究 MySQL 是如何实现这样复杂的功能的，大家可以到 MySQL 镜像的 Dockerfile 源码库里，找到 docker-entrypoint.sh 这个脚本，所有的秘密正暗藏在其中。MySQL 正是利用了 ENTRYPOINT 指令进行初始化这种任务安排，对容器中的 MySQL 进行初始化的。 通过 MySQL 镜像这样的逻辑，大家还可以举一反三，了解其他镜像所特用的使用方法，甚至可以参考编写、构建一些能够提供这类方法的 Dockerfile 和镜像。 共享自己的镜像 如果我们希望将我们镜像公开给网络上的开发者们，那通过 Docker Hub 无疑是最佳的方式。 要在 Docker Hub 上共享镜像，我们必须有一个 Docker Hub 的账号，这自不必说了。在登录到我们账号的控制面板后，我们能够找到创建的按钮，在这里选择 Create Automated Build ( 创建自动构建 )。 自动构建镜像是 Docker Hub 为我们提供的一套镜像构建服务，我们只需要提供 Dockerfile 和相关的基本文件，Docker Hub 就能够在云端自动将它们构建成镜像，之后便可以让其他开发者通过 docker pull 命令拉取到这一镜像。 自动构建让不需要我们再用本机进行镜像的构建，既能节约时间，又能享受高速的云端机器构建。 在 Docker Hub 中并不直接存放我们用于构建的 Dockerfile 和相关文件，我们必须将 Docker Hub 账号授权到 GitHub 或是 Bitbucket 来从这些代码库中获取 Dockerfile 和相关文件。 在连接到 GitHub 或 Bitbucket 后，我们就可以选择我们存放 Dockerfile 和相关文件的代码仓库用来创建自动构建了。 在基本信息填写完成，点击创建按钮后，Docker Hub 就会开始根据我们 Dockerfile 的内容构建镜像了。而此时，我们也能够访问我们镜像专有的详情页面了。 在 Build Details 页面里，我们可以看到镜像构建的进度和详细的构建情况。 留言互动 在本节中，我们介绍了如何掌握对 Docker Hub 中不同镜像的使用。这里给大家留一道思考题： 在实际开发中使用网络中由他人共享的 Docker 镜像，我们可以通过哪些内容快速了解这些镜像的使用？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对使用 Docker Hub 由其他网友提供的镜像还有什么不解之处，或者有具体的方法想要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/15.组合应用：编写Docker_Compose项目.html":{"url":"开发者必备的Docker实践指南/15.组合应用：编写Docker_Compose项目.html","title":"15.组合应用：编写Docker_Compose项目","keywords":"","body":"编写 Docker Compose 项目 通过阅读之前的小节，相信大家对 Docker 在开发中的应用已经有了一定的了解。作为一款实用的软件，我们必须回归到实践中来，这样才能更好地理解 Docker 的实用逻辑和背后的原理。在这一小节里，我们就举一个完整的例子，让大家跟随这个项目的脉络，熟悉如何通过 Docker 和 Docker Compose 来搭建应用开发环境。 设计项目的目录结构 在这一小节里，我们以一个由 MySQL、Redis、PHP-FPM 和 Nginx 组成的小型 PHP 网站为例，介绍通过 Docker 搭建运行这套程序运行环境的方法。 既然我们说到这个小型网站是由 MySQL、Redis、PHP-FPM 和 Nginx 四款软件所组成的，那么自然在 Docker 里，我们要准备四个容器分别来运行它们。而为了更好地管理这四个容器所组成的环境，我们这里还会使用到 Docker Compose。 与搭建一个软件开发项目类似，我们提倡将 Docker Compose 项目的组成内容聚集到一个文件目录中，这样更利于我们进行管理和迁移。 这里我已经建立好了一个目录结构，虽然我们在实践的过程中不一定要按照这样的结构，但我相信这个结构一定对你有所启发。 简单说明一下这个结构中主要目录和文件的功能和作用。在这个结构里，我们可以将根目录下的几个目录分为四类： 第一类是 Docker 定义目录，也就是 compose 这个目录。在这个目录里，包含了 docker-compose.yml 这个用于定义 Docker Compose 项目的配置文件。此外，还包含了我们用于构建自定义镜像的内容。 第二类是程序文件目录，在这个项目里是 mysql、nginx、phpfpm、redis 这四个目录。这些目录分别对应着 Docker Compose 中定义的服务，在其中主要存放对应程序的配置，产生的数据或日志等内容。 第三类是代码目录，在这个项目中就是存放 Web 程序的 website 目录。我们将代码统一放在这个目录中，方便在容器中挂载。 第四类是工具命令目录，这里指 bin 这个目录。我们在这里存放一些自己编写的命令脚本，我们通过这些脚本可以更简洁地操作整个项目。 编写 Docker Compose 配置文件 接下来我们就要编写 docker-compose.yml 文件来定义组成这个环境的所有 Docker 容器以及与它们相关的内容了。docker-compose.yml 规则和编写的方法在前两小节中已经谈到，这里我们就不再展开，直接来看看编写好的 docker-compose.yml 配置文件。 version: \"3\" networks: frontend: backend: services: redis: image: redis:3.2 networks: - backend volumes: - ../redis/redis.conf:/etc/redis/redis.conf:ro - ../redis/data:/data command: [\"redis-server\", \"/etc/redis/redis.conf\"] ports: - \"6379:6379\" mysql: image: mysql:5.7 networks: - backend volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - \"3306:3306\" phpfpm: build: ./phpfpm networks: - frontend - backend volumes: - ../phpfpm/php.ini:/usr/local/etc/php/php.ini:ro - ../phpfpm/php-fpm.conf:/usr/local/etc/php-fpm.conf:ro - ../phpfpm/php-fpm.d:/usr/local/etc/php-fpm.d:ro - ../phpfpm/crontab:/etc/crontab:ro - ../website:/website depends_on: - redis - mysql nginx: image: nginx:1.12 networks: - frontend volumes: - ../nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ../nginx/conf.d:/etc/nginx/conf.d:ro - ../website:/website depends_on: - phpfpm ports: - \"80:80\" 使用合适的镜像是提高工作效率的途径之一，这里讲解一下我们在这个项目中选择镜像的原由。 在这个项目里，我们直接采用了 MySQL、Redis 和 Nginx 三个官方镜像，而对于 PHP-FPM 的镜像，我们需要增加一些功能，所以我们通过 Dockerfile 构建的方式来生成。 对于 MySQL 来说，我们需要为它们设置密码，所以原则上我们是需要对它们进行改造并生成新的镜像来使用的。而由于 MySQL 镜像可以通过我们之前在镜像使用方法一节所提到的环境变量配置的方式，来直接指定 MySQL 的密码及其他一些关键性内容，所以我们就无须单独构建镜像，可以直接采用官方镜像并配合使用环境变量来达到目的。 对于 Redis 来说，出于安全考虑，我们一样需要设置密码。Redis 设置密码的方法是通过配置文件来完成的，所以我们需要修改 Redis 的配置文件并挂载到 Redis 容器中。这个过程也相对简单，不过需要注意的是，在官方提供的 Redis 镜像里，默认的启动命令是 redis-server，其并没有指定加载配置文件。所以在我们定义 Redis 容器时，要使用 command 配置修改容器的启动命令，使其读取我们挂载到容器的配置文件。 自定义镜像 相比较于 MySQL、Redis 这样可以通过简单配置即可直接使用的镜像不同，PHP 的镜像中缺乏了一些我们程序中必要的元素，而这些部分我们推荐使用自定义镜像的方式将它们加入其中。 在这个例子里，因为需要让 PHP 连接到 MySQL 数据库中，所以我们要为镜像中的 PHP 程序安装和开启 pdo_mysql 这个扩展。 了解如何安装扩展，这就要考验我们之前在 Docker Hub 镜像使用一节中学到的知识了。我们通过阅读 PHP 镜像的介绍页面，可以找到 PHP 镜像中已经为我们准备好了扩展的安装和启用命令，这让我们可以很轻松地在镜像中加入扩展。 在准备好这些使用方法之后，我们就可以开始编写构建 PHP 镜像的 Dockerfile 文件了。这里我已经编写好了一份，供大家参考。 FROM php:7.2-fpm MAINTAINER You Ming RUN apt-get update \\ && apt-get install -y --no-install-recommends cron RUN docker-php-ext-install pdo_mysql COPY docker-entrypoint.sh /usr/local/bin/ RUN chmod +x /usr/local/bin/docker-entrypoint.sh ENTRYPOINT [\"docker-entrypoint.sh\"] CMD [\"php-fpm\"] 由于 Docker 官方所提供的镜像比较精简，所以在这个 Dockerfile 里，我们还执行了 cron 的安装命令，来确保我们可以使用定时任务。 大家注意到，这里除了我们进行功能安装外，还将一个脚本拷入了镜像中，并将其作为 ENTRYPOINT 启动入口。这个文件的作用主要是为了启动 cron 服务，以便我们在容器中可以正常使用它。 #!/bin/bash service cron start exec \"$@\" 在 docker-entrypoint.sh 里，除了启动 cron 服务的命令外，我们在脚本的最后看到的是 exec \"$@\" 这行命令。$@ 是 shell 脚本获取参数的符号，这里获得的是所有传入脚本的参数，而 exec 是执行命令，直接执行这些参数。 如果直接看这条命令大家会有些疑惑，参数怎么拿来执行，这不是有问题么？ 请大家回顾一下，我们之前提到的，如果在镜像里同时定义了 ENTRYPOINT 和 CMD 两个指令，CMD 指令的内容会以参数的形式传递给 ENTRYPOINT 指令。所以，这里脚本最终执行的，是 CMD 中所定义的命令。 目录挂载 在这个例子里，我们会把项目中的一些目录或文件挂载到容器里，这样的挂载主要有三种目的： 将程序的配置通过挂载的方式覆盖容器中对应的文件，这让我们可以直接在容器外修改程序的配置，并通过直接重启容器就能应用这些配置； 把目录挂载到容器中应用数据的输出目录，就可以让容器中的程序直接将数据输出到容器外，对于 MySQL、Redis 中的数据，程序的日志等内容，我们可以使用这种方法来持久保存它们； 把代码或者编译后的程序挂载到容器中，让它们在容器中可以直接运行，这就避免了我们在开发中反复构建镜像带来的麻烦，节省出大量宝贵的开发时间。 上述的几种方法，对于线上部署来说都是不适用的，但在我们的开发过程中，却可以为我们免去大量不必要的工作，因此建议在开发中使用这些挂载结构。 编写辅助脚本 我们知道，虽然 Docker Compose 简化了许多操作流程，但我们还是需要使用 docker-compose 命令来管理项目。对于这个例子来说，我们要启动它就必须使用这样的 docker-compose 命令来管理项目。对于这个例子来说，我们要启动它就必须使用这样的： $ sudo docker-compose -p website up -d 而执行的目录必须是 docker-compose.yml 文件所在的目录，这样才能正确地读取 Docker Compose 项目的配置内容。 我编写了一个 compose 脚本，用来简化 docker-compose 的操作命令。 #!/bin/bash root=$(cd `dirname $0`; dirname `pwd`) docker-compose -p website -f ${root}/compose/docker-compose.yml \"$@\" 在这个脚本里，我把一些共性的东西包含进去，这样我们就不必每次传入这些参数或选项了。同时，这个脚本还能自适应调用的目录，准确找到 docker-compose.yml 文件，更方便我们直接调用。 通过这个脚本来操作项目，我们的命令就可以简化为： $ sudo ./bin/compose up -d $ sudo ./bin/compose logs nginx $ sudo ./bin/compose down 当然，我们还可以编写像代码部署、服务重启等脚本，来提高我们的开发效率。 留言互动 在本节中，我们展示了编写一个用于开发的完整 Docker Compose 项目的方法。这里给大家留一道实践题： 尝试自己编写适用于自己应用的 Docker Compose 项目，并将它提供给测试同事，进行测试环境的部署。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对编写 Docker Compose 项目还有疑问，或者有编写的心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 本小节中的示例，已经更新到了： https://github.com/youmingdot/docker-book-for-developer-samples "},"开发者必备的Docker实践指南/16.组合应用：常用的Docker_Compose配置项.html":{"url":"开发者必备的Docker实践指南/16.组合应用：常用的Docker_Compose配置项.html","title":"16.组合应用：常用的Docker_Compose配置项","keywords":"","body":"常用的 Docker Compose 配置项 与 Dockerfile 一样，编写 Docker Compose 的配置文件是掌握和使用好 Docker Compose 的前提。编写 Docker Compose 配置文件，其本质就是根据我们所设计的应用架构，对不同应用容器进行配置并加以组合。在这一节中，我们就来谈谈如何编写 Docker Compose 的配置文件，了解其中常见配置项的使用方法。 定义服务 为了理解在开发中常用的 Docker Compose 配置，我们通过一个在开发中使用的 Docker Compose 文件来进行下面的讲解。 version: \"3\" services: redis: image: redis:3.2 networks: - backend volumes: - ./redis/redis.conf:/etc/redis.conf:ro ports: - \"6379:6379\" command: [\"redis-server\", \"/etc/redis.conf\"] database: image: mysql:5.7 networks: - backend volumes: - ./mysql/my.cnf:/etc/mysql/my.cnf:ro - mysql-data:/var/lib/mysql environment: - MYSQL_ROOT_PASSWORD=my-secret-pw ports: - \"3306:3306\" webapp: build: ./webapp networks: - frontend - backend volumes: - ./webapp:/webapp depends_on: - redis - database nginx: image: nginx:1.12 networks: - frontend volumes: - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ./nginx/conf.d:/etc/nginx/conf.d:ro - ./webapp/html:/webapp/html depends_on: - webapp ports: - \"80:80\" - \"443:443\" networks: frontend: backend: volumes: mysql-data: 在这个 Docker Compose 的示例中，我们看到占有大量篇幅的就是 services 部分，也就是服务定义的部分了。在上一节里，我们已经说到了，Docker Compose 中的服务，是对一组相同容器集群统一配置的定义，所以可见，在 Docker Compose 里，主要的内容也是对容器配置的定义。 这里我们依然要声明一下，这本小册主要以开发中使用 Docker 的方法为主，所以在关于 Docker Compose 的内容里，依然以开发中的使用为主。由于我们开发中，鉴于本地机器性能和易管理性等的考虑，不会为服务进行集群配置，通常就是一个服务对应一个容器，所以这里均以这种方式来进行讲解。 在 Docker Compose 的配置文件里，对服务的定义与我们之前谈到的创建和启动容器中的选项非常相似，或者说 Docker Compose 就是从配置文件中读取出这些内容，代我们创建和管理这些容器的。 在使用时，我们首先要为每个服务定义一个名称，用以区别不同的服务。在这个例子里，redis、database、webapp、nginx 就是服务的名称。 指定镜像 容器最基础的就是镜像了，所以每个服务必须指定镜像。在 Docker Compose 里，我们可以通过两种方式为服务指定所采用的镜像。一种是通过 image 这个配置，这个相对简单，给出能在镜像仓库中找到镜像的名称即可。 另外一种指定镜像的方式就是直接采用 Dockerfile 来构建镜像，通过 build 这个配置我们能够定义构建的环境目录，这与 docker build 中的环境目录是同一个含义。如果我们通过这种方式指定镜像，那么 Docker Compose 先会帮助我们执行镜像的构建，之后再通过这个镜像启动容器。 当然，在 docker build 里我们还能通过选项定义许多内容，这些在 Docker Compose 里我们依然可以。 ## ...... webapp: build: context: ./webapp dockerfile: webapp-dockerfile args: - JAVA_VERSION=1.6 ## ...... 在配置文件里，我们还能用 Map 的形式来定义 build，在这种格式下，我们能够指定更多的镜像构建参数，例如 Dockerfile 的文件名，构建参数等等。 当然，对于一些可以不通过重新构建镜像的方式便能修改的内容，我们还是不建议重新构建镜像，而是使用原有的镜像做简单的修改。 例如上面的配置里，我们希望修改 Redis 的启动命令，加入配置文件以便对 Redis 服务进行配置，那么我们可以直接通过 command 配置来修改。而在 MySQL 的定义，我们通过 environment 配置为 MySQL 设置了初始密码。 这些对镜像的使用方法我们在之前都已经谈到过了，只不过我们之前用的是 Docker Engine 的命令以及其选项来控制的，而在 Docker Compose 里，我们直接通过配置文件来定义它们。 由于 Docker Compose 的配置已经固化下来，所以我们不需要担心忘记之前执行了哪些命令来启动容器，当每次需要开启或关闭环境时，只需要 docker-compose up -d 和 docker-compose down 命令，就能轻松完成操作。 依赖声明 虽然我们在 Docker Compose 的配置文件里定义服务，在书写上有由上至下的先后关系，但实际在容器启动中，由于各种因素的存在，其顺序还是无法保障的。 所以，如果我们的服务间有非常强的依赖关系，我们就必须告知 Docker Compose 容器的先后启动顺序。只有当被依赖的容器完全启动后，Docker Compose 才会创建和启动这个容器。 定义依赖的方式很简单，在上面的例子里我们已经看到了，也就是 depends_on 这个配置项，我们只需要通过它列出这个服务所有依赖的其他服务即可。在 Docker Compose 为我们启动项目的时候，会检查所有依赖，形成正确的启动顺序并按这个顺序来依次启动容器。 文件挂载 在 Docker Compose 里定义文件挂载的方式与 Docker Engine 里也并没有太多的区别，使用 volumes 配置可以像 docker CLI 里的 -v 选项一样来指定外部挂载和数据卷挂载。 在上面的例子里，我们看到了定义几种常用挂载的方式。我们能够直接挂载宿主机文件系统中的目录，也可以通过数据卷的形式挂载内容。 在使用外部文件挂载的时候，我们可以直接指定相对目录进行挂载，这里的相对目录是指相对于 docker-compose.yml 文件的目录。 由于有相对目录这样的机制，我们可以将 docker-compose.yml 和所有相关的挂载文件放置到同一个文件夹下，形成一个完整的项目文件夹。这样既可以很好的整理项目文件，也利于完整的进行项目迁移。 虽然 Docker 提倡将代码或编译好的程序通过构建镜像的方式打包到镜像里，随整个 CI 流部署到服务器中，但对于开发者来说，每次修改程序进行简单测试都要重新构建镜像简直是浪费生命的操作。所以在开发时，我们推荐直接将代码挂载到容器里，而不是通过镜像构建的方式打包成镜像。 同时，在开发过程中，对于程序的配置等内容，我们也建议直接使用文件挂载的形式挂载到容器里，避免经常修改所带来的麻烦。 使用数据卷 如果我们要在项目中使用数据卷来存放特殊的数据，我们也可以让 Docker Compose 自动完成对数据卷的创建，而不需要我们单独进行操作。 在上面的例子里，独立于 services 的 volumes 配置就是用来声明数据卷的。定义数据卷最简单的方式仅需要提供数据卷的名称，对于我们在 Docker Engine 中创建数据卷时能够使用的其他定义，也能够放入 Docker Compose 的数据卷定义中。 如果我们想把属于 Docker Compose 项目以外的数据卷引入进来直接使用，我们可以将数据卷定义为外部引入，通过 external 这个配置就能完成这个定义。 ## ...... volumes: mysql-data: external: true ## ...... 在加入 external 定义后，Docker Compose 在创建项目时不会直接创建数据卷，而是优先从 Docker Engine 中已有的数据卷里寻找并直接采用。 配置网络 网络也是容器间互相访问的桥梁，所以网络的配置对于多个容器组成的应用系统来说也是非常重要的。在 Docker Compose 里，我们可以为整个应用系统设置一个或多个网络。 要使用网络，我们必须先声明网络。声明网络的配置同样独立于 services 存在，是位于根配置下的 networks 配置。在上面的例子里，我们已经看到了声明 frontend 和 backend 这两个网络最简单的方式。 除了简单的声明网络名称，让 Docker Compose 自动按默认形式完成网络配置外，我们还可以显式的指定网络的参数。 networks: frontend: driver: bridge ipam: driver: default config: - subnet: 10.10.1.0/24 ## ...... 在这里，我们为网络定义了网络驱动的类型，并指定了子网的网段。 使用网络别名 直接使用容器名或服务名来作为连接其他服务的网络地址，因为缺乏灵活性，常常还不能满足我们的需要。这时候我们可以为服务单独设置网络别名，在其他容器里，我们将这个别名作为网络地址进行访问。 网络别名的定义方式很简单，这里需要将之前简单的网络 List 定义结构修改成 Map 结构，以便在网络中加入更多的定义。 ## ...... database: networks: backend: aliases: - backend.database ## ...... webapp: networks: backend: aliases: - backend.webapp frontend: aliases: - frontend.webapp ## ...... 在我们进行这样的配置后，我们便可以使用这里我们所设置的网络别名对其他容器进行访问了。 端口映射 在 Docker Compose 的每个服务配置里，我们还看到了 ports 这个配置项，它是用来定义端口映射的。 我们可以利用它进行宿主机与容器端口的映射，这个配置与 docker CLI 中 -p 选项的使用方法是近似的。 需要注意的是，由于 YAML 格式对 xx:yy 这种格式的解析有特殊性，在设置小于 60 的值时，会被当成时间而不是字符串来处理，所以我们最好使用引号将端口映射的定义包裹起来，避免歧义。 留言互动 在本节中，我们展示了 Docker Compose 中常见定义和配置的方法。这里给大家留一道实践题： 尝试利用 Docker Compose 以及之前所学习的 Docker 知识，为自己正在开发的应用搭建一个 Docker 运行环境。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Compose 的配置方法还有疑问，或者有自己的使用技巧要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/17.组合应用：使用Docker_Compose管理容器.html":{"url":"开发者必备的Docker实践指南/17.组合应用：使用Docker_Compose管理容器.html","title":"17.组合应用：使用Docker_Compose管理容器","keywords":"","body":"使用 Docker Compose 管理容器 通过之前的介绍，我们已经基本掌握了构建、运行容器的方法，但这还远远不够，由于 Docker 采用轻量级容器的设计，每个容器一般只运行一个软件，而目前绝大多数应用系统都绝不是一个软件所能组成的。虽然我们之前提到了容器间互相连接、交换数据的各种方法，通过这些方法足以搭建起完整的用于应用系统运行的容器群，但是这显然还不够，这个容器群的搭建需要执行太多命令，更重要的是需要考虑太多应用和容器间的依赖关系处理，是一波令人头大的操作。在这一节中，我们就来介绍如何解决这些问题。 解决容器管理问题 拿任何一个相对完整的应用系统来说，都不可能是由一个程序独立支撑的，而对于使用 Docker 来部署的分布式计算服务更是这样。随着时代的发展和技术演进，我们越来越推崇将大型服务拆分成较小的微服务，分别部署到独立的机器或容器中。也就是说，我们的应用系统往往由数十个甚至上百个应用程序或微服务组成。即使是一个小的微服务模块，通常都需要多个应用协作完成工作。 我们编写一个小型的微服务模块，虽然我们编写代码主要针对的是其中的应用部分，但如果我们要完整的进行开发、测试，与应用相关的周边软件必然是必不可少的。 虽然 Docker Engine 帮助我们完成了对应用运行环境的封装，我们可以不需要记录复杂的应用环境搭建过程，通过简单的配置便可以将应用运行起来了，但这只是针对单个容器或单个应用程序来说的。如果延伸到由多个应用组成的应用系统，那情况就稍显复杂了。 就拿最简单的例子来说吧，如果我们要为我们的应用容器准备一个 MySQL 容器和一个 Redis 容器，那么在每次启动时，我们先要将 MySQL 容器和 Redis 容器启动起来，再将应用容器运行起来。这其中还不要忘了在创建应用容器时将容器网络连接到 MySQL 容器和 Redis 容器上，以便应用连接上它们并进行数据交换。 这还不够，如果我们还对容器进行了各种配置，我们最好还得将容器创建和配置的命令保存下来，以便下次可以直接使用。 如果我们要想让这套体系像 docker run 和 docker rm 那样自如的进行无痕切换，那就更加麻烦了，我们可能需要编写一些脚本才能不至于被绕到命令的毛线球里。 说了这么多，其实核心还是缺少一个对容器组合进行管理的东西。 Docker Compose 针对这种情况，我们就不得不引出在我们开发中最常使用的多容器定义和运行软件，也就是 Docker Compose 了。 如果说 Dockerfile 是将容器内运行环境的搭建固化下来，那么 Docker Compose 我们就可以理解为将多个容器运行的方式和配置固化下来。 在 Docker Compose 里，我们通过一个配置文件，将所有与应用系统相关的软件及它们对应的容器进行配置，之后使用 Docker Compose 提供的命令进行启动，就能让 Docker Compose 将刚才我们所提到的那些复杂问题解决掉。 安装 Docker Compose 虽然 Docker Compose 目前也是由 Docker 官方主要维护，但其却不属于 Docker Engine 的一部分，而是一个独立的软件。所以如果我们要在 Linux 中使用它，还必须要单独下载使用。 Docker Compose 是一个由 Python 编写的软件，在拥有 Python 运行环境的机器上，我们可以直接运行它，不需要其它的操作。 我们可以通过下面的命令下载 Docker Compose 到应用执行目录，并附上运行权限，这样 Docker Compose 就可以在机器中使用了。 $ sudo curl -L \"https://github.com/docker/compose/releases/download/1.22.0/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose $ $ sudo docker-compose version docker-compose version 1.21.2, build a133471 docker-py version: 3.3.0 CPython version: 3.6.5 OpenSSL version: OpenSSL 1.0.1t 3 May 2016 我们也能够通过 Python 的包管理工具 pip 来安装 Docker Compose。 $ sudo pip install docker-compose 在 Windows 和 macOS 中的 Docker Compose 在我们更常用于开发的 Windows 和 macOS 中，使用 Docker Compose 会来得更加方便。不论你是使用 Docker for Win 还是 Docker for Mac，亦或是 Docker Toolbox 来搭建 Docker 运行环境，你都可以直接使用 docker-compose 这个命令。这三款软件都已经将 Docker Compose 内置在其中，供我们使用。 Docker Compose 的基本使用逻辑 如果将使用 Docker Compose 的步骤简化来说，可以分成三步。 如果需要的话，编写容器所需镜像的 Dockerfile；( 也可以使用现有的镜像 ) 编写用于配置容器的 docker-compose.yml； 使用 docker-compose 命令启动应用。 准备镜像这一过程我们之前已经掌握了，这里我们就简单来看看后面两个步骤。 编写 Docker Compose 配置 配置文件是 Docker Compose 的核心部分，我们正是通过它去定义组成应用服务容器群的各项配置，而编写配置文件，则是使用 Docker Compose 过程中最核心的一个步骤。 Docker Compose 的配置文件是一个基于 YAML 格式的文件。关于 YAML 的语法大家可以在网上找到，这里不再细说，总的来说，YAML 是一种清晰、简单的标记语言，你甚至都可以在看过几个例子后摸索出它的语法。 与 Dockerfile 采用 Dockerfile 这个名字作为镜像构建定义的默认文件名一样，Docker Compose 的配置文件也有一个缺省的文件名，也就是 docker-compose.yml，如非必要，我建议大家直接使用这个文件名来做 Docker Compose 项目的定义。 这里我们来看一个简单的 Docker Compose 配置文件内容。 version: '3' services: webapp: build: ./image/webapp ports: - \"5000:5000\" volumes: - ./code:/code - logvolume:/var/log links: - mysql - redis redis: image: redis:3.2 mysql: image: mysql:5.7 environment: - MYSQL_ROOT_PASSWORD=my-secret-pw volumes: logvolume: {} Docker Compose 配置文件里可以包含许多内容，从每个容器的各个细节控制，到网络、数据卷等的定义。 这里我们看几个主要的细节。首先是 version 这个配置，这代表我们定义的 docker-compose.yml 文件内容所采用的版本，目前 Docker Compose 的配置文件已经迭代至了第三版，其所支持的功能也越来越丰富，所以我们建议使用最新的版本来定义。 接下来我们来看 services 这块，这是整个 docker-compose.yml 的核心部分，其定义了容器的各项细节。 在 Docker Compose 里不直接体现容器这个概念，这是把 service 作为配置的最小单元。虽然我们看上去每个 service 里的配置内容就像是在配置容器，但其实 service 代表的是一个应用集群的配置。每个 service 定义的内容，可以通过特定的配置进行水平扩充，将同样的容器复制数份形成一个容器集群。而 Docker Compose 能够对这个集群做到黑盒效果，让其他的应用和容器无法感知它们的具体结构。 对于 docker-compose.yml 配置的具体细节，我们在下一节中还会专门讲解。 启动和停止 对于开发来说，最常使用的 Docker Compose 命令就是 docker-compose up 和 docker-compose down 了。 docker-compose up 命令类似于 Docker Engine 中的 docker run，它会根据 docker-compose.yml 中配置的内容，创建所有的容器、网络、数据卷等等内容，并将它们启动。与 docker run 一样，默认情况下 docker-compose up 会在“前台”运行，我们可以用 -d 选项使其“后台”运行。事实上，我们大多数情况都会加上 -d 选项。 $ sudo docker-compose up -d 需要注意的是，docker-compose 命令默认会识别当前控制台所在目录内的 docker-compose.yml 文件，而会以这个目录的名字作为组装的应用项目的名称。如果我们需要改变它们，可以通过选项 -f 来修改识别的 Docker Compose 配置文件，通过 -p 选项来定义项目名。 $ sudo docker-compose -f ./compose/docker-compose.yml -p myapp up -d 与 docker-compose up 相反，docker-compose down 命令用于停止所有的容器，并将它们删除，同时消除网络等配置内容，也就是几乎将这个 Docker Compose 项目的所有影响从 Docker 中清除。 $ sudo docker-compose down 如果条件允许，我更建议大家像容器使用一样对待 Docker Compose 项目，做到随用随启，随停随删。也就是使用的时候通过 docker-compose up 进行，而短时间内不再需要时，通过 docker-compose down 清理它。 借助 Docker 容器的秒级启动和停止特性，我们在使用 docker-compose up 和 docker-compose down 时可以非常快的完成操作。这就意味着，我们可以在不到半分钟的时间内停止一套环境，切换到另外一套环境，这对于经常进行多个项目开发的朋友来说，绝对是福音。 通过 Docker 让我们能够在开发过程中搭建一套不受干扰的独立环境，让开发过程能够基于稳定的环境下进行。而 Docker Compose 则让我们更近一步，同时让我们处理好多套开发环境，并进行快速切换。 容器命令 除了启动和停止命令外，Docker Compose 还为我们提供了很多直接操作服务的命令。之前我们说了，服务可以看成是一组相同容器的集合，所以操作服务就有点像操作容器一样。 这些命令看上去都和 Docker Engine 中对单个容器进行操作的命令类似，我们来看几个常见的。 在 Docker Engine 中，如果我们想要查看容器中主进程的输出内容，可以使用 docker logs 命令。而由于在 Docker Compose 下运行的服务，其命名都是由 Docker Compose 自动完成的，如果我们直接使用 docker logs 就需要先找到容器的名字，这显然有些麻烦了。我们可以直接使用 docker-compose logs 命令来完成这项工作。 $ sudo docker-compose logs nginx 在 docker-compose logs 衔接的是 Docker Compose 中所定义的服务的名称。 同理，在 Docker Compose 还有几个类似的命令可以单独控制某个或某些服务。 通过 docker-compose create，docker-compose start 和 docker-compose stop 我们可以实现与 docker create，docker start 和 docker stop 相似的效果，只不过操作的对象由 Docker Engine 中的容器变为了 Docker Compose 中的服务。 $ sudo docker-compose create webapp $ sudo docker-compose start webapp $ sudo docker-compose stop webapp 留言互动 在本节中，我们展示了 Docker Compose 这个用于管理容器的工具。这里给大家留一道思考题： 在我们的开发中，我们应该如何的合理利用 Docker Compose 进行容器管理呢？ 欢迎大家通过留言的方式说出你的看法。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker Compose 和容器管理还有什么疑惑，或者有自己的想法要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/18.组合应用：应用于服务化开发.html":{"url":"开发者必备的Docker实践指南/18.组合应用：应用于服务化开发.html","title":"18.组合应用：应用于服务化开发","keywords":"","body":"应用于服务化开发 上一节里我们谈到了小型的独立项目如何使用 Docker Compose 来搭建程序的运行环境，对于由多人或多部门参与的中大型服务化架构的项目，仅由一个 Docker Compose 项目来管理它们的运行环境显然是不切实际的。在这一小节里，我们就谈谈如何在服务化开发中合理利用 Docker 来搭建环境。 服务开发环境 在开始之前，我们依然来设定一个场景。在这里，假定我们处于一个 Dubbo 治下的微服务系统，而工作是开发系统中某一项微服务。 微服务开发与上一节里我们提到的小型项目开发在环境搭建上有一定的区别，我们要合理地调整 Docker 的使用方法和策略，就必须先了解这些区别。 在微服务开发中，我们所开发的功能都不是完整的系统，很多功能需要与其他服务之间配合才能正常运转，而我们开发所使用的机器时常无法满足我们在一台机器上将这些相关服务同时运行起来。 我们仅仅是开发某一部分服务的内容，既对其他服务的运转机制不太了解，又完全没有必要在自己的机器上运行其他的服务。所以我们最佳的实践自然就是让参与系统中服务开发的同事，各自维护自己开发服务的环境，而直接提供给我们对应的连接地址使用服务即可。 更确切地说，我们在开发中，只需要在本地搭建起自己所开发服务的运行环境，再与其他开发者搭建的环境互联即可。 搭建本地环境 在我们的开发机器上，我们只需要运行我们正在开发的服务，这个过程依然可以使用 Docker Compose 来完成。这里我给出了一个简单的例子，表示一个简单的小服务运行环境。 version: \"3\" networks: backend: mesh: services: mysql: image: mysql:5.7 networks: - backend volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - \"3306:3306\" app: build: ./spring networks: - mesh - backend volumes: - ../app:/app depends_on: - mysql 关于这里 Spring 镜像的使用和改造方法，我就不展开了，大家可以通过 Docker Hub 以及 Spring 官方所提供的镜像，练习如何改造它，使它适配自己的服务。 跨主机网络 搭建好本地的环境，我们就需要考虑如何与朋友们所搭建的环境进行互联了。 这时候大家也许会想到，可以将服务涉及的相关端口通过映射的方式暴露到我们机器的端口上，接着我们只需要通过各服务机器的 IP 与对应的端口就可以连接了。 然而这种方法还不算特别方便，一来除了处理映射外，我们还需要配置防火墙等才能使其他的机器正确访问到容器，二来是这种方式我们依然要记录各个服务的网络地址等配置，而开发中切换它们是个烦琐的过程。 在介绍 Docker Compose 的小节里，我们知道了可以通过设置网络别名 ( alias ) 的方式来更轻松地连接其他容器，如果我们在服务化开发里也能这么做就能减少很多烦琐操作了。 要实现设置网络别名的目的，自然要先确保所有涉及的容器位于同一个网络中，这时候就需要引出我们之前在网络小节里说到的 Overlay 网络了。 Overlay Network 能够跨越物理主机的限制，让多个处于不同 Docker daemon 实例中的容器连接到同一个网络，并且让这些容器感觉这个网络与其他类型的网络没有区别。 Docker Swarm 要搭建 Overlay Network 网络，我们就要用到 Docker Swarm 这个工具了。Docker Swarm 是 Docker 内置的集群工具，它能够帮助我们更轻松地将服务部署到 Docker daemon 的集群之中。 在真实的服务部署里，我们通常是使用 Docker Compose 来定义集群，而通过 Docker Swarm 来部署集群。 如果熟悉 Docker 周边知识的朋友，相信这时候已经想到了另外一个工具，即 Kubernetes ( K8s )。没错，Kubernetes 与这两者的组合相比，功能要丰富强大很多，也正因此，与它相关的内容完全足以另辟一本小册来说。而在开发里，我们几乎使用不到 Kubernetes，所以我们这里就不做介绍了。如果大家有想要了解的 Kubernetes 知识点，可以通过小册的微信群向我提出，我会挑选大家关注的内容补充到小册的后面。 Docker Swarm 最初是独立的项目，不过目前已经集成到了 Docker 之中，我们通过 docker CLI 的命令就能够直接操控它。 对于 Docker Swarm 来说，每一个 Docker daemon 的实例都可以成为集群中的一个节点，而在 Docker daemon 加入到集群成为其中的一员后，集群的管理节点就能对它进行控制。我们要搭建的 Overlay 网络正是基于这样的集群实现的。 既然要将 Docker 加入到集群，我们就必须先有一个集群，我们在任意一个 Docker 实例上都可以通过 docker swarm init 来初始化集群。 $ sudo docker swarm init Swarm initialized: current node (t4ydh2o5mwp5io2netepcauyl) is now a manager. To add a worker to this swarm, run the following command: docker swarm join --token SWMTKN-1-4dvxvx4n7magy5zh0g0de0xoues9azekw308jlv6hlvqwpriwy-cb43z26n5jbadk024tx0cqz5r 192.168.1.5:2377 在集群初始化后，这个 Docker 实例就自动成为了集群的管理节点，而其他 Docker 实例可以通过运行这里所打印的 docker swarm join 命令来加入集群。 加入到集群的节点默认为普通节点，如果要以管理节点的身份加入到集群中，我们可以通过 docker swarm join-token 命令来获得管理节点的加入命令。 $ sudo docker swarm join-token manager To add a manager to this swarm, run the following command: docker swarm join --token SWMTKN-1-60am9y6axwot0angn1e5inxrpzrj5d6aa91gx72f8et94wztm1-7lz0dth35wywekjd1qn30jtes 192.168.1.5:2377 我们通过这些命令来建立用于我们服务开发的 Docker 集群，并将相关开发同事的 Docker 加入到这个集群里，就完成了搭建跨主机网络的第一步。 建立跨主机网络 接下来，我们就通过 docker network create 命令来建立 Overlay 网络。 $ sudo docker network create --driver overlay --attachable mesh 在创建 Overlay 网络时，我们要加入 --attachable 选项以便不同机器上的 Docker 容器能够正常使用到它。 在创建了这个网络之后，我们可以在任何一个加入到集群的 Docker 实例上使用 docker network ls 查看一下其下的网络列表。我们会发现这个网络定义已经同步到了所有集群中的节点上。 $ sudo docker network ls NETWORK ID NAME DRIVER SCOPE ## ...... y89bt74ld9l8 mesh overlay swarm ## ...... 接下来我们要修改 Docker Compose 的定义，让它使用这个我们已经定义好的网络，而不是再重新创建网络。 我们只需要在 Docker Compose 配置文件的网络定义部分，将网络的 external 属性设置为 true，就可以让 Docker Compose 将其建立的容器都连接到这个不属于 Docker Compose 的项目上了。 networks: mesh: external: true 通过这个实现，我们在开发中就使整个服务都处于一个可以使用别名映射网络中，避免了要对不同功能联调时切换服务 IP 的烦琐流程。在这种结构下，我们只需要让我们开发的 Docker 退出和加入不同的集群，就能马上做到切换不同联调项目。 留言互动 在本节中，我们展示了使用 Docker 进行多人协同开发的方法。这里给大家留一道实践题： 尝试使用本小节中的知识，与同事搭建一套协同开发环境。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果你对 Docker 在服务化开发中的应用还有疑问，或者有自己的实践心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/19.实践之路：搭建Java_Web项目运行环境.html":{"url":"开发者必备的Docker实践指南/19.实践之路：搭建Java_Web项目运行环境.html","title":"19.实践之路：搭建Java_Web项目运行环境","keywords":"","body":"搭建 Java Web 项目运行环境 Java Web 泛指以 Java 程序为基础向外提供 Web 服务的技术及相关工具，狭义上来说，我们也可以说 Java Web 是由 Servlet 程序提供的 Web 服务。 对我们而言，Tomcat 无疑是最常见的 Servlet 容器，所以在这个小节里，我们来搭建一个以 Tomcat 为核心的 Web 应用运行环境。 在这个环境中，我们还要组合进 MySQL 作为数据存储，Redis 作为 KV 存储。 定义项目结构 与之前我们提及的一样，要搭建这样的由多个程序所协作组成的开发环境，使用 Docker Compose 是最佳的选择。 建立 Docker Compose 项目之前，我们先来规划一下项目的目录结构。 在开发过程中，我们倾向于将与项目有关的内容集合到同一个文件夹下，这样的做有几点好处： 项目内容清晰明确，复制、迁移和与他人共享的过程中，不会发生遗漏的情况； 在定义 Docker Compose 项目时可以使用相对路径，让共享、迁移后整个项目可以不需要额外操作就能运行。 在这些的基础上，我给出一个建议性的目录结构，供大家参考。 └─ project ├─ app ├─ compose │ └─ docker-compose.yml ├─ mysql │ └─ my.cnf ├─ redis │ └─ redis.conf └─ tomcat ├─ server.xml └─ web.xml 设计这样一个目录结构的主要目的是将不同程序的配置进行区分，这与我们之后会通过多个程序所关联的镜像及容器来组合这套环境的脉络是相契合的。 在这个目录结构中，区分了 5 个顶层目录： app ：用于存放程序工程，即代码、编译结果以及相关的库、工具等； compose ：用于定义 Docker Compose 项目； mysql ：与 MySQL 相关配置等内容； redis ：与 Redis 相关配置等内容； tomcat ：与 Tomcat 相关配置等内容。 准备程序配置 为了更方便在开发过程中对 MySQL、Redis、Tomcat 程序本身，所以我们会将它们的核心配置放置到项目里，再通过挂载的方式映射到容器中。 这样一来，我们就可以直接在我们宿主操作系统里直接修改这些配置，无须再进入到容器中了。 基于此，我们在完成目录的设计之后，首要解决的问题就是准备好这些程序中会经常变动的配置，并把它们放置在程序对应的目录之中。 我们常用下列几种方式来获得程序的配置文件： 借助配置文档直接编写 下载程序源代码中的配置样例 通过容器中的默认配置获得 下面我们来展示一下这几种获取配置的方式。 借助配置文档直接编写 这里我们利用 MySQL 文档中配置文件的介绍部分，来编写一个 MySQL 的配置文件。 我们先找到 MySQL 文档中关于配置文件的参考，也就是下面这个地址： https://dev.mysql.com/doc/refman/5.7/en/server-options.html 我们根据这些内容，选取跟我们程序运行有影响的几项需要修改的参数，编写成 MySQL 的配置文件。 # ./mysql/my.cnf [mysqld_safe] pid-file = /var/run/mysqld/mysqld.pid socket = /var/run/mysqld/mysqld.sock nice = 0 [mysqld] skip-host-cache skip-name-resolve explicit_defaults_for_timestamp bind-address = 0.0.0.0 port = 3306 user = mysql pid-file = /var/run/mysqld/mysqld.pid socket = /var/run/mysqld/mysqld.sock log-error = /var/log/mysql/error.log basedir = /usr datadir = /var/lib/mysql tmpdir = /tmp sql_mode = NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES lc-messages-dir = /usr/share/mysql symbolic-links = 0 使用软件的文档来编写配置文件，其优势在于在编写的过程实际上也是我们熟悉软件的过程，通过配置加文档形式的阅读，你一定会从中收获很多。 当然，这种方法也有很大的劣势，即需要仔细阅读文档，劳神劳力，对于常规开发中的使用来说，成效比很低。 下载程序源代码中的配置样例 除了通过配置文档来了解软件的配置外，大部分软件，特别是开源软件都会直接给出一份示例配置文件作为参考。 我们可以直接拿到这份配置，达到我们的目的。 这里我们以 Redis 为例，在 Redis 源代码中，就包含了一份默认的配置文件，我们可以直接拿来使用： https://github.com/antirez/redis/blob/3.2/redis.conf 在拿到这是默认的配置后，我们还可以根据需要对其中的部分配置进行修改，以更好的满足我们的需求。 这里我们以修改 Redis 的密码为例。 打开配置文件，找到定义 Redis 授权授权的地方，将密码修改为我们需要的内容。 # ./redis/redis.conf ##... ################################## SECURITY ################################### # Require clients to issue AUTH before processing any other # commands. This might be useful in environments in which you do not trust # others with access to the host running redis-server. # # This should stay commented out for backward compatibility and because most # people do not need auth (e.g. they run their own servers). # # Warning: since Redis is pretty fast an outside user can try up to # 150k passwords per second against a good box. This means that you should # use a very strong password otherwise it will be very easy to break. # requirepass my-secret-pw ##... 相对于通过配置文档获得配置，从配置示例里获得配置要来得更为简单容易。 但其也有一定的限制，既要对于的程序能够提供这样的示例配置，又要我们能够顺利找到这些配置文件。 通过容器中的默认配置获得 除了从官方手册或者配置示例中获得配置文件外，我们还有一种远在天边近在眼前的获取配置文件的方法。 大多数 Docker 镜像为了实现自身能够直接启动为容器并马上提供服务，会把默认配置直接打包到镜像中，以便让程序能够直接读取。 所以说，我们可以直接从镜像里拿到这份配置，拷贝到宿主机里备用。 那么我们就以最后一个尚未出场的 Tomcat 为例，说说如何从 Tomcat 镜像里拿到配置文件。 要拿到 Tomcat 中的配置文件，我们需要先创建一个临时的 Tomcat 容器。 # docker run --rm -d --name temp-tomcat tomcat:8.5 这里我们将容器命名为 temp-tomcat 以便我们之后的操作。 对于 Tomcat 来说，在开发过程中我们可能会经常改动的配置主要是 server.xml 和 web.xml 这两个文件，所以接下来我们就把这两个文件从容器中复制到宿主机里。 这里我们会用到 docker cp 这个命令，docker cp 能够在容器与宿主机的文件系统间拷贝文件和目录。 # docker cp temp-tomcat:/usr/local/tomcat/conf/server.xml ./server.xml # docker cp temp-tomcat:/usr/local/tomcat/conf/web.xml ./web.xml 在这个命令的使用中，几个参数的含义如下： temp-tomcat : 操作的容器。这里我们使用刚才创建的临时容器的容器名来指定。 /usr/local/tomcat/conf/server.xml : 需要拷贝的路径。也就是容器中配置文件的路径，这个路径可以通过 docker exec 等命令进到容器里寻觅一下就能获得。 ./server.xml : 是目标路径。即选择将文件拷贝到宿主机的什么位置上。 熟悉 Linux 中 cp 命令的朋友会非常容易看懂这个命令，这两者传参的方式是基本一致的。 主要的区别在于 docker cp 命令由于是在容器与宿主机间进行拷贝，所以来源目录或者目标目录中需要指定一下容器。 上述的命令是从容器中向宿主机里拷贝文件，我们还可以从宿主机中向容器里拷贝文件，只需要调换一下参数的位置即可。 # docker cp ./server.xml temp-tomcat:/usr/local/tomcat/conf/server.xml 回过头来看我们的配置，在执行了上述的命令之后，两个配置文件已经出现在我们系统的目录中了。 另外，别忘了在完成上面的操作后清理我们创建的临时容器。 # docker stop temp-tomcat 由于我们在创建临时容器的时候增加了 --rm 选项，所以我们在这里只需要使用 docker stop 停止容器，就可以在停止容器的同时直接删除容器，实现直接清理的目的。 编写 Docker Compose 定义文件 准备好了程序的配置，我们就可以来编写我们的 Docker Compose 项目定义文件了。 这里是我编写好的一份 Docker Compose 项目定义文件。 version: \"3\" services: redis: image: redis:3.2 volumes: - ../redis/redis.conf:/etc/redis/redis.conf:ro - ../redis/data:/data command: - redis-server - /etc/redis/redis.conf ports: - 6379:6379 mysql: image: mysql:5.7 volumes: - ../mysql/my.cnf:/etc/mysql/my.cnf:ro - ../mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: my-secret-pw ports: - 3306:3306 tomcat: image: tomcat:8.5 volumes: - ../app:/usr/local/tomcat/webapps/ROOT ports: - 80:8080 在这个项目里，我将 Redis 和 MySQL 的数据存储目录，也就是 Redis 容器中的 /data 目录和 MySQL 容器中的 /var/lib/mysql 目录通过挂载的方式绑定到了宿主机上的目录中。 这么做的目的是为了让 Redis 和 MySQL 的数据能够持久化存储，避免我们在创建和移除容器时造成数据的流失。 同时，这种将数据挂载出来的方法，可以直接方便我们打包数据并传送给其他开发者，方便开发过程中进行联调。 在 Tomcat 这个服务中，我们将程序直接挂载到 webapps/ROOT 目录下，这样我们就能够借助 Tomcat 访问我们的应用了。 如果大家有多个项目，也可以进行适当调整，将它们挂载到 webapps 下面的子目录中，实现同时访问多个应用的目的。 另外，这里我还把 Tomcat 默认的 8080 端口映射到了宿主机的 80 端口上，这样便于我们直接通过地址访问网站，不需要经常人工补充端口号了。 启动项目 一切就绪，我们就可以直接通过 Docker Compose 的命令来启动开发环境了。 # docker-compose -p javaweb -f ./compose/docker-compose.yml up -d 留言互动 在这节中，我们展示了通过 Docker 搭建一个 Java Web 开发环境的过程，下面就是大家自己动手进行实践的时候了。 本小节中的示例，已经更新到了： https://github.com/youmingdot/docker-book-for-developer-samples 大家可以在实践过程中的用其作为参考。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果大家在实践过程中遇到困难，或者有自己的实践心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/20.实践之路：在开发环境中使用服务发现.html":{"url":"开发者必备的Docker实践指南/20.实践之路：在开发环境中使用服务发现.html","title":"20.实践之路：在开发环境中使用服务发现","keywords":"","body":"在开发环境中使用服务发现 服务发现应用是很多服务化系统的组成部分，所以在开发、测试环境中也就有必要配备一套服务发现体系来配合我们的开发、测试工作。在这一小节里，我们就来谈谈如何在 Docker 环境下部署服务发现应用。 使用 Docker Compose 模拟 Zookeeper 集群 实现服务发现的方法有很多种，其中较为常见的一种是利用分布式注册中心，解决服务之间协调的问题。 在众多注册中心应用中，Zookeeper 是较为常见和常用的一款程序，这里我们就以 Zookeeper 为例，介绍如何使用 Docker 搭建 Zookeeper 的运行环境。 设计目录结构 由于 Zookeeper 的运行并不需要太多的关注配置和调整，这里我们就以最基础的形式来设计 Docker Compose 项目的结构。 └─ project ├─ bin │ └─ compose.sh └─ compose └─ docker-compose.yml 为了方便日常操作，我们依然编写了 compose.sh 这个脚本来辅助我们控制 Docker Compose 项目。 编写 docker-compose.yml 很多读者会问到一个问题，怎么样才能通过 Docker 的虚拟化技术实现在一个机器上模拟出多台机器的效果。或者说一个我们这里会涉及的具体问题，如何只用一个 Docker 来模拟一个高可用的 Zookeeper 集群。 我们知道，要实现 Zookeeper 的高可用，至少需要三个 Zookeeper 节点进行协作，所以这里我们用三个单独的 Docker Compose 服务定义来分别定义这三个节点。 version: '3' services: zk1: image: zookeeper:3.4 restart: always hostname: zk1 environment: ZOO_MY_ID: 1 ZOO_SERVERS: server.1=0.0.0.0:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 ports: - 2181:2181 zk2: image: zookeeper:3.4 restart: always hostname: zk2 environment: ZOO_MY_ID: 2 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=0.0.0.0:2888:3888 server.3=zk3:2888:3888 ports: - 2182:2181 zk3: image: zookeeper:3.4 restart: always hostname: zk3 environment: ZOO_MY_ID: 3 ZOO_SERVERS: server.1=zk1:2888:3888 server.2=zk2:2888:3888 server.3=0.0.0.0:2888:3888 ports: - 2183:2181 在这个 Docker Compose 项目中，我们定义的三个 Zookeeper 服务都直接使用了官方制作的 zookeeper 镜像。 在这个镜像里，我们可以留意定制 ZOO_MY_ID 和 ZOO_SERVERS 这两个环境变量。这两个变量主要是用来识别 Zookeeper 集群中不同 Zookeeper 程序的。 其中 ZOO_MY_ID 是 Zookeeper 在集群中的编号，而 ZOO_SERVERS 用来定义集群中的所有 Zookeeper 及它们的连接方式。 我们以 zk1 这个服务为例来解释一下 ZOO_SERVERS 的定义方法。 server.1=0.0.0.0:2888:3888 server.2=zk2:2888:3888 server.3=zk3:2888:3888 我们可以在 ZOO_SERVERS 中定义所有处于 Zookeeper 集群中的程序，通过空格来间隔它们。而每个服务的的定义形式为 server.[id]=[host]:[port]:[port]，所以就有了上面例子中我们看到的样子。 在这个例子里，我们描述了三个 Zookeeper 程序的连接地址。 由于每个容器都有独立的端口表，所以即使这些程序都运行在一个主机里，我们依然不需要担心，它们会造成端口的冲突。所以这里我们直接使用默认的 2888 和 3888 来进行服务间的相互通信即可。 而在进行容器互联的过程中，我们可以通过 Docker 的解析机制，直接填入对应服务的名称替代它们的 IP 地址，也就是这个例子里的 zk2 和 zk3。 重启机制 在项目定义中，我们还注意到了 restart: always 这个配置，这个配置主要是用来控制容器的重启策略的。 这里的 always 指的是不论任何情况，容器出现问题后都会自动重启，也包括 Docker 服务本身在启动后容器也会自动启动。 另外，restart 还支持几种配置： 配置值 说明 no 不设重启机制 always 总是重启 on-failure 在异常退出时重启 unless-stopped 除非由停止命令结束，其他情况都重启 在实际使用中，我们可以根据需要选择不同的重启策略。 而这个项目里，我们希望 Zookeeper 能够一直健壮的运行，所以使用了 always 这个重启策略。 启动项目 一切就绪，我们就可以直接通过 Docker Compose 的命令来启动开发环境了。 # ./bin/compose.sh up -d 留言互动 在这节中，我们展示了在开发中使用 Docker 部署服务发现工具的过程，下面就是大家自己动手进行实践的时候了。 本小节中的示例，已经更新到了： https://github.com/youmingdot/docker-book-for-developer-samples 大家可以在实践过程中的用其作为参考。 欢迎大家通过留言的方式说出你的实践之路。我会选出有代表性的优质留言，推荐给大家。 同时，如果大家在实践过程中遇到困难，或者有自己的实践心得要与大家分享，可以加入到这本小册的官方微信群中，参与对相关问题的讨论。 "},"开发者必备的Docker实践指南/21.百尺竿头，更进一步.html":{"url":"开发者必备的Docker实践指南/21.百尺竿头，更进一步.html","title":"21.百尺竿头，更进一步","keywords":"","body":"百尺竿头，更进一步 在这本小册里，我们从 Docker 最基础的知识谈起，介绍了 Docker 的核心组成部分以及操作这些功能的命令与方法，其后又讲解了开发中最常用的 Docker Compose，并完整的展示了通过它们搭建开发环境的过程。 然而 Docker 的生态太过丰富，不仅是 Docker 相关的知识浩如烟海，就连开发中所能使用到的技巧也不可胜数。虽然我尽心总结，但这本小册里肯定还存在许多欠缺和匮乏之处。 好在小册的结构经过我精心编排，形成了一条有逻辑的脉络，这能够帮助大家由浅入深的逐步掌握 Docker 及其与它相关的知识。 大家可以在阅读每一小节后，对其中仍有疑惑之处，可以直接加入到这本小册的微信群中，直接向大家提问并参与我们的交流。同时，如果你在开发中还有对工作效率或其他方面有提高的 Docker 使用经验技巧，也欢迎加入到微信群中，与大家分享。 另外，大家可以通过留言或在微信群中提问的方式，说出你还想了解的知识点或使用技巧，在这本小册后面，我会选择大家比较关注的一些知识或问题专门开辟篇幅进行讲解。 知识延伸 在小册里我们谈到了很多关于 docker 命令和 docker-compose 命令的使用方法，但这两个命令中还包含了大量的使用方法，大家可以通过阅读这两个命令的手册来获得更详细的解读。 docker : https://docs.docker.com/engine/reference/run/ docker-compose : https://docs.docker.com/compose/reference/overview/ 如果还希望了解更多关于 Docker 的知识，我想下面的这些社区会对你很有帮助。 掘金 Segmentfault 开源中国 我的专栏 最后，友情推荐下我自己的微信公众号「虞山脚下」，更多有关技术的知识我会逐渐更新到公众号中。使用微信扫一扫下面的二维码即可到访。 也欢迎到访：虞山脚下 : https://youmingdot.com "},"用npm-script打造超溜的前端工作流/00为什么选择npm-script.html":{"url":"用npm-script打造超溜的前端工作流/00为什么选择npm-script.html","title":"00为什么选择npm-script","keywords":"","body":"为什么选择 npm script？ 可能在你翻开这个页面的同时，心里在嘀咕，为什么要选择 npm script？我用着 grunt、gulp 不是挺好的么？ 如果你在心里这么问自己，我会很欣慰，因为理性的选择都应该从为什么开始。在小册介绍中我提到的重量级构建工具所带来的问题，已有前人总结的非常不错，吐血推荐大家阅读原文：Why I left gulp and grunt for npm scripts，中译版也有，可以自己去搜。 说说我自己的亲身经历，在前东家接手维护过使用了 39 个 gulp 插件的项目，因为项目起步较早，部分插件所依赖的基础工具版本都比较老，当这些插件所依赖的基础工具升级之后，gulp 插件本身并没有更新的那么快，我不得不 fork 原仓库去维护内部的版本，而当 gulp 发布了新版本之后，升级插件更是一场艰苦的持久战。 冷静思考下来，上面这种复杂性其实并没有必要，在软件工程里面有个重要的原则，就是简单性，越是简单的东西越是可靠，从概率论的角度，任何系统环节越多稳定性越差。 npm script 相比 grunt、gulp 之类的构建工具简单很多，因为它消除了这些构建工具所带来的抽象层，并带给我们更大的自由度。随着社区的发展，各种基础工具你都可以信手拈来，只要你会使用 npmjs.com 去搜索，或者去 libraries.io 上搜索。 废话不多说，我再补充 3 组数据，相信看完这 3 组数据，你就知道该做出什么选择了。 Google Trends 第 1 组数据来自 Google Trends，如果你想了解任何事物的长期发展趋势，Google Trends 是个非常不错的工具。 图中是 Google 上的 grunt、gulp、webpack、npm 等 4 种工具的搜索量呈现的趋势，npm 无疑是非常值得前端工程师关注的，而真正让他强大到无所不能（夸张说法）的 npm script 是不是应该熟练掌握？ Stack Overflow Trends 第 2 组数据来自 Stack Overflow Trends，就是那个遇到任何技术问题都可以去找答案的问答社区。 图中是 4 种工具逐月问题数在全部问题总数中的占比，虽然整体比例比较小，但是从趋势来看，webpack、npm 依然是值得的关注的技术。 The State of JS Survey 2016 第 3 组数据来自 The State of JS Survey 2016 年度调查的结果，虽然 npm script 在 javascript 开发者中接受度没有排到前四名（webpack、grunt、gulp、browserify），但是在其他项中名列前茅，个人也比较好奇今年的实际表现（统计结果还没出来）。 好，关于为什么该拥抱 npm script 就说到这里，期待接下来你能跟我一起去探索 npm script 的方方面面，把它学会用好，添加到自己的武器库里。 "},"用npm-script打造超溜的前端工作流/01入门篇：创建并运行npm-script命令.html":{"url":"用npm-script打造超溜的前端工作流/01入门篇：创建并运行npm-script命令.html","title":"01入门篇：创建并运行npm-script命令","keywords":"","body":"1.1 初识 npm script 首先介绍创建 package.json 文件的科学方法，目标是掌握 npm init 命令。然后，通过在终端中运行自动生成的 test 命令，详细讲解 npm 脚本基本执行流程。 然后，动手给项目增加 eslint 命令，熟悉创建自定义命令的基本流程。 用 npm init 快速创建项目 开始探索 npm script 之前，我们先聊聊这些 scripts 所依赖的文件 package.json，以它为基础的 npm 则是 node.js 社区蓬勃发展的顶梁柱。 npm 为我们提供了快速创建 package.json 文件的命令 npm init，执行该命令会问几个基本问题，如包名称、版本号、作者信息、入口文件、仓库地址、许可协议等，多数问题已经提供了默认值，你可以在问题后敲回车接受默认值： package name: (hello-npm-script) version: (0.1.0) description: hello npm script entry point: (index.js) test command: git repository: keywords: npm, script license: (MIT) 上面的例子指定了描述（description）和关键字（keywords）两个字段，基本问题问完之后 npm 会把 package.json 文件内容打出来供你确认： { \"name\": \"hello-npm-script\", \"version\": \"0.1.0\", \"description\": \"hello npm script\", \"main\": \"index.js\", \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, \"keywords\": [ \"npm\", \"script\" ], \"author\": \"wangshijun (https://github.com/wangshijun)\", \"license\": \"MIT\" } 按回车确认就能把package.json 的内容写到文件系统，如果要修改 package.json，可以直接用编辑器编辑，或者再次运行 npm init，npm 默认不会覆盖修改里面已经存在的信息。 TIP#1: 嫌上面的初始化方式太啰嗦？你可以使用 npm init -f（意指 --force，或者使用 --yes）告诉 npm 直接跳过参数问答环节，快速生成 package.json。 初始化 package.json 时的字段默认值是可以自己配置的，细心的同学可能已经发现，我上面的默认版本号是 0.1.0，而 npm 默认的版本号是 0.0.1，可以用下面的命令去修改默认配置： npm config set init.author.email \"wangshijun2010@gmail.com\" npm config set init.author.name \"wangshijun\" npm config set init.author.url \"http://github.com/wangshijun\" npm config set init.license \"MIT\" npm config set init.version \"0.1.0\" TIP#2: 将默认配置和 -f 参数结合使用，能让你用最短的时间创建 package.json，快去自己试试吧。 严肃的工程师都会使用 Git 对源代码进行版本管理，在 npm init 的基础上，你可以使用 git init 来初始化 git 仓库，不再展开。 纸上得来终觉浅，想掌握 npm script，请打开终端，执行下列命令： cd ~ mkdir hello-npm-script && cd $_ npm init npm init -f 执行上面第 3、4 行命令时结果是否符合预期？如果不符合预期，请在下面留言，或者在读者群里反馈。 用 npm run 执行任意命令 使用 npm init 创建的 package.json 文件中包含了 scripts 字段： \"scripts\": { \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, 在终端中运行 npm run test，能看到 Error: no test specified 的输出。npm run test 可以简写为 npm test，或更简单的 npm t，得到的结果是几乎相同的。npm test 顾名思义，就是运行项目测试，实际用法在实战环节会有介绍。 和 test 类似，start 也是 npm 内置支持的命令，但是需要先在 scripts 字段中声明该脚本的实际内容，如果没声明就执行 npm start，会直接报错。如下图所示： 那么，npm 是如何管理和执行各种 scripts 的呢？作为 npm 内置的核心功能之一，npm run 实际上是 npm run-script 命令的简写。当我们运行 npm run xxx 时，基本步骤如下： 从 package.json 文件中读取 scripts 对象里面的全部配置； 以传给 npm run 的第一个参数作为键，本例中为 xxx，在 scripts 对象里面获取对应的值作为接下来要执行的命令，如果没找到直接报错； 在系统默认的 shell 中执行上述命令，系统默认 shell 通常是 bash，windows 环境下可能略有不同，稍后再讲。 注意，上面这是简化的流程，更复杂的钩子机制后面章节单独介绍。 举例来说，如果 package.json 文件内容如下： { \"name\": \"hello-npm-script\", \"devDependencies\": { \"eslint\": \"latest\" }, \"scripts\": { \"eslint\": \"eslint **.js\" } } 如果不带任何参数执行 npm run，它会列出可执行的所有命令，比如下面这样： Available scripts in the myproject package: eslint eslint **.js 如果运行 npm run eslint，npm 会在 shell 中运行 eslint **.js。 有没有好奇过上面的 eslint 命令是从哪里来的？其实，npm 在执行指定 script 之前会把 node_modules/.bin 加到环境变量 $PATH 的前面，这意味着任何内含可执行文件的 npm 依赖都可以在 npm script 中直接调用，换句话说，你不需要在 npm script 中加上可执行文件的完整路径，比如 ./node_modules/.bin/eslint **.js。 创建自定义 npm script 知道如何运行 npm script 之后，接下来我们在 hello-npm-script 项目中添加有实际用途的 eslint 脚本，eslint 是社区中接受度比较高的 javascript 风格检查工具，有大把现成的规则集可供你选择，比如 google、 airbnb。 在新项目或者任何现有项目中添加 eslint 自定义脚本的步骤如下： 1. 准备被检查的代码 要做代码检查，我们必须有代码，创建 index.js 文件，输入如下内容： const str = 'some value'; function fn(){ console.log('some log'); } 2. 添加 eslint 依赖 执行如下命令将 eslint 添加为 devDependencies： npm install eslint -D 3. 初始化 eslint 配置 用 eslint 做检查需要配置规则集，存放规则集的文件就是配置文件，使用如下文件生成配置文件： ./node_modules/.bin/eslint --init TIP#3: 把 eslint 安装为项目依赖而非全局命令，项目可移植性更高。 在命令行提示中选择 Answer questions about your style，如下图回答几个问题，答案可以根据自己的偏好： 回车后根目录下就有了 .eslintrc.js 配置文件： module.exports = { env: { es6: true, node: true, }, extends: 'eslint:recommended', rules: { indent: ['error', 4], 'linebreak-style': ['error', 'unix'], quotes: ['error', 'single'], semi: ['error', 'always'], }, }; 4. 添加 eslint 命令 在 package.json 的 scripts 字段中新增命令 eslint： { \"scripts\": { \"eslint\": \"eslint *.js\", \"test\": \"echo \\\"Error: no test specified\\\" && exit 1\" }, } 手动修改 package.json 时一定要注意语法正确。 5. 运行 eslint 命令 执行 npm run eslint，可以看到，按照官方推荐规则代码里有 3 处不符合规范的地方： 如果读到这里，相信你已经完成 npm script 上手，接下来我们去探索更高级的话题。 20171205 增补：eslint 完成 react、vue.js 代码的检查 如果需要结合 eslint 检查主流前端框架 react、vue.js，下面提供两条线索，因为官方仓库的 README 就可以作为入门文档，仔细读读相信绝大多数同学都能配置好。 使用 eslint-plugin-react 检查 react 代码，使用 react-plugin-react-native 检查 react-native 代码，如果你比较懒，可以直接使用 eslint-config-airbnb，里面内置了 eslint-plugin-react，新人常遇到 peerDependencies 安装失败问题可参照 npmjs 主页上的如下方法解决： ( export PKG=eslint-config-airbnb; npm info \"$PKG@latest\" peerDependencies --json | command sed 's/[\\{\\},]//g ; s/: /@/g' | xargs npm install --save-dev \"$PKG@latest\" ) 推荐使用 vue.js 官方的 eslint 插件：eslint-plugin-vue 来检查 vue.js 代码，具体的配置方法官方 README 写的清晰明了，这里就不赘述了。 上面的几种 eslint 规则集的官方仓库都列出了各自支持的规则，如果你需要关闭某些规则，可以直接在自己的 .eslintrc* 里面的 rules 中配置，比如我们仓库里面的： module.exports = { env: { es6: true, node: true, }, extends: 'eslint:recommended', rules: { indent: ['error', 2], 'linebreak-style': ['error', 'unix'], quotes: ['error', 'single'], semi: ['error', 'always'], }, }; 如果你配置过程中遇到什么问题，欢迎留言或者在读者群里面交流。 "},"用npm-script打造超溜的前端工作流/02入门篇：运行多个npm-script的各种姿势.html":{"url":"用npm-script打造超溜的前端工作流/02入门篇：运行多个npm-script的各种姿势.html","title":"02入门篇：运行多个npm-script的各种姿势","keywords":"","body":"1.2 运行多个 npm script 的各种姿势 前端项目通常会包括多个 npm script，对多个命令进行编排是很自然的需求，有时候需要将多个命令串行，即脚本遵循严格的执行顺序；有时候则需要让它们并行来提高速度，比如不相互阻塞的 npm script。社区中也有比 npm 内置的多命令运行机制更好用的解决方案：npm-run-all。 哪来那么多命令？ 通常来说，前端项目会包含 js、css、less、scss、json、markdown 等格式的文件，为保障代码质量，给不同的代码添加检查是很有必要的，代码检查不仅保障代码没有低级的语法错误，还可确保代码都遵守社区的最佳实践和一致的编码风格，在团队协作中尤其有用，即使是个人项目，加上代码检查，也会提高你的效率和质量。 我通常会给前端项目加上下面 4 种代码检查： eslint，可定制的 js 代码检查，1.1 中有详细的配置步骤； stylelint，可定制的样式文件检查，支持 css、less、scss； jsonlint，json 文件语法检查，踩过坑的同学会清楚，json 文件语法错误会知道导致各种失败； markdownlint-cli，Markdown 文件最佳实践检查，个人偏好； 需要注意的是，html 代码也应该检查，但是工具支持薄弱，就略过不表。此外，为代码添加必要的单元测试也是质量保障的重要手段，常用的单测技术栈是： mocha，测试用例组织，测试用例运行和结果收集的框架； chai，测试断言库，必要的时候可以结合 sinon 使用； TIP#4：测试工具如 tap、ava 也都提供了命令行接口，能很好的集成到 npm script 中，原理是相通的。 包含了基本的代码检查、单元测试命令的 package.json 如下： { \"name\": \"hello-npm-script\", \"version\": \"0.1.0\", \"main\": \"index.js\", \"scripts\": { \"lint:js\": \"eslint *.js\", \"lint:css\": \"stylelint *.less\", \"lint:json\": \"jsonlint --quiet *.json\", \"lint:markdown\": \"markdownlint --config .markdownlint.json *.md\", \"test\": \"mocha tests/\" }, \"devDependencies\": { \"chai\": \"^4.1.2\", \"eslint\": \"^4.11.0\", \"jsonlint\": \"^1.6.2\", \"markdownlint-cli\": \"^0.5.0\", \"mocha\": \"^4.0.1\", \"stylelint\": \"^8.2.0\", \"stylelint-config-standard\": \"^17.0.0\" } } 让多个 npm script 串行？ 在我们运行测试之前确保我们的代码都通过代码检查会是比较不错的实践，这也是让多个 npm script 串行的典型用例，实现方式也比较简单，只需要用 && 符号把多条 npm script 按先后顺序串起来即可，具体到我们的项目，修改如下图所示： diff --git a/package.json b/package.json index c904250..023d71e 100644 --- a/package.json +++ b/package.json @@ -8,7 +8,7 @@ - \"test\": \"mocha tests/\" + \"test\": \"npm run lint:js && npm run lint:css && npm run lint:json && npm run lint:markdown && mocha tests/\" }, 然后直接执行 npm test 或 npm t，从输出可以看到子命令的执行顺序是严格按照我们在 scripts 中声明的先后顺序来的： eslint ==> stylelint ==> jsonlint ==> markdownlint ==> mocha 需要注意的是，串行执行的时候如果前序命令失败（通常进程退出码非0），后续全部命令都会终止，我们可以尝试在 index.js 中引入错误（删掉行末的分号）： diff --git a/index.js b/index.js index ab8bd0e..b817ea4 100644 --- a/index.js +++ b/index.js @@ -4,7 +4,7 @@ const add = (a, b) => { } return NaN; -}; +} module.exports = { add }; 然后重新运行 npm t，结果如下，npm run lint:js 失败之后，后续命令都没有执行： 让多个 npm script 并行？ 在严格串行的情况下，我们必须要确保代码中没有编码规范问题才能运行测试，在某些时候可能并不是我们想要的，因为我们真正需要的是，代码变更时同时给出测试结果和测试运行结果。这就需要把子命令的运行从串行改成并行，实现方式更简单，把连接多条命令的 && 符号替换成 & 即可。 代码变更如下： diff --git a/package.json b/package.json index 023d71e..2d9bd6f 100644 --- a/package.json +++ b/package.json @@ -8,7 +8,7 @@ - \"test\": \"npm run lint:js && npm run lint:css && npm run lint:json && npm run lint:markdown && mocha tests/\" + \"test\": \"npm run lint:js & npm run lint:css & npm run lint:json & npm run lint:markdown & mocha tests/\" }, 重新运行 npm t，我们得到如下结果： 细心的同学可能已经发现上图中哪里不对，npm run lint:js 的结果在进程退出之后才输出，如果你自己运行，不一定能稳定复现这个问题，但 npm 内置支持的多条命令并行跟 js 里面同时发起多个异步请求非常类似，它只负责触发多条命令，而不管结果的收集，如果并行的命令执行时间差异非常大，上面的问题就会稳定复现。怎么解决这个问题呢？ 答案也很简单，在命令的增加 & wait 即可，这样我们的 test 命令长这样： npm run lint:js & npm run lint:css & npm run lint:json & npm run lint:markdown & mocha tests/ & wait 加上 wait 的额外好处是，如果我们在任何子命令中启动了长时间运行的进程，比如启用了 mocha 的 --watch 配置，可以使用 ctrl + c 来结束进程，如果没加的话，你就没办法直接结束启动到后台的进程。 有没有更好的管理方式？ 有强迫症的同学可能会觉得像上面这样用原生方式来运行多条命令很臃肿，幸运的是，我们可以使用 npm-run-all 实现更轻量和简洁的多命令运行。 用如下命令将 npm-run-all 添加到项目依赖中： npm i npm-run-all -D 然后修改 package.json 实现多命令的串行执行： diff --git a/package.json b/package.json index b3b1272..83974d6 100644 --- a/package.json +++ b/package.json @@ -8,7 +8,8 @@ - \"test\": \"npm run lint:js & npm run lint:css & npm run lint:json & npm run lint:markdown & mocha tests/ & wait\" + \"mocha\": \"mocha tests/\", + \"test\": \"npm-run-all lint:js lint:css lint:json lint:markdown mocha\" }, npm-run-all 还支持通配符匹配分组的 npm script，上面的脚本可以进一步简化成： diff --git a/package.json b/package.json index 83974d6..7b327cd 100644 --- a/package.json +++ b/package.json @@ -9,7 +9,7 @@ - \"test\": \"npm-run-all lint:js lint:css lint:json lint:markdown mocha\" + \"test\": \"npm-run-all lint:* mocha\" }, 如何让多个 npm script 并行执行？也很简单： diff --git a/package.json b/package.json index 7b327cd..c32da1c 100644 --- a/package.json +++ b/package.json @@ -9,7 +9,7 @@ - \"test\": \"npm-run-all lint:* mocha\" + \"test\": \"npm-run-all --parallel lint:* mocha\" }, 并行执行的时候，我们并不需要在后面增加 & wait，因为 npm-run-all 已经帮我们做了。 TIP#5：npm-run-all 还提供了很多配置项支持更复杂的命令编排，比如多个命令并行之后接串行的命令，感兴趣的同学请阅读文档，自己玩儿。 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 02-run-multiple-npm-scripts。运行命令前别忘了安装 node_modules，😆 "},"用npm-script打造超溜的前端工作流/03入门篇：给npm-script传递参数和添加注释.html":{"url":"用npm-script打造超溜的前端工作流/03入门篇：给npm-script传递参数和添加注释.html","title":"03入门篇：给npm-script传递参数和添加注释","keywords":"","body":"1.3 给 npm script 传递参数和添加注释 本小节会介绍 3 个知识点：给 npm script 传递参数以减少重复的 npm script；增加注释提高 npm script 脚本的可读性；控制运行时日志输出能让你专注在重要信息上。 给 npm script 传递参数 eslint 内置了代码风格自动修复模式，只需给它传入 --fix 参数即可，在 scripts 中声明检查代码命令的同时你可能也需要声明修复代码的命令，面对这种需求，大多数同学可能会忍不住复制粘贴，如下： diff --git a/package.json b/package.json index c32da1c..b6fb03e 100644 --- a/package.json +++ b/package.json @@ -5,6 +5,7 @@ \"lint:js\": \"eslint *.js\", + \"lint:js:fix\": \"eslint *.js --fix\", 在 lint:js 命令比较短的时候复制粘贴的方法简单粗暴有效，但是当 lint:js 命令变的很长之后，难免后续会有人改了 lint:js 而忘记修改 lint:js:fix（别问我为啥，我就是踩着坑过来的），更健壮的做法是，在运行 npm script 时给定额外的参数，代码修改如下： diff --git a/package.json b/package.json --- a/package.json +++ b/package.json @@ -5,6 +5,7 @@ \"lint:js\": \"eslint *.js\", + \"lint:js:fix\": \"npm run lint:js -- --fix\", 要格外注意 --fix 参数前面的 -- 分隔符，意指要给 npm run lint:js 实际指向的命令传递额外的参数。 运行效果如下图： 上图第2个红色框里面是实际执行的命令，可以看到 --fix 参数附加在了后面。 TIP#6：如果你不想单独声明 lint:js:fix 命令，在需要的时候直接运行： npm run lint:js -- --fix 来实现同样的效果。 问题来了，如果我想为 mocha 命令增加 --watch 模式方便在开发时立即看到测试结果，该怎么做呢？相信读到这里你心中已经有了答案。 :stuck_out_tongue: 给 npm script 添加注释 如果 package.json 中的 scripts 越来越多，或者出现复杂的编排命令，你可能需要给它们添加注释以保障代码可读性，但 json 天然是不支持添加注释的，下面是 2 种比较 trick 的方式。 第一种方式是，package.json 中可以增加 // 为键的值，注释就可以写在对应的值里面，npm 会忽略这种键，比如，我们想要给 test 命令添加注释，按如下方式添加： diff --git a/package.json b/package.json --- a/package.json +++ b/package.json @@ -10,6 +10,7 @@ + \"//\": \"运行所有代码检查和单元测试\", \"test\": \"npm-run-all --parallel lint:* mocha\" 这种方式的明显不足是，npm run 列出来的命令列表不能把注释和实际命令对应上，如果你声明了多个，npm run 只会列出最后那个，如下图： 另外一种方式是直接在 script 声明中做手脚，因为命令的本质是 shell 命令（适用于 linux 平台），我们可以在命令前面加上注释，具体做法如下： diff --git a/package.json b/package.json --- a/package.json +++ b/package.json @@ -10,8 +10,7 @@ - \"//\": \"运行所有代码检查和单元测试\", - \"test\": \"npm-run-all --parallel lint:* mocha\" + \"test\": \"# 运行所有代码检查和单元测试 \\n npm-run-all --parallel lint:* mocha\" 注意注释后面的换行符 \\n 和多余的空格，换行符是用于将注释和命令分隔开，这样命令就相当于微型的 shell 脚本，多余的空格是为了控制缩进，也可以用制表符 \\t 替代。这种做法能让 npm run 列出来的命令更美观，但是 scripts 声明阅读起来不那么整齐美观。 上面两种方式都有明显的缺陷，个人建议的更优方案还是把复杂的命令剥离到单独的文件中管理，在单独的文件中可以自由给它添加注释，详见后续章节。 调整 npm script 运行时日志输出 在运行 npm script 出现问题时你需要有能力去调试它，某些情况下你需要让 npm script 以静默的方式运行，这类需求可通过控制运行时日志输出级别来实现。 日志级别控制参数有好几个，简单举例如下： 默认日志输出级别 即不加任何日志控制参数得到的输出，可能是你最常用的，能看到执行的命令、命令执行的结果。 显示尽可能少的有用信息 结合其他工具调用 npm script 的时候比较有用，需要使用 --loglevel silent，或者 --silent，或者更简单的 -s 来控制，这个日志级别的输出实例如下（只有命令本身的输出，读起来非常的简洁）： 如果执行各种 lint script 的时候启用了 -s 配置，代码都符合规范的话，你不会看到任何输出，这就是没有消息是最好的消息的由来，哈哈！ 显示尽可能多的运行时状态 排查脚本问题的时候比较有用，需要使用 --loglevel verbose，或者 --verbose，或者更简单的 -d 来控制，这个日志级别的输出实例如下（详细打印出了每个步骤的参数、返回值，下面的截图只是部分）： 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 03-arguments-comments-logs。 "},"用npm-script打造超溜的前端工作流/04进阶篇：使用npm-script的钩子.html":{"url":"用npm-script打造超溜的前端工作流/04进阶篇：使用npm-script的钩子.html","title":"04进阶篇：使用npm-script的钩子","keywords":"","body":"2.1 使用 npm script 的钩子 为了方便开发者自定义，npm script 的设计者为命令的执行增加了类似生命周期的机制，具体来说就是 pre 和 post 钩子脚本。这种特性在某些操作前需要做检查、某些操作后需要做清理的情况下非常有用。 举例来说，运行 npm run test 的时候，分 3 个阶段： 检查 scripts 对象中是否存在 pretest 命令，如果有，先执行该命令； 检查是否有 test 命令，有的话运行 test 命令，没有的话报错； 检查是否存在 posttest 命令，如果有，执行 posttest 命令； 到目前为止我们所覆盖的前端工作流包含了代码检查和测试自动化运行环节，衡量测试效果的重要指标是测试覆盖率，而收集覆盖率也非常的简单，下面逐步讲解如何把代码检查、测试运行、覆盖率收集这些步骤串起来。 改造 test 命令 首先，我们基于钩子机制对现有的 scripts 做以下 3 点重构，把代码检查和测试运行串起来： 增加简单的 lint 命令，并行运行所有的 lint 子命令； 增加 pretest 钩子，在其中运行 lint 命令； 把 test 替换为更简单的 mocha tests/； 代码 diff 如下： diff --git a/package.json b/package.json index 8f67810..d297f2e 100644 --- a/package.json +++ b/package.json @@ -4,13 +4,17 @@ + \"lint\": \"npm-run-all --parallel lint:*\", \"lint:js\": \"eslint *.js\", \"lint:js:fix\": \"npm run lint:js -- --fix\", \"lint:css\": \"stylelint *.less\", \"lint:json\": \"jsonlint --quiet *.json\", \"lint:markdown\": \"markdownlint --config .markdownlint.json *.md\", - \"mocha\": \"mocha tests/\", - \"test\": \"# 运行所有代码检查和单元测试 \\n npm-run-all --parallel lint:* mocha\" + \"pretest\": \"npm run lint\", + \"test\": \"mocha tests/\", 当我们运行 npm test 的时候，会先自动执行 pretest 里面的 lint，实际输出如下： 增加覆盖率收集 接下来，我们把运行测试和覆盖率收集串起来，具体做法是：增加覆盖率收集的命令，并且覆盖率收集完毕之后自动打开 html 版本的覆盖率报告。要实现目标，我们需要引入两个新工具： 覆盖率收集工具 nyc，是覆盖率收集工具 istanbul 的命令行版本，istanbul 支持生成各种格式的覆盖率报告，我已经使用多年； 打开 html 文件的工具 opn-cli，是能够打开任意程序的工具 opn 的命令行版本，作者是\b前端社区非常高产的 Sindre Sorhus，它在 npm 上发布了超过 1000 个包，并且质量都很不错。 使用如下命令安装依赖： npm i nyc opn-cli -D 然后在 package.json 增加 nyc 的配置，告诉 nyc 该忽略哪些文件。最后是在 scripts 中新增 3 条命令： precover，收集覆盖率之前把之前的覆盖率报告目录清理掉； cover，直接调用 nyc，让其生成 html 格式的覆盖率报告； postcover，清理掉临时文件，并且在浏览器中预览覆盖率报告； 具体 diff 如下： diff --git a/package.json b/package.json index 8f67810..d297f2e 100644 --- a/package.json +++ b/package.json @@ -4,13 +4,17 @@ scripts: { + \"precover\": \"rm -rf coverage\", + \"cover\": \"nyc --reporter=html npm test\", + \"postcover\": \"rm -rf .nyc_output && opn coverage/index.html\" }, @@ -22,7 +26,15 @@ \"devDependencies\": { \"npm-run-all\": \"^4.1.2\", + \"nyc\": \"^11.3.0\", + \"opn-cli\": \"^3.1.0\", \"stylelint\": \"^8.2.0\", \"stylelint-config-standard\": \"^17.0.0\" + }, + \"nyc\": { + \"exclude\": [ + \"**/*.spec.js\", + \".*.js\" + ] } } 改完之后，我们可以直接运行 npm run cover，运行的详细截图如下： TIP#7：到目前为止，我们的工作流中已经包含代码检查、测试运行、覆盖率收集、覆盖率查看等功能，你是不是可以用来改进下自己的工作流呢？ 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 04-pre-and-post-hooks。 "},"用npm-script打造超溜的前端工作流/05进阶篇：在npm-script中使用环境变量.html":{"url":"用npm-script打造超溜的前端工作流/05进阶篇：在npm-script中使用环境变量.html","title":"05进阶篇：在npm-script中使用环境变量","keywords":"","body":"2.2 在 npm script 中使用变量 npm 为加高效的执行 npm script 做了大量的优化，创建并运行 npm script 命令 里面讲到的环境变量特性能让我们在 npm script 中直接调用依赖包里的可执行文件，更强大的是，npm 还提供了 $PATH 之外的更多的变量，比如当前正在执行的命令、包的名称和版本号、日志输出的级别等。 DRY（Don't Repeat Yourself）是基本的编程原则，在 npm script 中使用预定义变量和自定义变量让我们更容易遵从 DRY 原则，因为使用这些变量之后，npm script 就具备了自适应的能力，我们可以直接把积累起来的 npm script 使用到其他项目里面，而不用做任何修改。 使用预定义变量 首先我们来看预定义变量，通过运行 npm run env 就能拿到完整的变量列表，这个列表非常长，这里我使用 npm run env | grep npm_package | sort 拿到部分排序后的预定义环境变量： // 作者信息... npm_package_author_email=wangshijun2010@gmail.com npm_package_author_name=wangshijun npm_package_author_url=http://github.com/wangshijun // 依赖信息... npm_package_devDependencies_markdownlint_cli=^0.5.0 npm_package_devDependencies_mocha=^4.0.1 npm_package_devDependencies_npm_run_all=^4.1.2 // 各种 npm script npm_package_scripts_lint=npm-run-all --parallel lint:* npm_package_scripts_lint_css=stylelint *.less npm_package_scripts_lint_js=eslint *.js npm_package_scripts_lint_js_fix=npm run lint:js -- --fix npm_package_scripts_lint_json=jsonlint --quiet *.json // 基本信息 npm_package_version=0.1.0 npm_package_gitHead=3796e548cfe406ec33ab837ac00bcbd6ee8a38a0 npm_package_license=MIT npm_package_main=index.js npm_package_name=hello-npm-script npm_package_readmeFilename=README.md // 依赖的配置 npm_package_nyc_exclude_0=**/*.spec.js npm_package_nyc_exclude_1=.*.js 变量的使用方法遵循 shell 里面的语法，直接在 npm script 给想要引用的变量前面加上 $ 符号即可。比如： { \"dummy\": \"echo $npm_package_name\" } 回到我们的项目，测试覆盖率归档是比较常见的需求，因为它方便我们追踪覆盖率的变化趋势，最彻底的做法是归档到 CI 系统里面，对于简单项目，则可以直接归档到文件系统中，即把收集到的覆盖率报告按版本号去存放。 比如，我们在根目录下新建 coverage_archive 目录存储覆盖率归档，并利用变量机制把归档和版本号关联起来。具体的 npm script 修改如下： diff --git a/package.json b/package.json index d297f2e..d86f65c 100644 --- a/package.json +++ b/package.json @@ -12,9 +12,10 @@ \"scripts\": { - \"precover\": \"rm -rf coverage\", \"cover\": \"nyc --reporter=html npm test\", - \"postcover\": \"rm -rf .nyc_output && opn coverage/index.html\" + \"cover:cleanup\": \"rm -rf coverage && rm -rf .nyc_output\", + \"cover:archive\": \"mkdir -p coverage_archive/$npm_package_version && cp -r coverage/* coverage_archive/$npm_package_version\", + \"postcover\": \"npm run cover:archive && npm run cover:cleanup && opn coverage_archive/$npm_package_version/index.html\" }, 主要改动是：增加 cover:cleanup 和 cover:archive 命令，并且修改 postcover 命令。下面对使用了环境变量的 npm script 稍作解释： cover:archive 做了 2 件事情： mkdir -p coverage_archive/$npm_package_version 准备当前版本号的归档目录； cp -r coverage/* coverage_archive/$npm_package_version，直接复制文件来归档； 而 postcover 做了 3 件事情： npm run cover:archive，归档本次覆盖率报告； npm run cover:cleanup，清理本次覆盖率报告； opn coverage_archive/$npm_package_version/index.html，直接预览覆盖率报告； 配置好之后，我们直接运行 npm run cover，最后的目录结构如下： 使用自定义变量 除了预定义变量外，我们还可以在 package.json 中添加自定义变量，并且在 npm script 中使用这些变量。 为把测试覆盖率报告分享给其他同事浏览，我们就不能使用 opn-cli 打开文件了，需要启动简单的 http 服务，把网址发给别人浏览，比如我们约定网址 http://IP:3000，这里的 IP 需要替换成自己的实际 IP。 http-server 提供了非常轻量的 http 服务，我们先把它加到 devDependencies 中： npm i http-server -D # 等价命令 npm install http-server --save-dev 接下来，在 package.json 增加自定义端口配置和相应的 npm script 命令，完整的 diff 如下： diff --git a/package.json b/package.json index d86f65c..abc9d01 100644 --- a/package.json +++ b/package.json @@ -3,6 +3,9 @@ \"version\": \"0.1.0\", + \"config\": { + \"port\": 3000 + }, \"scripts\": { @@ -15,7 +18,9 @@ \"cover\": \"nyc --reporter=html npm test\", - \"postcover\": \"npm run cover:archive && npm run cover:cleanup && opn coverage_archive/$npm_package_version/index.html\" + \"cover:serve\": \"http-server coverage_archive/$npm_package_version -p $npm_package_config_port\", + \"cover:open\": \"opn http://localhost:$npm_package_config_port\", + \"postcover\": \"npm-run-all cover:archive cover:cleanup --parallel cover:serve cover:open\" }, @@ -23,6 +28,7 @@ \"devDependencies\": { \"chai\": \"^4.1.2\", + \"http-server\": \"^0.10.0\", \"mocha\": \"^4.0.1\", 关于改动做以下几点解释： 新增的命令 cover:serve 中同时使用了预定义变量 $npm_package_version 和自定义变量 $npm_package_config_port； 预览覆盖率报告的方式从直接打开文件修改为打开网址： http://localhost:$npm_package_config_port； postcover 命令要做的事情比较多，我们直接使用 npm-run-all 来编排子命令。 TIP#8：注意这里给 cover:serve 和 cover:open 增加了并行参数 --parallel，因为 cover:serve 不会自动退出。 TIP#9：可能有同学会好奇，是否可以在自定义变量的声明中使用预定义变量，笔者也有这种好奇，并且做过尝试，结果是不支持。 修改完之后，我们再次运行 npm run cover，终端会在 cover:serve 之后进入等待状态： 同时浏览器会打开覆盖率报告，如下图： 好，关于 npm script 里面的变量使用就介绍到这里，留给你的问题是，在你的项目里面怎么用起来呢？如果想到了，什么时候落地？ 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 05-use-config-variables。 "},"用npm-script打造超溜的前端工作流/06进阶篇：实现npm-script命令自动补全.html":{"url":"用npm-script打造超溜的前端工作流/06进阶篇：实现npm-script命令自动补全.html","title":"06进阶篇：实现npm-script命令自动补全","keywords":"","body":"2.3 实现命令行自动补全 当 npm script 里面积累的命令越来越多时，重度命令行用户肯定会好奇，能不能实现类似 bash、zsh 里面的命令自动补全？答案是肯定的，下面来逐一介绍。 使用 npm run 直接列出 前面章节有过介绍，不带任何参数运行 npm run 能列出 scripts 对象中定义的所有命令，再结合管道操作符、less 命令（这里的 less 不是 css 领域的 less，而是 linux 里面的工具），即使 scripts 子命令很多我们也能移动自如。 比如，我们在项目中执行：npm run | less，得到如下结果，注意截图左下方的红框，按空格能翻页： 在这个结果里面，我们可以进行类似于 Vim 中的搜索，先按 / 进入搜索模式，然后输入 markdown，搜索结果如下图： 把 npm completion 集成到 shell 中 npm 自身提供了自动完成工具 completion，将其集成到 bash 或者 zsh 里也非常容易（顺便说一句，早期我是 bash 的忠实用户，两年前切换到 zsh，就再也没回头）。 官方文档里面的集成方法如下： npm completion >> ~/.bashrc npm completion >> ~/.zshrc TIP#10：如果你好奇上面的命令究竟做了什么，尝试直接运行 npm completion，就能看到它其实在你的配置文件中追加了一大坨 shell。上面命令中的 >> 意思是把前面命令的输出追加到后面的文件中。 如果你也有代码洁癖，为了保持 .zshrc 或者 .bashrc 文件的整洁，可以用下面的方法： 第 1 步，把 npm completion 产生的那坨命令放在单独的文件中： npm completion >> ~/.npm-completion.bash 第 2 步，在 .bashrc 或者 .zshrc 中引入这个文件： echo \"[ -f ~/.npm-completion.bash ] && source ~/.npm-completion.bash;\" >> ~/.bashrc echo \"[ -f ~/.npm-completion.bash ] && source ~/.npm-completion.bash;\" >> ~/.zshrc TIP#11：执行完上面的命令一定要记得 source ~/.zshrc 或者 source ~/.bashrc，来让自动完成生效。 接下来我们就可以尽情享受自动完成带来的便利了，尝试在命令行中输入 npm run，然后键入空格（空格很重要），然后键入 tab 键，发现命令行有什么反应了么？在列出备选项之后，继续按 tab，就能在不同的选项之间切换，找到自己想要的，直接回车就能完成命令补全。多练习几次，你的手指和大脑就能熟练掌握这个过程。 在我们的项目目录里面键入 npm run cov 再键入 tab 键，命令行又有什么反应？ 需要单独说明的是，npm completion 能实现的自动完成不仅仅是 scripts 里面的子自命令，npm 的子命令也是可以的，可以依次输入 npm、空格、tab，看看命令行的反应。 更高级的自动完成 人类对于效率的追求是永无止境的，工程师更是如此，npm 命令补全到目前为止显然还不够高效，能不能补全 package.json 里面的依赖名称？能不能在补全 npm script 的时候列出这个命令是干啥的？ 有人已经帮我们解决了这个痛点，还写成了 zsh 插件（bash 的同学无福消受了）：zsh-better-npm-completion，它有以下几个让人无法拒绝的便利： 1. 在 npm install 时自动根据历史安装过的包给出补全建议 2. 在 npm uninstall 时候根据 package.json 里面的声明给出补全建议 3. 在 npm run 时补全建议中列出命令细节 看到这里，是不是心痒痒？具体的安装方法参照官方 README.md 文件就好，我就不在这里啰嗦了。 TIP#12：如果你要使用 zsh-better-npm-completion 插件，需要把 .bashrc、.zshrc 文件里面 npm completion 部分的配置删掉，避免冲突。 好了，本小节没有代码，读到这里，你动手做了几个？ 20171206 增补：如何实现 yarn 的命令自动补全？ 已经有人帮我们做好了 yarn-completions，能实现类似于 zsh-better-npm-completion 的命令补全，参照官方 README.md 安装即可。 "},"用npm-script打造超溜的前端工作流/07高阶篇01：实现npmscript跨平台兼容.html":{"url":"用npm-script打造超溜的前端工作流/07高阶篇01：实现npmscript跨平台兼容.html","title":"07高阶篇01：实现npmscript跨平台兼容","keywords":"","body":"3.1 实现 npm script 跨平台兼容 到目前为止，如果你在 Linux、Mac 平台做开发，所有的 npm script 都会顺利运行，但是 Windows 下面的同学可能就比较痛苦了，因为不是所有的 shell 命令都是跨平台兼容的，甚至各种常见的文件系统操作也是不兼容的。 可能有部分同学处理过 npm script 跨平台兼容的问题，比如粗暴的为两种平台各写一份 npm script，像下面这样： { \"name\": \"hello-npm-script\", \"scripts\": { \"bash-script\": \"echo Hello $npm_package_name\", \"win-script\": \"echo Hello %npm_package_name%\" } } 有技术追求的工程师肯定不会满足上面的解决方案，实际上社区中已经有非常多的小工具可以帮我们优雅的实现跨平台的 npm script，下面我们探索下如何实现跨平台的文件系统操作、变量引用、环境变量设置。 特别说明，windows 环境的同学建议使用 git bash 来运行 npm script，使用 windows 自带的 cmd 可能会遇到比较多的问题 文件系统操作的跨平台兼容 npm script 中涉及到的文件系统操作包括文件和目录的创建、删除、移动、复制等操作，而社区为这些基本操作也提供了跨平台兼容的包，列举如下： rimraf 或 del-cli，用来删除文件和目录，实现类似于 rm -rf 的功能； cpr，用于拷贝、复制文件和目录，实现类似于 cp -r 的功能； make-dir-cli，用于创建目录，实现类似于 mkdir -p 的功能； 使用上面这几个小工具改造 npm script 的具体步骤如下： 第 1 步，添加开发依赖： npm i rimraf cpr make-dir-cli -D # npm install rimraf cpr make-dir-cli --save-dev # yarn add rimraf cpr make-dir-cli -D 第 2 步，改造涉及文件系统操作的 npm script： \"scripts\": { - \"cover:cleanup\": \"rm -rf coverage && rm -rf .nyc_output\", - \"cover:archive\": \"cross-var \\\"mkdir -p coverage_archive/$npm_package_version && cp -r coverage/* coverage_archive/$npm_package_version\\\"\", + \"cover:cleanup\": \"rimraf coverage && rimraf .nyc_output\", + \"cover:archive\": \"cross-var \\\"make-dir coverage_archive/$npm_package_version && cpr coverage/* coverage_archive/$npm_package_version -o\\\"\", \"cover:serve\": \"cross-var http-server coverage_archive/$npm_package_version -p $npm_package_config_port\", \"cover:open\": \"cross-var opn http://localhost:$npm_package_config_port\", - \"postcover\": \"npm-run-all cover:archive cover:cleanup --parallel cover:serve cover:open\" + \"precover\": \"npm run cover:cleanup\", + \"postcover\": \"npm-run-all cover:archive --parallel cover:serve cover:open\" }, 对改动的几点说明： rm -rf 直接替换成 rimraf； mkdir -p 直接替换成 make-dir； cp -r 的替换需特别说明下，cpr 默认是不覆盖的，需要显示传入 -o 配置项，并且参数必须严格是 cpr [options] 的格式，即配置项放在最后面； 把 cover:cleanup 从 postcover 挪到 precover 里面去执行，规避 cpr 没归档完毕覆盖率报告就被清空的问题； TIP#13：任何改动之后记得重新运行 npm run cover，确保所有的 npm script 还是按预期工作的 用 cross-var 引用变量 2.2 在 npm script 中使用变量 介绍了如何使用内置和预定义变量减少代码重复的技巧，如本节开头的例子，Linux 和 Windows 下引用变量的方式是不同的，Linux 下直接可以用 $npm_package_name，而 Windows 下必须使用 %npm_package_name%，我们可以使用 cross-var 实现跨平台的变量引用，具体步骤如下： 第 1 步，安装 cross-var 为开发依赖： npm i cross-var -D # npm install cross-var --save-dev # yarn add cross-var -D 第 2 步，改写引用变量 npm script，具体 diff 如下： \"scripts\": { \"cover:cleanup\": \"rm -rf coverage && rm -rf .nyc_output\", - \"cover:archive\": \"mkdir -p coverage_archive/$npm_package_version && cp -r coverage/* coverage_archive/$npm_package_version\", - \"cover:serve\": \"http-server coverage_archive/$npm_package_version -p $npm_package_config_port\", - \"cover:open\": \"opn http://localhost:$npm_package_config_port\", + \"cover:archive\": \"cross-var \\\"mkdir -p coverage_archive/$npm_package_version && cp -r coverage/* coverage_archive/$npm_package_version\\\"\", + \"cover:serve\": \"cross-var http-server coverage_archive/$npm_package_version -p $npm_package_config_port\", + \"cover:open\": \"cross-var opn http://localhost:$npm_package_config_port\", \"postcover\": \"npm-run-all cover:archive cover:cleanup --parallel cover:serve cover:open\" }, 因为 cover:serve 和 cover:open 命令都比较简单，直接在原始命令前增加 cross-var 命令即可，而 cover:archive 内含了两条子命令，我们需要用引号把整个命令包起来（注意这里是用的双引号，且必须转义），然后在前面加上 cross-var。 此外，细心的同学可能发现引入 cross-var 之后，它竟然给我们安装了 babel，如果想保持依赖更轻量的话，可以考虑使用 cross-var-no-babel。 用 cross-env 设置环境变量 在 node.js 脚本和 npm script 使用环境变量也是比较常见的，比如我们在运行测试时，需要加上 NODE_ENV=test，或者在启动静态资源服务器时自定义端口号。因为不同平台的环境变量语法不同，我们可以使用 cross-env 来实现 npm script 的跨平台兼容，具体步骤如下： 第 1 步，添加 cross-env 到开发依赖： npm i cross-env -D # npm install cross-env --save-dev # yarn add cross-env -D 第 2 步，改写使用了环境变量的 npm script： \"scripts\": { - \"test\": \"NODE_ENV=test mocha tests/\", + \"test\": \"cross-env NODE_ENV=test mocha tests/\", }, 上面的改动更简单，直接在设置了环境变量的命令前面加上 cross-env 即可。 再多说几句 关于 npm script 的跨平台兼容，还有几点需要大家注意： 所有使用引号的地方，建议使用双引号，并且加上转义； 没做特殊处理的命令比如 eslint、stylelint、mocha、opn 等工具本身都是跨平台兼容的； 还是强烈建议有能力的同学能使用 Linux 做开发，只要你入门并且熟练了，效率提升会惊人； 短时间内继续拥抱 Windows 的同学，可以考虑看看 Windows 10 里面引入的 Subsystem，让你不用虚拟机即可在 Windows 下使用大多数 Linux 命令。 TIP#14：如果你在编写 npm script 过程中有更多的跨平台兼容需求，基本思路是去 npmjs.com 上找对应的包，关键词自然少不了 cross platform，你遇到的问题，肯定很多其他人遇到过，相信我，你并不孤独！ 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 06-add-cross-platform-support。 "},"用npm-script打造超溜的前端工作流/08高阶篇02：把庞大的npm-script拆到单独文件中.html":{"url":"用npm-script打造超溜的前端工作流/08高阶篇02：把庞大的npm-script拆到单独文件中.html","title":"08高阶篇02：把庞大的npm-script拆到单独文件中","keywords":"","body":"3.2 把庞大的 npm script 拆到单独文件中 当 npm script 不断累积、膨胀的时候，全部放在 package.json 里面可能并不是个好主意，因为这样会导致 package.json 糟乱，可读性降低。 借助 scripty 我们可以将 npm script 剥离到单独的文件中，从而把复杂性隔到单独的模块里面，让代码整体看起来更加清晰。 示例项目中的覆盖率相关的 npm script 占据了很大的篇幅，如下： \"scripts\": { \"cover\": \"nyc --reporter=html npm test\", \"cover:cleanup\": \"rimraf coverage && rimraf .nyc_output\", \"cover:archive\": \"cross-var \\\"make-dir coverage_archive/$npm_package_version && cpr coverage/* coverage_archive/$npm_package_version -o\\\"\", \"cover:serve\": \"cross-var http-server coverage_archive/$npm_package_version -p $npm_package_config_port\", \"cover:open\": \"cross-var opn http://localhost:$npm_package_config_port\", \"precover\": \"npm run cover:cleanup\", \"postcover\": \"npm-run-all cover:archive --parallel cover:serve cover:open\" }, 如果要隔离复杂性，我们可以考虑从 cover 相关的 script 入手，具体操作步骤如下： 1. 安装依赖 npm i scripty -D # npm install scripty --save-dev # yarn add scripty -D 2. 准备目录和文件 mkdir -p scripts/cover 先创建两层的目录，因为我们计划把 cover 脚本写成多个，方便单独去执行，这里命名为 scripts 是 scripty 默认的，实际上是可以自定义的。 touch scripts/cover.sh touch scripts/cover/serve.sh touch scripts/cover/open.sh 然后创建空白的脚本文件，因为有了单独的脚本，我们可以把原来的 precover、cover、postcover、cover:archive、cover:cleanup 合并到一个文件中。 按照 scripty 的默认约定，npm script 命令和上面各文件的对应关系如下： 命令 文件 备注 cover scripts/cover.sh 内含 precover、postcover 的逻辑 cover:serve scripts/cover/serve.sh 启动服务 cover:open scripts/cover/open.sh 打开预览 特别注意的是，给所有脚本增加可执行权限是必须的，否则 scripty 执行时会报错，我们可以给所有的脚本增加可执行权限： chmod -R a+x scripts/**/*.sh 3. 修改 scripty 脚本 准备好目录和文件之后，接下来需要给脚本填充内容，脚本内容如下（因为脚本使用的是 bash，所以直接忽略了跨平台兼容的处理，跨平台兼容脚本最好使用 Node.js 编写，下节会介绍）： scripts/cover.sh 内容如下（cleanup --> cover --> archive --> preview）： #!/usr/bin/env bash # remove old coverage reports rimraf coverage && rimraf .nyc_output # run test and collect new coverage nyc --reporter=html npm run test # achive coverage report by version mkdir -p coverage_archive/$npm_package_version cp -r coverage/* coverage_archive/$npm_package_version # open coverage report for preview npm-run-all --parallel cover:serve cover:open scripts/cover/serve.sh 内容如下： #!/usr/bin/env bash http-server coverage_archive/$npm_package_version -p $npm_package_config_port scripts/cover/open.sh 内容如下（这里有个 sleep，是为了确保文件系统写入完成）： #!/usr/bin/env bash sleep 1 opn http://localhost:$npm_package_config_port 细心的同学可能注意到了，在 shell 脚本里面是可以随意使用 npm 的内置变量和自定义变量的。 4. 修改 package.json 主要改动是清理 cover:* 命令，接入 scripty，具体的 diff 如下： \"scripts\": { \"test\": \"cross-env NODE_ENV=test mocha tests/\", - \"cover\": \"nyc --reporter=html npm test\", - \"cover:cleanup\": \"rimraf coverage && rimraf .nyc_output\", - \"cover:archive\": \"cross-var \\\"make-dir coverage_archive/$npm_package_version && cpr coverage/* coverage_archive/$npm_package_version -o\\\"\", - \"cover:serve\": \"cross-var http-server coverage_archive/$npm_package_version -p $npm_package_config_port\", - \"cover:open\": \"cross-var opn http://localhost:$npm_package_config_port\", - \"precover\": \"npm run cover:cleanup\", - \"postcover\": \"npm-run-all cover:archive --parallel cover:serve cover:open\" + \"cover\": \"scripty\", + \"cover:serve\": \"scripty\", + \"cover:open\": \"scripty\" }, 这里我们只保留了 cover、cover:serve、cover:open 等 3 个命令，让它们都指向 scripty，调用哪个脚本都由 scripty 来处理。 5. 实际测试 修改完毕之后，重新运行 npm run cover，不出意外的话，我们能得到和原来完全相同的结果，仔细观察运行的日志，会发现在代码执行前有段额外的输出，如下图中红色框中的内容，scripty 在实际执行的时候会把执行的命令内容打印出来，方便调试： 高级技巧 scripty 比上面演示的要更强大，也支持通配符运行、脚本并行等特性、静默模式，如果有需求可以阅读官方的 README.md，毕竟咱们已经入门了，不是么？ 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 07-manage-complexity-using-scripty。 "},"用npm-script打造超溜的前端工作流/09高阶篇03：用node.js脚本替代复杂的npm-script.html":{"url":"用npm-script打造超溜的前端工作流/09高阶篇03：用node.js脚本替代复杂的npm-script.html","title":"09高阶篇03：用node.js脚本替代复杂的npm-script","keywords":"","body":"3.3 用 node.js 脚本替代复杂的 npm script Node.js 丰富的生态能赋予我们更强的能力，对于前端工程师来说，使用 Node.js 来编写复杂的 npm script 具有明显的 2 个优势：首先，编写简单的工具脚本对前端工程师来说额外的学习成本很低甚至可以忽略不计，其次，因为 Node.js 本身是跨平台的，用它编写的脚本出现跨平台兼容问题的概率很小。 下面我们就一起探索下，如何把上节中使用 shell 编写的 cover 脚本改写成 Node.js 脚本，在 Node.js 脚本中我们也能体味到 shelljs 这个工具包的强大。 1. 安装 shelljs 依赖 使用如下命令安装 shelljs 到项目依赖中： npm i shelljs -D # npm install shelljs --save-dev # yarn add shelljs -D 此外，我们计划使用 chalk 来给输出加点颜色，让脚本变的更有趣，同样安装到 devDependencies 里面： npm i chalk -D # npm install chalk --save-dev # yarn add chalk -D 2. 创建 Node.js 脚本 touch scripts/cover.js 3. 用 Node.js 实现同等功能 shelljs 为我们提供了各种常见命令的跨平台支持，比如 cp、mkdir、rm、cd 等命令，此外，理论上你可以在 Node.js 脚本中使用任何 npmjs.com 上能找到的包。清理归档目录、运行测试、归档并预览覆盖率报告的完整 Node.js 代码如下： const { rm, cp, mkdir, exec, echo } = require('shelljs'); const chalk = require('chalk'); console.log(chalk.green('1. remove old coverage reports...')); rm('-rf', 'coverage'); rm('-rf', '.nyc_output'); console.log(chalk.green('2. run test and collect new coverage...')); exec('nyc --reporter=html npm run test'); console.log(chalk.green('3. archive coverage report by version...')); mkdir('-p', 'coverage_archive/$npm_package_version'); cp('-r', 'coverage/*', 'coverage_archive/$npm_package_version'); console.log(chalk.green('4. open coverage report for preview...')); exec('npm-run-all --parallel cover:serve cover:open'); 关于改动的几点说明： 简单的文件系统操作，建议直接使用 shelljs 提供的 cp、rm 等替换； 部分稍复杂的命令，比如 nyc 可以使用 exec 来执行，也可以使用 istanbul 包来完成； 在 exec 中也可以大胆的使用 npm script 运行时的环境变量，比如 $npm_package_version； 4. 让 package.json 指向新脚本 准备好 Node.js 脚本之后，我们需要修改 package.json 里面的命令，使其运行该脚本： \"scripts\": { \"test\": \"cross-env NODE_ENV=test mocha tests/\", - \"cover\": \"scripty\", + \"cover\": \"node scripts/cover.js\", \"cover:open\": \"scripty\" }, 5. 测试 cover 命名 重新运行 npm run cover 命令，不出意外的话，基本功能是正常的，除了我们新加的绿色输出，如下图： 以上，本小节完，这里只是简单展示了如何组织 Node.js 脚本并且让其与 npm script 关联起来，至于具体在脚本中做什么事情，请你自由发挥吧。 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 08-using-nodejs-script-as-replacement。 "},"用npm-script打造超溜的前端工作流/10实战篇01：监听文件变化并自动运行npm-script.html":{"url":"用npm-script打造超溜的前端工作流/10实战篇01：监听文件变化并自动运行npm-script.html","title":"10实战篇01：监听文件变化并自动运行npm-script","keywords":"","body":"4.1 文件变化时自动运行 npm script 软件工程师做的事情基本都是在实现自动化，比如各种业务系统是为了业务运转的自动化，部署系统是为了运维的自动化，对于开发者本身，自动化也是提升效率的关键环节，在实际开发过程中也有不少事情是可以自动化的。 拥抱现代前端工作流的同学都会有代码风格检查、单元测试等环节，这样就很需要在代码变更之后立即得到反馈，如代码改动导致了那个 Case 失败，哪块不符合团队的编码规范等。 使用 gulp、grunt 的同学，可能对这种功能非常熟悉，不就是 watch 么？确实是，使用 npm script 我们也可以实现类似的功能。下面详细介绍如何改造我们的项目实现单测、代码检查的自动化。 单元测试自动化 幸运的是，mocha 本身支持 --watch 参数，即在代码变化时自动重跑所有的测试，我们只需要在 scripts 对象中新增一条命令即可： \"test\": \"cross-env NODE_ENV=test mocha tests/\", + \"watch:test\": \"npm t -- --watch\", \"cover\": \"node scripts/cover.js\", 尝试运行 npm run watch:test，我们会发现进程并没有退出，接下来尝试去修改测试代码，测试是不是自动重跑了呢？自己试试看。 代码检查自动化 我们使用的代码检查工具 stylelint、eslint、jsonlint 不全支持 watch 模式，这里我们需要借助 onchange 工具包来实现，onchange 可以方便的让我们在文件被修改、添加、删除时运行需要的命令。 1. 安装项目依赖 使用如下命令安装 onchange 到项目依赖中： npm i onchange -D # npm install onchange --save-dev # yarn add onchange -D 2. 添加 npm script 按照如下提示添加 watch:lint 和 watch 两个子命令： + \"watch\": \"npm-run-all --parallel watch:*\", + \"watch:lint\": \"onchange -i \\\"**/*.js\\\" \\\"**/*.less\\\" -- npm run lint\", \"watch:test\": \"npm t -- --watch\", 关于改动的几点说明： watch:lint 里面的文件匹配模式可以使用通配符，但是模式两边使用了转义的双引号，这样是跨平台兼容的； watch:lint 里面的 -i 参数是让 onchange 在启动时就运行一次 -- 之后的命令，即代码没变化的时候，变化前后的对比大多数时候还是有价值的； watch 命令实际上是使用了 npm-run-all 来运行所有的 watch 子命令； TIP#15：有没有好奇过 onchange 是怎么实现文件系统监听的？所有的魔法都藏在它的源代码里面，实际上它使用了跨平台的文件系统监听包 chokidar，基于它，你能做点什么有意思的事情呢？ onchange 有个不太醒目的特性是，文件系统发生变化之后，他在运行指定命令之前输出哪个文件发生了哪些变化，如下图红框中的内容： 读到这里，有没有觉得 onchange 可以和 gulp、grunt 的 watch 一样强大。 除了上面的单测重跑和代码检查之外，你还有什么需求需要放在 onchange 里面？欢迎留言讨论。 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 09-run-npm-script-with-onchange。 "},"用npm-script打造超溜的前端工作流/11实战篇02：结合live-reload实现自动刷新.html":{"url":"用npm-script打造超溜的前端工作流/11实战篇02：结合live-reload实现自动刷新.html","title":"11实战篇02：结合live-reload实现自动刷新","keywords":"","body":"4.2 使用 livereload 实现自动刷新 前端工程师日常开发最频繁（实际上最浪费时间）的操作是什么？可能你已经想到了，就是刷新页面，要让变更生效，需要重新加载，刷新页面的操作就变成了重复低效的操作。 于是社区里出现了 LiveReload 来把这个过程自动化，react 种子项目生成工具 create-react-app 中就使用了这种技术。 但随着技术的演化，在单页应用中刷新页面意味着客户端状态的全部丢失，特别是复杂的单页应用刷新意味着更大量的重复工作才能回到刷新前的状态，于是社区又捣鼓出了 Hot Module Replacement，简称为 HMR，比如使用 vue-cli 创建的 webpack 种子项目中就包含这种特性，react-native 也内置了这种特性，来帮助开发者提高效率。 读到这里，你可能会嘀咕，看起来 LiveReload 并不是最新的技术，还讨论它干啥，实际上它是自动刷新技术的鼻祖，后续的 HMR、HR 等都是它的改良版，动手配置下自动刷新，也能让你对这些技术的基本原理略知一二。 下面介绍如何在经典的前端项目中（引用了 css、js 的 html 页面）接入 LiveReload 的详细步骤： 1. 安装项目依赖 使用如下命令安装 livereload 和 http-server 到项目依赖中： npm i livereload http-server -D # npm install livereload http-server --save-dev # yarn add livereload http-server -D 2. 添加 npm script 按如下提示添加命令，方便我们启动 LiveReload 服务器和通过 HTTP 的方式访问页面： - \"cover:open\": \"scripty\" + \"cover:open\": \"scripty\", + \"client\": \"npm-run-all --parallel client:*\", + \"client:reload-server\": \"livereload client/\", + \"client:static-server\": \"http-server client/\" 其中 client 命令能同时启动 livereload 服务、静态文件服务。 TIP#16：可能有同学会问，为什么需要启动两个服务，其中 http-server 启动的是静态文件服务器，该服务启动后可以通过 http 的方式访问文件系统上的文件，而 livereload 是启动了自动刷新服务，该服务负责监听文件系统变化，并在文件系统变化时通知所有连接的客户端，在 client/index.html 中嵌入的那段 js 实际上是和 livereload-server 连接的一个 livereload-client。 3. 在页面中嵌入 livereload 脚本 修改 client/index.html 嵌入 livereload 脚本（能够连接我们的 livereload 服务），diff 如下： LiveReload Demo + + document.write('') + TIP#17：livereload 是支持在启动时自定义端口的，如果你使用了自定义端口，在页面中嵌入的这段 js 里面的 35729 也需要替换成对应的端口。 4. 启动服务并测试 最后，运行 npm run client 之后，截图如下，注意两个红框里面的输出表示服务启动成功： 然后，打开浏览器访问：http://localhost:8080，接着修改 client/main.css 并保存（别忘了保存），你会发现浏览器自动刷新了。如果没有刷新，欢迎留言交流。 TIP#18：有代码洁癖的同学可能会问，在页面中嵌入的那段 js 在线上环境咋办？实际上在嵌入这段脚本的时候可以通过简单的手段（比如判断 location.hostname）去检查当前页面运行环境，如果是线上环境就不嵌入了，或者使用打包工具处理 html 文件，上线前直接去掉即可。 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 10-livereload-with-npm-script。 "},"用npm-script打造超溜的前端工作流/12实战篇03：在git-hooks中运行npm-script.html":{"url":"用npm-script打造超溜的前端工作流/12实战篇03：在git-hooks中运行npm-script.html","title":"12实战篇03：在git-hooks中运行npm-script","keywords":"","body":"4.2 在 Git Hooks 中执行 npm script 严肃的研发团队都会使用 Git 之类的版本管理系统来管理代码，随着 GitHub 的广受欢迎，相信大家对 Git 并不陌生。Git 在代码版本管理之外，也提供了类似 npm script 里 pre、post 的钩子机制，叫做 Git Hooks，钩子机制能让我们在代码 commit、push 之前（后）做自己想做的事情。 Git Hooks 能给我们的开发工作流带来哪些可能呢？我带的团队中，大部分项目通过 npm script 为本地仓库配置了 pre-commit、pre-push 钩子检查，且正计划为远程仓库（Remotes）配置 pre-receive 钩子检查。两种钩子的检查目的各不相同，本地检查是为了尽早给提交代码的同学反馈，哪些地方不符合规范，哪些地方需要注意；而远程检查是为了确保远程仓库收到的代码是符合团队约定的规范的，因为如果没有远程检查环节，熟悉 Git 的同学使用 --no-verify（简写为 -n） 参数跳过本地检查时，本地检查就形同虚设。 可能有同学会嘀咕，在 IDE 里面配置各种检查难道还不够么？对个人开发者来说足够了，但对于团队，如果对代码里面的坏味道听之任之，久而久之整个团队的代码质量标准都会被拉低，到最后坑的还是团队的每个成员，不是么？之前没想到这层的同学建议去看看破窗理论。 那么增加 Git Hooks 的必要性聊清楚了，我们应该在 Git Hooks 里面做哪些事情呢？通常来说：检查编码规范，把低级错误趁早挖出来修好；运行测试，用自动化的方法做功能回归，测试本身就包含很多话题，且按下不表。 前端社区里有多种结合 npm script 和 git-hooks 的方案，比如 pre-commit、husky，相比较而言 husky 更好用，它支持更多的 Git Hooks 种类，再结合 lint-staged 试用就更溜。 接下来我们逐步给示例项目配置本地的 Git Hooks，而在钩子中运行的是已有的 npm script，比如 lint、test： 1. 安装项目依赖 使用如下命令安装 husky、lint-staged 到项目依赖中： npm i husky lint-staged -D # npm install husky lint-staged --save-dev # yarn add husky lint-staged -D husky 的基本工作原理可以稍作解释下，翻看 husky 的 package.json，注意其中的 scripts 声明： \"scripts\": { \"test\": \"jest\", \"format\": \"prettier --single-quote --no-semi --write **/*.js\", \"install\": \"node ./bin/install.js\", \"uninstall\": \"node ./bin/uninstall.js\" }, 这里面的 install 就是你在项目中安装 husky 时执行的脚本（所有的魔法都藏在在这里了，哈哈）。 然后再检查我们仓库的 .git/hooks 目录，会发现里面的钩子都被 husky 替换掉了，注意下图中三个红色框中的内容： 2. 添加 npm script 接下来需要在 scripts 对象中增加 husky 能识别的 Git Hooks 脚本： \"scripts\": { + \"precommit\": \"npm run lint\", + \"prepush\": \"npm run test\", \"lint\": \"npm-run-all --parallel lint:*\", \"lint:js\": \"eslint *.js\", 这两个命令的作用是在代码提交前运行所有的代码检查 npm run lint；在代码 push 到远程之前，运行 lint 和自动化测试（言外之意，如果测试失败，push 就不会成功），虽然运行的是 npm run test，但是 lint 也配置在了 pretest 里面。 然后尝试提交代码：git commit -am 'add husky hooks'，能看到 pre-commit 钩子已经生效： 3. 用 lint-staged 改进 pre-commit 如上的配置乍看起来没有任何问题，但是在大型项目、遗留项目中接入过 lint 工作流的同学可能深有体会，每次提交代码会检查所有的代码，可能比较慢就不说了，接入初期 lint 工具可能会报告几百上千个错误，这时候估计大多数人内心是崩溃的，尤其是当你是新规范的推进者，遇到的阻力会增大好几倍，毕竟大多数人不愿意背别人的锅，坏笑。 好在，我们有 lint-staged 来环节这个问题，每个团队成员提交的时候，只检查当次改动的文件，具体改动如下： \"scripts\": { - \"precommit\": \"npm run lint\", + \"precommit\": \"lint-staged\", \"prepush\": \"npm run test\", \"lint\": \"npm-run-all --parallel lint:*\", }, + \"lint-staged\": { + \"*.js\": \"eslint\", + \"*.less\": \"stylelint\", + \"*.css\": \"stylelint\", + \"*.json\": \"jsonlint --quiet\", + \"*.md\": \"markdownlint --config .markdownlint.json\" + }, \"keywords\": [], 接下来我们故意在 index.js 中引入错误： - return NaN; + return NaN 然后尝试提交这个文件：git commit -m 'try to add eslint error' index.js，结果如下图： 上图中带有 Running Tasks 字样的列表就是 lint-staged 根据当前要提交的文件和 package.json 中配置的检查命令去执行的动态输出。红色框里面提示 husky 的 pre-commit 钩子执行失败，提交也就没有成功。 关于 lint-staged 还有些高级的用法，比如对单个文件执行多条命令，对单个文件动态自动修复，自动格式化等等，留待大家自己去探索好了。 撤销掉有错误的修改，提交之后，我们往远程 push 新分支，结果如下图： 读过我其他文章的同学可能已经想到，本小节的内容部分和我早期的文章《用 husky 和 lint-staged 构建超溜的代码检查工作流》有部分内容是重叠的。 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改（记得安装 npm 依赖之后再运行脚本），注意切换到正确的分支 11-run-npm-script-in-git-hooks。 "},"用npm-script打造超溜的前端工作流/13实战篇04：用npm-script实现构建流水线.html":{"url":"用npm-script打造超溜的前端工作流/13实战篇04：用npm-script实现构建流水线.html","title":"13实战篇04：用npm-script实现构建流水线","keywords":"","body":"4.4 使用 npm script 实现构建流水线 在现代前端项目的交付工作流中，部署前最关键的环节就是构建，构建环节要完成的事情通常包括： 源代码预编译：比如 less、sass、typescript； 图片优化、雪碧图生成； JS、CSS 合并、压缩； 静态资源加版本号和引用替换； 静态资源传 CDN 等。 现在大多数同学所接触的项目构建过程可能都是别人配置好的，但是对于构建过程中的某些考量可能并不是很清楚。 接下来，我们将组合 npm script 和简单的命令行工具为实际项目添加构建过程，以加深对构建过程的理解，同时也会用到前面很多章节的知识点。 项目目录结构 对之前的示例项目做简单改造，让目录结构包括典型的前端项目资源引用情况： client ├── images │ └── schedule.png ├── index.html ├── scripts │ └── main.js └── styles └── main.css 可能的资源依赖关系如下： css、html 文件中引用了图片； html 文件中引用了 css、js； 显而易见，我们的构建过程必须遵循下面的步骤才能不出错： 压缩图片； 编译 less、压缩 css； 编译、压缩 js； 给图片加版本号并替换 js、css 中的引用； 给 js、css 加版本号并替换 html 中的引用； 添加构建过程 下面介绍如何结合 npm script 正确的给这样的项目结构加上构建过程。 1. 准备构建目录 我们约定构建产生的结果代码，放在 dist 目录下，与 client 的结构完全相同，每次构建前，清空之前的构建目录，利用 npm 的钩子机制添加 prebuild 命令如下： - \"client:static-server\": \"http-server client/\" + \"client:static-server\": \"http-server client/\", + \"prebuild\": \"rm -rf dist && mkdir -p dist/{images,styles,scripts}\", 2. 准备脚本目录 构建过程需要的命令稍长，我们可以使用 scripty 来把这些脚本剥离到单独的文件中，为此需要准备单独的目录，并且我们的构建过程分为：images、styles、scripts、hash 四个步骤，每个步骤准备单独的文件。 mkdir scripts/build touch scripts/build.sh touch scripts/build/{images,styles,scripts}.sh chmod -R a+x scripts 脚本文件的可执行权限必须添加正确，否则 scripty 会直接报错，上面命令执行完之后，scripts 目录包含如下内容： scripts ├── build │ ├── hash.sh │ ├── images.sh │ ├── scripts.sh │ └── styles.sh ├── build.sh 3. 图片构建过程 图片构建的经典工具是 imagemin，它也提供了命令行版本 imagemin-cli，首先安装依赖： npm i imagemin-cli -D # npm install imagemin-cli --save-dev # yarn add imagemin-cli -D 然后在 scripts/build/images.sh 中添加如下内容： imagemin client/images/* --out-dir=dist/images 然后在 package.json 中添加 build:images 命令： + \"build:images\": \"scripty\", 尝试运行 npm run prebuild && npm run build:images，然后观察 dist 目录的变化。 4. 样式构建过程 我们使用 less 编写样式，所以需要预编译样式代码，可以使用 less 官方库自带的命令行工具 lessc，使用 sass 的同学可以直接使用 node-sass。此外，样式预编译完成之后，我们需要使用 cssmin 来完成代码预压缩。首先安装依赖： npm i cssmin -D # npm install cssmin --save-dev # yarn add cssmin -D 然后在 scripts/build/styles.sh 中添加如下内容，这里我们使用到了 shell 里面的管道操作符 | 和输出重定向 >： for file in client/styles/*.css do lessc $file | cssmin > dist/styles/$(basename $file) done 然后在 package.json 中添加 build:styles 命令： + \"build:styles\": \"scripty\", 尝试运行 npm run prebuild && npm run build:styles，然后观察 dist 目录的变化，应该能看到 less 编译之后再被压缩的 css 代码。 4. JS 构建过程 我们使用 ES6 编写 JS 代码，所以需要 uglify-es 来进行代码压缩，如果你不使用 ES6，可以直接使用 uglify-js 来压缩代码，首先安装依赖： npm i uglify-es -D # npm install uglify-es --save-dev # yarn add uglify-es -D 然后在 scripts/build/scripts.sh 中添加如下内容，需要额外注意的是，这里我们需要手动指定 uglify-es 目录下的 bin 文件，否则识别不了 ES6 语法，因为 uglify-es 在 npm install 过程自动创建的软链是错误的。 for file in client/scripts/*.js do ./node_modules/uglify-es/bin/uglifyjs $file --mangle > dist/scripts/$(basename $file) done 然后在 package.json 中添加 build:scripts 命令： + \"build:scripts\": \"scripty\", 尝试运行 npm run prebuild && npm run build:scripts，然后观察 dist 目录的变化，应该能看到被 uglify-es 压缩后的代码。 TIP#19：uglify-es 支持很多其他的选项，以及 sourcemap，对 JS 代码做极致的优化，详细参考 4. 资源版本号和引用替换 给静态资源加版本号的原因是线上环境的静态资源通常都放在 CDN 上，或者设置了很长时间的缓存，或者两者兼有，如果资源更新了但没有更新版本号，浏览器端是拿不到最新内容的，手动加版本号的过程很繁琐并且容易出错，为此自动化这个过程就显得非常\b有价值，通常的做法是利用文件内容做哈希，比如 md5，然后以这个哈希值作为版本号，版本号附着在文件名里面，线上环境的资源引用全部是带版本号的。 为了\b实现这个过程，我们需要引入两个小工具： hashmark，自动添加版本号； replaceinfiles，自动完成引用替换，它需要将版本号过程的输出作为输入； 首先安装\b依赖： npm i hashmark replaceinfiles -D # npm install hashmark replaceinfiles --save-dev # yarn add hashmark replaceinfiles -D 然后在 scripts/build/hash.sh 中添加如下内容： # 给图片资源加上版本号，并且替换引用 hashmark -c dist -r -l 8 '**/*.{png,jpg}' '{dir}/{name}.{hash}{ext}' | replaceinfiles -S -s 'dist/**/*.css' -d '{dir}/{base}' # 给 js、css 资源加上版本号，并且替换引用 hashmark -c dist -r -l 8 '**/*.{css,js}' '{dir}/{name}.{hash}{ext}' | replaceinfiles -S -s 'client/index.html' -d 'dist/index.html' 然后在 package.json 中添加 build:hash 命令： + \"build:hash\": \"scripty\", 这个步骤需要依赖前几个步骤，不能单独运行，接下来我们需要增加完整的 build 命令把上面几个步骤串起来。 5. 完整的构建步骤 最后我们在 package.json 中添加 build 命令把所有的步骤串起来，完整的 diff 如下： - \"client:static-server\": \"http-server client/\" + \"client:static-server\": \"http-server client/\", + \"prebuild\": \"rm -rf dist && mkdir -p dist/{images,styles,scripts}\", + \"build\": \"scripty\", + \"build:images\": \"scripty\", + \"build:scripts\": \"scripty\", + \"build:styles\": \"scripty\", + \"build:hash\": \"scripty\" 其中 scripts/build.sh 的内容如下： for step in 'images' 'scripts' 'styles' 'hash' do npm run build:$step done 然后我们尝试运行 npm run build，完整的过程输出如下： 构建完成的 dist 目录内容如下： 可以看到，所有的静态资源都加上了版本号。 构建完成的 dist/index.html 内容如下： 可以看到，静态资源的版本号被正确替换了，为了验证构建出来的页面是否正常运行，可以运行 ./node_modules/.bin/http-server dist，然后浏览器打开：http://127.0.0.1:8080，不出意外的话，浏览器显示如下： 好了，到这里，我们给简单但是五脏俱全的前端项目加上了构建过程，这些环节你是否都清楚？你觉得还缺失些什么环节？欢迎留言交流 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 12-use-npm-script-as-build-pipeline。 "},"用npm-script打造超溜的前端工作流/14实战篇05：用npm-script实现服务自动化运维.html":{"url":"用npm-script打造超溜的前端工作流/14实战篇05：用npm-script实现服务自动化运维.html","title":"14实战篇05：用npm-script实现服务自动化运维","keywords":"","body":"4.5 使用 npm script 进行服务运维 需要事先说明的是，本节部分内容涉及到非前端的话题，比如服务的部署、日志，但会从前端项目管理开始，比如依赖管理、版本管理等。即使对自己定位是纯粹前端开发的同学，也建议阅读下，因为技不压身，了解整个前端项目交付流程中需要考量的点能让我们更有大局观。 通常来说，项目构建完成之后，就成为待发布的版本，因此版本管理需要考虑，甚至做成自动化的，然后，最新的代码需要部署到线上机器才能让所有用户访问到，部署环节涉及到服务的启动、重启、日志管理等需要考虑。 下面我们介绍 npm script 在服务运维时的几个用途： 使用 npm script 进行版本管理 每次构建完的代码都应该有新的版本号，修改版本号直接使用 npm 内置的 version 自命令即可，如果是简单粗暴的版本管理，可以在 package.json 中添加如下 scripts： + \"release:patch\": \"npm version patch && git push && git push --tags\", + \"release:minor\": \"npm version minor && git push && git push --tags\", + \"release:major\": \"npm version major && git push && git push --tags\", \"precommit\": \"lint-staged\", 这 3 条命令遵循 semver 的版本号规范来方便你管理版本，patch 是更新补丁版本，minor 是更新小版本，major 是更新大版本。在必要的时候，可以通过运行 npm run version:patch 来升补丁版本，运行输出如下： 如果要求所有的版本号不超过 10，即 0.0.9 的下个版本是 0.1.0 而不是 0.0.10，可以编写简单的 shell 脚本来实现（注意这样会破坏 semver 的约定），具体步骤如下： 首先，在 scripts 目录下新增 bump.sh（别忘了文件的可执行权限：chmod a+x scripts/bump.sh）： #!/usr/bin/env bash # get major/minor/patch version to change version=`cat package.json| grep version | grep -v release | awk -F\\\" '{print $4}'` components=($(echo $version | tr '.' '\\n')) major=${components[0]} minor=${components[1]} patch=${components[2]} release='patch'; # decide which version to increment if [ $patch -ge 9 ]; then if [ $minor -ge 9 ]; then release='major' else release='minor' fi else release='patch' fi echo \"major=$major, minor=$minor, patch=$patch, release=$release\" # upgrade version npm run release:$release 然后，在 package.json 中新增 bump 子命令： \"release:major\": \"npm version major && git push && git push --tags\", + \"bump\": \"scripty\", \"precommit\": \"lint-staged\", 在必要的时候执行 npm run bump，输出示例如下： 使用 npm script 进行服务进程和日志管理 在生产环境的服务进程和日志管理领域，pm2 是当之无愧的首选，功能很强大，使用简单，开发环境常用的是 nodemon。 在我们的项目中使用 npm script 进行服务进程和日志管理的基本步骤如下： 1. 准备 http 服务 在使用 npm script 作为构建流水线的基础上，我们在项目中引入了 express 和 morgan，并使用如下脚本启动 http 服务器方便用户访问我们的网页（morgan 使用来记录用户的访问日志的）： 先安装依赖： npm i express morgan -D # npm install express morgan --save-dev # yarn add express morgan -D 然后在根目录下创建文件 server.js，内容如下： const express = require('express'); const morgan = require('morgan'); const app = express(); const port = process.env.PORT || 8080; app.use(express.static('./dist')); app.use(morgan('combined')); app.listen(port, err => { if (err) { console.error('server start error', err); // eslint-disable-line process.exit(1); } console.log(`server started at port ${port}`); // eslint-disable-line }); 2. 准备日志目录 为简单起见，我们项目中创建日志存储目录 logs，有些公司可能不会把日志存在项目部署目录下： mkdir logs touch logs/.gitkeep git add logs/.gitkeep git commit -m 'add logs folder' 并且设置该目录为 git 忽略的，再改动 .gitignore： dist +logs TIP#21：这里加 logs/.gitkeep 空文件的目的是为了能把 logs 目录提交到 git 里面，但是我们故意忽略 logs 目录里面的内容，这是在 git 中提交目录结构而忽略其中内容的常见做法。 3. 安装和配置 pm2 安装 pm2 作为依赖： npm i pm2 -D # npm install pm2 --save-dev # yarn add pm2 -D 然后添加服务启动配置到项目根目录下 pm2.json，更多配置项可以参照文档： { \"apps\": [ { \"name\": \"npm-script-workflow\", \"script\": \"./server.js\", \"out_file\": \"./logs/stdout.log\", \"error_file\": \"./logs/stderr.log\", \"log_date_format\": \"YYYY-MM-DD HH:mm:ss\", \"instances\": 0, \"exec_mode\": \"cluster\", \"max_memory_restart\": \"800M\", \"merge_logs\": true, \"env\": { \"NODE_ENV\": \"production\", \"PORT\": 8080, } } ] } 上面的配置指定了服务脚本为 server.js，日志输出文件路径，日志时间格式，进程数量 = CPU 核数，启动方式为 cluster，以及两个环境变量。 4. 配置服务部署命令 在没有集成 CI 服务之前，我们的部署命令应该是下面这样的： \"release:major\": \"npm version major && git push && git push --tags\", + \"predeploy\": \"yarn && npm run build\", + \"deploy\": \"pm2 restart pm2.json\", \"bump\": \"scripty\", 即在部署前需要安装最新的依赖，重新构建，然后使用 pm2 重新启动服务即可，如果你有多台机器跑通1个服务，建议有个集中的 CI 服务器专门负责构建，而部署时就不需要运行 build 了。 每次需要部署服务时只需要运行 npm run deploy 就行了，运行成功输出如下： 5. 配置日志查看命令 至于日志，虽然 pm2 提供了内置的 logs 管理命令，如果某台服务器上启动了多个不同的服务进程，那么 pm2 logs 会展示所有服务的日志，个人建议使用如下命令查看当前服务的日志： + \"logs\": \"tail -f logs/*\", \"bump\": \"scripty\", 需要查看日志时，直接运行 npm run logs，运行输入如下： 当然如果你有更复杂的日志查看需求，直接用 cat、grep 之类的命令好了。 到这里，小册的内容基本结束了，接下来的一周，我会准备好视频版教程，在圣诞节的时候放出来给大家。如果你对内容有任何疑问，欢迎留言或者在读者群里面交流 本节用到的代码见 GitHub，想边看边动手练习的同学可以拉下来自己改，注意切换到正确的分支 13-use-npm-script-for-devops。 视频版教程已经录制完毕，下载地址：链接: https://pan.baidu.com/s/1gfeZ619 密码: xx8j，请享用 ** 对于购买了小册，没有加到读者群里面的同学，可以加我微信：feweekly，备注：掘金小册，我会拉你入群。感谢支持！** "},"程序员职业小白书/常见问题解答.html":{"url":"程序员职业小白书/常见问题解答.html","title":"常见问题解答","keywords":"","body":"常见问题解答 方法论往往看起来简单，但实际操作时遇到的问题总是千奇百怪。所以这里把我之前在微博问答中回答过的一些相对典型的问题整理出来，供大家参考。 A：初级程序员，如何建立自己工作之余的学习规划。我是花大部分时间到读技术方面的书籍还是花更多的时间在开拓视野的书籍？ Q：对于程序员来讲，通常不是书读的太少，而是代码写的太少。所以我觉得对于初级程序员来讲，最好的学习规划是去写一个实用的、和工作相关的开源小项目或者可以发布到市场的独立小软件。 如果在写这个小项目的过程中，你遇到了问题，再带着这些问题去看其他开源项目的代码，或者去读相关的论文和技术书籍，你的成长会比单纯的去读书要快得多。 当我刚学完PHP的时候，我读了很多技术书，比如设计模式，比如敏捷开发，这些书都非常的不错，但是他们很难直接提升我的技术能力，而我用两个月的业余时间写完一个CMS时，回过头看，发现成长比过去一年都多。 A：Easy老师您好。我大学毕业两年了，现在在北京一家国企上班，想利用业余时间学习编程。想请教您三个问题： 1.我现在只是单纯想学，还不知道究竟能派上什么用场，想的是也许边学边能发现用处，但毕竟工作性质与码农毫不沾边，像我这种情况，您觉得究竟有无学的必要呢？ 2.周围有人推荐我从Python学起，有人推荐我从Ruby on Rails开始，众说纷纭，您的观点呢？ 3.关于学习方法。纯靠看书+自己摸索，我觉得对我这种纯小白来说难度太大，“从0开始学习编程”，您有推荐的学习方法吗？ 一 我觉得你首先要弄明白的是你为什么要来学习编程，这是非常重要的。如果你有很强烈的创造欲望，或者需要持续编码的场景，再投入精力去学会比较好。不是说编程有多难，你学不会，而是说如果你只是学会，但是你不经常去使用的话，那么很快就会慢慢的忘掉。我学过Java，也学过Python，还学过Rails。刚学完的时候还能写一些小程序，但过上一两年很快就忘掉了。即使没有忘，以这行业现在的发展速度，可能你休个长假回来，发现好多项目依赖的组件都变了。😂 总而言之，就是如果你确定要来学习编程，就要想办法把它坚持下去，一直写一直用，否则的话还不如干脆就不要学了，省下时间去做一些更有意思的事情。比如逛街吃饭看电影🍲。 二 具体学习什么语言，主要看你想学来干什么。如果你想搞人工智能的话，Python会比较好；如果你想做云计算的话，GO就是首选；如果你要写APP当然是Swift；如果你想做Web的话，那就去学JavaScript；如果你想尽快找到份专职编程的工作，那么现在PHP缺得还是蛮多的。当然，关于语言每个人的看法都会不一样，以上这都是我的一些个人偏见。 三 如果你没有编程基础，那么你需要找一门语言把它的语法全部学会，然后逐渐的把它变成一个日常工具。 学习资料上的话，如果你英文比较好，可以找国外大学的语言教学视频。如果英文不太好，那么买国内的也行。 遇到问题以后，可以去搜stack overflow，绝大部分的技术问题在上边都有答案。 如果你不幸要做微信这种只有中国人才大量用的东西，那么记得去加入对应的开发交流群。 在这个基础上，再给自己定一些小任务。比如日常工作中，哪些重复劳动可以通过编写代码自动化掉。这样用以致学，想不学好都不行。 A：我零基础，非科班，想通过培训进入程序员行业，可行性大吗？互联网公司招聘对学校专业限制大吗？ 如果你的培训质量足够的好，你学的也足够用心，能完成大部分互联网公司的日常开发工作，那么成为一个程序员问题不太大。 从我了解的情况来看，要找一份工作还是比较容易的（毕竟还有一堆的外包公司），但要找一份好工作，则是需要运气的（因为现在培训出来的程序员有点多了）。 不管是科班、培训还是自学，都是一个过程，最终看的还是你的能力，能干多少活，能管多少人。 专业一般不会成为门槛，但是会成为竞争优势。如果能力差不多的两个候选人，其中一个是计算机专业，那么他被优先录取的可能性会很高。 A：Easy老师，你好。我是一位工作刚好半年的前端开发工程师。最近觉得公司发展前景和培养新人方面很大欠缺，所以想换个工作。自认为已经完全可以胜任一年经验的工作，没想到企业好像都商量好一样，简历都石沉大海。您对工作刚满半年却想要换工作的新人怎么看待？希望得到您的指点。 我觉得有两点你需要想明白。 第一，通常来讲只有大公司，有比较完备的培养计划，但事实上完全不懂的新手是很难有机会进入大公司的，即使是应届毕业生，里面也是百里挑一。而小公司，基本都不会在新人上边投入大量的培养精力，一般给你分配一个师傅带着往前走就已经很不错了，所以，越是新手，培养这事儿越要靠自己，不能老指望公司。公司能培养你的时候，让公司培养你；公司不能培养你的时候，你要自己培养自己。 第二，在程序员这个行业是不论工龄的，半年经验和一年经验其实都是没啥经验。重点是你能写出什么样的代码、会用哪些框架、能处理哪些需求？在产品经理频繁变更的情况下，能否保持准时上线？是否有习惯写单元测试，如何保证你的代码质量。 所以，问题的中心又重新回到了你在这半年时间以来，你的能力提升了多少？你现在的能力，是否达到或者超过了你应聘公司的要求。 只要你自己能力彪悍，完全可以碾压其他工作更久的程序员。不服的话把代码摊开来，大家一比谁好谁坏，一目了然。这可能是这个行业最有意思，但又最残忍的地方。 更多的问题，可以到我的微博问答 上边查看，绝大部分问题都已经超过三个月了，可以免费看。 小册总结 好了，这本小册子到这里也就结束了，非常感谢花上时间和金钱来阅读，也希望它能给你的职业带来新的气象。除了在掘金，大家还可以通过以下方式和我交流： 微博：@Easy (主要活动场所) Twitter：@EasyChen (主要分享二次元小姐姐) 博客：方糖气球 （有一些很不错的免费内容） 公众号：方糖君 （很少更新，因为懒🤣） "},"程序员职业小白书/职业经营1：程序员职业的本质.html":{"url":"程序员职业小白书/职业经营1：程序员职业的本质.html","title":"职业经营1：程序员职业的本质","keywords":"","body":"如何理解程序员职业的本质 程序员这个职业，和其他职业非常不一样。这大概是由软件的本质决定的。 自动化 其他行业的工作，都需要由人来完成；今天做的事情，明天可能还要同样的做一遍。但这是人类工作的方式，不是机器工作的方式。 软件，仔细想想，它不就是一系列可以重复执行的命令么？ 为了让机器去做重复的工作，我们才需要编码，通过各种编程语言告诉机器如何去完成一项特定的工作，而在这之后，这项工作就由机器完成了，再也不需要人类来参与。程序员的注意力会转移到下一个还没有被自动化的工作上。对，「自动化」就是软件的本质。 DRY 是程序员的职业信条 所有重复的工作，都应该被抽象和描述成命令，交给机器去做；人类，至少程序员，应该把时间花在创造性的工作上。 《程序员修炼之道》中提出的 DRY 原则（ Don't Repeat Yourself ）将这种内在信念表现得更为具体。相对的，我们把违反DRY原则的解决方案通常被称为 WET （ Write Everything Twice ）。 仔细想想，为了避免重复，程序员们都做过什么：从函数库到框架再到脚手架、从面向过程的函数级重用到面向对象的继承式重用、从软件分包和管理到SOA和服务发现，我们不断的改良着重用的技巧。 更进一步，为了不重复别人的代码，从古代开始，程序员们就开始通过软盘交换程序；有了互联网以后，更是发起了规模庞大的开源运动，把一个巨大的代码仓库毫无保留的开放给了全世界，让新一代的程序员们可以轻松的站在巨人的肩上，写出更美妙的程序。 为什么一个好的程序员可以代替很多普通的程序员？ 深入理解了程序员们和重复的不共戴天以后，你就会明白为什么一个好的程序员可以代替成百上千个普通的程序员，因为机器放大了这个差距。如果一个普通程序员在重复劳动，那么一个好的程序员花一天写段代码就能干掉他/她一年的活。 所以你看，程序员就是不断的干掉自己的后路，逼着自己去做创造性的工作，不断指数级的提升生产率的职业。 自动化的残酷现实和应对策略 所有尝试过将工作自动化的程序员最后都会毫无例外的认识到，理想是丰满的、现实是骨干的。在现实世界，并不是所有东西都可以自动化的，有各种原因，一些是因为时间和精力所限、一些是因为有不遵守规则的人类参与。 好在我们所处的世界并不是二元的，在「完全自动化」和「不能自动化」之间，还有各种选择。在多年的「自动化」尝试之后，我总结出了一个准则，可以在理想和现实之间做一个不错的折中： 能自动化的自动化，不能自动化的半自动化 完美主义害死人，我见过不少做着重复劳动的程序员，问为什么不用代码将其自动化时，他们总是会说，因为不能完全自动化，所以干脆就全部手写好了。 其实不能全自动化的工作，是可以半自动化的，可以通过交互操作来完成，Web 界面就是最常见的一种、而命令行询问输入参数是写起来最方便的一种。 整个工作流程不能自动化时，只自动一小部分也能提升不少效率。 我之前做过的一个小工具，就是把数据表的各个字段都显示出来，你复选上以后，可以生成增删改查的 SQL 语句。这个工具至少帮我节省了上千次字段拼写，因为用到它的那个项目表很多字段更多，最后做下来光 SQL 都 100 多K。 再举一个例子。之前我们的一些资料是编辑给的，他们都用 Word 发过来。当时没有特别好的 Doc 格式解析工具，所以好多同学都放弃了解析数据。我给的解决方案是这样的，直接在 Word 里边选中表格，然后粘贴到一个 textarea 里边。用 PHP 分析 tab 和换行就能把数据抓取出来。多动动脑子，解决办法很多。不完美，也可以很精彩。 只为自己设计 通用工具往往无法面面俱到，而只为自己设计的时候，事情就变得非常简单，生成器最终只需要生成你每天写的代码而已，工具也只是在重复你的日常，你非常清楚元数据是哪儿来的，应该怎样被加工，最终要生成怎样的输出才合格。当然坏处就是，这个只为自己设计的工具，也只能自己开发。 使用最高性价比的工具 凡事都自动化还有一个现实问题，就是成本太高。但如果这些自动化工具只是为你或者你的团队设计，只给程序员使用，那么我们不一定非要用图形界面这种更友好的但是开发周期更长的东西。 交互式命令行就是一个廉价又好用的解决方案，即使最后要做图像用户界面，也应该先用脚本把整个流程弄通，先把工作效率提升起来，再用节省下来的时间去开发界面细节。 工程化 另一方面，程序员其实是「软件工程师」，持续稳定的保证整个工程的质量是最为重要的。所有的「创造性」都要臣服于这个核心目标。 工程最重要的不是创造，而是去风险化。 工程是关于如何 低成本、高效率、按时按量完成既定任务的。 所以判断一个工程师是否优秀，并不是他多有创意多有名气，而是看他有多稳，看他能多 Getting Things Done，中文就是「靠谱」。 有时候一个好的解决方案，未必采用了最新的技术和框架，而是看上去朴实无华，功力都包涵在背后的细节里。就像顶尖高手打的斯洛克台球，每一杆都平淡无奇，只是因为上一杆的回球太到位。 同样的，一个好的工程师，会选择最适合需求和团队的方案，考虑开发效率和系统效率的均衡，从而已达到最优效果；而不是整天和别人去争论什么语言最好、哪些框架过时了。 工程的另一个要求是进度控制和质量控制。 在项目立项之后动工之前，对要做的事项作出详尽的规划，对未来一到两周的工作给出细致的排期，这是进度控制的基础。 代码的及时入库与合并，自动化测试和每日构建，Code Review 和文档编写，这些看似无关紧要的习惯则决定了项目质量。 不幸的是，很多程序员把这些工程上至关重要的东西当成垃圾，视为对他们「创造力」的压抑。 他们总是以创造力为借口去寻求自身的自在，比如上班不带胸牌不打卡，中午休息时间在公司看视频打游戏，最好可以远程上班，项目到期之前再来检查进度，公司不要用统一框架，只有傻X才写文档。 对职业的理解偏差和工程能力上的荒芜，培养了大批能写代码但死活写不好代码的「码农」，反而让那些有着彪悍工程能力和良好习惯的程序员变得奇货可居。 总结 「工程化」和「自动化」可能是程序员职业中最重要的两个信念，如何在保证「工程」品质的前提下，「创造性」的通过「自动化」来避免重复劳动，是值得我们花上经年累月的时间，在工作中时刻思考和实践的问题。对这个问题的思考，将帮助你获得前所未有的竞争力，比如说，如果你拥有了一系列的半自动化工具，在人工智能日益成熟的时代，它们就可能变成全自动工具，这背后的职业价值和商业价值不言而喻。 "},"程序员职业小白书/职业经营2：如何选择技术方向和编程语言.html":{"url":"程序员职业小白书/职业经营2：如何选择技术方向和编程语言.html","title":"职业经营2：如何选择技术方向和编程语言","keywords":"","body":"如何选择技术方向和编程语言 如何选择技术方向和编程语言，大概是新人们最困惑的问题之一了，当然也是我被问到最多的问题之一。这里就和大家详细的聊聊。 先选技术方向，再选语言 各种语言都各有所长，所以在选择语言之前，最好先选定你想从事的技术方向，然后根据这个技术方向，再去选对应的语言。 各个语言的适用场景 Python：人工智能的好选择 举例来说，如果你想做人工智能方向的话，Python语言就是非常不错的选择。因为它在各个大学和研究机构用的非常多，有成熟好用的数学库，适合于科学计算。在深度学习等热门方向上，有大量用 Python 开发的框架，新出的 Paper 也能很快在 GitHub 上找到 Python 的代码实现，可以说是不二选择了。 JavaScript：前端和全端 如果你想做前端，那么目前来看，除了 JavaScript 还真没有别的选择，因为现在能在浏览器里边跑起来，也就是它了。过两年等 wasm 成熟可能会有其他选择，但现在，是真没有。 而相应的，如果你学会了 JavaScript ，想在这个基础上再把后端给做了，那么 Node.JS 就是非常好的选择。因为它使用的就是 JavaScript 的解释器，按 JavaScript 写就好了。从学习成本上来讲，它是非常低的，可以通过很低的投入，就进入了服务器端的领域。 同时，如果你已经学了 React 这个 JS 框架的话，你可以再花点时间把 React Native 也给学了，这样的话，你就可以通过 JS 来写移动客户端，甚至通过 Electron 等框架来写电脑客户端。 这些应用可能会比原生的差一点，但可以适用于大部分场景，加上投入成本又不高，非常适合作为新手的切入点。 Go：云计算和容器管理 如果你现在要想去做云计算，那 Go 就是一个非常好的选择。 因为它就是为了大规模计算设计的，并发管理和性能都非常不错。而且有很多云计算的软件，它就是 Go 写的，如果你要去修改它，调整里边的实现逻辑的话，不会 Go 可能很麻烦。当然，理论上讲，你也可以通过容器和微服务的方式来搞定，但肯定比直接改代码麻烦。 PHP：依然是网站首选 如果你要做网站，那么 PHP 就是首选了。一方面是有大量的可用代码，世界上超过80%的网站都用的 PHP，基本上你能想到的网站功能，都有能找到的实现，悬念只是有没有免费的；另一方面，PHP7 的性能提升了很多，用来写 API 也非常好。 另外一点，就是目前使用 PHP 的团队非常多，即使在二三线城市也比较容易找到工作，当然，组建团队也同样相对容易。 Java：大数据分析 如果你要做大数据分析，那么可能就离不开 Java 了。从 Hadoop 开始一系列的 Google Big Table 的开源实现都是 Java 的，用于海量数据搜索的 Elastic Stack 也是 Java 的。 语言并没有对立关系 需要说明的是，语言这种东西不是配偶，只能选一个。技多不压身嘛，多学几门语言也是挺好的，这样就能在适合的场景下，用适合的语言了。 作为初学者，我们的学习时间是有限的，所以我们可以先去学习离我们想做的技术方向最近的一种，先把工作找到、把业务跑起来，然后再拿空余时间慢慢的来补其他可能用到的语言。 另外，对初学者来说，要尽量选择主流语言。这样你遇到问题时，才有社区可以问、才有 Stack Overflow 可以搜。你要选一个小众语言，你会发现出了问题只有看源码。 事实上，你也很难成为只会一种语言的人，我们的工作是以业务为导向的，业务总是会推着我们去做各种事情，比如当你需要做全文检索时，就算你是 PHP 程序员，也得尝试着去假设 Elastic Search，这种时候就可以把 Java 学一学。 我们看到的那些趋势 预测技术趋势是一种高风险的事情，就和猜股票差不多，所以之前我一直不怎么想做。但我同时也明白初学者的那种迷茫，就像没带手机被扔在一个完全陌生的城市里边一样。 所以我们这里做一个折中，只对看见的趋势做分析，不对未来的趋势做预测，预测部分交给你自己。 Web 的富媒体化趋势 这个趋势非常明显，它其实是跟着网速发展的。 文本时代 古代我们上网的时候，还是用电话线，拨号上网，那个时候非常的慢，看个图片都要等半天。论坛帖子标题里经常写的一句话叫「多图杀猫」，就是说这个帖子图片太多了，打开以后要等半天才出内容。 所以在那个时代，互联网应用必然是以文字为主流的。比如聊天室，大家都是打字聊天的；然后门户，也是整屏的都是密密麻麻的字，为什么？因为新开一个网页，要等老半天才显示出来，还不如在一个网页里边塞足够多的字。那时候很多门户的网页编码都用 GB2312 不用 UTF-8，就为了省那么点字节。 甚至游戏都是文字的，MUD嘛，场景都是要靠想象力的，大概类似于勇者斗恶龙把上边的图给去掉，「你受到了史莱姆的会心一击，损失了20点HP」… 图文时代 再往后，大家的网速慢慢就好一些了，图片就开始了大量的上了。但基本都局限在「看图」，这是因为那时候智能手机和移动网络都没起来，图片要用数码相机拍，然后再导入到电脑，传到网站上去。这个对于 PGC（ Professional Generated Content，专业生产内容 ） 的编辑来说没什么，但对于 UGC（ User Generated Content，用户生产内容 ）来说，还是太复杂了。 所以当时兴起的基本还是图文内容，博客是其中一大代表，也是聚集了一大批的流量。 再往后，移动资费慢慢下来了，再后来有了以 iPhone 为代表的智能机，这时候 UGC 的图片才大规模的上来。观察微博所带的图片比例，就可以很明显的发现这个趋势，09年时，带图的微博并不多，到现在，不带图的微博已经非常少了。 智能机的发展极大的推动了互联网的富媒体化，因为它是数据的采集端嘛。 视频和直播时代 视频网站倒是很早就来了，那时候优酷土豆天天打架。但视频 UGC 是没有跟上，那时候叫做「播客」，主推就是音频和视频。后来也一直没发展起来，主流视频网站最后还是买版权，然后靠 PGC 做了自制剧。我觉得很大程度上和视频的沉浸式体验有关，这种体验抑制了传播，现在微博上，长度超过十分钟的视频依然是很难传播的。 直播为视频带来了互动性，同时对带宽和实时性提出了新的要求。其实直播，尤其是移动直播是一个很有意思的事情，以前电脑直播，你基本就只能看对方在一个房间里边唱歌跳舞，秀秀身材；但移动直播却可以带你到地球的每一个角落，只要有手机信号，就能看得到的。 直播的互动性也为视频带来了前所未有的体验，比如说，以前看数码测评，只能看编辑整理好的内容；而现在看测评直播，你可以让测评的同学把手机转过来让你看看电源口，还能让他们装个农药看看卡不卡。 趋势背后 这些趋势背后，都是各种支撑技术。比如文字上来了，要做分词和搜索吧？图片来了，要做识别和监管吧？直播来了，要做 P2P 、视频压缩和实时数据传送吧？ 最明显的，就是做 CDN 的只要活下来的都很挣钱，因为这么下去，消费的带宽只会越来越多嘛。 另外就是，我们可以明显的看到，一个技术上的能实现的事情，到大规模的商用之间，还隔得很远。图片和视频的普及就是一个例子；同样，VR 技术的成熟，也要等到硬件、内容等边界条件达到一个临界点的。 后移动互联网时代的应用开发 过去五年是移动优先（ Mobile first ）的时代，我们的生活、娱乐和工作正在大规模的从电脑向手机转移。 一方面是，Android 的廉价化，让很多买不起或者不想买电脑的人，买了手机；另一方面是，天天用电脑的人回到家里以后，已经不想再碰电脑，就想躺沙发上，听着电视刷手机。 APP 撼动了 Web 的地位 移动优先这事，其实对于 Web 的打击挺大的。最主要是苹果开了个坏头，对把他们所有东西都弄成 APP 了，当然，Web 在手机上的确有操作上的不便，光是输入网址就要花好久，还一堆英文符号数字，没法用语言输入。APP 点一下就开了，的确是一个更好的入口。 但是 APP 虽然体验更好，但也有它自己的问题。首先是制造成本更高了，要为每个平台做一个，开发完还要一直维护；然后它又给设计成一个中心化的东西，要提交应用商店走审核。人家不给通过，用户就没法用，驳回理由千奇百怪的；就算所有内容都 OK ，每次更新又要审一回。另外就是 APP 的体积越来越大了，不买个 64G 的手机都不好意思装应用。 而 Web 是完全开放的，没有这些繁文缛节。所以很多公司就想，能不能把 APP 和 Web 的优点给结合下，搞点免安装的 APP 出来？ 于是 Google 做了 PWA ，微信出了小程序。 总之，APP 对 Web 的冲击是非常大的，记得前几年，现在好像也还是吧，很多创业公司的产品是没有 Web 版的，官网就一个 APP 下载页面。 后端语言的移动化方案 说到这里，微信还在国内给 Web 开辟了另外一块生存空间，那就是 H5 。 这个 H5 并不是指的 HTML5 而是特指嵌入到微信和微博之类应用的 WebView 里边的移动网页。 大部分后端程序，比如 PHP ，对于移动化的解决方案就是 Responsive Web。不管你是手机还是电脑，我就一个页面，然后根据屏幕的宽度来显示内容，你宽呢，我就显示更多内容；你窄呢，我就只显示核心的内容。 这种方案其实也还算好用，在 H5 生态下工作得挺好。但是如果这家公司开始做移动客户端了，他们就会面临一个问题，移动客户端的 API 从哪儿来？简单粗暴的方式当然是重写一个了，但出于一致性等因素考虑，将 Web 也前后端分离才是正解。 后端语言只负责 API ，也就是数据的输出。Web 被视为客户端的一种，和 iOS、Android、Mac、PC并列，通过 JS 读取数据，并进行渲染。 在这种模式下，随着 JS 的进化，它慢慢变成了一个全栈语言。这个前边我也提到过，有了 NodeJS ，它就能做后端了，提供 API；有了 React Native，它就可以写移动客户端；还有 Electron 这种封装 NodeJS 和 JS 为电脑 APP 的包装方案，它又能覆盖电脑客户端。 混合 APP VS 原生 APP 在 JS 的全栈方案中，它使用混合（ Hybrid ）方式来构建 APP。有两种层次的混合，一种是里边用 WebView ，外边封一个壳，这种方案学习成本低，开发者只需要使用原有的 Web 技术就 OK ，但性能上会差一点，遇到超长列表可能会卡顿，另外动效也不如原生的顺滑；另一种是内置一个 JS 引擎，解析 JS 代码然后去渲染原生的 UI 组件，这种方案性能更好，感官上和原生 APP 非常接近，但需要开发者学习各个平台对应的 UI 库，有较高的学习成本。 但整体来讲，混合 APP 的出现，给很多创业公司和预算不充裕的团队提供了一种渐进式的解决方案。你可以选择先用 H5 来做产品，在微信里边内测；然后将其打包成 APP ，通过应用市场分发，占领手机的入口；再之后可以通过 React Native 等方案，提升其性能；如果这些都达不到体验的要求时，再去开发原生 APP 。 后端开发的平台化 聊完了前端我们来说后端。后端其实有一个非常明显的趋势，那就是后端慢慢的云化了。 最开始我们都用物理机，需要经常跑机房，还要打电话让看机房的大爷给重启服务器；后来有了虚拟机，有了 VPS ， 操作方便了，利用率也慢慢上来了。 不管是什么样的企业，今天都开始用云，区别只是用别人的云还是自己的云，别人的云就是公有云、自己的云就是私有云，混着用就是混合云。 随着云平台的成熟，很多后端日常使用的功能，慢慢的就变成了云平台上的标准服务，比如数据库、高速缓存、队列、对象存储和CDN，而后端程序本身，更专注在实现业务逻辑本身上边，这是一个非常明显的趋势。那就是所有能服务化的功能，最后都会服务化；而后端程序会成为业务逻辑和服务之间的胶水。 AI 很可能就是下一个被大规模服务化的领域，我们可能需要很顶尖的专家来设计和优化模型，但一旦调整好，规范好接口，对接到云平台上，它就变成一个标准服务。工程师们不需要懂 AI ，他们只需要懂 API 就能做出不错的人工智能应用。 这件事情已经发生在 iOS 程序员身上了，很多 iOS 程序员利用 Apple 提供的人工智能库，做出了很多令人惊讶的 APP ，即使他们一点都不懂人工智能。 所以整体来讲，以后的后端会更加纯粹，要么处理业务，要么处理服务。 后端的云化的同时，还会导致运维的云化。因为大家都用云了，管机器的人就不需要那么多了，需要的是管理云的人了。但云里边都是虚拟机啊，不需要你挨个跑机房换硬盘，直接用命令就 OK ，这要求运维也能写程序，这就是最近提的很多的 DevOps 。 AI 优先的时代 深度学习是人工智能新起点 人工智能其实已经说了很多年了，但以前我一直对它不看好，主要是因为它们不够自动化，需要人工制定规则，远不如UGC+推荐系统+正则表达式效果好。但现在的人工智能有些不同了，因为有了深度学习这个东西，下边我详细说。 传统的机器学习很蛋疼，它的特征提取是人工做的。别看用起来很牛逼，但其实边界条件变一点，规则就要进行调整，特别脆弱。这哪儿能叫机器学习，这是人学习，机器干活，和我们以前的编程没什么区别。 但深度学习不同。深度学习是通过模拟神经网络，用训练数据动态调整权重来自动发现规则生成模型，这个就NB了。首先是普适性，特征和规则的自动发现让人力从「机器学习」中解放出来（虽然取而代之的是昂贵的计算资源），可以瞬间规模化，从而让人工智能真正有了能成了水和电一样的东西的可能。不同的行业，只要喂给它不同训练数据，它就能得出不同的规则（当然，有很大的优化空间），从而更好的完成以前机器无法完成的任务。 然后是动态性。以前的规则是人搞的，数据和需求是实时变化的，而人是要睡觉的，很容易规则跟不上数据的变化；现在换成机器以后，规则是机器出的，一旦用户反馈数据不对，就引导进入数据纠错流程，让用户对数据做标记，然后机器再从大量的已标记数据中生成新规则，当用户量足够大的时候，这个过程可以非常快。 以前，我们通过一个规则系统将人类强大但不确定的能力封装起来，搞出了一堆基于UGC和Web2.0的系统。而现在，深度学习封装了机器自动生成规则这个强大而不确定的能力，可以大规模的替换掉经济系统中的人力。 似乎之前因为机器不够智能的曲线救国，现在可以回归正轨了，付出的代价就是，我们必须要拥抱不确定性 —— 因为我们完全不知道这些规则是怎么来的。 这本不是什么新鲜事，我们到现在也没弄明白量子坍塌的细节，但一样在外边建立起来了相关理论，才有了整个数码世界。就算在编程领域，很多程序员从github下载软件包时，其实也没看过内部实现 😂。 机器取代人类的大部分工作，悬念只是时间 以十年为粒度去看，深度学习是非常可怕的。一方面在于计算成本会持续下降；另一方面在于机器智能的自举。前者比较好理解，你只要关注下GPU的性价比就清楚；后者我解释下。 Google已经开始在用机器给深度学习调参了，这是一个快速自举的过程。用60分智能的机器给60分智能的机器调参，通过深度学习使其变成65分；然后再换65分智能机器去给65分的机器调参。这TM就是进化，可怕的是这种进化是以光速进行的。 但我们无需害怕丢掉工作（真正值得关注的是失去对机器的控制权），如果你认同我之前对软件本质的定义的话，就会明白，程序员其实就是一个用机器不断减少（恶意一点叫剥夺也行）人类工作的职业。而人类就会把旧工作交给机器，发明新的工作，整个社会的服务能力、人类生活的舒适和美好程度都因此往前不停推进。想想工业革命。 为什么现在AI看着像假的 很多同学都觉得，现在人工智能就是个人工智障，完全不堪大用。你们是对的。因为现在 AI 大概也就能做人类在几秒钟内能做的事情。而且局限于「图片分类」、「语音识别」等常规任务，以及通过 GAN （生成式对抗网络）等生成一些喜忧参半的内容。 然而，很多同学没有意识到，其实大部分人的日常工作，不过也都是由一堆「几秒钟能做」的「分类」和「识别」任务组合而成的。 现在 AI 无法胜任日常工作，其实是没有人去把这些繁杂的工作，分解成简单的任务。这个分解过程，其实就是自动化的过程，也就是领域语言的建模过程。 大家对 AI 的期望，是它可以自动完成领域语言的建模，并在此基础上直接完成任务。这种复杂程度的智能，我觉得还要过些年实现了机器的自我学习以后才能实现。但如果我们自己来完成领域语言的建模，让 AI 只处理那些分解以后的简单任务，那么 AI 很快就能进入实用领域了。 当 DL 遇到 DL 所以，光有 Deep Learning 其实很难直接应用于业务上，还需要有 Domain Language。大公司们现在的精力都放在通用行业的 Domain Language 上，比如自动驾驶。这正好给各个细分行业的小公司们留下了几年的机会窗口。而最熟悉行业 Domain Language 的，恰恰就是工程师这个岗位。 其实很多工程师已经开始各种尝试了，让我印象深刻的几个例子是：亚马逊的工程师用 AI 调整 RDS 数据库配置，测试效果超过了资深DBA。还有自动扫描界面图片，生成 iOS 和 Android APP的布局代码。 所以说，不是 AI 没应用场景，而是领域语言没有跟上。就像当年支付没跟上，电商就做不起来一样。当前公司最要紧的工作，是完成业务的领域建模，这样不管是以半自动还是以AI的方式运作，都能大规模的提升生产效率。 由于 AI 对于输入的数据高度敏感，所以领域语言上的差距会被加倍放大到最终结果里边。随着AI常用算法的日益成熟，应用上竞争可能反而会慢慢转到领域语言上来。这也将会是工程x算法跨界人才最值钱的一段时间（ 我猜🤠 ）。 总结 以上就是我们看到的技术趋势，能力有限，错误难免，请大家带着质疑精神来读吧。 "},"程序员职业小白书/职业经营3.1：新手如何快速起步.html":{"url":"程序员职业小白书/职业经营3.1：新手如何快速起步.html","title":"职业经营3.1：新手如何快速起步","keywords":"","body":"新手如何快速起步 充电期 我们还是新人的时候，并不是一进来就能给公司贡献价值，往往需要一个相当长的时期来学习专业知识、练习专业技能。在处于充电期时，你在网上看到的职业鸡汤很可能不适用，这是为什么我们专门分一个话题来讲。 处于充电期的你，基本不能为公司贡献价值，而公司不但要支付你的工资，还要提供培训、安排专人指导，这些都是成本。换句话说，你对公司的价值是负数，这是一个非常不利的状态。 而你最重要的任务就是，尽快的充满电，然后脱离这个状态。一旦过久的处于这个状态，公司的耐心就会耗尽，判定你的学习能力不足，成长空间有限，从未来的种子选手名单中去除。 所以充电期最主要考虑的事情，就是怎么尽快的成长，再无其他。每当我在网上看到一堆同学抱怨自己的实习薪资低时，我就觉得他们根本没弄明白自己的处境。如果一家公司可以为你提供良好的培训、指派行业大牛一对一的对你进行指导，让你在短时间内从一个新手变成合格的程序员，即使公司不给你提供实习薪资，这也是绝对划算的买卖啊。只要你很快的度过了充电期，就可以成为正式员工，领正式员工的薪水，甚至还可能在转正时涨薪。所以目光要放长远一点，实习期那点小钱，根本就不是个事儿。 相反的，如果一家公司给你不错的实习薪资，但却没有培训和培养，让你在那里自身自灭，这种公司恰恰是对不能去的。因为刚毕业的这一年，是非常关键的时期。 利用好校招 校园招聘是一个非常特殊的渠道，从这个渠道来的同学，即使「什么都不懂」那也是很正常的。我们对校招的预期就是，这个人聪明而且又肯学，那就够了，不指望你有太多工作经验。 但是，如果你没有利用好校招这个时间窗口，即使是几个月以后，再以社会招聘的渠道进来，就完全不一样了。因为我们对社招的预期就是，你应该有工作经验，你来了以后就应该立刻能工作。你都毕业半年一年了，充电期应该已经过了，应该能输出价值了。如果你现在还没学好，那就是能力不行了。 和你竞争的对手也变了，从大学同学变成了已经充完电的同行们。不要以为你毕业一年，就只有同样毕业一年的同行能和你竞争，我们经常说「一个有三年工作经验的，能抵五六个一年工作经验的」。这个行业残酷的竞争会毫不留情的压到你的身上。 所以好好利用这大学最后的礼物吧。 放电期 前边说了，充电期不要被薪资迷惑，你将来一个月的薪资，可能是你刚开始工作时的五倍十倍，提升自己的能力才是当务之急；这里要说的是，放电期不要被人情迷惑。 有很多小公司很不错，培养你的时候很用心，同事也和蔼可亲，老板也 Nice ，但是时间久了你开始发现，自己在技术上再也没有成长空间了。如果你的技术已经到了行业里很高的水平，这倒也无所谓了；但如果还只是个初中级开发者，就要留意了。 比如一些外包建站的公司（ 并不是说所有的这样哈 ），它可能什么都好，但就是每天的工作就是写表单，增删改查；为了降低学习成本，版本管理可能用的还是 SVN；新技术客户没需求，天天都在别人的平台上二次开发。 如果你在这种公司停留时间过长，那么很可能会对你职业发展不利。因为这些时间你都处于放电状态，没有成长；但别人在成长啊。如果一个十年工作经验的 PHP 和三年工作经验的 PHP 能力相当，我们会选择三年的，因为那个十年的要么学习能力不行，要么学习意愿不行。 这个行业很残酷，如果你不能确定将来你找不到工作的时候，你的老板和同事会养着你，那么把自己能力的提升放到第一位吧。其实离职以后，原来的同事还是可以变成朋友的。 之所以写到「新人篇」里边，是因为等你变成老人，离职多了就习惯了，也就不会纠结了…… 🤣 "},"程序员职业小白书/职业经营3.2：老手如何远离职业误区.html":{"url":"程序员职业小白书/职业经营3.2：老手如何远离职业误区.html","title":"职业经营3.2：老手如何远离职业误区","keywords":"","body":"老手如何远离职业误区 即使工作了蛮多年的同学，在职业上还是会有一些容易掉进去的陷阱，这里把我经常被咨询的问题整理出来。 工作不是一分钱一分货的交易 之前在微博上有一个讨论，大概是说，一个员工觉得公司给他的工资不够多，就消极怠工，明明能做到八十分的工作，只做到六十分。 但其实工作并不是一分钱一分货的交易，表面上看，你的确是在为公司上班，公司给你付薪资，但实际上，你还在付出时间。 这个时间是非常宝贵的，我们花了十多年的时间去读书，二十岁到四十岁也就只有二十年的时间。每周除去吃饭睡觉上下班和周末，真正用到工作上的时间并不多。 这就像玩 RPG 游戏一样，我们去打怪表面上看是为了挣金币，但事实上我们更是为了尽快升级，提升自己的能力；我们表面上是为了工资去公司上班，但事实上我们更是为了提升我们的能力，增强我们的职业竞争力。如果我们不把时间花在最能涨经验的地方，我们就可能被同行拉下；如果我们还每天对能做好的事情敷衍了事，最后就会养成做不好事情的习惯，白白浪费了自己的时间和天赋。 有同学可能会想，公司那么不待见我，我还那么用心的工作，我又不是受虐狂。是的，我们没必要做不讨好的事，但你可以换一家待见你的公司待着呀。如果你发现你找不到比现在这家更好的公司，那么就先用心提升自己的能力吧。 谁对谁错没有意义，没人犯错才有意义 太在意对错，也是程序员们在职场容易犯的一个问题，我刚毕业时就有这毛病。比如服务出问题了，第一时间想的就是去查到底是谁的错，查完了不是自己的错，就一副事不关己的样子。一些责任不清的地方出问题，还和同事争论这到底应该算是谁的错。 我当时觉得，对的就是对的，错的就是错的；对的就应该得到表扬，错的就应该得到惩罚。 但工作时间久一些了我就慢慢发现，团队里边不管是谁的错，只要有人犯错，最后整个团队都要为这个错误付出代价 —— 并不是你对了，你就可以幸免。所以谁对谁错没有意义，没人犯错才有意义。 于是后来我开始有意识的去留意和自己接口的人可能犯错的地方，然后在出错之前想办法去确认状况。也开始留意团队总是出错的细节，在必要时提醒项目经理确认。一段时间以后，背锅的次数少了很多，虽然刚开始有同事会不习惯，但时间久了，效果出来以后，他们也慢慢认可了。比起做老好人，想尽一切办法把事情做好更重要一些，因为流量压过来的时候，你和服务器关系再好也扛不住的。 公司不能培养自己时，要学会自己培养自己 很多同学抱怨公司不用新技术，自己没有办法接触一些新的东西，成长的空间受到了限制。或者没有办法接触到公司的核心业务，天天都在做外围。 在很多同学眼里，公司就应该像大学一样提供完整的培训课程，帮助员工成长和提高。在很多大公司的确是这个样子的，但事实上，公司毕竟不是一个慈善机构，它只是一个为了挣钱而存在的商业实体。所以从比例上来讲，绝大部分公司是希望你进去以后能尽快的提供价值，而不是消耗公司资源。只不过大公司有足够的影响力，以至于你看得见的都是这些公司提供的空间和福利。 那么没有机会进这些大公司或者进了大公司，却在一个没有什么发展空间的部门的同学要怎么样来成长呢。 我觉得首先有一点，就是大家一定要想明白，成长是你个人的事情，公司只是助力。你要把成长这件事牢牢地控制在自己手上，不能把它交给运气。 从课程角度讲，现在美国很多大学都开放了他们非常好的课程，字幕组现在也很勤奋，看不懂英文，看字幕都可以把它给学下来。 在国内，周末通常也会有很多的行业技术分享会，有很多一流的互联网公司，也能接触到他们很多的技术。 从实战角度讲，如果公司没有发展空间，不愿意使用新技术，那么你可以把自己的业余时间花在这些新技术上去做一些开源项目或者独立项目。这些东西不但会为你带来能力上的提升，还会给你带来意想不到的机会。 之前投资人找到我，是因为我用业余时间做了teamtoy。出版社找到我，是因为我用业余时间写了《程序员跳槽全攻略》。 当然，如果这样还是不能满足你的成长规划，那么跳槽也是一种选择，但前提是你得找到一家更好的公司。 关于跳槽我有一个特别重要的建议就是尽量不要去长期 996 （早九点到晚九点，一周上六天）的公司，因为这样你就再也没有业余时间了，它看起来只是一周一天的时间，但实际上是你所有的可能性，是你可以自主控制的成长空间。 三十五岁不是程序员的中年危机 华为前段时间清退了一些三十到四十岁左右的程序员，又将这个经常被讨论的话题推了起来。 我们经常感叹，那个人三十多了还在做程序员。其实并不是说三十多不能写程序，五六十的大爷写程序我们也习以为常了，之所以感叹，是因为我们对一个写了多年程序的人，有一个更高的预期。 就像我们之前在职业路线图里边看到的，如果二十岁开始写程序，十多年的时间，走管理线的应该走到经理层级了；走专家线的也应该在业内小有名气了。而如果一个人十多年了都还在原地踏步，那么他的运气坏到了极点，要么他的职业竞争力出了大问题。 所以，所谓的中年危机，本质上还是竞争力的危机，是能力的危机和职业的危机。如果年轻的时候有好好的规划自己的职业，一步一个脚印的走下来，三十多岁正是收获的时期。因为虽然体力上不能和二十多岁比了，但经验慢慢的累积起来了，有资本去选择一些不是那么累的公司和职位了。 规划好你的职业，哪年都不会有危机。 "},"程序员职业小白书/职业经营3.3：突破管理岗发展中的主要瓶颈.html":{"url":"程序员职业小白书/职业经营3.3：突破管理岗发展中的主要瓶颈.html","title":"职业经营3.3：突破管理岗发展中的主要瓶颈","keywords":"","body":"如何跨过高阶成长中的常见瓶颈 所谓高阶成长，主要就是指管理线的中高级岗位。专家线本来也算，但只要一心专注于技术本身就好了，所以就不花太多时间来说了。 瓶颈一：不明白人和机器的区别 一旦进入管理线，我们会非常明显的感受到和以前的不同。因为之前主要都是和机器打交道，纯逻辑的二元化生物，非此即彼，非常好相处。 但是从管理线开始呢，我们就要开始和人打交道了。这些人可能是你的下属、也可能是公司其他部门的同事，比如我们「深恶痛绝」的产品经理、测试部门、HR部门（ 招聘面试 ）等等。各种各样的人都会进入到你的工作中来，人嘛，都是情绪化的动物，和机器是完全不同的。所以我们在进入管理线的时候，要尽快适应和他们打交道的方法。 瓶颈二：不理解规则的意义，崇尚「自由主义」 当程序员的时候，往往是单枪匹马解决问题，很多东西自己想怎么来就怎么来。但当你走上管理岗位以后，人一多就会发现，不能由着每个人按自己的想法来，不然这个程序员用 PHP ，旁边那个用 Python ，代码库格式百花齐放，完全没法看。 所以规则是为了提升整体的生产效率，所做的一些妥协。不要敌视规则，现在你可以一定程度的参与规则的制定了，尝试好好的改进它和利用它。 瓶颈三：缺乏良好的沟通和表达能力 在开发岗时，虽然也需要一定的沟通和表达能力，但其实基本也就写文档、和做工作汇报时会用到；但在管理岗上，就不一样了。 这是一个承上启下的岗位，一方面你需要理解领导的意图，将其转化为对应的解决方案，再提交领导审阅，想办法说服领导支持你的方案；另一方面你又要培养新人，确保他们明白自己要做的工作，习得对应的技能，能按时按量的完成开发工作。在这种岗位，一旦在沟通和表达中出现问题，就会被成倍的放大。 这种能力需要花时间去培养，很难一蹴而就。但好在我们虽然是管理岗，但它依然是技术相关的，它描述的依然是非常理性的东西，不太会出现创意行业那种「跳跃性思维」和「无法用语言来表述的感觉」之类的内容。所以基本上，只要我们把条理性把握好，就能输出简单易懂的内容。即使它可能有一点点枯燥，但会很清晰。如果你还能自然的嵌几个笑话进去，那么应付技术讲座就绰绰有余了。 瓶颈四：不能迅猛的招聘和培养下属，将工作分担下去 招聘和培养下属，是中层管理者除技术以外最重要的能力之一，我们要持续而稳定的为公司提供研发能力，确保能支持公司现在的业务，并能跟得上未来的发展。 所以我们必须掌握一整套的方法，包括如何招聘新人、招聘进来以后如何培养、试用期如何识别种子选手、转正后如何最大的为公司贡献价值，还要留意他们对公司的满意度啊、个人的发展意愿和发展空间，以免刚培养出来就跳槽了之类的。 掌握不好这些技能，就无法放大自己的能力，所有的事情都只好亲力亲为，天天加班。为了避免这种悲惨未来，我们甚至从进入管理线之前，就应该有意识的去培养这些能力。首先要养成写技术博客或者笔记的习惯；然后可以试试把日常工作中的经验和教训总结下来，以书籍或课程的方式分享出去，这样除了能提升能力，还可以挣点零花钱。 瓶颈五：面对大挑战时失去斗志，茫然无措 刚进入管理线，或者突然老板给了你一个难度很大的任务的时候，面对千头万绪的事情，很容易发蒙。这种时候，首先要镇定下来，然后将这个任务拆分成一个一个的小挑战，去分析其中的风险，从而制定出一系列容易达到的小目标。 当我们不断的去完成这些难度不大的小目标时，会获得持续的小成功，这些成功堆积起来的信心，最后会帮助我们解决掉最后的那个难题。因为在难题面前，最常见的失败就是失去信心。你都不相信自己能做出来的时候，那当然就做不出来了。 一个小建议：来一次「迷你技术创业」 管理是非常依赖于实践的事情，你看着那些管理大师的巨著，然后在脑海中演练，其实最后什么用都没有的，只有实际经历过，才能感同身受。 好在我们是程序员，可以从无到有的创建一个软件。所以我们可以利用业余时间，去开发一个商业软件，或者 Lead 一个开源项目。当你控制着一个有业务在流动的组织的时候，就能清晰的感受到各种问题、然后想出自己的解决方案，并能看到这些方案最终的效果。 这样做，不但可以更深入的理解人和组织，也可以更好的理解商业。产品如何被设计、被制作、被销售、被运营；现金如何变成资源、商品最后又变回更多的钱。当你明白了这些之后，就能对自己的岗位有新的看法，也能和老板们有更多的共同语言。 "},"程序员职业小白书/职业规划1：通过职业价值论理解一个程序员的真实价值.html":{"url":"程序员职业小白书/职业规划1：通过职业价值论理解一个程序员的真实价值.html","title":"职业规划1：通过职业价值论理解一个程序员的真实价值","keywords":"","body":"如何理解职业价值论 方法论 「求职」和「跳槽」我们虽然经常都在说，但却很少认真想过这些行为背后的意义。 在我决定自己写书之前，经常会有程序员遇到职业困扰来找我，我一般会给他们推荐一些职业书。 有一回我就遇到了一个认真的程序员，他记下了我推荐的书单，然后用一个长假买来读完了。假期过后，他又跑来找我，问了我一个问题。他说「这些书往往只告诉我要怎样怎样，却从来不告诉我为什么要这样。如果它解释不清楚这样做的意义，那凭什么我要相信它呢？仅仅是因为它的作者有名么？」 我仔细一想，发现他说得很有道理。从作者角度讲，要知其然才能触及本质，不然那些小技巧就流于表层；从读者角度讲，程序员天天和逻辑打交道，是一种逻辑动物，只有理解了求职到底是一种什么行为以后，才能做出有意义的行动。我当时没有回答出来，但这个问题就一直留在我脑子里，经过几年的思考，最后慢慢的形成了一套方法论。 这个方法论包含了三个工具。分别是： ① 讲述原理的「职业价值论」 ② 展现行业职业概况和关键节点的「职业象限和路线图」 ③ 以及分析如何在职业节点移动的「职业画布」 顺便说一句，这种职业节点间的移动，其实就是我们常说的求职、内部转岗或者跳槽。 接下来的章节我们将重点讨论这三个工具。 价值论 价值论解决的问题就是，一个程序员应该值多少钱。 这是一个非常有意思的问题，我之前做人才拍卖服务的时候，经常问候选人说，你为什么觉得自己值这么多钱呢？ 很多同学都说，我现在的薪资是怎样怎样啊、或者市场上同样工作年限的程序员都是多少多少呀。这些都没错，但都不算好答案，因为它还没有触及到本质，没有明白薪资到底是怎样的东西。 你想过老板为什么要雇用我们么？ 老板之所以雇用我们，是想要我们给企业带来价值，说白了，就是直接或者间接的帮公司挣钱。 我们的薪资，一般是作为公司的人力成本。虽然控制成本很重要，但其实真正的重点却在「你为公司带来的价值」和「你的薪资」之间的差额。 所以当老板觉得「你的薪资高了」，其实是在说「你为公司带来的价值不够」。 当我们进入一家新公司的时候，由于没有实际工作的数据可以衡量，「你认为的你的价值」、「公司认为的你的价值」和最终「你给公司带来的实际价值」之间会存在一定误差。而简历和面试，就是为了让「你认为的你的价值」和「公司认为的你的价值」离得更近。 简历其实就是一个价值主张，它说的是：「我到这家公司来，能完成这些和那些工作，为公司带来这样和那样的价值，而我只要这么一点点的薪水，所以赶紧雇用我吧」。 改变思维方式很重要 总之，一定要改变「我上班别人给我钱」的思维方式，转换到「我能为这家公司创造什么价值」的方向上来。 这种换位思考能帮助你想明白很多事情，比如说： ① 拥有一系列技能的同一个人，在不同的公司创造的价值往往是不同的，于是他能拿到的薪资也就不同。 ② 公司雇佣一个人，并不是看他有多牛，而是看他能给公司带来哪些价值。 虽然大部分情况下，个人能力和能给公司带来的价值是正相关的，但如果你能提出并证明一个更好的价值主张，你很可能就会比这个牛人更适合这家公司。 一个极端的例子是：一个顶级架构师在一家使用 ServerLess（无服务器端架构） 的创业公司很可能没有用武之地，而一个客户端高手在这家公司里可能能搞定一切。 其他因素 从整个求职市场来看，影响我们薪资的，除了「你能为公司创造的价值」也就是「人才的使用价值」本身，还会受到「市场供需」、「信息透明度」等因素的影响。 读者问答 问：「你为企业带来的价值」，这个自己怎么衡量，企业又是怎么衡量的？ 答：未入职员工是你提价值主张，告诉企业你能提供哪些价值，通过简历、面试和笔试、以及试用期获得企业的认同，从而最终雇佣你。员工通过绩效系统来进行考量。自我价值一般是从之前工作经历和业绩的基础上估算的。 "},"程序员职业小白书/职业规划1.1：程序员市场的供需关系对求职的影响.html":{"url":"程序员职业小白书/职业规划1.1：程序员市场的供需关系对求职的影响.html","title":"职业规划1.1：程序员市场的供需关系对求职的影响","keywords":"","body":"市场供需 当一个岗位供大于求时，招聘方就有了更多的砝码来压低薪资，从而获取更多的剩余价值；而当一个岗位供小于求时，候选人就有了更多的选择，也就更值钱。 一个岗位的供求从长远来讲，是受行业和技术发展影响的，比如随着网络的大规模发展，同样是从事软件开发工作，传统软件的开发岗位就没有互联网和移动开发岗位的需求量大；而从短期来讲，每一波浪潮带来的新兴市场和高利润的行业交叉细分市场职位就会更值钱一些。 行业和技术发展趋势我们后边留了一个独立问题来讨论；这里先重点说说细分市场和新兴市场两种求职策略。 针对供需的求职策略 「专注细分市场」和「专注新兴市场」是最常见的两种求职策略。其中「专注细分市场」是通过削减宽度来提升深度的求职策略；「专注新兴市场」则是利用技术边界的变动来拉平经验差距的求职策略。 专注细分市场 细分市场是指整个市场的一小块，我们把原本用来覆盖整个市场的精力，用到这一小块上，来让我们在这个细分的领域里做得比别人更好。 这通常是行业和技术的一个交叉点，我们之所以能在这个市场上比其他人做得更好，是因为我们拥有适应这个细分市场的行业知识、行业技能和行业技术。这些行业相关的东西和通用技能 CrossOver ， 从而形成了我们独有的竞争力。 通俗一点的例子比如，「比我漂亮的没我聪明，比我聪明的没我漂亮」，这就是一个非常独特的细分定位。 在细分市场里边因为招聘方的选择并不是那么多，而我们的优势又足够的明显，所以通常会有很好的竞争力。 但是，我们将所有精力都投入到细分市场之前，要仔细考量这个细分市场的大小和发展，因为如果这个市场非常小，那么招聘方数量可能也就不够，尤其是对没有在北上广的同学来说，机会就非常少。这是专注细分市场策略需要注意的地方。 专注新兴市场 新兴市场也是一个有意思的策略。它只是说，当一个新技术出来的时候，原来的技术边界会发生变动。原来不能做的事情变得能做了，原来的一些规则和经验变得不再那么好用了。 所以呢，这是一个非常好的新人切入的机会。因为老人积累的经验很可能很大部分不适用了；这样我们和老人之间的差距就变小了。把握住这个差距，然后再勤奋一点，就可以在这些新兴市场上获得强竞争力。 比如 iOS 刚出来的时候如果适时跟进，你的竞争力可以在很短时间内赶上甚至超过那些用 J2ME 开发功能机的资深工程师。 最简单的判断一个新兴市场是否靠谱的方式，其实是看资本流入的速度。这个比较反直觉，大家都觉得资本是泡沫，但事实上，资本是很精明的。即使抛开最后这些方向能不能成功，单是资本的涌入，就会催生大量的公司，而这些公司就会大量的招人。然后就会在短时间内造出一个非常大量的需求，而供应端往往还非常小。所以不管资本带来的是不是泡沫，这些岗位的薪水都会水涨船高。 回过头来看，资本催生的高薪职位和方向，从云计算、移动开发，再到直播、区块链、人工智能，最先涉足这些领域的程序员们薪资都没有低过。退一步讲，一个行业没了，你在里边两三年挣到的钱是在那些稳定的行业挣到的三倍五倍，那也不亏吧。 新兴市场也是小市场，但对个人来讲，只要在里边做得足够好的话，总是能找到一些好机会的。除市场容量外，还会遇到 早期技术接口不稳定 和 生态不成熟 之类的问题，会带来额外的工作量和重复劳动。比如 Swift 的各个版本都有「轻微」的不兼容。 "},"程序员职业小白书/职业规划1.2：实操职业供需关系的量化分析.html":{"url":"程序员职业小白书/职业规划1.2：实操职业供需关系的量化分析.html","title":"职业规划1.2：实操职业供需关系的量化分析","keywords":"","body":"对供需进行量化分析 当然，除了这种面向整个行业和技术方向的定性分析，我们还可以通过工具来做定量分析。 量化分析 招聘网站的招聘启事中包含了大量的信息，只不过因为数据量较大，全部浏览下来往往会耗费大量时间。然而对于程序员来说，这都不叫事对吧。 这里我们以拉勾网为数据源，来演示下如何通过数据来分析或者证实我们猜想。 拉勾网覆盖了20多万家互联网公司，在一二线城市的职位充足，算是不错的数据源。 最近有一些培训机构推出了面向初学者的免费培训课程，这本来是好事，但它们忽悠说，只要花几周学会 HTML5 ，就能找到工作。那么我们就来看看，只会 HTML5 到底能不能找到工作。 搜索结果在说话 在进行编码抓取数据之前，我们应该先确认下数据的量级，所以我们先搜索一把。先看看全国范围内，面向应届生的 HTML5 工作岗位，只有七个。 为什么要选择应届？因为培训完的同学也没有1~3年工作经验呀。 这也太少了，那么会不会是 HTML5 这个关键词的问题？我们再来试试 HTML 好了。 一样，看来拉勾做过同义词合并了。再来看看实习岗位： 更少一点，只有五个。这说明只会 HTML5 是找不到工作的，HTML5 只是前端岗位技能的一小部分，单是一个入门培训是完全不够的，如果要胜任前端岗位，我们还需要学习更多的东西。 前端到底要会什么？ 那么，企业对应届的前端岗位的需求到底是什么？先搜一下。 总共有160个岗位，还算不错。这时候我们就不一个个去浏览了，该使用我们的技能了。思路是，先把包含这些岗位的全部页面抓下来，然后把每个职位的信息提取并保存为 JSON 。最后按需要分析统计这些 JSON 数据，就能得出我们需要的最终数据。 通过 Chrome DevTools 查找数据源 打开 Chrome 的 DevTools 面板，切换到 Network > XHR 选项下（这样可以过滤掉无关请求），然后对满足我们要求的搜索页面进行翻页。 我们可以发现，数据就存在于下边这个 URL 里边： https://www.lagou.com/jobs/positionAjax.json?px=default&gx=%E5%85%A8%E8%81%8C&needAddtionalResult=false&isSchoolJob=1 仔细观察它的 Header 会发现参数是通过 POST 请求发送过去的： 其中 pn 就是页数，我们这里总共有 11 页。 通过构造请求抓取数据 在请求上点击右键，选择 Copy as cURL ，可以获得模拟请求的 cURL 命令参数。大概是下面这个样子。 curl 'https://www.lagou.com/jobs/positionAjax.json?px=default&gx=%E5%85%A8%E8%81%8C&needAddtionalResult=false&isSchoolJob=1' -H 'Cookie: ...' -H 'Origin: https://www.lagou.com' -H 'X-Anit-Forge-Code: 0' -H 'Accept-Language: en-US,en;q=0.8,zh-CN;q=0.6,zh;q=0.4,ja;q=0.2,zh-TW;q=0.2' -H 'X-Requested-With: XMLHttpRequest' -H 'Accept-Encoding: gzip, deflate, br' -H 'Connection: keep-alive' -H 'Pragma: no-cache' -H 'User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36' -H 'Content-Type: application/x-www-form-urlencoded; charset=UTF-8' -H 'Accept: application/json, text/javascript, */*; q=0.01' -H 'Cache-Control: no-cache' -H 'Referer: https://www.lagou.com/jobs/list_%E5%89%8D%E7%AB%AF?px=default&gx=%E5%85%A8%E8%81%8C&gj=&isSchoolJob=1&city=%E5%85%A8%E5%9B%BD' -H 'X-Anit-Forge-Token: None' --data 'first=false&pn=1&kd=%E5%89%8D%E7%AB%AF' --compressed 我们只需要将 pn 参数替换，然后请求11次，就可以获得全部的职位数据了。 以下的内容均使用 PHP 来实现，逻辑很简单，如果你是合格的程序员，应该很轻松就能将其改写成自己想要的语言实现。 下边是实现的 PHP 代码（需要建立data目录，根目录要可写，PHP7.1 测试通过）： 最终在 all.json 文件中，我们得到了所有职位的信息，但是这些信息里边只包括了薪资范围，并没有技能要求。于是我们需要进一步的去抓取职位页面的信息。 观察 all.json 中的数组，发现职位数组位于 $item['content']['positionResult']['result'] 部分，通过其属性 positionId ，我们可以构建职位页面的 URL ： https://www.lagou.com/jobs/${positionId}.html。 于是我们可以遍历 all.json 中的职位，来抓取对应的页面： 最后再通过正则表达式来分析这些页面中的包含的技术关键词的词频。严格的讲，要统计词频需要进行分词，不过绝大部分技术关键词都是英文的，这里我们简单粗暴的把英文单词提取出来排序。 在这种并不是经常进行的、只给自己看的分析工作中，可以更灵活的选择性价比。 (.+?)/is'; if( preg_match($reg, strtolower($content) , $out )) { $out[1] = str_replace( ['&nbsp;','&amp'], [' ',' '] , $out[1] ); $text = strip_tags($out[1]); return $words = get_tech_words( $text ); } return false; } function get_tech_words( $string ) { // 提取英文单词 $reg = \"/([A-Za-z][0-9A-Za-z]+)/i\"; if( preg_match_all($reg, $string , $out )) { $ret = array_unique($out[0]); return $ret; } } 然后我们就得到了招聘前端应届生的公司的精确的需求，虽然里边混有一些非技术关键词，我们可以很容易识别，算是无伤大雅了。 [javascript] => 152 [css] => 134 [web] => 101 [html5] => 74 [html] => 72 [react] => 56 [jquery] => 52 [vue] => 50 [nodejs] => 46 [angular] => 39 [ajax] => 35 [java] => 30 [php] => 30 [pc] => 25 [bootstrap] => 25 [http] => 24 [w3c] => 23 [webpack] => 22 [python] => 21 [ui] => 18 [app] => 17 [gulp] => 17 [git] => 16 [es6] => 15 [dom] => 14 [json] => 14 [xhtml] => 13 [github] => 12 [div] => 12 [xml] => 11 [mobile] => 11 [android] => 10 [native] => 10 ... 可以看到 JavaScript 才是前端工程师的最大诉求；HTML/HTML5 加起来排名第二；然后是 CSS。接下来是几大框架：Vue 、React、jQuery、Angular；再然后是后端语言：Java、PHP、NodeJS。 这对应届生的指导意义非常明显：JS、HTML、CSS 三大块是核心，必须学完才能找到工作（在157个职位里边出现了超过150次）；主流框架也是要掌握的，Vue 和 React 目前正在风头、jQuery 也还没老（超过三分之一的职位要求会其中一种）；后端语言是加分项，NodeJS 和前端最为契合，其次是 Java 和 PHP（近五分之一的职位有提到）。 完整的列表我放到GitHub上了，可以点这里查看。 从上边的例子举一反三，可以很容易的知道诸如「北京地区前端应届生的薪资范围」、「重庆招聘 PHP 的公司都在使用什么技术栈」这些非常具体的问题，从而为自己量身定制对应的面试攻略。 均值的意义 需要注意的是，平均值的参考价值非常有限，数据越多，它就离个体值越远。它就像股市的大盘，大盘涨了，你未必能挣钱，只有你买的股票涨了才行。所以应该尽可能具体的去分析数据。 每隔一段时间，也应该去其他公司面试下，面试谈下来的薪资，就是你这只股票的「交易价格」，是你能拿到手的真金白银。 "},"程序员职业小白书/职业规划1.3：扩展渠道，减少信息不对称带来的求职损失.html":{"url":"程序员职业小白书/职业规划1.3：扩展渠道，减少信息不对称带来的求职损失.html","title":"职业规划1.3：扩展渠道，减少信息不对称带来的求职损失","keywords":"","body":"信息透明度 信息透明度对求职的影响 市场供需虽然存在，但是我们不可能凭空地去接触到它。只有透过各种渠道，我们才能接触到这些供需。信息透明度就是关于这些渠道的。 当人才市场很小的时候，信息很容易透明，比如学校院系有个几个兼职岗位，只要贴个招聘启事在公告栏，然后大家都知道了。 但当这个信息量变得很大以后，可能就没有精力读完所有招聘启事了，这时候，信息就会出现不对称。 只有你知道的职位对你来讲才有意义。比如北京现在有100家公司都在前端，但你只知道其中三家，那其他九十七家公司对你而言都是没有意义的。如果你急需工作，即使这三家给你的薪资比其他公司低，你也就只能被迫接受了。这就是信息透明度对我们的影响。 要做选择题，不要做判断题 我们要学会和这种信息不对称做斗争。最基本的规则就是，一旦决定要找工作，就要争取在短时间内拿到大量的 offer ，这样才能做选择题，而不是做判断题。 所谓选择题，就是你手上有一堆 offer ，可以选择这家或者那家；所谓判断题，是说你现在手上就一个 offer ，你要么去要么不去。不是说你实力好就一定能做选择题，这里更多的是时间上的考量，如果你总是等到一家公司面完再去找另一家，你就只能一直做判断题了。这其实在信息上边吃了很大的亏。 渠道 说到这了，我们就顺便说一下渠道。一般来讲，求职渠道越多，信息就越透明。 渠道成本 但是渠道本身是有成本的，以招聘网站为例吧，虽然绝大部分招聘网站对求职者都是免费的，但每去一个新的招聘网站都要注册帐号呀、填写资料呀、上传简历呀，一堆的事情。如果要去十个招聘网站投简历，这些事情得做十遍，这就是渠道成本。 这是可见的，还有不可见的成本在后边，比如你个人的信息安全甚至人身安全。很多不知名的新兴招聘网站，以及一些年久失修的上市招聘网站，在招聘方验证上偷工减料，在用户信息保护上做得也不算好；再加上很多企业对简历的保密意识不足，接触的渠道越多，越存在资料泄漏的风险。前段时间不是还出现过因为找工作误入传销，最后不幸身亡的事情么。 但我们不能因哽废食呀，该投的简历还是要投的，首先要在脑子里对陌生人电话保持警惕；然后可以买一个备用号码找工作专用。 我强烈建议三五年没有更换手机号的同学去买张新的流量卡，既可以用于招聘、租房等高危事务，又可以为日常提供充足的廉价流量。很多和网站合作的流量卡都可以对常用的业务免流量，比如微博的V卡直播免流量、B站的22/33卡对视频免流量、腾讯的大王卡对QQ音乐等旗下服务免流量。即使超出流量，也可以拿到几块钱1G的便宜价格，非常划算。PS：这段不是广告，只是对运营商无视老用户的吐槽😭 渠道优劣 那么到底哪些渠道更好了？ 从我的个人经验来讲：内推 > 拍卖 > 猎头 > 官网/招聘网站投递。但拍卖和猎头通常对工作多年的人来讲更为合适，对于新人而言，基本可以无视了。 内推是我认为的最优渠道，最理想的找工作方式就是你正好要找一份工作，而你正好有一个熟识的朋友在这家公司，他/她对你的实力很了解，于是向公司 HR 推荐了你。这种内推是效果最好的，除了是内部渠道，还有员工背书在。 另一种就是你本来不认识这家公司的人，但你也可以找这家公司的员工帮你内推。一方面，你可以得到一些非官方的信息，比如公司是否加班、老大是否靠谱、团队是否好相处；另一方面，推荐人虽然不认识你，但他/她可以阅读你的简历，判断是否适合自己团队，然后决定是否推荐，因为大部分公司都有推荐奖金，所以很多员工也是很乐意干这件事情的。 内推的简历，尤其是用人部门员工内推的简历，一般只要不出现某些重大负面因素，基本都能获得面试机会，非常好用。 除了可以在微博上搜索这些公司的员工，然后私信求推荐以外，多参加技术大会、多参与技术社区、多贡献开源项目，都可以扩展你的行业人脉。 但求人推荐之前要记得看看对应职位的基本要求，确定自己满足再求推荐；贡献的开源项目要有价值，力争能让大家都用起来，在 GitHub 画猫这种事情就没啥意思了。 我之前建过一个内推的微信群，但人满了。稍后会开放两个Q群，分别用于校招和社招岗位的内推。 "},"程序员职业小白书/职业规划2.1：通过四大象限和职业路线图理解程序员的主要职业发展路径.html":{"url":"程序员职业小白书/职业规划2.1：通过四大象限和职业路线图理解程序员的主要职业发展路径.html","title":"职业规划2.1：通过四大象限和职业路线图理解程序员的主要职业发展路径","keywords":"","body":"如何理解四大象限和使用职业路线图 四大象限 《穷爸爸富爸爸》的作者罗伯特·清崎，从现金流向将工作分到了四个象限，从而总结出来了这么一张图。 这张图里边有四个象限。 其中左上角是「雇员象限」，帮别人挣钱；左下角是「SOHO象限」，为自己挣钱；然后右上角呢，它其实是一个「企业主象限」，在这里我们把它写成了「创业象限」，因为对程序员来讲，企业主象限通常都是技术创业相关的，都是让雇员挣钱；而右下角的就是投资象限，让钱挣钱。 我们只要把在每一个象限里边的对应的职业节点加上，再画出它们之间的流动方向，就构成了一张相对完整的职业路线图。接下来，我们就在每一个象限里边挨个看看这些节点，及其之间的流动情况。 雇员象限 首先是雇员象限，这个象限风险小，收入稳定，起步点也低，属于绝大部分人最开始所在的象限。 稳定既是它的好处，也是它的坏处。你做的好的话，也就是比平均薪资高个三倍五倍，但很不错啊，不少人能做到百万年薪，但是你想要做到千万年薪，就很难了。 在这个象限里边，大体分为管理线和专家线。 管理线 我们先把管理线的节点给画出来了，管理线主要是跟人打交道。 最开始进来，你是一个开发，做一段时间能力提升了，就会变成高级开发、资深开发；然后再往上走，就要开始管人了，这个时候你会变成小组经理，也就 Team Leader。然后小组管得比较多了，然后如果上边有部门的话可能再往上晋升就是部门经理；没有部门的话，就直接总监了。总监之上是CTO，小公司的话，层级会更少一些。 这就是管理线的大致方向。之所以叫它管理线，是因为它主要依赖于你的管理能力。资深开发、高级开发岗位上，你就基本完成了对自己能力的提升；从小组经理开始，你的任务就变成怎么批量的复制自己的能力，尤其是小组经理和部门经理这种中层岗位，实际上核心任务就是不断地去招募新人，然后通过培训培养，团队协作等各种各样的办法把他们的能力变得和你一样好，从而批量的、稳定的为公司提供各种研发能力。 再往上走，就是总监和CTO的部分。除了要管人，可能更多要开始管理公司的技术相关的资源，比如服务器啊、机房啊、对外的技术联调合同啊，各种和技术相关的杂七杂八的事情。 CTO除了管这些，他毕竟是公司的高管嘛，很可能还要参与到公司的发展决策里边去。比如将来公司要怎么发展啊，在技术上怎么去做保驾护航啊，各种备选方案的技术可行性是什么样子的啊，研发资源是否够分配啊，进度怎么控制、质量怎么保障啊，诸如此类。 各个公司会有所不同，但大体来讲，这个管理线就是这些事情。但是如果你不想就是去管那些人啊，资源啊，也不想和人类天天打交道，我知道很多程序员就对人类不感兴趣，那你可以选择专家线。 专家线 一般大一点的公司才有专家线，小公司的专家线都是和管理线混在一起的。走专家线，一样要至少要做到高级开发，先就把自己的能力提上来，对技术对行业要有足够的了解。 然后你可以选择公司发展中会遇到的、有相当难度的技术方向，进行潜心研究，等出成果以后，自然就成为了这个领域的行业专家、或者公司的科学家之类的。 你也可以选择管理海量的机器和服务，从而走向架构师职位，但架构师要求对各种解决方案都有所了解，从而进行择优，从后端和运维岗位发展过来更为自然。 当然你也可以选择成为行业大牛，这个就是传统意义上的「专家」了。比如很多做布道师，整天就出去开会呀、然后写写文章、搞搞自媒体，让公司在技术圈里边更有影响力，更容易招到程序员，所谓「千金买马骨」嘛。 流动方向 那不管是专家线还是管理线，它都还在这个雇员象限，也就有雇员象限的天花板。虽然有个别的同学通过股票等方式获得了很大的回报，但大部分人的收入天花板还是明显的。 刚进入公司做开发的时候都还是小年轻，等做到小组经理、部门经理了，经济压力就慢慢来了，要买房啊、还要养家糊口啊、小孩要上幼儿园、以后要不要买学区房… 另外就是，越往上走，岗位就越少。尤其是稳定的大公司，人员流动少。管理线并不是你能力好就能上位的，之前位置上的人得走，你才有机会。 所以这个象限有大量的人流向的「创业象限」。 创业象限和投资象限 明确创业意愿 首先，我想和大家聊聊程序员如何来参与创业这个事情。大部分人，可能是受媒体影响，对创业是有误解的。不少人都还以为创业就是很苦情的在一个出租房里边，不拿工资，天天加班加到死，然后突然之间就一夜成名，一鸣惊人天下，什么钱都有了。 实际上，现在创业并不是这个样子了，而且很可能从来就没有这样子过。 现在创业已经变成一个很普遍的事情，你去创业不一定非要怎么破斧成舟、卧薪尝胆。而且也不是说每一个创业的人，都要成为一个创始人、CEO，要从无到有的去建立自己的公司。 实际上，完全可以根据你创业的目标，在创业生态里选择一个最合适的位置。一般来说，我觉得可以有下边几种选择。 「我有一个无论如何都要做成的idea」：创始人/CEO founder 「我遇到了一个和我想法相同的人，我们决定一起做」：联合创始人 co-founder 「我很认可某人的想法，我有很好的能力，我想帮他」：合伙人 partner 「我觉得创业很有钱途，想赌一把」：已获投资公司的核心员工，有期权的那种 「我觉得创业很有意思，想体验下」：已获投资公司的早期员工，如果你不缺钱，那么没投资的公司也无所谓 把自己的创业意愿明确了，才好确定自己的在创业生态中的位置，才能管理好自己的付出和预期。 CEO 和 CTO 的技能鸿沟 别看 CEO 和 CTO 只差一个字母，但它们之间的技能要求是完全不同的。一般情况下，我是不推荐没有团队管理经验和市场营销经验的同学直接去做 CEO 的，因为这个位置对技术的要求并不算高，对其他技能的要求却非常高，更多的是发现一个价值，然后把它制造出来，销售出去。 在绝大多数公司里边，技术并不破冰开路、而只是保驾护航的。当然，现在像大疆、讯飞这种技术驱动型公司也慢慢多了，随着 AI 的发展，预计会越来越多，但从当前的整体来看，技术起的还是支撑作用。 不是说技术出身的就做不了 CEO ，是说你得有这个意愿、也得有这个觉悟。CEO 是一个和人打交道的活，必要时还要和媒体打官腔，在员工面前装镇定。 总之，我觉得 CTO 是程序员们技术创业的首选职位。当然，也不是所有人都有能力和机会当 CTO 的，你也可以从核心员工干起。 创业象限的可能回报，注意是可能回报，是非常高的。一旦公司上市或者被收购，可以获得雇员象限很难得到的回报。从职业节点来看，一般是「创业公司核心员工」> 「创业公司CTO」> 「上市公司CTO」（公司上市了）。一旦做到上市公司CTO（知名公司的话，CD轮就差不多了），基本上就很容易在行业里边换公司了。 再次提醒一句，除了雇员象限，其他象限都是风险较高的象限。高收益往往都伴随着高风险。整个创业象限里边，风险较低的路径大概是从「大公司总监」到「B轮以后的创业公司CTO」。 投资象限 简单说下投资象限，和我们关系不太大。简单的说就是钱太多了的人，想让钱来挣钱，于是通过天使投资的方式来赌一些高风险的小项目。 也有很多创业失败或者成功的同学，后来不想创业了，但在创业领域有非常丰富的经验，他们就很适合去做机构投资人。这种投资人其实算是雇员，需要天天跟各个创业团队聊天啊，然后去挖掘其中有潜力的项目。这种事情看起来很高大上，但其实特别的累，整天飞来飞去，很多行业 TOP 的投资机构，会把一个看好的行业几乎所有的创业团队都聊一遍，还要赶在别人之前，各种辛苦。 SOHO象限 除了创业打拼以外呢，还有一个SOHO象限，这个象限的典型路径是「小老板线」。 这条线一般是从雇员象限的高级开发以及小组、部门经理这些中层，厌倦了职场、厌烦了给别人打工，转而改为给自己打工的路线。 有不少改行开饭馆的，这个我们不讨论；还有一般就是两种。一种是出售自己的技术，通常是建站和做外包；另一种是出售自己的产品，通常是搞工作室和自己独立做游戏、APP等产品的。 做外包的通常是有自己的客户来源，比如在国外的自由职业者网站接单、或者和国内云平台有合作，这样可以让订单相对稳定。 做独立开发的一般就是在 APP Store 和 Steam 上边出售应用了，随着现在个人支付意愿的快速提升，收益开始慢慢变好了。 小老板线往往还伴随了「逃离北上广」的剧情，因为你在家办公以后，就没必要在一个房价很贵的城市待着了。当然，也有很多因果倒置的，因为要离开北上广，所以走上了小老板线。 整体来讲，这条线算是一个可进可退的区域。因为在二线城市或者非核心区域，可以更容易控制成本。外包的更容易找到廉价的劳动力；独立开发的可以更少顾虑的专注于产品。 而且独立产品做好了，不但会有好的现金流，更会带来各种投资的机会，从而进入创业象限，而基于这种经过市场检验的产品再去创业，成功的可能性也会更大。 总结 把之前讨论的象限、节点和流向整合起来，我们就得到一个行业的职业路线图。通过这张图，你很容易就能对整个行业有一个全面的认识。 需要注意的是，这张图上只有各个象限里的常见节点，每一个行业，每一个公司和每个人的具体情况都不一样，你需要根据自己所在的行业、公司和自己整理的具体情况对其中的节点进行增减调整，从而为自己做出一张量身定制的职业路线图。 职业总是循序渐进，水到渠成的过程，虽然偶有意外，但基本都是一个节点一个节点移动的，很少有从开发直接变成CTO的，因为各个岗位负责的具体事务不同、能力的侧重也不同，直接提升风险太高。创业公司很多时候人出问题，就是因为跨过了这个过程。 职业节点之间的移动又是费时费力的，一个合理的移动，一般至少需要一两年。多花点时间想清楚路线图，可以节省你很多的时间。 "},"程序员职业小白书/职业规划2.2：不同职业发展的程序员的日常.html":{"url":"程序员职业小白书/职业规划2.2：不同职业发展的程序员的日常.html","title":"职业规划2.2：不同职业发展的程序员的日常","keywords":"","body":"程序员们的日常是怎样的 技术相关的岗位 我们来说一下互联网行业的技术岗。 现在几乎所有的软件都已经互联网化了，就算没有互联网化的，它以后也会互联网化，所以我们就不单纯地去说软件开发这个行业了。 开发岗 首先就是开发岗，这个就包括了，前端开发、后端开发和移动开发。 前端开发和后端开发，主要是 B/S 结构里的。B/S 结构就是 Browser-Server 结构。而前端指的就是浏览器这个端；后端指的就是服务器这个端。 前端 前端主要做的事情，就是把从服务器端读取到的数据展现给用户，然后通过各种 UI 控件和用户互动，再将新的数据送回服务器端。具体的技术包括 HTML、CSS、JavaScript，还可能有一些嵌入浏览器运行的组件，比如 Flash 、 WebGL 。 后端 后端则主要送数据给前端，一般有两种方式，以前用的比较多的是，将数据在服务器端先渲染完，然后将输出的结果发送给前端；现在用的比较多的方式是将纯数据通过 Json 或者 xml 等格式发送给前端，在浏览器中通过 JS 来进行渲染。 所以以前很多后端的工程师往往也懂一些前端的知识，比如我认识的很多 PHP 程序员，他们不但懂 MySQL 和 Apache，还懂 HTML 、 CSS 、 JS 和 PS。这种前后端都懂的工程师，也叫全栈工程师。 后端可以用各种语言开发，国内用的比较多的包括 Java、PHP ，还有相对小众一些的 Python 、 Ruby 、 Go。其实 C 也是可以写后端的，不过现在已经很少有公司直接用它写了。 后来有了 NodeJS ，JavaScript 也能跑到后端了，所以很多前端工程师也有了后端开发的能力，他们也占了全栈工程师的很大一部分。 客户端 相对于 B/S 结构，还有 C/S 结构，就是 Client-Server 。C/S 结构下不用浏览器来展现数据和交互，而是用客户端，一般是 Mac/Win/Linux 三大平台。 移动端 手机大潮起来以后，不管是 B/S 结构还是 C/S 结构，全部移动化了。B/S 结构对应的就是适配手机浏览器的移动网页、以及嵌入在微信、微博里边的 H5 页面; C/S 结构就是 APP ，一般覆盖 iOS 和 Android 两个主流平台。 除了这些标准开发岗，而还有一些新兴或者相对小众的开发方向，比如人工智能/算法工程师、做智能硬件的硬件开发工程师、给企业做解决方案的企业软件工程师。 其他岗位 软件并不是开发出来就完了的，在上线或者发布之前，我们还需要「测试工程师」来进行测试；而上线以后，还需要「运维工程师」来管理和优化服务器集群。现在服务器都虚拟化和容器化了，运维工程师中也出现了懂开发的分支，叫做 DevOps。 中高级岗位 不管是开发岗还是测试、运维岗，都有其对应的中高级岗位。开发一般是技术经理；运维一般是架构师；测试一般是测试总监。技术总监、CTO 就是更高一级的职位了。 以上的职位分类我们参考了招聘网站的分类，不一定准确，可能会有很多岗位没覆盖到，不少公司也会有自己独特的岗位设置。 程序员访谈 为了帮大家更深入的了解程序员们的日常，我们访谈了不同城市、不同岗位、处于不同职业阶段的程序员，并将其整理和汇总到了下边。访谈的内容只做了简单的标点和文字修正，以提供原汁原味的感受。 访谈一·后端工程师的日常（Java/福州公司） 受访人 @一条死云，今年22岁，在福州一家做财政厅业务相关的公司担任Java后端开发。 平时每天的上班时间和下班时间分别是？ 早上 9 点上班， 晚上 6 点下班 最近一周有加班么？加班的天数是？一般加到多晚？ 最近一周加班三天，工作日加班到晚上8点30左右，周末一天加班一整天，晚上不加。 能否按小时描述一下你的「典型的一天」？ 我是住在公司提供的宿舍，所以： 早上8:40起床， 9点到公司食堂吃早饭， 9:30左右开始正式上班， 到11:30会稍微休息一会，然后浏览一些技术博客、运动相关的东西。 12点在公司的食堂吃午饭， 12:30到一13:30回宿舍休息，14点左右再回到工位上开始上班。刚开始到位置上，如果任务赶的话直接开始敲代码，如果任务不赶，会拿30分钟到1一个小时看一下公司的前端框架。 期间会在公司的休闲室休息一会，然后到18.00下班。 18:00 去健身房锻炼一个小时 19:30 训练结束回到宿舍，洗澡，准备晚饭。 20:00 吃完饭，这时候追两集动漫，看看视频，刷刷微博 到22:00 因为自我感觉基础非常薄弱，这个时候通常会学一点东西。 在上边描述的日常中，你最想吐槽的是什么？ 毕业之后一直在负责维护一个公司比较旧版本的项目，所以经常出现一些非常奇怪的需求。还有一些非常老旧的代码，找不到之前的author，也不知道如何调试。 在上边描述的日常中，你最满意的是什么？ 很自由，我可以在正常的上班时间之内自己支配。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 在熟悉公司新开发的一套框架上。因为文档不齐全，而且前端相对薄弱，所以一直不知道如何去下手。后面为了能够快速熟悉起来，我就找带我的小哥要了一个很简单的任务，直接进行下手，然后直接在开发中对遇到的问题进行跟踪调试，开发完这个模块花了一个礼拜，虽然进度很慢..但是现在对这个框架已经有点熟悉了。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 刚毕业因为对薪酬不满意，在纠结了很久之后向经理提出了提薪的申请（经理说毕业生对薪资不满意可以申请），申请完经理也不知道为什么就没有回复我。在这之后我很经常在想，是要留在这家公司（传统IT，活少钱少）先利用时间学习，还是直接裸辞去北上广深杭找一家规模小点的互联网公司先学习一段时间。解决：和家人朋友商量之后决定，现在先在现在这家公司积累一些经验，然后明年再去大城市发展。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 其实现在还是一个新人。公司曾在我们实习的时候安排了一个月的培训，主要是对公司在使用中的框架（Spring MyBatis）等进行培训。我觉得最有用的还是给我们上课的大牛给我们的一些学习方法，以及工作方法。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 要做：我是一个非985/211大学的学生，等我有职业规划的想法的时候已经是大三下学期了，所以我感觉自己起步非常非常慢，技术也很差。所以我想说的是，如果想走技术这条路，那一定不要呆在懒惰区，而且对基础的东西要更重视，同时也要关注新的技术。 不要做：对自己的规划模棱俩可.不知道自己为什么要做技术相关的工作。 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦 ①Java的Jrebel 热部署插件，可以节省很多时间②Xrebel 开发的时候可以直接看到SQL语句，花费的时间，以及一些错误信息。 访谈二·后端工程师的日常（Java/北京/D轮知名创业公司） 受访人 @ScienJus ，今年 23 岁，北京土著，后端产品研发工程师。 平时每天的上班时间和下班时间分别是？ 前公司一般是 11 点上班，现在是 10 点，下班时间我一般工作外也会待在公司做些别的，大概平均也得 9、10 点吧。 最近一周有加班么？加班的天数是？一般加到多晚？ 属于比较忙的组，之前一直封闭开发，差不多 11、10、6 吧（也就持续一两周）。 能否按小时描述一下你的「典型的一天」？ 一般来说是： 9:00 起床 10:00 打车到公司 上午主要是整理性质，会开站会，整理下今天要做的事（不光工作，翻翻邮件、订阅的博客、Github 之类的） 12:00 在食堂吃饭，然后出去散散步，没有午睡的习惯 下午基本都在工作 7:00 在食堂吃晚饭 之后如果工作还比较忙就接着弄工作，否则会按照优先级选一些个人的事去做（Side Project、知识积累、阅读） 9:00~10:00 下班回家。到家基本上就只是放松了，看看日剧、追番 偶尔有很感兴趣的事驱动的时候（比如 Side Project 灵感很多的时候），会熬夜做，大概到 3:00 为底线 在上边描述的日常中，你最想吐槽的是什么？ 在最近一条推特中吐槽过： 目前在新公司还有两个比较严重的问题： 对任务的估时准确度不高，很多时候要么过忙，要么被严重 Block。 对任务的优先级分配有问题，我希望能静下心做一些重要且不紧急的事情，但是实际上大部分时间都在帮别人解决一些小问题。 之前订阅过一年付费的 Todoist，觉得自己对任务管理已经挺有把握了，但是来了新公司还是不太适应，准备买 Things3 重新靠 GTD 帮助我改善现状。 在上边描述的日常中，你最满意的是什么？ 上家公司是技术很好的小团队（ 好到什么程度呢？后端 + 平台 15 人左右，能维护一套微服务，并且自研容器编排 ），但是很遗憾的是业务本身没有太大量级，对后端来说历练还太小。 来新公司主要是为了技术挑战，业务上的压力肯定是有的，就看自己能不能抓住机会了。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 技术挑战可能不会太多，我认为很多业务场景都是有取巧的解决方案的（取巧可能形容有误，非贬义，类似于分库分表即使不需要太多技术也可以 Hard Coding 实现，并且能有效解决问题）。而中小型公司的平台方案一般又都是追随开源的，所以我也选择尽量追随开源社区。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 我比较不擅长编程以外的任何事，最不擅长的就是与人相处。讨厌漫长的会议，讨厌一些混日子的同事。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 呆的都是中小型公司，没参与过什么培训，个人感觉比较幸运的主要还是多逛开源社区吧，很多时候公司交给我去做的事都是因为我之前有过了解（哪怕只是简单了解，也比大部分人强很多），这样慢慢的就能成为良性循环。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 不要盲目崇拜自己公司的技术，很多时候技术会因为架构师的喜好、成本、甚至一些和技术无关的因素而决定。即使去用了，也要明白这些技术有哪些优点、哪些缺点、如何改进。这样你至少迈出了第一步：不会因为最开始运气不好去了一家不好的公司或是部门而陷入技术上的恶性循环。 其次就是无论前端也好、后端也好，多去了解了解新技术，即使作为一个后端我也会偶尔和 Android 同事聊聊 Kotlin，和前端同事聊聊 React、Vue，你会发现只需花费非常低的成本就能学到一门可以弥补你短板的新技术，让你之前很多看似做不到的想法都可以轻松实现。 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦。 如果买了 Mac，一定要好好用，先装上 iTerm、Zsh、Homebrew，在适当买一些付费软件，比如 GTD 工具、笔记工具等。我有一个习惯就是喜欢通过看一个人的开发环境来评估他的技术水平，因为如果一个经常敲代码、对工作效率有追求的人，一定会尝试用软件改善自己的开发环境。 访谈三·前端工程师的日常（前端/北京/人工智能创业公司） 受访人 梁杰，24岁，在北京一家做人工智能平台的创业公司工作。 平时每天的上班时间和下班时间分别是？ 9点上班，18点下班 最近一周有加班么？加班的天数是？一般加到多晚？ 因为是新公司，业务压力还没有那么大，所以目前没有加班。 能否按小时描述一下你的「典型的一天」？ 7点起床， 7点半出门（再晚五号线就上不去了）， 9点到公司开始工作， 11点半吃午饭， 14点继续工作到18点下班， 19点半左右到家。 偶尔下午会开会，不过时间不会太长，一般在半个小时以内 在上边描述的日常中，你最想吐槽的是什么？ 毫无疑问是交通。北京的五号线人实在太多了，几乎从7点到10点都是高峰期，挤得要死，到公司之后心情很差。如果遇上雾霾天，会更难受 在上边描述的日常中，你最满意的是什么？ 公司氛围不错，创业公司没有那么多乱七八糟的内耗，大家都能专心在工作上，老板也很亲切。另外技术上没太多限制，可以用自己喜欢的东西，只要完成目标。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 最大的技术挑战就是重复性的工作太多，只是不断使用已经熟练的技术，没有压力也没有太多动力尝试新东西。我能想到的解决方法就是多看书，先在理论上学会新东西，然后再找机会用在新项目中。当然，很可能没有实际使用的机会，但是学了总比不学强。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 最大的非技术挑战是沟通。虽然创业公司人数不多，但是有同事是远程工作，所以很多问题需要在线上沟通，感觉效率偏低，没有那么顺畅。解决方法其实也没啥，就是适应，尽量在一次沟通中把问题描述清楚，把自己需要对方处理的地方明确出来，减少整体的沟通次数。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 公司没有安排培训。我过渡的方式就是多写代码，这可能是最简单也是最实用的方式。刚开始写前端的时候什么都不懂，我就自己跟着教程写网站，不断添加功能。在这个阶段你会遇到很多很多问题，这很正常，卡住了就去搜解决方案，解决问题的过程就是成长的过程。做完一个项目之后，可以再做一两个去巩固技术，心里有底之后再做东西就不害怕了。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 多写代码，大部分工作内容其实没太多技术含量，唯手熟尔；多读书，读好书，读英文原版书；多参加活动，开拓眼界，也多认识一些朋友，找工作时候内推永远比投简历靠谱。少抱怨，单纯的抱怨并不能解决问题，同事和老板不是你爸妈，没义务开导你，如果你确实遇到了问题，更好的方式是尝试找出解决方案并反馈给老板。少做低效的事，能看书就别看文章，能看文章就别看视频，能自己搜问题就别问人，能打字就别发语音，能不废话就不废话（你看这条我自己都没做到） 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦。 技术角度，推荐几本书： 《You Don’t Know JS》系列书，GitHub上有作者开放的免费版可以看； 《Speaking JavaScript》从实现原理角度讲解JS，进阶必备； 《精通CSS（第二版）》名字很俗但是一本入门好书； 《CSS Secrets》CSS进阶书籍，让你看看CSS到底有多少种用法。 另外，我个人不推荐犀牛书和高级程序设计，或许在当年这两本算是JS圣经，但现在已经有了很多更好的书，比如我推荐的那两本，所以如果你相信我，就不要再看犀牛和高程了。 非技术角度，能推荐的就太多了，只推荐三个吧： 第一个是吴军博士写的所有书，通俗易懂，看完之后会对整个计算机行业和计算机发展历史有一个宏观的了解； 第二个是《Algorithms to Live By: The Computer Science of Human Decisions》，这本书讲了很多算法在日常生活中的应用，能帮助你开拓眼界，非常有趣； 第三个是Easy之前写的《程序员跳槽全攻略》，不讨论观点对错，这本书的重点是提出了许多新想法，能帮你从不同角度分析跳槽这件事，读完会有很多启发。 访谈四·前端工程师的日常（前端/北京/D轮知名移动互联网公司） 受访人 某丸，21岁，在北京某D轮知名移动互联网公司担任前端。 平时每天的上班时间和下班时间分别是？ 早9点，晚6:30。 最近一周有加班么？加班的天数是？一般加到多晚？ 最近有加班因为双11，基本天天加班，加班到7:30，平时较少加班。 能否按小时描述一下你的「典型的一天」？ 每天 8:30 起床， 接近 9 点出门， 到公司 9 点多一点， 中午 11:30 骑摩拜去公司另一个食堂吃饭， 回来 12:30 开始午休， 1:30 缓一会儿看看邮件消息， 2点开始干活， 6:30去楼下食堂吃饭然后回家 在上边描述的日常中，你最想吐槽的是什么？ 最想吐槽日常低效率的沟通，每天花费在看邮件和消息的时间比较多，很多内容和自己没有太大的关系，比较影响工作效率，还有就是需求变更比较频繁。 在上边描述的日常中，你最满意的是什么？ 日常比较满意的是宽松的工作氛围，和谐的上下级关系，以及团队有技术上的大牛，当然还有很多妹纸~ 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 其实目前来说还没有遇到真正意义上的技术挑战，因为轮子已经有前人造好了，挑战可能更多的是需要自己去了解这些实现细节。如果确实遇到困难，我会先去看看之前项目里面的代码别人是怎么实现的，然后自己也会了。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 非技术挑战可能是需要协调好在开发过程中与PM，设计，运营以及其他工程师之间的teamwork，避免因为交流不够彻底而导致做一些无意义或者重复的事情。 解决这个问题其实是比较困难的，我们可能有时问同一项目里面不同两个人对相同的问题给出不同的答案，这个时候我一般会明确的这个问题真正的需求是什么，同时会和同一团队的成员都确认一下。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 从新人到现在的转变就是不明确的或者不会的地方，就去看前人是怎么实现，再不会就问leader(一般很少发生这种情况)。 公司有安排培训，培训的价值其实在输出的内容上并没有对我有多大的提升，反倒是让我对认识问题的态度有很大的转变，我们喜欢用事实标准去讲一个问题，而不是通过别人的经验或者某些技术博客的介绍就认为问题就是这样。 技术人看待问题就应该是非常严谨，就像写代码一样，我们要做到bug free，虽然这是不可能的。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 我想说，与其把大把的时间花在学习几个瞬息万变的新框架API使用中，不如多花点时间在基础知识学习。我认为这才是真正决定一个技术人能走多远的基石，虽然这句话可能你已经听烦了。 新的东西解决了很多问题，但是很多人甚至都不知道为什么会存在这些问题更别谈解决方案和实现的原理，还有就是不要盲目的相信技术网红的一些观点，他们不一定是正确或者恰当的。 前端最不缺网红，工作后我才认识到大部分真正牛逼的人都是比较低调的(但并不是高调的人就不牛)；在有一些基础后可以多看一些原理性质或者质量高的博客，多读一些业界认可度高的书籍，看看一些开源项目从简单的入手，自己去实践并验证你学习到的知识，同时多关注开源社区 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦。 推荐一本书《JavaScript高级程序设计》，相当于 Web API Wiki 的 MDN ，以及 Google 开发者文档中的 Web 部分，更细节可以看看 W3C 标准、ECMAScript 标准、WHATWG 标准。在准备读一本书的时候可以先去豆瓣上看看评价，如果只有6、7分你就要慎重了，因为他可能不仅仅是在浪费你的时间还可能误导你。 访谈五·前端工程师的日常（PHP·前端/成都公司） 受访人 peakcool，23岁，在成都一家企业信息化解决方案公司工作。入职是php，现在是前端工程师。 平时每天的上班时间和下班时间分别是？ 9:30-18:00 最近一周有加班么？加班的天数是？一般加到多晚？ 没有。 能否按小时描述一下你的「典型的一天」？ 7:30：起床 9:00：出门上班 9:30：开始工作 12:00：午饭 13:00：休息 14:00：开始工作 18:00：下班回家 18:30：到家 19:30：吃完饭看直播、看书、看剧、弄花、玩游戏 23:00：洗簌 24:00：休息 在上边描述的日常中，你最想吐槽的是什么？ 最近看书越来越少，看剧和玩游戏越来越多……（自制力啊……吐槽下自己） 在上边描述的日常中，你最满意的是什么？ 没有加过班！！！ 薪水中上吧，上司人很nice。 早上起来弄完花，看会儿书，每天都是好心情，哈哈哈。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 做项目前端的架构，工程化，不能算解决，在一步一步优化学习中。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 演示产品吧，无力吐槽自己的普通话了。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 今年毕业，不过大二暑假开始在外无薪实习，大四在现在公司做实习生直到6月份转正；新人的时期算是大二暑假那段时间吧，没薪资住学校，但是每天很充实，第一次发现原来代码是这样写的，也养成了一些不错的写代码习惯；有问题请教老大，慢慢地熟悉了代码，熟悉了业务。小公司，自力更生，没培训。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 多看看，多玩玩，拥抱变化（了解地越多，越能融会贯通） 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦。 snap 神器！Mac上设置快捷键软件，现在开发已经离不开它了... 《深入浅出node js》 《Javascript高级指南》 访谈六·客户端工程师的日常（iOS/上海/日企） 受访人 udspj，30岁，在上海一家日企工作。 平时每天的上班时间和下班时间分别是？ 9:00-18:00 和 10:30-19:30 之间弹性，去掉中午1小时，满8小时即可。 最近一周有加班么？加班的天数是？一般加到多晚？ 最近一周都没有加班，平时加班也不多，唯一一次连续一周包括周末每天加班是因为同事把项目搞砸了，在紧急帮他修一堆bug。 能否按小时描述一下你的「典型的一天」？ 早上8点闹铃， 9点前出门， 9点半到公司， 上午时间基本都做些零碎的事情比如修bug、开小会、和同事讨论项目问题等， 12点－13点吃午饭， 下午开始干正事专心写代码， 晚上6点半准时下班。 在上边描述的日常中，你最想吐槽的是什么？ 似乎没啥特别的槽点，除了，日常工作大多只能做iOS开发，没有其他方面的技术工作可以给我做。 在上边描述的日常中，你最满意的是什么？ 在不加班的情况下薪水算还不错的了；公司氛围轻松没有政治斗争；可以有机会练习日语口语。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 由于是日企，日本人在手工测试方面很严格，经常需要解决一些很细节的问题。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 「不会营销自己」这个算不算。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ （在第一家公司实习时）没有培训，新人阶段是跟着开发部做页游模块，开局一人一任务，剩下全靠自学。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 移动端开发差不多都饱和了，如果不是特别喜欢这方面的话还是选择其他技术入行吧。 访谈七·创业公司技术负责人的日常（PHP/深圳/创业中） 受访人 安正超，今年 27 ，5月份离开微博到深圳已经半年，目前与几个朋友创业中，负责技术部分。 平时每天的上班时间和下班时间分别是？ 创建阶段也没有固定吧，其实也与大家都差不多。 最近一周有加班么？加班的天数是？一般加到多晚？ 创业阶段就没有加班一说了，因为也没有固定的下班时间，有事情就多忙一会儿，晚点回家，没事就早点回去。 能否按小时描述一下你的「典型的一天」？ 一般是 8 点左右起床， 然后 9 点从坪洲站出发， 9 点 50 左右到水湾站，出站就是公司所在地：深圳自贸中心。 整体感觉还是很方便的。 中午楼下吃饭， 然后工作到 7-8 点左右回家。 在上边描述的日常中，你最想吐槽的是什么？ 其实相对于北京，深圳给我的印象没有太多槽点，大家都很有秩序的排队是印象最深刻的，地铁也不挤（也许是我9点才出发的原因吧），因为我住坪洲，办公室在深圳自贸中心稍微离我稍微远一点，40-50 分钟左右的地铁也许是最差的一点了吧，不过都还能接受了。 在上边描述的日常中，你最满意的是什么？ 最满意的就是团队了，几个合伙人的执行力是我见过最棒的，然后很满意的就是公司环境很好，大家有空可以来参观一下。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 由于我们是创业项目，线上线下联动，并非纯互联网项目，我们没有太多的难点需要解决，所以大部分是在接入一些服务时感觉比较麻烦一些吧，目前来讲没有遇到什么技术难题，因为不管从项目复杂度上还是用户量级上都还没有到有挑战的程度。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 作为技术负责人，除了搞定技术问题外，更多的时间都是与大家在讨论产品，用户体验，以及一些未来规划可能需要做的准备工作。另外就是需要扩大技术广度来避免团队扩大时的管理难题。目前来讲就是在时间管理上还需要一些调整，不是太能控制好个人时间。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 其实很多的实践经验基本都来自公司项目或者自己业余项目，工作之外的时间主要就是做一些基础知识的积累。还是得感谢这几年经历的几家公司，对我的成长提升都很大，在微博的两年，领导的大力支持给了我很多帮助。然后折腾开源项目的时间也是我个人成长过程中收益最大的投入。公司培训的话，有过，不过比较少，更多的是团队内的知识分享，这方面手机微博做得还是很棒的。其实分享不在于能让你在这么短时间内学会什么，我觉得它最大的益处就是增加知识面：你会的东西，在分享过程中可能会看到新的玩法，或者更有效的玩法，你不会的东西，增加知识广度，新东西能增加个人的学习气氛（折腾新东西的时候持续的兴奋感特别棒）。另外主动分享也能锻炼表达能力。 你对即将入职这个岗位的新人，有什么建议？（做什么、不要做什么） 新人最大的难点可能在选择上，这个选择包括很多方面吧，比如用什么语言（这个争吵太多了）、用什么编辑器到用什么框架、写不写注释等等，我个人的建议是：把握一个方向，找比较能入手的（像 PHP 就很容易入手），大家都在用的（或者说用得人多的）深入学习，精通它，在项目中去实践，然后扩大知识面，了解一下其它周边的东西，比如你写后端，你起码也得懂 CSS，js 之类的基础使用比较好。少看社区八卦，他们爱吵不吵，不要受影响，相信自己的选择。因为到后面你会发现，真正的牛人，不是在于哪个语言他用得 6 不 6，而是在项目上的架构能力，解决问题的能力才是最厉害的。 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦。 太多了，不过不常用的我就不提了，自己常用的东西有： 工具方面（全部已购买正版授权）： 写代码：Sublime Text 3 + PHPStorm(开源授权)做设计：Sketch数据库：Sequel pro记笔记：BearTODO：Things 3办公：企业微信项目管理：Teambition其它工具：1password、Charles、Item2 等 书籍方面其实我不太有发言权，因为比较懒，不过还是有两本认为很棒的推荐给大家：《深入PHP：面向对象、模式与实践（第3版）》、《C和指针》系列。 访谈八·CTO 的日常（CTO/北京/云计算创业公司） 受访人 董先生，39岁，北京某云计算公司 CTO ，原知名上市公司研发总监。 平时每天的上班时间和下班时间分别是？ 早10:30到晚8:30。 最近一周有加班么？加班的天数是？一般加到多晚？ 有加班，2天，一般加班到9点30。 能否按小时描述一下你的「典型的一天」？ 8点起床， 9点出门， 10点半到公司，处理邮件，处理和工作相关的微信，和同事讨论工作进展情况， 12点吃饭， 12点半看业内资讯、技术文章， 1点半休息半小时， 2点会议或者面试， 3点会议或者面试， 4点和同事或者客户沟通工作， 5点看工作相关的运营数据、邮件、文档、了解各项工作的进展， 6点吃饭，有时候约了饭局出发，不出去的话， 6点半和同事沟通工作， 8点半下班。 在上边描述的日常中，你最想吐槽的是什么？ 上班太远，路上总堵车。 在上边描述的日常中，你最满意的是什么？ 发展空间大。 在现在这个职位上，你遇到的最大的技术挑战是什么？怎么解决的？ 产品和服务的质量，体现在服务的响应速度快、稳定性好故障率底，主要通过不断改进系统的缺陷，完善技术开发和变更的流程机制。 在现在这个职位上，你遇到的最大的非技术挑战是什么？怎么解决的？ 非技术挑战就是拓展业务，跟更多的潜在客户沟通，介绍公司的产品，争取测试的机会。 你是怎么度过从新人到熟手的阶段的？公司有安排培训么？如果有，你觉得其中对你最有用的内容是什么？ 自己和公司的人多沟通，了解公司的人、流程、部门。 你在这些年的工作中，有没有遇到特别好的工具、资料、书籍之类，想要推荐给大家？一两样也行哦。 事物管理工具用 JIRA ，文档管理用 Confluence ，代码管理用 BitBucket 。 下一篇试读：如何写出一份专业的程序员简历 "},"程序员职业小白书/职业规划3.1：通过职业画布理解应届生和新手的市场竞争力.html":{"url":"程序员职业小白书/职业规划3.1：通过职业画布理解应届生和新手的市场竞争力.html","title":"职业规划3.1：通过职业画布理解应届生和新手的市场竞争力","keywords":"","body":"应届生和新手如何提升竞争力 我们接下来讲一下应届生和新手如何提升职业竞争力。因为应届生和新手，没有经验或者经验比较少，所以在求职的时候难度相对来说比较大。一旦你熟悉了这个方法，在后边就会走得比较顺了。 职业画布 在这里会用到我们前边提到的第三个工具——「职业画布」。「职业画布」其实是从「商业模式画布」演变过来的，虽然作用的行业不同，但它们其实都是关于价值的规划工具，只不过一个是商业价值，一个是职业价值。 设计价值主张 在画布被分成了九个格子。最中间的格子，就是我们的价值主张。这个格子不是独立的，它其实是和最右边的格子联动的。其实就是说，「我们能给什么样的公司，贡献什么样的价值」。同样能力的人，对于不同的公司的价值不同，这个之前我们已经强调过了。 构建价值 左边的格子，是关于如何构建价值的，我们把价值主张定义好了，那我们要按照这个定义来构建价值。 首先是清晰的自我分析，我是谁、我具备哪些资源和技能、相对于其他求职者，我的竞争优势是什么；然后是在我们所做的价值主张中，哪些能力是我薄弱的或者暂时还不具备的，通过什么样的手段可以获得或增强，具体的措施和时间表是什么；最左边，是外部资源和优势，属于加分项，有最好，没有也无所谓。 传递价值主张 右边的格子，是关于如何传递和证明价值主张的。我们规划好了价值主张，又及时的补齐了对应的能力，但酒好也怕巷子深，这样是不够的。首先要考虑「如何让雇主知道你」，也就是求职渠道问题，这个前边我们有过讨论；然后是「如何让雇主相信你」，是说我们还要尽可能的提供可信的证据来证明我们的价值主张是正确的，一般是在简历中和面试提供「经历证明」和「能力证明」来达到目的的。关于简历在下一章会详细讲，这里先略过。 应届生求职实践 这里我们以一个虚拟的大学生——薛小生同学为例子，来进行一个完整的求职实践。 薛小生的基本情况 从上边的图可以看到，薛小生同学是一个非重点大学（学校虚构的）的计算机系学生，现在大三。 为什么应届生的求职实践我们找了一个大三的同学呢？因为「构建价值」需要时间。尤其是应届生，绝大部分都不具备和其他同学不一样的价值，所以越早进行职业规划、越容易和同学们拉开差距，在校招中，你只需要「跑赢同学」。 薛小生同学有一点不算突出的爱好，就是喜欢拍照，所以会用 PS 修图，在科技社缺人的情况下，他帮着做过网页，懂一点 HTML 。 大体来讲，这就是一个稍微懂点技术的计算机系学生的样本。 薛小生的求职意向 去什么样的公司，似乎是一个傻问题。当然是去能的最好最有名薪资最多还不加班的公司了对吧。但越好的公司，对求职者的要求就越高，竞争就越激烈，需要为其准备的时间就越长、难度就越大。 而从薛小生同学的个人情况看，并不属于 90 分以上人群；从剩余时间来看，他大概还有三个月到六个月的时间来构建自己的竞争优势（也就是职业价值）。 如何合理的利用这段时间，成为了求职的关键。 适用于薛小生的求职策略 如前所述，薛小生同学在最优秀公司的竞争中，很可能会失败；所以应该重点保证他在次一级公司中的竞争力。这里我们借鉴高考志愿的方式，将他想去的公司划分为三等，第一志愿、第二志愿、第三志愿；每一级志愿可以有好几家公司。 在公司的选择上，我们要尽量保证各个级别的公司的要求逐级追加的，只要每个公司都选择同样的岗位，这点基本上能保证。 然后就是岗位的选择。考虑到薛小生同学做过网页，而且有具备较好的美感，离他最近就是前端岗了。 通过之前在「需求的量化分析」一节中描述的方法，我们可以对招聘方的需求关键字进行分析。同时，我们还可以将公司按上述第一到第三志愿分级后分别分析需求关键字，然后结合分级来考虑学习或者强化的顺序和精力。 通过这样的分析，我们大体得出了一个技能补全的顺序。 首先，补全已经接触过的 HTML 和 CSS ，因为已经实际用过，所以学习成本应该不高。这里需要特别注意的是，将「响应式设计」和「移动浏览器的优化」也纳入到学习中来，等这一部分内容学完时，薛小生同学就可以改网站的移动版和嵌入微博微信的 H5 页面。这样，我们就构成了一个基本但相对完整的价值主张。 接着，是学习 JavaScript 。从之前的量化分析可以看到，绝大部分公司都要求 HTML 、CSS 和 JavaScript 三大块技能。这部分内容较多，学习时间会比较长，要学会分成一个个小目标，不断获取成就感。每学到一部分内容，就可以加到原来做的 HTML 和 CSS 的页面上去，使其动起来。 在 JavaScript 基本学习完成后，我们应该算是完成了一个大的独立价值 —— 能独立开发一些基础的前端功能。应该回过头来强化这三部分技巧，同时选择一个常用框架，去实际的写一些例子。从之前的分析数据看，jQuery + Vue 是一个不错的组合。对框架的学习应该先理解基本原理，然后不断的在实际业务中发现问题和解决问题。如果以你想入职的公司的产品为目标去写 DEMO ，在将来面试中会很有优势。 框架层使用熟练后，就基本达到进入一般创业公司的水平了。如果这时候还有时间，为了在一流公司的求职者中脱颖而出，可以学习下如何使用 NodeJS 写后端，这部分作为加分项，通晓流程，能做基本的开发即可。 另一方面，如果薛小生同学一直跨不过框架层这一关（可能性不小，因为即使 Vue 这种号称易学的框架，也已经是 Vue + VueX + Vue-Router 这样的全家桶了），或者自觉没有竞争力，那么可以考虑学习下 PHP 作为加分项，毕竟五分之一的公司都提到了。 薛小生的职业画布 然后我们来填写薛小生的职业画布。其中黄色的是第一志愿，表示最好的情况；红色的是第三志愿（假设只分了三级），表示最差的情况。紫色部分表示各级志愿公用。 我们先讲紫色部分。 认清自己 首先是「我是谁」。薛小生同学要认识到自己一个二本大学的计算机系学生，这意味着他在学历上不占优势；然后他熟悉网页制作、有较好的美感，有基本的 C 语言编程能力，所以学习其他的编程语言问题应该不大。 怎么让雇主知道你 最靠谱的是在该公司的学长帮你内推，然后是官网投递和校园招聘会。另外就是如果该公司有其他岗位的实习，你能胜任，但是可能没啥发展，比如最后不能转正之类的，你可以先去实习，然后将来再想办法转岗。因为在实习的时候，你的能力会逐渐表现出来，如果被认可的话，内部转岗的门槛是很低的。 怎么让雇主相信你 对于应届生来讲，经历证明主要就是实习经历了；不过对程序员来讲，还有你参与或者主导的一些开源项目也可以算进来。 然后是你的个人品牌，比如你写的技术分析文章之类、你在技术社区做的分享和演讲之类的。 最后就是大公司技术部门一般有自己的微博和博客，你可以经常去互动，给他们一些反馈，讨论一些技术细节，这也会增强对你的信任感。不过切记不懂装懂。 第一志愿（黄色部分） 价值主张 这是一个对知名上市互联网公司提出的价值主张。 有专业的计算机知识，然后能熟练地使用 Vue 框架，同时对于刚开始流行的 PWA 有深入的研究。 这些描述背后在说，「我基础扎实、能胜任日常开发；愿意学习，对新技术有专研精神」。这些都是大公司比较看重的。 我缺少的能力 薛小生同学现在的基础并没有所说的那么扎实，所以需要安排时间，将计算机专业的那些基础课程从头到尾再过一遍，然后针对将来的面试去做相应的一些准备，比如算法和网络基础这种互联网公司经常面的东西。 「旺盛的兴趣」可以试着培养下，如果培养不出来，那就当你是在对钱感兴趣吧。 「对细节的深究」这个相对简单，主要是要学会分析问题和解决问题的方法。具体来说就是「读源码」、「跟踪分析」、「修复BUG」和「调整解决方案」的能力。 这里的这些能力要求，不是绝对的，不用和行业里边的高手去比，只要和跟你一起毕业的同学们比就好了，所以难度其实未必像看起来那么大，多花些时间，就会有收获。 我要加入这家公司付出什么 三个月到六个月的认真学习，三个以上的实际项目的实践，一个以上的关键细节的精通。 这里还包含了「即使你都做到了，还是可能进不去」的风险。 我加入了这家公司能得到什么 良好的培训、有竞争力的薪资、强大的职业背景、巨大的发展空间。 毕竟是国内顶级的互联网公司嘛。 第三志愿（红色部分） 然后我们来看最坏的情况。 价值主张 熟练使用 jQuery，会做移动网页适配和 H5 ，了解 PHP 和 PS。 这个价值主张背后的意思是，我过来就能干活，不但能做前端，后端还能帮点忙，学习一段时间就能独当一面。 我缺少的能力 从薛小生同学的情况来看，他虽然有一些基础，但还没能形成独立的价值。需要再强化一下做网页的能力，同时将 PHP 等后端能力作为备用和加分项。 我要加入这家公司付出什么 相对来说，要比之前容易多了。网页薛小生同学本来就做过，只需强化下。PHP 只要简单了解，能架设基本就能及格。 我加入了这家公司能得到什么 首先是，有工作肯定比没工作好对吧，至少你有一个基本的薪资，不用整天处于没钱吃饭的恐惧中。 然后你可以留在互联网这个行业里，虽然当前的状况不是那么好，但埋好了火种，等到能力提升了，就有机会去更好的公司。 最后吧，它给了你一个用于学习的真实环境，那些教程都是纸上得来的，和跑着业务的系统还是不一样，各种在真实世界中才能遇到的场景，会帮你一点点累积经验。万一运气好的话，还有人手把手教。 总结 OK，我们大致梳理了职业画布，每一部分都还可以做进一步的深化，比如「我缺少的能力」的「补全策略」的深化我们就在「薛小生的画布」前一节详细讨论过了。 「职业画布」本身没有好坏，它只给你提供一个围绕职业价值的多维度思考方式，多花些时间去想它，会帮你更全面的解构问题。 「职业画布」也是动态的，最初填写的时候很粗糙，当你开始实践以后，就会获知更多的细节，也会发现之前的错误，这时候要回来充实它修正它，把它一直维持在最新，让你的职业竞争力一目了然。 "},"程序员职业小白书/职业规划3.2：如何写出一份专业的技术简历.html":{"url":"程序员职业小白书/职业规划3.2：如何写出一份专业的技术简历.html","title":"职业规划3.2：如何写出一份专业的技术简历","keywords":"","body":"如何写出一份专业的技术简历 在这一部分，我们聊一聊怎么写简历，尤其是技术简历。我们将从简历的本质、简历的内容和简历模版等方面来和大家分享。 简历的本质 首先，在写之前，要明白简历的本质，也就是说，它的作用是什么、写简历是为了什么？ 往深了说，简历其实就是一个销售文案，是你向招聘方销售你的价值主张的载体。你要在里边清楚的告诉招聘方，我是谁、我想来这家公司担任什么职位、我将在这个职位上完成哪些工作、为公司带来怎样的价值、我期望的薪水是多少，赶紧雇用我吧！ 但是这些话也可以留到面试时去讲，所以往浅点说呢，简历最重要的作用就是帮你约到面试。 简历的形态 从形式上来讲，简历并不一定非得是文本的，它可以就是一段视频、一个开源项目、一张照片、甚至是一行字。但对于绝大部分普通人来讲，简历就是一份最好不超过一页的文本。因为就算你不走寻常路，拿到了 offer ，最后办理各种入职手续的时候，HR 还是需要一份文本简历来归档。 所以呢，无论你要准备视频简历还是其他，那都是锦上添花的事，文本简历是逃不掉的，不要想偷懒，好好准备吧。 从格式上来讲，我们推荐使用 Markdown 写，用 PDF 发。使用 Markdown 书写可以更好的控制格式，而通过 PDF 发送可以保证对方的阅读效果，不会因为在不同的机器、不同的操作系统导致样式丢失。 如果你没有称手的简历写作工具，可以试试冷熊简历，它是一个运行在浏览器里边的 Markdown 编辑器，可以一键生成 PDF ，提供简单大方的单页式排版。 简历和面试关系 我一般把简历看成面试的一个提纲，简历上浓缩了你的价值主张，而面试，则是展开讨论这个价值主张的时候。 很多同学觉得面试是招聘方选候选人，是单向的；但实际上，面试也是你选招聘方的时候，在认真回答了招聘方的问题之后，你完全可以围绕着「我如何为公司提供价值」这个核心，提出自己有疑惑的问题。如果招聘方不能很好做出回答，那么很可能他们对于这个岗位、甚至这个部门（尤其是新部门）没有想清楚，失败的可能性会陡增，需要慎重考虑。 简历的内容 很多同学都很喜欢写流水账，我在什么地方出生、上的什么小学中学大学、读过什么专业、得过什么奖、参加过哪些项目、甚至自己的兴趣爱好都写上。 其实简历并不是履历，你要明白你其实是处在一个竞争环境，你是在 推销 自己。你不但要让对方明白你做过什么，还要低调的把你的价值主张潜移默化的植入到招聘方的大脑里边，让他/她不由自主的觉得，「这个人对我们公司非常有价值，我一定不能放过」。 那么如何才能做到呢？三个要点，第一是按 FAB 法则来陈述、第二是给论据但不给论点、第三是提供充足的证明。 FAB 法则 FAB 法则的思路其实非常简单，就是你不但要说「是什么」、还要回答「好在哪里」以及「能给对方带来什么价值」。 下边是一个简单的 FAB 的例子： 2006年，参与了手机XX网发布系统WAPCMS的开发（F，是什么）。作为核心程序员，不但完成了网站界面、调度队列的开发工作，更提出了高效的组件级缓存系统，通过碎片化缓冲有效的提升了系统的渲染效率（F，细化具体工作，要写出你在这个项目中具体负责的部分，以及你贡献出来的价值）。在该系统上线后，Web前端性能从10QPS提升到200QPS，服务器由10台减少到3台（A，通过量化的数字进行对比）。2008年升任WAPCMS项目负责人，带领一个3人小组支持着每天超过2亿的PV（B，你能带给前雇主的价值，也就是你能带给新雇主的价值）。 给论据不给论点 议论文的结构通常是最有说服力的，但是简历是一篇你自己介绍自己的文章，如果你的论点是你很优秀，论据是你这里优秀那里优秀，即使你真的那么优秀，读起来也容易招人反感。因为我们的文化是一个内敛的文化，所以要学会留一些话不要说。 这里的一个小技巧就是，把论点隐藏起来，只大量去说论据。让简历的读者自己去得出这个论点，这样他/她就会相信这是自己的想法，从而更容易接受它。 提供充足的证明 企业招人其实也是有风险的，光是时间成本就是非常大，所以招聘方往往希望从你的简历上寻找一些证明，来降低风险，说服自己招聘这个候选人。 经历证明 最靠谱的证明是「经历证明」，「经历证明」的逻辑是，这个人既然在别的公司做过这样的事情，那么让他/她在我们工作也做这样的事情，应该也能胜任。「经历证明」屡试不爽，即使偶有失误，公司也不会怪罪到招聘方上。经常有同学问我大学毕业应该去大公司还是创业公司，从「经历证明」的角度来看，肯定是去大公司，因为之后你在大公司的这一段「经历证明」，可以帮你很多，甚至在创业时都会很有用。 能力证明 其次就是「能力证明」，「能力证明」的问题在于对招聘方的要求较高，他们得有验证的能力和手段。技术面试就是一种能力证明，开源项目则是另外一种能力证明。在简历中透露一些解决高难度问题的细节，同样是一种能力证明。 当「经历证明」不够强时，要通过「能力证明」来做补充。 学习能力也是一种能力 对于应届生和新人来说，「学习能力」也是一种「能力证明」，它表现出来的就是「成长」。当你的绝对数据不是那么好的时候，要强调增长数据。因为企业对新人的要求，往往并不是有现成的技能（有当然最好，但一般候选人都没有），而是「聪明」和「学得快」。 简历模板 最后我们提供了一系列的简历模板供大家参考，可以访问 GitHub 获取。 试读内容结束，如果您觉得不错，可点此购买全本 "}}